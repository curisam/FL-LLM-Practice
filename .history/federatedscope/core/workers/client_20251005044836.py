# FedBiscuit/federatedscope/core/workers/client.py
# -*- coding: utf-8 -*-

import copy
import logging
import sys
import pickle

from federatedscope.core.message import Message
from federatedscope.core.communication import StandaloneCommManager, \
    StandaloneDDPCommManager, gRPCCommManager
from federatedscope.core.monitors.early_stopper import EarlyStopper
from federatedscope.core.auxiliaries.trainer_builder import get_trainer
from federatedscope.core.secret_sharing import AdditiveSecretSharing
from federatedscope.core.auxiliaries.utils import merge_dict_of_results, \
    calculate_time_cost, add_prefix_to_path, get_ds_rank
from federatedscope.core.workers.base_client import BaseClient

import os
from uuid import uuid4


"""
ê° ëª¨ë“ˆ(client.py ë“±): ìê¸° ëª¨ë“ˆ ì „ìš© ë¡œê±° ê°ì²´ ìƒì„± â†’ main.py ì„¤ì •ì„ ìë™ìœ¼ë¡œ ë”°ë¼ê°.
logging.basicConfig(level=logging.INFO,
                    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s")
â†’ ë•ë¶„ì— ë¡œê·¸ë¥¼ ì°ì„ ë•Œ ì–´ëŠ ëª¨ë“ˆì—ì„œ ë‚˜ì™”ëŠ”ì§€ êµ¬ë¶„ ê°€ëŠ¥.

"""

logger = logging.getLogger(__name__)
# if get_ds_rank() == 0:
#     logger.setLevel(logging.INFO)

logger.setLevel(logging.DEBUG)

import os
import json

from collections import Counter
import itertools
import inspect
import time

def _summarize_content(msg):
    c = msg.content
    try:
        if msg.msg_type == 'model_para':
            if isinstance(c, tuple) and len(c) == 2:
                n, mp = c
                keys = list(mp.keys()) if hasattr(mp, 'keys') else []
                return f"(sample={n}, param_keys={len(keys)})"
        elif msg.msg_type == 'metrics':
            if isinstance(c, dict):
                ks = sorted(list(c.keys()))
                # í‚¤ ì „ë¶€ ì¶œë ¥(ê°œìˆ˜ ì ìŒ). ê¸¸ë©´ ì˜ë ¤ë„ ë¬´ë°©.
                return f"keys={ks}"
        return type(c).__name__
    except Exception as e:
        return f"<summ err: {e}>"

def _dump_queue_snapshot(comm_mgr, tag:str, drain:bool=False, max_tail:int=10, filter_state=None):
    q = comm_mgr.comm_queue  # deque
    items = list(q)
    vis = [m for m in items if (filter_state is None or m.state == filter_state)]
    print(f"[queue@{tag}] len={len(items)} (vis={len(vis)} filter_state={filter_state})")
    kinds = Counter((m.msg_type, m.state, tuple(m.receiver)) for m in vis)
    print("  summary:", dict(kinds))
    tail = list(itertools.islice(vis, max(0, len(vis)-max_tail), len(vis)))
    for i, m in enumerate(tail, 1):
        print(f"  tail[-{len(tail)-i+1}]: "
              f"type={m.msg_type} state={m.state} sender={m.sender} recv={m.receiver} "
              f"ts={getattr(m,'timestamp',None)} content={_summarize_content(m)}")

    if drain:
        print("  [drain] dumping ALL (arrival order):")
        for idx, m in enumerate(items):
            print(f"    {idx:03d}: type={m.msg_type} state={m.state} sender={m.sender} recv={m.receiver} "
                  f"content={_summarize_content(m)}")
        print("  [drain] (not removing; snapshot only)")


def _wrap_comm_send_debug(comm_mgr):
    if getattr(comm_mgr, "_debug_wrapped", False):
        return
    orig = comm_mgr.send
    def wrapped(msg):
        caller = inspect.stack()[1]
        where = f"{caller.function}@{caller.filename.split('/')[-1]}:{caller.lineno}"
        print(f"[SEND] t={time.time():.3f} from={where} "
              f"type={msg.msg_type} state={msg.state} sender={msg.sender} -> recv={msg.receiver} "
              f"content={_summarize_content(msg)} (before_len={len(comm_mgr.comm_queue)})")
        return orig(msg)
    comm_mgr.send = wrapped
    comm_mgr._debug_wrapped = True












class Client(BaseClient):
    """
    The Client class, which describes the behaviors of client in an FL \
    course. The behaviors are described by the handling functions (named as \
    ``callback_funcs_for_xxx``)

    Arguments:
        ID: The unique ID of the client, which is assigned by the server
        when joining the FL course
        server_id: (Default) 0
        state: The training round
        config: The configuration
        data: The data owned by the client
        model: The model maintained locally
        device: The device to run local training and evaluation

    Attributes:
        ID: ID of worker
        state: the training round index
        model: the model maintained locally
        cfg: the configuration of FL course, \
            see ``federatedscope.core.configs``
        mode: the run mode for FL, ``distributed`` or ``standalone``
        monitor: monite FL course and record metrics, \
            see ``federatedscope.core.monitors.monitor.Monitor``
        trainer: instantiated trainer, see ``federatedscope.core.trainers``
        best_results: best results ever seen
        history_results: all evaluation results
        early_stopper: determine when to early stop, \
            see ``federatedscope.core.monitors.early_stopper.EarlyStopper``
        ss_manager: secret sharing manager
        msg_buffer: dict buffer for storing message
        comm_manager: manager for communication, \
            see ``federatedscope.core.communication``

    ---------------------------------------------------------------
    ğŸ”§ ì´ ë²„ì „ì—ì„œì˜ ì£¼ìš” ì»¤ìŠ¤í„°ë§ˆì´ì§•(í•œê¸€ ì£¼ì„ ìœ ì§€/ì¶”ê°€)
    - ë©”ì¸ í”„ë¡œì„¸ìŠ¤ì—ì„œë§Œ íŒŒì¼ ê¸°ë¡ / ì„œë²„ ì „ì†¡ â†’ ì¤‘ë³µ ë°©ì§€
    - eval_results.raw: test_*ì™€ val_*ê°€ ëª¨ë‘ ìˆì„ ë•Œë§Œ 1íšŒ ê¸°ë¡
    - eval.best_res_update_round_wise_key ê°€ ì—†ì„ ê²½ìš° ì•ˆì „í•œ ëŒ€ì²´ í‚¤ ìë™ ì„ íƒ
    - evaluate()ëŠ” í•­ìƒ metricsë¥¼ ì •ì˜(ì´ˆê¸°í™”)í•˜ê³  ì˜ˆì™¸ ë³´í˜¸
    - train()/evaluate() ì‹œì‘ ì „ í•´ë‹¹ split ìºì‹œë¥¼ ë¦¬ì…‹(ë¼ìš´ë“œ ê°„ ëˆ„ì  ë°©ì§€)
    - ë¡œê¹…: ë¡œì»¬(per-rank), per-proc ë¦¬ìŠ¤íŠ¸(rank0), ì§‘ê³„ë³¸(rank0) 3ë‹¨ ì¶œë ¥
    ---------------------------------------------------------------
    """
    def __init__(self,
                 ID=-1,
                 server_id=None,
                 state=-1,
                 config=None,
                 data=None, # ClientData í´ë˜ìŠ¤
                 model=None,
                 device='cpu',
                 strategy=None,
                 is_unseen_client=False,
                 *args,
                 **kwargs):
        super(Client, self).__init__(ID, state, config, model, strategy)

        self.data = data  # ClientData í´ë˜ìŠ¤

        # Register message handlers
        self._register_default_handlers()

        # Un-configured worker
        if config is None:
            return

        # the unseen_client indicates that whether this client contributes to
        # FL process by training on its local data and uploading the local
        # model update, which is useful for check the participation
        # generalization gap in
        # [ICLR'22, What Do We Mean by Generalization in Federated Learning?]
        self.is_unseen_client = is_unseen_client

        # Parse the attack_id since we support both 'int' (for single attack)
        # and 'list' (for multiple attacks) for config.attack.attack_id
        parsed_attack_ids = list()
        if isinstance(config.attack.attacker_id, int):  # True, -1
            parsed_attack_ids.append(config.attack.attacker_id)
        elif isinstance(config.attack.attacker_id, list):
            parsed_attack_ids = config.attack.attacker_id
        else:
            raise TypeError(f"The expected types of config.attack.attacker_id "
                            f"include 'int' and 'list', but we got "
                            f"{type(config.attack.attacker_id)}")

        # Attack only support the stand alone model;
        # Check if is a attacker; a client is a attacker if the
        # config.attack.attack_method is provided
        self.is_attacker = ID in parsed_attack_ids and \
            config.attack.attack_method != '' and \
            config.federate.mode == 'standalone'   # False

        # Build Trainer
        # trainer might need configurations other than those of trainer node
        self.trainer = get_trainer(model=model,
                                   data=data,
                                   device=device,
                                   config=self._cfg,
                                   is_attacker=self.is_attacker, #False
                                   monitor=self._monitor)  # federatedscope.llm.trainer.reward_choice_trainer.RewardChoiceTrainer
        

        self.trainer.ctx.client_ID = int(self.ID)   # â† í´ë¼ì´ì–¸íŠ¸ IDë¥¼ ì»¨í…ìŠ¤íŠ¸ì— ì‹¬ê¸°
        self.trainer.ctx.role = "client"

        self.device = device

        # ğŸ”’ outdir ê°•ì œ: sub_exp/rank-* ì œê±°í•˜ê³  ìƒìœ„ exp í´ë” í•˜ë‚˜ë§Œ ì“°ê¸°


        self._force_single_outdir()



        # in local or global training mode, we do use the early stopper.
        # Otherwise, we set patience=0 to deactivate the local early-stopper
        patience = self._cfg.early_stop.patience if \
            self._cfg.federate.method in [
                "local", "global"
            ] else 0   # 0
        self.early_stopper = EarlyStopper(
            patience, self._cfg.early_stop.delta,
            self._cfg.early_stop.improve_indicator_mode,
            self._monitor.the_larger_the_better)  # self._cfg.early_stop.improve_indicator_mode='best'.  #self._monitor.the_larger_the_better: False ->lossì˜ ê²½ìš° í´ìˆ˜ë¡ ì•ˆì¢‹ì€ ê±°ë¼ì„œ.

        # Secret Sharing Manager and message buffer
        self.ss_manager = AdditiveSecretSharing(
            shared_party_num=int(self._cfg.federate.sample_client_num
                                 )) if self._cfg.federate.use_ss else None  # None

        self.msg_buffer = {'train': dict(), 'eval': dict()} #ë‚´ë¶€ ë¹„ë°€ ì…°ì–´ë§(ss) ì¡°ê° ìˆ˜ì§‘ì´ë‚˜, (ì´ ì˜ˆì‹œì—ì„œëŠ”) ê±°ì˜ ì“°ì´ì§€ ì•ŠëŠ” train/eval í‚¤ë§Œ ê°€ì§‘ë‹ˆë‹¤. ì˜ë¯¸ ì—†ìŒ.

        # Communication and communication ability
        if 'resource_info' in kwargs and kwargs['resource_info'] is not None:  # PASS
            self.comp_speed = float(
                kwargs['resource_info']['computation']) / 1000.  # (s/sample)
            self.comm_bandwidth = float(
                kwargs['resource_info']['communication'])  # (kbit/s)
        else:  # ì—¬ê¸° ê±¸ë¦¼
            self.comp_speed = None
            self.comm_bandwidth = None

        if self._cfg.backend == 'torch':  # ì—¬ê¸° ê±¸ë¦¼
            try:
                self.model_size = sys.getsizeof(pickle.dumps(
                    self.model)) / 1024.0 * 8.  # kbits
            except Exception as error:
                self.model_size = 1.0
                logger.warning(f'{error} in calculate model size.')
        else:
            # TODO: calculate model size for TF Model
            self.model_size = 1.0
            logger.warning(f'The calculation of model size in backend:'
                           f'{self._cfg.backend} is not provided.')

        # Initialize communication manager
        self.server_id = server_id
        

        # íë¥¼ ì´ìš©í•´ ì„œë²„Â·í´ë¼ì´ì–¸íŠ¸ ê°„ ë©”ì‹œì§€ ì†¡ìˆ˜ì‹ ì„ ë‹´ë‹¹í•  CommManager ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±
        comm_queue = kwargs.get('shared_comm_queue')  # deque([]). # Runnerê°€ ì£¼ì…í•´ ì£¼ëŠ” deque.


        # self.comm_manager:  send() / receive() APIë¥¼ ì œê³µí•˜ë©´ì„œ, ë‚´ë¶€ì ìœ¼ë¡œëŠ” comm_queue.append(msg)ì™€ comm_queue.popleft()ë¥¼ í˜¸ì¶œí•´ ë©”ì‹œì§€ë¥¼ ì£¼ê³ ë°›ê²Œ í•©ë‹ˆë‹¤.
        if self._cfg.federate.process_num <= 1:  # ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ì‹œë®¬ë ˆì´ì…˜ìš©
            self.comm_manager = StandaloneCommManager(
                comm_queue=comm_queue, monitor=self._monitor)
        else: # DDP ê¸°ë°˜ ë³‘ë ¬ ì‹œë®¬ë ˆì´ì…˜ìš©
            self.comm_manager = StandaloneDDPCommManager(
                comm_queue=comm_queue, monitor=self._monitor)
        self.local_address = None #gRPCë¡œ ë„˜ì–´ê°ˆ ë•Œ í´ë¼ì´ì–¸íŠ¸ ìì‹ ì˜ ë„¤íŠ¸ì›Œí¬ ì£¼ì†Œ(host: port)ë¥¼ ë‹´ëŠ” í•„ë“œ. standaloneì—ì„œëŠ” ì“°ì´ì§€ ì•ŠìŒ.

        self.logger = logger


        ###############################################################################################################################################################

        # === ì¤‘ë³µ ê¸°ë¡ ë°©ì§€ ë§ˆì»¤ë“¤ ===. í‰ê°€(eval) ë˜ëŠ” í•™ìŠµ(train) ê²°ê³¼ê°€ ë™ì¼ ë¼ìš´ë“œì— ì¤‘ë³µ ê¸°ë¡ë˜ëŠ” ê²ƒ ë°©ì§€. ë©€í‹°í”„ë¡œì„¸ìŠ¤/ì¬ì‹œë„/ì½œë°± ì¤‘ë³µ í˜¸ì¶œ ê°™ì€ ìƒí™©ì—ì„œ ê°™ì€ (í´ë¼ID, ë¼ìš´ë“œ) ê²°ê³¼ë¥¼ ë‘ ë²ˆ íŒŒì¼ì— ì“°ì§€ ì•Šë„ë¡ ê°€ë“œ.
        self._eval_written_marker = set()   # {(client_id, round)}
        self._train_written_marker = set()  # í•„ìš”ì‹œ trainì—ë„ ì‚¬ìš©

        # ì´ë¯¸ ìˆëŠ” ì´ˆê¸°í™”ë“¤ ë’¤ì— ì¶”ê°€.  ë©”ì‹œì§€ í•¸ë“¤ëŸ¬(idempotency) ìš©. ë™ì¼ ë¼ìš´ë“œì˜ ê°™ì€ íƒ€ì… ë©”ì‹œì§€ê°€ ë‘ ë²ˆ ë“¤ì–´ì™€ë„ í•œ ë²ˆë§Œ ì²˜ë¦¬í•˜ê²Œë”. 
        # callback_funcs_for_train/evaluate ê°™ì€ í•¸ë“¤ëŸ¬ ì§„ì… ì‹œ, (round in handled_set) ì²´í¬ â†’ ì´ë¯¸ ì²˜ë¦¬í–ˆìœ¼ë©´ ë°”ë¡œ ë¦¬í„´.
        self._handled_rounds = {
            'model_para': set(),   # í•™ìŠµ(í›ˆë ¨) ì§€ì‹œ ë©”ì‹œì§€ ì²˜ë¦¬í•œ ë¼ìš´ë“œ ê¸°ë¡
            'evaluate': set(),     # í‰ê°€ ì§€ì‹œ ë©”ì‹œì§€ ì²˜ë¦¬í•œ ë¼ìš´ë“œ ê¸°ë¡
        }

        ###############################################################################################################################################################


    def _force_single_outdir(self):
        """
        accelerateê°€ ìˆìœ¼ë©´ rank-ë³„ í•˜ìœ„ í´ë”(sub_exp/rank-*)ì— ë¡œê·¸ê°€ ìŒ“ì´ëŠ”ë°, ì´ë¥¼ ìƒìœ„ ê³µìš© í´ë”(exp/<expname>/<run>/)ë¡œ ëª¨ìë‹ˆë‹¤.
        ì¦‰, ì—¬ëŸ¬ rankê°€ ë™ì‹œì— ì“¸ ë•Œ ê²°ê³¼ íŒŒì¼ì´ í©ì–´ì§€ì§€ ì•Šê³  í•œ í´ë”ì—ë§Œ 1ë²Œ ìƒì„±ë˜ë„ë¡ ì •ë¦¬í•˜ëŠ” ë™ì‘ì…ë‹ˆë‹¤.
        
        """


        try:
            outdir = getattr(self._monitor, "outdir", None)  #'exp/tldr/choice_qwen/fedbis_test'
            if not outdir:
                return
            norm = os.path.normpath(outdir)
            parts = norm.split(os.sep)
            if "sub_exp" in parts: #NO
                idx = parts.index("sub_exp")
                fixed = os.sep.join(parts[:idx])  # sub_exp ì•ê¹Œì§€ë§Œ
                if fixed:
                    self._monitor.outdir = fixed
                    os.makedirs(self._monitor.outdir, exist_ok=True)
                    self.logger.info(f"[outdir-fixed] monitor.outdir -> {self._monitor.outdir}")
        except Exception as e:
            self.logger.debug(f"[outdir-fixed] skip due to: {e}")


    # ------------------------------------------------------------------
    # íŒŒì¼ ì•„ì›ƒë””ë ‰í† ë¦¬ ë³´ì¥ / JSONL append ìœ í‹¸ / (rankë³„) ë¡œê¹… ìœ í‹¸
    # ------------------------------------------------------------------

    def _ensure_outdir(self):
        if hasattr(self._monitor, "outdir") and self._monitor.outdir:
            # âœ… outdir ìƒì„± ì§ì „ í•œ ë²ˆ ë” ìƒìœ„ í´ë”ë¡œ ê³ ì •
            self._force_single_outdir()
            os.makedirs(self._monitor.outdir, exist_ok=True)

    # def _is_main_process(self) -> bool: # accelerateê°€ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì—†ìœ¼ë©´ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ ê°€ì • 
    #     trainer = getattr(self, 'trainer', None) 
    #     if trainer is not None and hasattr(trainer, 'accelerator') and trainer.accelerator is not None: 
    #         return trainer.accelerator.is_main_process 
        
    #     return True # accelerator ë¯¸ì‚¬ìš© ì‹œ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ì´ë¯€ë¡œ True

    def _is_main_process(self) -> bool:
        """
        ë­í¬0ë§Œ True.
        ìš°ì„ ìˆœìœ„:
        1) accelerate ì‚´ì•„ìˆìœ¼ë©´ acc.is_main_process
        2) í™˜ê²½ë³€ìˆ˜ RANK/PMI_RANK/SLURM_PROCID == 0
        3) torch.distributed ì´ˆê¸°í™”ë¼ ìˆìœ¼ë©´ dist.get_rank() == 0
        4) ê·¸ ì™¸(ì§„ì§œ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤)ë§Œ True
        """
        # 1) acceleratorê°€ ì‚´ì•„ìˆìœ¼ë©´ ê·¸ ê°’ ì‚¬ìš©
        trainer = getattr(self, 'trainer', None)
        acc = getattr(trainer, 'accelerator', None)
        if acc is not None:
            try:
                return bool(acc.is_main_process)
            except Exception:
                pass  # ë¹„ì •ìƒ ìƒíƒœë©´ ì•„ë˜ fallbackìœ¼ë¡œ

        # 2) í™˜ê²½ë³€ìˆ˜ ê¸°ë°˜( torchrun / SLURM / Intel MPI ë“± ê³µí†µ )
        import os
        for k in ("RANK", "PMI_RANK", "SLURM_PROCID"):
            v = os.environ.get(k)
            if v is not None:
                try:
                    return int(v) == 0  # ê¸€ë¡œë²Œ ë­í¬ê°€ 0ì´ë©´ ë©”ì¸
                except ValueError:
                    break  # í˜•ì‹ ì´ìƒ ì‹œ ë‹¤ìŒ ë‹¨ê³„ë¡œ

        # 3) torch.distributedê°€ ì‚´ì•„ìˆë‹¤ë©´ ê·¸ ë­í¬ ì‚¬ìš©
        try:
            import torch.distributed as dist
            if dist.is_available() and dist.is_initialized():
                return dist.get_rank() == 0
        except Exception:
            pass

        # 4) ì§„ì§œë¡œ ë¶„ì‚° íŒíŠ¸ê°€ ì „í˜€ ì—†ìœ¼ë©´ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ ê°„ì£¼
        return True


    def _append_raw_line(self, role_str: str, round_idx, results_dict: dict, filename: str):

        """
        í•¨ìˆ˜ ì •ì˜:

            role_str: "Client #1", "Server" ë“± ì—­í•  ë¬¸ìì—´

            round_idx: í˜„ì¬ ë¼ìš´ë“œ ë²ˆí˜¸

            results_dict: ê¸°ë¡í•˜ë ¤ëŠ” ê²°ê³¼(ì˜ˆ: train_loss, val_acc ë“±)

            filename: ê¸°ë¡í•  íŒŒì¼ëª… (ì˜ˆ: eval_results.raw)        
        """

        """
        ëª©í‘œ:

        outdir (self._monitor.outdir)/filename ì— JSON ë¼ì¸ í•œ ì¤„ append
        results_dict: {'train_*'...} ë˜ëŠ” {'test_*','val_*'...} ê°™ì€ ì§‘ê³„ í‚¤ë§Œ ë„˜ê¸°ì„¸ìš”.
        """

        try:
            outdir = getattr(self._monitor, "outdir", None)
            os.makedirs(outdir, exist_ok=True) #í•´ë‹¹ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„± (exist_ok=True â†’ ì´ë¯¸ ìˆìœ¼ë©´ ë¬´ì‹œ).
            outpath = os.path.join(outdir, filename) # ìµœì¢… íŒŒì¼ ê²½ë£¨(outpath) ìƒì„±.

            line = {
                "Role": role_str,
                "Round": round_idx,
                "Results_raw": results_dict
            }#ê¸°ë¡í•  JSON line ë”•ì…”ë„ˆë¦¬ êµ¬ì„±.

            #íŒŒì¼ì„ append ëª¨ë“œ("a")ë¡œ ì—´ê³  UTF-8ë¡œ ì¸ì½”ë”©. json.dumpsë¡œ ë¬¸ìì—´ ë³€í™˜ í›„ \n ë¶™ì—¬ì„œ í•œ ì¤„ ë‹¨ìœ„ë¡œ ê¸°ë¡. ensure_ascii=False â†’ í•œê¸€ ê°™ì€ ë¹„ASCII ë¬¸ìë„ ê·¸ëŒ€ë¡œ ê¸°ë¡
            with open(outpath, "a", encoding="utf-8") as f:
                f.write(json.dumps(line, ensure_ascii=False) + "\n")
        except Exception as e:
            # íŒŒì¼ ë¬¸ì œë¡œ í•™ìŠµì´ ì£½ì§€ ì•Šë„ë¡ ë°©ì–´
            self.logger.warning(f"[append_raw_line] failed to write {filename}: {e}")

    def _log_split_metrics(self, role_str, round_idx, split, trainer_ctx):

        """
        í•¨ìˆ˜ëŠ” ê° ë¼ìš´ë“œ í•™ìŠµ/í‰ê°€ ê²°ê³¼ë¥¼ ë¡œê·¸ë¡œ ë‚¨ê¸°ëŠ” ìœ í‹¸ë¦¬í‹°.

        role_str: "Client #1", "Server" ê°™ì€ ì—­í•  ì´ë¦„

        round_idx: í˜„ì¬ ë¼ìš´ë“œ ë²ˆí˜¸

        split: 'train' | 'val' | 'test' ì¤‘ í•˜ë‚˜

        trainer_ctx: trainer.ctx ê°ì²´, ë‚´ë¶€ì— ë¡œì»¬/ì§‘ê³„ metricë“¤ì´ ë“¤ì–´ ìˆìŒ

        """

        """
        â‘  ê° rank ë¡œì»¬ ìŠ¤ëƒ…ìƒ·
        â‘¡ rank0ì—ì„œ per-proc ë¦¬ìŠ¤íŠ¸ (ëª¨ë“  rankì˜ local ìŠ¤ëƒ…ìƒ· ëª¨ìŒ)
        â‘¢ rank0ì—ì„œ í•´ë‹¹ splitì˜ ì§‘ê³„ ê²°ê³¼(ì ‘ë‘ì‚¬ 'split_')
        """

        #1) accelerator ì°¾ê¸° (client, trainer.ctx, trainer ìˆœìœ¼ë¡œ ì‹œë„), self.trainer.acceleratorì— ë³´í†µ ì§€ì •ë˜ì–´ ìˆìŒ.
        accel = getattr(self, "accelerator", None)
        if accel is None:
            accel = getattr(trainer_ctx, "accelerator", None)
        if accel is None and hasattr(self, "trainer") and hasattr(self.trainer, "accelerator"):
            accel = self.trainer.accelerator


        #2) ë­í¬/ì›”ë“œ ì¶”ì • (accelerator ì—†ì„ ë•Œ envë¡œ ë³´ì™„). worldì™€ rankì˜ ê¸°ë³¸ê°’ì€ 1,0.
        if accel is not None:
            world = getattr(accel, "num_processes", 1)
            rank  = getattr(accel, "process_index", 0)
        else:
            world = int(os.getenv("WORLD_SIZE", "1"))
            rank  = int(os.getenv("LOCAL_RANK", "0"))



        #3) ê° rank ë¡œì»¬ ìŠ¤ëƒ…ìƒ·.  í„°ë¯¸ë„ì—ëŠ” ëª¨ë“  rankì— ëŒ€í•´ì„œ ë‹¤ ëœ¬ë‹¤. exp_print.logì—ëŠ” rank 0ì— ëŒ€í•´ì„œë§Œ ê¸°ë¡.
        local = getattr(trainer_ctx, "local_results_for_log", {}) or {} #local_results_for_log: ê° rank(í”„ë¡œì„¸ìŠ¤)ê°€ ê°œë³„ì ìœ¼ë¡œ ì¸¡ì •í•œ ê²°ê³¼.
        self.logger.info({
            'Role': role_str, 'Round': round_idx, 'Split': split,
            'Rank': f'{rank}/{world}', 'Local': True,
            'Results': local
        })#INFO: {'Role': 'Client #44', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.59094136953354, 'train_avg_loss': 0.7049245114127795, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
        # â‘¢ ì§‘ê³„ ê²°ê³¼(í•´ë‹¹ split ì ‘ë‘ì‚¬ 4í‚¤ë§Œ; alias ê¸ˆì§€)
        agg = getattr(trainer_ctx, "eval_metrics", {}) or {}
        sp  = f"{split}_"
        agg_clean = {k: v for k, v in agg.items() if k.startswith(sp)} #spì— í•´ë‹¹í•˜ëŠ” ê²°ê³¼ë§Œ ì¶”ì¶œ

        # ì§‘ê³„ ê²°ê³¼ëŠ” ì˜¤ì§ rank0ì—ì„œë§Œ ì¶œë ¥. subprocessì—ì„œëŠ” aggê°€ ë¹ˆ {} ì´ê¸°ì—/
        if agg_clean and rank == 0:
            self.logger.info({
                'Role': role_str, 'Round': round_idx, 'Split': split,
                'Aggregated': True, 'Results_raw': agg_clean
            })#INFO: {'Role': 'Client #44', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 348.3512268066406, 'train_avg_loss': 0.7257317225138347, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
 

    def _gen_timestamp(self, init_timestamp, instance_number):
        if init_timestamp is None:
            return None

        comp_cost, comm_cost = calculate_time_cost(
            instance_number=instance_number,
            comm_size=self.model_size,
            comp_speed=self.comp_speed,
            comm_bandwidth=self.comm_bandwidth) #self.comp_speed=self.comp_bandwidth=Noneì¸ ìƒí™©. ë”°ë¼ì„œ  comp_cost=comm_cost=0ìœ¼ë¡œ ë‚˜ì˜´.
        return init_timestamp + comp_cost + comm_cost #init_timestampìœ¼ë¡œ ë‚˜ì˜´.

    def _reset_ctx_split_metrics(self, split: str):
        """
        âœ… (ì¤‘ìš”) ë¼ìš´ë“œ ì‹œì‘ ì „ì— í•´ë‹¹ splitì˜ ìºì‹œë¥¼ ë¦¬ì…‹
        - trainer.ctx.eval_metrics, trainer.ctx.local_results_for_log ë“±ì—ì„œ split ì ‘ë‘ì‚¬ì˜ í‚¤ë¥¼ ì œê±°.
        - DDP ìƒí™©ì—ì„œ ë¼ìš´ë“œ ê°„ ëˆ„ì ë˜ì–´ train_total ì´ 960ì²˜ëŸ¼ ë¶ˆì–´ë‚˜ëŠ” í˜„ìƒ ë°©ì§€.
        """
        try:
            ctx = getattr(self.trainer, "ctx", None)
            if ctx is None:
                return

            # 1) ì§‘ê³„ë³¸ì—ì„œ split ì ‘ë‘ì‚¬ í‚¤ ì‚­ì œ
            em = getattr(ctx, "eval_metrics", None)
            if isinstance(em, dict):
                for k in list(em.keys()):
                    if k.startswith(f"{split}_"):
                        del em[k]

            # 2) ë¡œì»¬ ìŠ¤ëƒ…ìƒ·ì—ì„œ split ì ‘ë‘ì‚¬ í‚¤ ì‚­ì œ
            lr = getattr(ctx, "local_results_for_log", None)
            if isinstance(lr, dict):
                for k in list(lr.keys()):
                    if k.startswith(f"{split}_"):
                        del lr[k]

        except Exception as e:
            self.logger.debug(f"[reset split={split}] skip due to: {e}")

    # ------------------------------------------------------------------
    # ëŸ¬ë‹ ë£¨í”„
    # ------------------------------------------------------------------

    def join_in(self): #client:"join_in" ë©”ì‹œì§€ë¥¼ ì„œë²„ì—ê²Œ ë³´ëƒ„.
        """
        To send ``join_in`` message to the server for joining in the FL course.
        """
        self.comm_manager.send(
            Message(msg_type='join_in',
                    sender=self.ID,
                    receiver=[self.server_id],
                    timestamp=0,
                    content=self.local_address))

    def run(self): #ì•ˆì“°ì„.
        """
        To listen to the message and handle them accordingly (used for \
        distributed mode)
        """
        while True:
            msg = self.comm_manager.receive()
            if self.state <= msg.state:
                self.msg_handlers[msg.msg_type](msg)

            if msg.msg_type == 'finish':
                break

    def run_standalone(self): #ì•ˆì“°ì„.
        """
        Run in standalone mode
        """
        self.join_in()
        self.run()

    # ------------------------------------------------------------------
    # ì„œë²„ë¡œë¶€í„° ë°›ì€ ê¸€ë¡œë²Œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì²˜ë¦¬í•˜ê³ ,
    # ë¡œì»¬ í•™ìŠµì„ íŠ¸ë¦¬ê±°í•œ ë’¤ ê²°ê³¼ë¥¼ ì„œë²„ì— ë‹¤ì‹œ ë³´ëƒ…ë‹ˆë‹¤.
    # ------------------------------------------------------------------
    def callback_funcs_for_model_para(self, message: Message):
        """
        The handling function for receiving model parameters, \
        which triggers the local training process. \
        This handling function is widely used in various FL courses.

        Arguments:
            message: The received message
        """

        # ---- ì—¬ê¸°ë¶€í„° ì¼ë°˜(ë¹„-SS) ì¼€ì´ìŠ¤ ----
        round = message.state  # ì„œë²„ê°€ ë³´ë‚¸ ë¼ìš´ë“œ ë²ˆí˜¸
        sender = message.sender  # ë©”ì‹œì§€ë¥¼ ë³´ë‚¸ ì£¼ì²´(ì„œë²„) ID
        timestamp = message.timestamp  # ì„œë²„ ì‹œê°
        content = message.content  # ì‹¤ì œ ëª¨ë¸ íŒŒë¼ë¯¸í„° (ë˜ëŠ” íŒŒë¼ë¯¸í„° ë¸íƒ€)

        # When clients share the local model, we must set strict=True to
        # ensure all the model params (which might be updated by other
        
        # clients in the previous local training process) are overwritten
        # and synchronized with the received model
        if self._cfg.federate.process_num > 1:
            for k, v in content.items():
                content[k] = v.to(self.device)


        is_main = self._is_main_process()

        self.trainer.update(content,
                            strict=self._cfg.federate.share_local_model)  # ì„œë²„ì—ì„œ ë³´ë‚¸ íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì„ ë®ì–´ì”Œì›ë‹ˆë‹¤.

        self.state = round






        # ì´ë¯¸ ë¡œì»¬ ìˆ˜ë ´í•œ í´ë¼ì´ì–¸íŠ¸ë¼ë©´ í›ˆë ¨ì„ ê±´ë„ˆë›°ê¸°ë„ í•˜ê³ â€¦
        if self.early_stopper.early_stopped and \
                self._monitor.local_convergence_round == 0: #self.early_stopper.early_stoppedê°€  Falseë¼ Pass!!
            logger.info(
                f"[Normal FL Mode] Client #{self.ID} has been locally "
                f"early stopped. "
                f"The next FL update may result in negative effect")
            self._monitor.local_converged()  # self._monitorì˜ self.local_convergence_wall_time, self.local_convergence_round ì§€ì •.

        # âœ… (ì¤‘ìš”) ì´ë²ˆ ë¼ìš´ë“œ train ì „ì— split ìºì‹œ ë¦¬ì…‹ â€” ëˆ„ì  ë°©ì§€
        self._reset_ctx_split_metrics('train')

        sample_size, model_para_all, results = self.trainer.train(round_num=self.state)  # ì „ì²´ train data ê°¯ìˆ˜, model_para_all (adapter 1ê°œì¸ ìƒí™©ì´ë¼ ì´ê²ƒì€ active adapterì˜ state_dict), split routine ëŒë©° ì§‘ê³„ëœ results (num_total, loss, acc ë“±) ë¦¬í„´

        if self._cfg.federate.share_local_model and not self._cfg.federate.online_aggr:
            model_para_all = copy.deepcopy(model_para_all)  # ì•ˆì „í•˜ê²Œ ë³µì‚¬

        # âœ… ë­í¬ë³„ train result ë¡œê·¸ ë„ì›€ 2)ëª¨ë“¤ ë­í¬ ì¢…í•©í•œ train result ë¡œê·¸ ë„ì›€.
        self._log_split_metrics(
            role_str=f'Client #{self.ID}',
            round_idx=self.state,
            split='train',
            trainer_ctx=self.trainer.ctx
        )

        # train ëë‚˜ê³  _log_split_metrics(...) ë’¤:     
 
        ctx = getattr(self.trainer, "ctx", None)
        agg = getattr(ctx, "eval_metrics", {}) if ctx is not None else {}
        train_agg = {k: v for k, v in (agg or {}).items() if k.startswith("train_")}#í•œ í´ë¼ì´ì–¸íŠ¸ ê¸°ì¤€ ì§‘ê³„ëœ train split ê²°ê³¼.
        if is_main: # âœ… rank0(=main process)ì—ì„œë§Œ ì§‘ê³„ë³¸ì„ íŒŒì¼ë¡œ ê¸°ë¡
            self._append_raw_line(
                role_str=f"Client #{self.ID}",
                round_idx=self.state,
                results_dict=train_agg,
                filename="train_results.raw"
            )

        

        train_agg = {
            k: v for k, v in getattr(self.trainer.ctx, "eval_metrics", {}).items()
            if k.startswith("train_")
        }
        if is_main: # âœ… exp_printìš©: train ì§‘ê³„ë³¸ë§Œ í•œ ì¤„ (rank0ì—ì„œë§Œ)
            self.logger.info({
                'Role': f'Client #{self.ID}',
                'Round': self.state,
                'Results_raw': train_agg
            }) #INFO: {'Role': 'Client #44', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 348.3512268066406, 'train_avg_loss': 0.7257317225138347, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
 
        # Return the feedbacks to the server after local update

        shared_model_para = model_para_all

        # âœ… ëª¨ë“  rankì— ëŒ€í•´ì„œ ë™ì¼í•˜ê²Œ ë©”ì‹œì§€ë¥¼ ë³´ëƒ„. ì„œë²„ëŠ” ê° processë§ˆë‹¤ ë™ì¼í•˜ê²Œ self.comm_manager.comm_queueë¥¼ ê´€ë¦¬í•´ì•¼í•¨.
        self.comm_manager.send(
            Message(msg_type='model_para',  # â†” ì„œë²„ê°€ â€œtrainâ€ ë‹¨ê³„ë¡œ ì¸ì‹
                    sender=self.ID,  # ì´ í´ë¼ì´ì–¸íŠ¸ ID
                    receiver=[sender],  # ì•ì„œ ì €ì¥í•œ ì„œë²„ ID
                    state=self.state,  # (ê°™ì€) ë¼ìš´ë“œ ë²ˆí˜¸
                    timestamp=self._gen_timestamp(
                        init_timestamp=timestamp,
                        instance_number=sample_size),  # â†’ ì„œë²„ì˜ time-based staleness ì œì–´ìš©
                    content=(sample_size, shared_model_para)))  # ë°ì´í„° ê°¯ìˆ˜ ë° ë¡œì»¬ ëª¨ë¸ì„ contentë¡œ ë‹´ì•„ì„œ ë³´ë‚¸ë‹¤.    




 
    # ------------------------------------------------------------------
    # ì„œë²„ê°€ â€œí‰ê°€ ìš”ì²­(evaluate)â€ ë©”ì‹œì§€ë¥¼ ë³´ë‚¼ ë•Œ,
    # ë¡œì»¬ ë°ì´í„°ì— ëŒ€í•´ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³  ê²°ê³¼(metrics)ë¥¼ ì„œë²„ì— ë³´ëƒ…ë‹ˆë‹¤.
    # ------------------------------------------------------------------






    def callback_funcs_for_evaluate(self, message: Message):
        """
        The handling function for receiving the request of evaluating
        """

        # í•­ìƒ ë¨¼ì € ì´ˆê¸°í™”í•´ì„œ NameError ë°©ì§€
 

        metrics = {}
        sender, timestamp = message.sender, message.timestamp
        self.state = message.state


        is_main = self._is_main_process()

        # 1) ì„œë²„ íŒŒë¼ë¯¸í„°ë¡œ ë™ê¸°í™”
        if message.content is not None:
            self.trainer.update(
                message.content,
                strict=self._cfg.federate.share_local_model
            )

        # 2) í‰ê°€ ì‹¤í–‰
        try:
            # âœ… (ì¤‘ìš”) ì´ë²ˆ ë¼ìš´ë“œ í‰ê°€ ì‹œì‘ ì „, ìš”ì²­ëœ split ìºì‹œë¥¼ ì„ ì œ ë¦¬ì…‹
            #    (val â†’ test ìˆœì„œë¡œ ëŒë”ë¼ë„ ë¼ìš´ë“œ ê°„/ìŠ¤í”Œë¦¿ ê°„ ëˆ„ì  ë°©ì§€)
            for sp in set(self._cfg.eval.split): #['val', 'test']
                self._reset_ctx_split_metrics(sp)

            if self._cfg.finetune.before_eval: #False. PFLì—ì„œëŠ” Trueë¡œ í•´ë„ ë ë“¯.
                self.trainer.finetune()

            for split in self._cfg.eval.split:  #['val', 'test']
                # logger.info(f"[DEBUG] after evaluate(split={split}): eval_metrics={eval_metrics}")
                # eval_metrics = self.trainer.evaluate(target_data_split_name=split)
                eval_metrics = self.trainer.evaluate(target_data_split_name=split)
                """
                    eval_metrics = {
                    f'{split}_total':    int(total_all),
                    f'{split}_loss':     float(loss_all),
                    f'{split}_avg_loss': float(loss_all / total_all),
                    f'{split}_seen':     int(seen_all),
                    f'{split}_correct':  int(correct_all),
                    f'{split}_acc':      float(correct_all / max(1, seen_all))
                    } 

                    ì˜ í˜•íƒœ.    
                """

                if is_main:
                    logger.info(f"[DEBUG][after {split}] eval_metrics            = {eval_metrics}")
                    logger.info(f"[DEBUG][after {split}] metrics (merged so far) = {metrics}")
                    logger.info(f"[DEBUG][after {split}] ctx.eval_metrics        = {self.trainer.ctx.eval_metrics}")



                metrics.update(**eval_metrics)


                # âœ… ì›í•˜ëŠ” í¬ë§·ì˜ ë¡œê·¸ 3ì¢…(ë¡œì»¬ / per-proc / ì§‘ê³„) ì¶œë ¥
                self._log_split_metrics(
                    role_str=f'Client #{self.ID}',
                    round_idx=self.state,
                    split=split,
                    trainer_ctx=self.trainer.ctx
                )

        except Exception as e:
            # í‰ê°€ ì¤‘ ë¬¸ì œê°€ ë‚˜ë„ ì„œë²„ë¡œëŠ” ë¹ˆ dictë¼ë„ ë³´ë‚´ë„ë¡
            self.logger.warning(f"[evaluate] exception during evaluation: {e}", exc_info=True)



          

        # ìš°ì„ ìˆœìœ„: trainer.ctx.eval_metrics(ì§‘ê³„ë³¸) -> metrics(ë³‘í•©ë³¸)
        ctx = getattr(self.trainer, "ctx", None)
        agg_all = getattr(ctx, "eval_metrics", {}) if ctx is not None else {}

        logger.info(f"[DEBUG][before write] agg_all={agg_all}, metrics={metrics}") 

        base = {**agg_all, **metrics}

        # test_/val_ë§Œ ì¶”ì¶œ
        combined = {k: v for k, v in (base or {}).items()
                    if k.startswith("test_") or k.startswith("val_")}
        has_test = any(k.startswith("test_") for k in combined) #Boolean
        has_val  = any(k.startswith("val_") for k in combined) #Boolean

        logger.info(f"[DEBUG] combined keys={list(combined.keys())}, has_val={has_val}, has_test={has_test}")


        write_key = (self.ID, int(self.state))

        # 3) rank0ë§Œ íŒŒì¼ ê¸°ë¡/ì„œë²„ ì „ì†¡
        if is_main:

            self._ensure_outdir()


            # âœ… íŒŒì¼ ê¸°ë¡: test & val ë‘˜ ë‹¤ ìˆê³ , ì•„ì§ ì•ˆ ì“´ ê²½ìš° 1íšŒë§Œ
            if has_test and has_val:
                if write_key not in self._eval_written_marker:
                    self._append_raw_line(
                        role_str=f"Client #{self.ID}",
                        round_idx=self.state,
                        results_dict=combined,
                        filename="eval_results.raw"
                    )
                    self._eval_written_marker.add(write_key)
                else:
                    self.logger.debug(f"[skip duplicate eval write] {write_key}")
            else:
                self.logger.debug(
                    f"[skip write eval_results.raw] only one split present. "
                    f"available={list(combined.keys())}"
                )


            # 3-2) ëª¨ë‹ˆí„°ì— ê¸°ë¡. round_formatted_results_raw ë°˜í™˜í•˜ëŠ” ê²ƒ.
            try:
                self._monitor.format_eval_res(
                    metrics, rnd=self.state, role=f'Client #{self.ID}', forms=['log']
                )
            except Exception as e:
                # metricsê°€ ë¹„ì–´ë„ ë¡œê¹… ì‹¤íŒ¨í•˜ì§€ ì•Šë„ë¡
                self.logger.debug(f"[format_eval_res] skip log due to: {e}")

        #4) ëª¨ë“  RANKì—ì„œ ì„œë²„ë¡œ  ë©”ì‹œì§€ ì „ì†¡
        if metrics:    # â† metrics ê°€ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ ì „ì†¡

            # _seen, _correct ì ‘ë¯¸ì‚¬ í‚¤ ì œê±°í•œ ì‚¬ë³¸ ë§Œë“¤ê¸°
            pruned_metrics = {
                k: v for k, v in metrics.items()
                if not (k.endswith('_seen') or k.endswith('_correct'))
            }

            # ë¹„ì›Œì¡Œìœ¼ë©´ êµ³ì´ ë³´ë‚´ì§€ ì•ŠìŒ
            if pruned_metrics:
                self.comm_manager.send(
                        Message(msg_type='metrics',
                                sender=self.ID,
                                receiver=[sender],
                                state=self.state,
                                timestamp=timestamp,
                                content=pruned_metrics)
                    )
        else:
            logger.debug(f"[skip send metrics] empty metrics for Client #{self.ID}, round={self.state}")







    # FL ê³¼ì •ì´ â€œì™„ë£Œ(finish)â€ ì‹ í˜¸ë¥¼ ë°›ì„ ë•Œ, ìµœì¢… ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ë¡œì»¬ ëª¨ë‹ˆí„°ì— ì¢…ë£Œë¥¼ ì•Œë¦½ë‹ˆë‹¤.
    def callback_funcs_for_finish(self, message: Message):
        """
        The handling function for receiving the signal of finishing the FL \
        course.

        Arguments:
            message: The received message
        """
        logger.info(
            f"================= client {self.ID} received finish message "
            f"=================")
        
        self._monitor.finish_fl()
        return

        if message.content is not None:
            self.trainer.update(message.content,
                                strict=self._cfg.federate.share_local_model)
            
        # âœ… rank0ë§Œ ì¢…ë£Œ íŒŒì¼ ê¸°ë¡(ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë“±)
        if self._is_main_process():
            self._monitor.finish_fl() #self.fl_end_wall_time ê³„ì‚°. system_metricsì„ ì–»ì–´ë‚´ì„œ "system_metrics.log"ì— ê¸°ë¡.



    def _calculate_model_delta(self, init_model, updated_model): # ì“¸ ì¼ ì—†ìŒ.
        if not isinstance(init_model, list):
            init_model = [init_model]
            updated_model = [updated_model]

        model_deltas = list()
        for model_index in range(len(init_model)):
            model_delta = copy.deepcopy(init_model[model_index])
            for key in init_model[model_index].keys():
                model_delta[key] = updated_model[model_index][
                    key] - init_model[model_index][key]
            model_deltas.append(model_delta)

        if len(model_deltas) > 1:
            return model_deltas
        else:
            return model_deltas[0]



    # ë³¼ í•„ìš” ì—†ì„ ë“¯. ë¶„ì‚° ëª¨ë“œì—ì„œ ì„œë²„ê°€ ë¶€ì—¬í•œ í´ë¼ì´ì–¸íŠ¸ ID (assign_client_id)ë¥¼ ë°›ì•„ self.ID ì— ì„¤ì •í•©ë‹ˆë‹¤.
    def callback_funcs_for_assign_id(self, message: Message):
        """
        The handling function for receiving the client_ID assigned by the \
        server (during the joining process), which is used in the \
        distributed mode.

        Arguments:
            message: The received message
        """
        content = message.content
        self.ID = int(content)
        logger.info('Client (address {}:{}) is assigned with #{:d}.'.format(
            self.comm_manager.host, self.comm_manager.port, self.ID))

    # ë³¼ í•„ìš” ì—†ì„ ë“¯. ì„œë²„ê°€ â€œì°¸ê°€ ì •ë³´â€ë¥¼ ìš”ì²­í•  ë•Œ(batch size, ìƒ˜í”Œ ê°œìˆ˜, ë¦¬ì†ŒìŠ¤ ë“±), ë¡œì»¬ ì„¤ì •ì„ ì½ì–´ ì±„ì›Œì„œ ì‘ë‹µí•©ë‹ˆë‹¤.
    def callback_funcs_for_join_in_info(self, message: Message):
        """
        The handling function for receiving the request of join in \
        information (such as ``batch_size``, ``num_of_samples``) during \
        the joining process.

        Arguments:
            message: The received message
        """
        requirements = message.content
        timestamp = message.timestamp
        join_in_info = dict()
        for requirement in requirements:
            if requirement.lower() == 'num_sample':
                if self._cfg.train.batch_or_epoch == 'batch':
                    num_sample = self._cfg.train.local_update_steps * \
                                 self._cfg.dataloader.batch_size
                else:
                    num_sample = self._cfg.train.local_update_steps * \
                                 len(self.trainer.data.train_data)
                join_in_info['num_sample'] = num_sample
                if self._cfg.trainer.type == 'nodefullbatch_trainer':
                    join_in_info['num_sample'] = \
                        self.trainer.data.train_data.x.shape[0]
            elif requirement.lower() == 'client_resource':
                assert self.comm_bandwidth is not None and self.comp_speed \
                       is not None, "The requirement join_in_info " \
                                    "'client_resource' does not exist."
                join_in_info['client_resource'] = self.model_size / \
                    self.comm_bandwidth + self.comp_speed
            else:
                raise ValueError(
                    'Fail to get the join in information with type {}'.format(
                        requirement))
        self.comm_manager.send(
            Message(msg_type='join_in_info',
                    sender=self.ID,
                    receiver=[self.server_id],
                    state=self.state,
                    timestamp=timestamp,
                    content=join_in_info))

    # ë³¼ í•„ìš” ì—†ì„ ë“¯. (ë¹„ë°€ ì…°ì–´ë§ ë“±) ë³µì¡í•œ í† í´ë¡œì§€ë¥¼ ìœ„í•´ ì„œë²„ê°€ ë‹¤ë¥¸ í´ë¼ì´ì–¸íŠ¸ ì£¼ì†Œ ëª©ë¡ì„ ë³´ë‚¼ ë•Œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ë³¼ í•„ìš” ì—†ì„ ë“¯.
    def callback_funcs_for_address(self, message: Message):
        """
        The handling function for receiving other clients' IP addresses, \
        which is used for constructing a complex topology

        Arguments:
            message: The received message
        """
        content = message.content
        for neighbor_id, address in content.items():
            if int(neighbor_id) != self.ID:
                self.comm_manager.add_neighbors(neighbor_id, address)


    # ë³¼ í•„ìš” ì—†ì„ ë“¯. ì„œë²„ê°€ â€œì¡°ê¸° ìˆ˜ë ´(converged)â€ ì‹ í˜¸ë¥¼ ë³´ëƒˆì„ ë•Œ, ë¡œì»¬ ëª¨ë‹ˆí„°ë¥¼ í†µí•´ ë” ì´ìƒì˜ ì—…ë°ì´íŠ¸ë¥¼ ë©ˆì¶¥ë‹ˆë‹¤.
    def callback_funcs_for_converged(self, message: Message):
        """
        The handling function for receiving the signal that the FL course \
        converged

        Arguments:
            message: The received message
        """
        self._monitor.global_converged() #self.global_convergence_wall_time , self.local_convergence_round ê¸°ë¡.

    @classmethod
    def get_msg_handler_dict(cls):
        return cls().msg_handlers_str
