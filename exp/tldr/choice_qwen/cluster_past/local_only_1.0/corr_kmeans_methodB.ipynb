{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a20750c",
   "metadata": {},
   "source": [
    "\n",
    "# Correlation-aware k-Means (Signed-Logit Margin → Column z-score → Row-center & L2 → k-Means)\n",
    "\n",
    "**디렉토리 구조**\n",
    "```\n",
    "./raw/src_{i:03d}/probs/tgt_{j:03d}.csv   # columns: p_A, label_num\n",
    "```\n",
    "프로세스: 확률→로짓(클립)→서명 마진 → **열 z-score** → **행 중심화+L2** → **k-means(U)**  \n",
    "유사도/거리: \\(S=\\frac{UU^\\top+I}{2}\\), \\(D=1-S\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e874312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 0) Imports & Config\n",
    "import os, math, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Tuple, List\n",
    "from collections import Counter\n",
    "\n",
    "np.set_printoptions(suppress=True, linewidth=140)\n",
    "\n",
    "M=53; J=53; T=40; S=J*T\n",
    "DIR_PATH=\"./raw\"\n",
    "PROB_EPS=1e-6; LOGIT_CLIP=7.0; STD_EPS=1e-12; SEED=0\n",
    "rng=np.random.default_rng(SEED); random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255e7c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded label clients: 53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1) Strict loader\n",
    "def load_probs_labels_strict(dir_path: str, M: int, J: int):\n",
    "    probs={i:{} for i in range(1,M+1)}\n",
    "    labels={j: None for j in range(1,J+1)}\n",
    "    any_found=False\n",
    "    for i in range(1,M+1):\n",
    "        for j in range(1,J+1):\n",
    "            f=os.path.join(dir_path, f\"src_{i:03d}\", \"probs\", f\"tgt_{j:03d}.csv\")\n",
    "            if not os.path.exists(f):\n",
    "                continue\n",
    "            df=pd.read_csv(f)\n",
    "            if \"p_A\" not in df.columns or \"label_num\" not in df.columns:\n",
    "                raise ValueError(f\"{f}: columns p_A,label_num required\")\n",
    "            p=df[\"p_A\"].to_numpy(float); q=df[\"label_num\"].to_numpy(int)\n",
    "            if labels[j] is None: labels[j]=q\n",
    "            else:\n",
    "                if labels[j].shape!=q.shape or not np.array_equal(labels[j],q):\n",
    "                    raise ValueError(f\"Label mismatch for client {j}: {f}\")\n",
    "            probs[i][j]=p; any_found=True\n",
    "    if not any_found:\n",
    "        raise RuntimeError(\"No files found under ./raw/...\")\n",
    "    labels={j:v for j,v in labels.items() if v is not None}\n",
    "    return probs, labels\n",
    "\n",
    "probs, labels = load_probs_labels_strict(DIR_PATH, M, J)\n",
    "print(\"Loaded label clients:\", len(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4883ba09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xz: (53, 2120)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) Build signed-logit margin matrix and column z-score\n",
    "import math\n",
    "def build_margin_matrix(probs, labels, prob_eps=PROB_EPS, logit_clip=LOGIT_CLIP, std_eps=STD_EPS):\n",
    "    cols=[]\n",
    "    for j in range(1,J+1):\n",
    "        if j not in labels: continue\n",
    "        for t in range(len(labels[j])):\n",
    "            cols.append((j,t))\n",
    "    S_eff=len(cols); \n",
    "    X=np.full((M,S_eff), np.nan, float)\n",
    "    for s,(j,t) in enumerate(cols):\n",
    "        q=labels[j][t]; y=2*q-1\n",
    "        for i in range(1,M+1):\n",
    "            arr=probs.get(i,{}).get(j,None)\n",
    "            if arr is None or t>=len(arr): continue\n",
    "            p=float(np.clip(arr[t], prob_eps, 1-prob_eps))\n",
    "            lv=math.log(p/(1-p))\n",
    "            lv=max(-logit_clip, min(logit_clip, lv))\n",
    "            X[i-1,s]=y*lv\n",
    "    good=~np.isnan(X).any(axis=0)\n",
    "    X=X[:,good]\n",
    "    mu=X.mean(axis=0, keepdims=True); Xc=X-mu\n",
    "    sd=Xc.std(axis=0, keepdims=True); sd=np.where(sd<std_eps,1.0,sd)\n",
    "    Xz=Xc/sd\n",
    "    return Xz\n",
    "\n",
    "Xz=build_margin_matrix(probs, labels)\n",
    "print(\"Xz:\", Xz.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d095d0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_matrix shape: (53, 53) range: 0.00826237447558692 to 1.0\n",
      "U: (53, 2120) S range: 0.00826237447558692 to 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Row-center + L2 -> U; S and D\n",
    "def to_U_row_center_l2(Xz, std_eps=STD_EPS):\n",
    "    row_mean=Xz.mean(axis=1, keepdims=True)\n",
    "    Xr=Xz-row_mean\n",
    "    n=np.linalg.norm(Xr, axis=1, keepdims=True)\n",
    "    n=np.where(n<std_eps,1.0,n)\n",
    "    return Xr/n\n",
    "\n",
    "def corr_similarity_from_U(U):\n",
    "    C=U@U.T\n",
    "    C=np.clip(C,-1.0,1.0)\n",
    "    S=0.5*(C+1.0)\n",
    "    np.fill_diagonal(S,1.0)\n",
    "    return S\n",
    "\n",
    "U=to_U_row_center_l2(Xz)\n",
    "S_matrix=corr_similarity_from_U(U)\n",
    "print(\"S_matrix shape:\", S_matrix.shape, \"range:\", float(S_matrix.min()), \"to\", float(S_matrix.max()))\n",
    "D=1.0-S_matrix; np.fill_diagonal(D,0.0)\n",
    "print(\"U:\", U.shape, \"S range:\", S_matrix.min(), \"to\", S_matrix.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24d0b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) k-means on U\n",
    "from sklearn.cluster import KMeans\n",
    "def run_kmeans_on_U(U, K, n_init=50, max_iter=1000, random_state=SEED):\n",
    "    km=KMeans(n_clusters=K, n_init=n_init, max_iter=max_iter, random_state=random_state, tol=1e-4, algorithm=\"lloyd\")\n",
    "    labels=km.fit_predict(U)\n",
    "    centers=km.cluster_centers_\n",
    "    # spherical refinement\n",
    "    cn=np.linalg.norm(centers, axis=1, keepdims=True)+1e-12\n",
    "    centers=centers/cn\n",
    "    labels=(U@centers.T).argmax(axis=1)\n",
    "    centers=np.vstack([U[labels==k].mean(axis=0) if np.any(labels==k) else km.cluster_centers_[k] for k in range(K)])\n",
    "    centers=centers/(np.linalg.norm(centers, axis=1, keepdims=True)+1e-12)\n",
    "    sse=float(np.sum((U-centers[labels])**2))\n",
    "    return labels, centers, sse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de4c9378",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) Evaluation helpers\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def sizes_dict(labels):\n",
    "    c=Counter(labels.tolist())\n",
    "    return {int(k):int(v) for k,v in sorted(c.items())}\n",
    "\n",
    "def silhouette_from_D(D, labels):\n",
    "    N=D.shape[0]; labs=np.array(labels); uniq=np.unique(labs)\n",
    "    masks={k:(labs==k) for k in uniq}; sizes={k:int(m.sum()) for k,m in masks.items()}\n",
    "    a=np.zeros(N); b=np.zeros(N); s=np.zeros(N)\n",
    "    for i in range(N):\n",
    "        ki=labs[i]; m=masks[ki].copy(); m[i]=False\n",
    "        n_same=sizes[ki]-1\n",
    "        a[i]=0.0 if n_same<=0 else float(D[i,m].mean())\n",
    "        bmin=np.inf\n",
    "        for k in uniq:\n",
    "            if k==ki: continue\n",
    "            mm=masks[k]; \n",
    "            if sizes[k]==0: continue\n",
    "            bmin=min(bmin, float(D[i,mm].mean()))\n",
    "        b[i]=0.0 if not np.isfinite(bmin) else bmin\n",
    "        denom=max(a[i],b[i])\n",
    "        s[i]=0.0 if denom<=0 else (b[i]-a[i])/denom\n",
    "    s_macro={k:(0.0 if sizes[k]<=1 else float(s[masks[k]].mean())) for k in uniq}\n",
    "    return s, float(s.mean()), float(a.mean()), s_macro\n",
    "\n",
    "def intra_inter_S(S, labels):\n",
    "    labs=np.array(labels); uniq=np.unique(labs)\n",
    "    masks={k:(labs==k) for k in uniq}; sizes={k:int(m.sum()) for k,m in masks.items()}\n",
    "    # intra macro/micro\n",
    "    intra_vals=[]; pair_weights=[]\n",
    "    for k in uniq:\n",
    "        idx=np.where(masks[k])[0]; nk=len(idx)\n",
    "        if nk<=1: intra_vals.append(1.0); pair_weights.append(0)\n",
    "        else:\n",
    "            sub=S[np.ix_(idx,idx)].copy(); np.fill_diagonal(sub, np.nan)\n",
    "            intra_vals.append(float(np.nanmean(sub))); pair_weights.append(nk*(nk-1)//2)\n",
    "    intra_macro=float(np.mean(intra_vals))\n",
    "    tot_pairs=sum(pair_weights)\n",
    "    intra_micro=float(np.sum([v*w for v,w in zip(intra_vals, pair_weights)])/(tot_pairs if tot_pairs>0 else 1))\n",
    "    # inter macro/micro\n",
    "    inter_vals=[]; inter_w=[]\n",
    "    keys=list(uniq)\n",
    "    for a in range(len(keys)):\n",
    "        for b in range(a+1,len(keys)):\n",
    "            ia=np.where(masks[keys[a]])[0]; ib=np.where(masks[keys[b]])[0]\n",
    "            sub=S[np.ix_(ia,ib)]; v=float(sub.mean())\n",
    "            inter_vals.append(v); inter_w.append(len(ia)*len(ib))\n",
    "    inter_macro=float(np.mean(inter_vals)) if inter_vals else 0.0\n",
    "    inter_micro=float(np.sum(np.array(inter_vals)*np.array(inter_w))/np.sum(inter_w)) if inter_w else 0.0\n",
    "    # nearest-inter (size-weighted)\n",
    "    nearest=[]\n",
    "    for k in uniq:\n",
    "        best=0.0\n",
    "        for l in uniq:\n",
    "            if l==k: continue\n",
    "            ia=np.where(masks[k])[0]; ib=np.where(masks[l])[0]\n",
    "            v=float(S[np.ix_(ia,ib)].mean())\n",
    "            best=max(best,v)\n",
    "        nearest.append((k,best,sizes[k]))\n",
    "    Ntot=float(sum(sizes.values())); nearest_sw=sum(w*v for _,v,w in nearest)/(Ntot if Ntot>0 else 1.0)\n",
    "    NI_D_sw=1.0-nearest_sw\n",
    "    NI_D_min=min(1.0-v for _,v,_ in nearest) if nearest else 0.0\n",
    "    return intra_macro, intra_micro, inter_macro, inter_micro, NI_D_sw, NI_D_min\n",
    "\n",
    "def neg_sil_metrics(s):\n",
    "    r_neg=float(np.mean(s<0.0))\n",
    "    burden=float(np.mean(np.maximum(0.0,-s)))\n",
    "    return r_neg, burden\n",
    "\n",
    "def distance_margin(NI_D_sw, mean_a):\n",
    "    return float(NI_D_sw - mean_a)\n",
    "\n",
    "def prototypes_nearest(U, centers, labels):\n",
    "    K=centers.shape[0]; protos={}\n",
    "    for k in range(K):\n",
    "        idx=np.where(labels==k)[0]\n",
    "        if len(idx)==0: protos[k]=None; continue\n",
    "        sims=(U[idx]@centers[k][:,None]).ravel()\n",
    "        protos[k]=int(idx[int(np.argmax(sims))])\n",
    "    return protos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d065675d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Algorithm must be 'auto', 'full' or 'elkan', got lloyd instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2666610/1899265923.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mK_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mK\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_kmeans_on_U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0mprint_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'kmeans_K{K}'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnull_R\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2666610/3021258854.py\u001b[0m in \u001b[0;36mrun_kmeans_on_U\u001b[0;34m(U, K, n_init, max_iter, random_state)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrun_kmeans_on_U\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mkm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lloyd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcenters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# spherical refinement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fedfn/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit_predict\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mIndex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m \u001b[0mbelongs\u001b[0m \u001b[0mto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \"\"\"\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fedfn/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         )\n\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fedfn/lib/python3.7/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"full\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"elkan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             raise ValueError(\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0;34m\"Algorithm must be 'auto', 'full' or 'elkan', \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m                 \u001b[0;34mf\"got {self.algorithm} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Algorithm must be 'auto', 'full' or 'elkan', got lloyd instead."
     ]
    }
   ],
   "source": [
    "\n",
    "# 6) Runner: try multiple K and print reports\n",
    "def print_report(name, U, S, D, labels, centers, sse, null_R=0, rng=np.random.default_rng(0)):\n",
    "    from collections import Counter\n",
    "    N=U.shape[0]\n",
    "    s_vals, s_all, mean_a, s_macro = silhouette_from_D(D, labels)\n",
    "    s_macro_avg=float(np.mean(list(s_macro.values()))) if s_macro else s_all\n",
    "    intra_macro, intra_micro, inter_macro, inter_micro, NI_D_sw, NI_D_min = intra_inter_S(S, labels)\n",
    "    r_neg, burden = neg_sil_metrics(s_vals)\n",
    "    M_D = distance_margin(NI_D_sw, mean_a)\n",
    "    sizes = {int(k):int(v) for k,v in sorted(Counter(labels).items())}\n",
    "    # prototypes\n",
    "    protos = prototypes_nearest(U, centers, labels)\n",
    "    protos_1b = {k:(v+1 if v is not None else None) for k,v in protos.items()}\n",
    "    # size-weighted nearest-inter similarity\n",
    "    nearest_inter_sw = 1.0 - NI_D_sw\n",
    "    # print\n",
    "    print(f\"=== {name} (K={len(set(labels))}) ===\")\n",
    "    print(f\"Silhouette (all points avg):       {s_all: .6f}\")\n",
    "    print(f\"Silhouette (macro by cluster):     {s_macro_avg: .6f}\")\n",
    "    print(f\"  s̄_k by cluster: { {k: s_macro[k] for k in sorted(s_macro)} }\")\n",
    "    print(f\"Intra macro:   {intra_macro: .6f}\")\n",
    "    print(f\"Intra micro:   {intra_micro: .6f}\")\n",
    "    print(f\"Inter macro:   {inter_macro: .6f}\")\n",
    "    print(f\"Inter micro:   {inter_micro: .6f}\")\n",
    "    print(f\"Nearest-Inter (size-weighted):      {nearest_inter_sw: .6f}  <-- 값↑ ⇒ 분리도 나쁨/경계 혼선\")\n",
    "    print(f\"NI_D (size-weighted):            {NI_D_sw: .6f}\")\n",
    "    print(f\"NI_D_min (worst cluster):        {NI_D_min: .6f}\")\n",
    "    print(f\"Distance Margin M_D:             {M_D: .6f}\")\n",
    "    print(f\"Prototypes (nearest model 1-based): {protos_1b}\")\n",
    "    print(f\"SSE Cost (U-space): {sse: .6f}\")\n",
    "    print(f\"Cluster sizes: {sizes}\")\n",
    "    # Optional: simple null for M_D\n",
    "    if null_R>0:\n",
    "        sizes_list=[v for _,v in sorted(sizes.items())]\n",
    "        sims=[]\n",
    "        for r in range(null_R):\n",
    "            perm=rng.permutation(N)\n",
    "            lbl=np.empty(N,dtype=int); start=0\n",
    "            for kk,nk in enumerate(sizes_list):\n",
    "                lbl[perm[start:start+nk]]=kk; start+=nk\n",
    "            _, mean_a_n, _, _, NI_D_sw_n, NI_D_min_n = intra_inter_S(S, lbl)\n",
    "            sims.append(NI_D_sw_n - mean_a_n)\n",
    "        mu=float(np.mean(sims)); sd=float(np.std(sims)+1e-12)\n",
    "        print(f\"[Null]  M_D Z = {(M_D-mu)/sd: .3f}\")\n",
    "    print()\n",
    "\n",
    "K_list=[2,3,4,5,6,7,8,9,10]\n",
    "for K in K_list:\n",
    "    labels, centers, sse = run_kmeans_on_U(U, K)\n",
    "    print_report(f'kmeans_K{K}', U, S_matrix, D, labels, centers, sse, null_R=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedfn",
   "language": "python",
   "name": "fedfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
