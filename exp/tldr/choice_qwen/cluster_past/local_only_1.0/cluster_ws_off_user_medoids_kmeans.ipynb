{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e4cd24f",
   "metadata": {},
   "source": [
    "# ws≡1 OFF — User Medoids + Spherical k-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Imports & Config\n",
    "import os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, Optional, Tuple, List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "rng = np.random.default_rng(RANDOM_STATE)\n",
    "\n",
    "M = 53\n",
    "J = 53\n",
    "DIR_PATH = \"./raw\"\n",
    "\n",
    "PROB_EPS = 1e-6      # probability clipping\n",
    "LOGIT_CLIP = 7.0     # logit clipping in [-7,7]\n",
    "STD_EPS = 1e-12      # z-score denom floor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) Data Loading\n",
    "\n",
    "# probs, labels 초기화\n",
    "probs = {i: {} for i in range(1, M+1)}  # probs[i][j] -> 확률 값\n",
    "labels = {j: [] for j in range(1, J+1)}  # labels[j] -> 라벨 값\n",
    "\n",
    "# CSV 파일 로드 및 전처리\n",
    "for i in range(1, M+1):  # 모델 번호\n",
    "    for j in range(1, J+1):  # 클라이언트 번호\n",
    "        file_path = os.path.join(DIR_PATH, f\"src_{str(i).zfill(3)}/probs/tgt_{str(j).zfill(3)}.csv\")\n",
    "        \n",
    "        # 각 파일이 존재하면 읽기\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # 확률(p_A)과 라벨(label_num) 추출\n",
    "            probs[i][j] = df['p_A'].values  # 모델 i의 클라이언트 j에 대한 p(A) 확률\n",
    "            labels[j] = df['label_num'].values  # 클라이언트 j에 대한 라벨\n",
    "            \n",
    "        else:\n",
    "            print(f\"Warning: File {file_path} not found!\")\n",
    "\n",
    "# 데이터 확인\n",
    "print(probs[1][1][:5])  # 첫 번째 모델과 첫 번째 클라이언트에 대한 확률 예시\n",
    "print(labels[1][:5])  # 첫 번째 클라이언트에 대한 라벨 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ef958",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) Signed-Logit Margin -> Column Z-score -> Correlation Similarity\n",
    "\n",
    "def build_margin_matrix(probs: Dict[int, Dict[int, np.ndarray]],\n",
    "                        labels: Dict[int, np.ndarray],\n",
    "                        prob_eps: float = PROB_EPS,\n",
    "                        logit_clip: float = LOGIT_CLIP,\n",
    "                        std_eps: float = STD_EPS) -> Tuple[np.ndarray, List[Tuple[int,int]]]:\n",
    "    # compute total columns\n",
    "    col_meta: List[Tuple[int,int]] = []  # (j,t)\n",
    "    for j in range(1, J+1):\n",
    "        if j not in labels:\n",
    "            continue\n",
    "        n = len(labels[j])\n",
    "        for t in range(n):\n",
    "            col_meta.append((j,t))\n",
    "    S = len(col_meta)\n",
    "    if S == 0:\n",
    "        raise ValueError(\"labels 데이터가 비어 있습니다.\")\n",
    "    X = np.zeros((M, S), dtype=float)\n",
    "    # fill\n",
    "    for s, (j,t) in enumerate(col_meta):\n",
    "        q = labels[j][t]\n",
    "        y = 2*q - 1   # {-1,+1}\n",
    "        for i in range(1, M+1):\n",
    "            arr = probs.get(i, {}).get(j, None)\n",
    "            if arr is None or t >= len(arr):\n",
    "                X[i-1, s] = np.nan\n",
    "            else:\n",
    "                pv = float(np.clip(arr[t], prob_eps, 1-prob_eps))\n",
    "                lv = math.log(pv/(1-pv))\n",
    "                if lv > logit_clip: lv = logit_clip\n",
    "                if lv < -logit_clip: lv = -logit_clip\n",
    "                X[i-1, s] = y * lv\n",
    "    # drop columns with NaN\n",
    "    good = ~np.isnan(X).any(axis=0)\n",
    "    X = X[:, good]\n",
    "    # column standardization\n",
    "    mu = X.mean(axis=0, keepdims=True)\n",
    "    Xc = X - mu\n",
    "    sd = Xc.std(axis=0, keepdims=True)\n",
    "    sd = np.where(sd < std_eps, 1.0, sd)\n",
    "    Xz = Xc / sd\n",
    "    return Xz, good.nonzero()[0].tolist()\n",
    "\n",
    "Xz, kept_cols = build_margin_matrix(probs, labels)\n",
    "print(\"Xz shape:\", Xz.shape)\n",
    "print(Xz)\n",
    "\n",
    "def compute_S_matrix(Xz: np.ndarray) -> np.ndarray:\n",
    "    # row-wise Pearson correlation -> [0,1] similarity\n",
    "    C = np.corrcoef(Xz)  # (M,M), correlation between rows\n",
    "    C = np.clip(C, -1.0, 1.0)\n",
    "    S = 0.5*(C + 1.0)\n",
    "    np.fill_diagonal(S, 1.0)\n",
    "    return S\n",
    "\n",
    "S_matrix = compute_S_matrix(Xz)\n",
    "print(\"S_matrix shape:\", S_matrix.shape, \"range:\", float(S_matrix.min()), \"to\", float(S_matrix.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def nll_i_to_j(p: np.ndarray, q: np.ndarray, smooth_eps: float = 1e-9) -> float:\n",
    "    \"\"\"Binary NLL calculation.\"\"\"\n",
    "    # 라벨 스무딩 (옵션)\n",
    "    q_ = (1 - smooth_eps) * q + smooth_eps * (1 - q)\n",
    "    \n",
    "    # 확률 클리핑\n",
    "    p = np.clip(p, smooth_eps, 1 - smooth_eps)\n",
    "    \n",
    "    # NLL 계산\n",
    "    nll = -np.mean(q_ * np.log(p) + (1 - q_) * np.log(1 - p))\n",
    "    return nll\n",
    "\n",
    "def compute_T_matrix(probs: Dict[int, Dict[int, np.ndarray]], labels: Dict[int, np.ndarray], smooth_eps: float = 1e-9) -> np.ndarray:\n",
    "    \"\"\"Compute the Transferability proxy T.\"\"\"\n",
    "    T = np.zeros((M, J))  # 모델 x 클라이언트 크기의 행렬\n",
    "    \n",
    "    for i in range(1, M+1):\n",
    "        for j in range(1, J+1):\n",
    "            T[i-1, j-1] = nll_i_to_j(probs[i][j], labels[j], smooth_eps)\n",
    "    \n",
    "    # 열별(min-max) 정규화\n",
    "    T = (T - T.min(axis=0)) / (T.max(axis=0) - T.min(axis=0))  # column-wise normalization\n",
    "    return T\n",
    "\n",
    "T_matrix = compute_T_matrix(probs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2b38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "def plot_heatmap_T(\n",
    "    T_matrix,\n",
    "    title=\"T heatmap\",\n",
    "    cmap=\"RdBu_r\",        # 추천 diverging\n",
    "    center=0.5            # 0.5를 중립(흰색/밝은색)으로\n",
    "):\n",
    "    T = np.asarray(T_matrix)\n",
    "    norm = TwoSlopeNorm(vmin=0.0, vcenter=center, vmax=1.0)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    im = plt.imshow(T, aspect='auto', cmap=cmap, norm=norm)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('j (datasets D_j)')\n",
    "    plt.ylabel('i (models)')\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label('T (column-wise min–max)', rotation=90)\n",
    "\n",
    "    # 보기 좋은 1-based 눈금\n",
    "    ni, nj = T.shape\n",
    "    plt.xticks(\n",
    "        np.linspace(0, nj-1, min(nj, 12), dtype=int),\n",
    "        [str(x) for x in np.linspace(1, nj, min(nj, 12), dtype=int)]\n",
    "    )\n",
    "    plt.yticks(\n",
    "        np.linspace(0, ni-1, min(ni, 12), dtype=int),\n",
    "        [str(x) for x in np.linspace(1, ni, min(ni, 12), dtype=int)]\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 예시:\n",
    "# plot_heatmap_T(T_matrix, cmap=\"RdBu_r\")       # 깔끔, 대비 적당\n",
    "# plot_heatmap_T(T_matrix, cmap=\"RdYlBu_r\")     # 대비 강함(보색+노랑)\n",
    "# plot_heatmap_T(T_matrix, cmap=\"coolwarm\")     # 부드러운 대비\n",
    "plot_heatmap_T(T_matrix, cmap=\"viridis\")      # 중립 불필요할 때(순차형)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c789486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db50ecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4531a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "# Load\n",
    "p = Path('x_raw.npy')\n",
    "if not p.exists():\n",
    "    p = Path('/mnt/data/x_raw.npy')\n",
    "X = np.load(p)\n",
    "n,d = X.shape\n",
    "print('Loaded', p, 'shape=', X.shape)\n",
    "\n",
    "# ws≡1 preprocessing\n",
    "def preprocess_ws_off(X, delta=1e-6):\n",
    "    mu_s = X.mean(axis=0, keepdims=True)\n",
    "    sd_s = np.maximum(X.std(axis=0, ddof=0, keepdims=True), delta)\n",
    "    Xz = (X - mu_s) / sd_s\n",
    "    mu_i = Xz.mean(axis=1, keepdims=True)\n",
    "    Xc = Xz - mu_i\n",
    "    norms = np.linalg.norm(Xc, axis=1, keepdims=True)\n",
    "    norms = np.where(norms==0, 1.0, norms)\n",
    "    U = Xc / norms\n",
    "    rho = np.clip(U @ U.T, -1.0, 1.0)\n",
    "    D = 0.5*(1.0 - rho); np.fill_diagonal(D, 0.0)\n",
    "    return U, D\n",
    "\n",
    "U, D = preprocess_ws_off(X)\n",
    "print('U:', U.shape, 'D:', D.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bad107",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PAM (k-medoids++) minimal implementation\n",
    "def kmedoids_pam(D, k, n_init=16, max_swaps=200, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n = D.shape[0]\n",
    "    all_idx = np.arange(n)\n",
    "    best_labels, best_meds, best_cost = None, None, np.inf\n",
    "    for _ in range(n_init):\n",
    "        meds = [rng.choice(n)]\n",
    "        dist_min = D[meds[0]].copy()\n",
    "        for _ in range(1, k):\n",
    "            probs = dist_min / (dist_min.sum() + 1e-12)\n",
    "            nx = rng.choice(n, p=probs)\n",
    "            meds.append(nx)\n",
    "            dist_min = np.minimum(dist_min, D[nx])\n",
    "        meds = np.array(sorted(set(meds)))\n",
    "        if meds.size < k:\n",
    "            rest = np.setdiff1d(all_idx, meds)\n",
    "            meds = np.concatenate([meds, rng.choice(rest, k - meds.size, replace=False)])\n",
    "        labels = np.argmin(D[:, meds], axis=1)\n",
    "        improved, swaps = True, 0\n",
    "        while improved and swaps < max_swaps:\n",
    "            improved = False\n",
    "            non_meds = np.setdiff1d(all_idx, meds, assume_unique=True)\n",
    "            current_cost = np.sum(D[np.arange(n), meds[labels]])\n",
    "            for m in meds.copy():\n",
    "                for h in non_meds:\n",
    "                    cand = meds.copy()\n",
    "                    cand[np.where(cand == m)[0][0]] = h\n",
    "                    cand = np.sort(cand)\n",
    "                    cand_labels = np.argmin(D[:, cand], axis=1)\n",
    "                    cand_cost = np.sum(D[np.arange(n), cand[cand_labels]])\n",
    "                    if cand_cost + 1e-9 < current_cost:\n",
    "                        meds = cand\n",
    "                        labels = cand_labels\n",
    "                        current_cost = cand_cost\n",
    "                        improved = True; swaps += 1\n",
    "                        break\n",
    "                if improved or swaps >= max_swaps: break\n",
    "        cost = np.sum(D[np.arange(n), meds[labels]])\n",
    "        if cost < best_cost:\n",
    "            best_cost, best_labels, best_meds = cost, labels, meds\n",
    "    return best_labels, best_meds, best_cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2620354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run K=2\n",
    "K=2\n",
    "lab_pm, meds, cost = kmedoids_pam(D, K, n_init=16, max_swaps=200, random_state=42)\n",
    "lab_km = KMeans(n_clusters=K, n_init=32, max_iter=300, random_state=42).fit_predict(U)\n",
    "\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "for name, labels in [('medoids', lab_pm), ('kmeans', lab_km)]:\n",
    "    sil = silhouette_score(D, labels, metric='precomputed')\n",
    "    ch  = calinski_harabasz_score(U, labels)\n",
    "    db  = davies_bouldin_score(U, labels)\n",
    "    sizes = [int(s) for s in np.bincount(labels)]\n",
    "    print(f'{name}: sil={sil:.3f} CH={ch:.1f} DB={db:.3f} sizes={sizes}')\n",
    "\n",
    "# Save CSVs\n",
    "pd.DataFrame({'client_id': np.arange(1, n+1), 'cluster_k2_medoids': lab_pm}).to_csv('ws_off_medoids_k2.csv', index=False)\n",
    "pd.DataFrame({'client_id': np.arange(1, n+1), 'cluster_k2_kmeans': lab_km}).to_csv('ws_off_kmeans_k2.csv', index=False)\n",
    "print('Saved ws_off_medoids_k2.csv, ws_off_kmeans_k2.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
