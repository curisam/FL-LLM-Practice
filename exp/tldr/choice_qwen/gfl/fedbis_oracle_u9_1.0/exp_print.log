2025-10-09 08:48:27 (root:426) INFO: [logger] file handler -> exp/tldr/choice_qwen/gfl/fedbis_oracle_u9_1.0/exp_print.log
2025-10-09 08:48:27 (root:51) INFO: [main] outdir=exp/tldr/choice_qwen/gfl/fedbis_oracle_u9_1.0
2025-10-09 08:48:50 (federatedscope.core.data.base_translator:234) INFO: Main process: Completion file found. Skipping generation.
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:264) INFO: [Final Split Summary][loaded][server=0][rank=0/4] Train=92858, Val=33082, Test=50715, Total=176655
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=1][rank=0/4] Train=2793, Val=146, Test=40, Total=2979
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=2][rank=0/4] Train=214, Val=11, Test=40, Total=265
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=3][rank=0/4] Train=691, Val=36, Test=40, Total=767
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=4][rank=0/4] Train=213, Val=11, Test=40, Total=264
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=5][rank=0/4] Train=285, Val=14, Test=40, Total=339
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=6][rank=0/4] Train=2547, Val=134, Test=40, Total=2721
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=7][rank=0/4] Train=1088, Val=57, Test=40, Total=1185
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=8][rank=0/4] Train=1316, Val=69, Test=40, Total=1425
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=9][rank=0/4] Train=3572, Val=188, Test=40, Total=3800
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=10][rank=0/4] Train=1209, Val=63, Test=40, Total=1312
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=11][rank=0/4] Train=621, Val=32, Test=40, Total=693
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=12][rank=0/4] Train=2605, Val=137, Test=40, Total=2782
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=13][rank=0/4] Train=1372, Val=72, Test=40, Total=1484
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=14][rank=0/4] Train=3055, Val=160, Test=40, Total=3255
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=15][rank=0/4] Train=14550, Val=200, Test=40, Total=14790
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=16][rank=0/4] Train=2589, Val=136, Test=40, Total=2765
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=17][rank=0/4] Train=5883, Val=200, Test=40, Total=6123
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=18][rank=0/4] Train=2576, Val=135, Test=40, Total=2751
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=19][rank=0/4] Train=2102, Val=110, Test=40, Total=2252
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=20][rank=0/4] Train=2399, Val=126, Test=40, Total=2565
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=21][rank=0/4] Train=2915, Val=153, Test=40, Total=3108
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=22][rank=0/4] Train=224, Val=11, Test=40, Total=275
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=23][rank=0/4] Train=583, Val=30, Test=40, Total=653
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=24][rank=0/4] Train=4944, Val=200, Test=40, Total=5184
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=25][rank=0/4] Train=4647, Val=200, Test=40, Total=4887
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=26][rank=0/4] Train=3063, Val=161, Test=40, Total=3264
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=27][rank=0/4] Train=2342, Val=123, Test=40, Total=2505
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=28][rank=0/4] Train=1434, Val=75, Test=40, Total=1549
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=29][rank=0/4] Train=6191, Val=200, Test=40, Total=6431
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=30][rank=0/4] Train=3247, Val=170, Test=40, Total=3457
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=31][rank=0/4] Train=3679, Val=193, Test=40, Total=3912
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=32][rank=0/4] Train=2144, Val=112, Test=40, Total=2296
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=33][rank=0/4] Train=1409, Val=74, Test=40, Total=1523
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=34][rank=0/4] Train=4486, Val=200, Test=40, Total=4726
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=35][rank=0/4] Train=4736, Val=200, Test=40, Total=4976
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=36][rank=0/4] Train=1030, Val=54, Test=40, Total=1124
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=37][rank=0/4] Train=4273, Val=200, Test=40, Total=4513
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=38][rank=0/4] Train=6171, Val=200, Test=40, Total=6411
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=39][rank=0/4] Train=1594, Val=83, Test=40, Total=1717
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=40][rank=0/4] Train=4005, Val=200, Test=40, Total=4245
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=41][rank=0/4] Train=2275, Val=119, Test=40, Total=2434
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=42][rank=0/4] Train=5772, Val=200, Test=40, Total=6012
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=43][rank=0/4] Train=1694, Val=89, Test=40, Total=1823
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=44][rank=0/4] Train=7916, Val=200, Test=40, Total=8156
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=45][rank=0/4] Train=1901, Val=100, Test=40, Total=2041
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=46][rank=0/4] Train=2100, Val=110, Test=40, Total=2250
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=47][rank=0/4] Train=2812, Val=147, Test=40, Total=2999
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=48][rank=0/4] Train=880, Val=46, Test=40, Total=966
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=49][rank=0/4] Train=2521, Val=132, Test=40, Total=2693
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=50][rank=0/4] Train=2527, Val=133, Test=40, Total=2700
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=51][rank=0/4] Train=1580, Val=83, Test=40, Total=1703
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=52][rank=0/4] Train=3589, Val=188, Test=40, Total=3817
2025-10-09 08:49:31 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=53][rank=0/4] Train=6791, Val=200, Test=40, Total=7031
2025-10-09 08:49:32 (federatedscope.core.configs.config:256) INFO: the used configs are: 
adapter:
  use: False
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  load_splits: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  save_splits: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.9, 0.09, 0.01]
  splits_path: ./final_data_splits
  splitter: meta
  splitter_args: []
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: reddit-tldr-comparison-choice@llm
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 2
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 0
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: False
  freq: 500
  metrics: ['loss', 'acc']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['val', 'test']
expname: 
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_idx_for_local_train: 0
  client_num: 53
  data_weighted_aggr: False
  ignore_weight: True
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 5
  sample_client_rate: -1.0
  sampler: cluster
  save_client_model: False
  save_freq: 100
  save_to: checkpoints_1.0_oracle/tldr_choice_qwen_fedbis_oracle_u9.ckpt
  share_local_model: True
  total_round_num: 241
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  use: False
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: -1.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
llm:
  accelerator:
    config: 
    use: True
  adapter:
    args: [{'adapter_package': 'peft', 'adapter_method': 'lora', 'r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']}]
    balance: True
    boundaries: []
    cluster_runtime: {'schedule_file': 'exp/tldr/choice_qwen/gfl/fedbis_oracle_u9_1.0/cluster_schedule/cluster_schedule_u9.json'}
    clusters: [[2, 8, 11], [4], [5], [6, 15, 16, 20, 22, 28, 36, 40, 43, 48, 50, 51], [7, 9, 12, 17, 33, 35, 42], [3, 21, 31, 32, 37, 41], [24, 25, 27, 30, 44], [1, 26, 29, 34, 45, 47], [10, 13, 14, 18, 19, 23, 38, 39, 46, 49, 52, 53]]
    clusters_file: fedbiscuit_script/tldr/clusters_u9_53.json
    count: 9
    grouping:
      round: 50
      use: False
    local_only: False
    mv_to_cpu: False
    per_client_target: 18.867924528301888
    round_budget: 200
    round_ends: [19, 38, 57, 103, 130, 153, 172, 195, 241]
    round_physical: []
    sample_num_per_adapter: [3, 1, 1, 5, 5, 5, 5, 5, 5]
    target_per_round: 5
    use: True
    warmup:
      round: 0
      use: True
  cache:
    model: 
  chat:
    max_history_len: 10
    max_len: 1024
  deepspeed:
    ds_config: 
    use: False
  fedrlhf:
    config_file: 
    frequency: 100
    pretrained: False
    train:
      batch_or_epoch: batch
      local_update_steps: 10
    use: False
  grad_accum_step: 2
  max_new_token: 60
  num_completions: 2
  offsite_tuning:
    emu_align:
      data:
        root: data
        splits: [0.8, 0.1, 0.1]
        type: alpaca@llm
      exit_after_align: False
      init_enable_ground_truth: False
      initial_only: True
      kl_divergence: raw
      layerwise_distill: False
      restore_from: 
      save_to: 
      sim_loss: l2
      train:
        batch_or_epoch: batch
        enable_ground_truth: False
        initial_update_rounds: 50
        kd_loss_weight: 0.9
        lm_loss_weight: 0.1
        local_update_steps: 10
        optimizer:
          lr: 0.01
          type: SGD
      use: False
    emu_l: 1
    emu_r: 10
    eval_type: emu
    kwargs: [{}]
    llm_generated:
      ratio: 0.1
      use: False
    save_full_model: False
    strategy: drop_layer
    use: False
  retry_on_nan_loss: False
  reward_coeff: 0.1
  rlhf: False
  tok_len: 1024
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  llm_kwargs: [{}]
  llm_type: CausalLM
  load_from_local_pretrained_fs_config: 
  load_from_local_pretrained_model_path: 
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 1
  pretrain_tasks: []
  stage: 
  task: node
  type: Qwen/Qwen2-0.5B@huggingface_llm
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp/tldr/choice_qwen/gfl/fedbis_oracle_u9_1.0
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 30
  lr: 1e-05
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.0
  type: 
seed: 0
sgdmf:
  use: False
train:
  batch_or_epoch: batch
  data_para_dids: []
  is_enable_half: True
  local_update_steps: 30
  optimizer:
    betas: (0.9, 0.95)
    lr: 1e-05
    type: AdamW
  scheduler:
    gamma: 1.0
    milestones: [75, 125]
    type: 
    warmup_ratio: 0.0
trainer:
  choices: ['A', 'B']
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: llmrewardchoicetrainer
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-10-09 08:49:33 (federatedscope.core.auxiliaries.utils:175) INFO: The device information file is not provided
2025-10-09 08:49:33 (federatedscope.core.auxiliaries.model_builder:139) WARNING: The input shape is None. Please specify the `data.input_shape`(a tuple) or give the representative data to `get_model` if necessary
2025-10-09 08:49:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-build][rank=0] tok_len=151643 | base=Qwen2ForCausalLM | in_emb=(Embedding) num=151646 ptr=140159704981568 | out_emb=(Linear) num=151646 ptr=140159704981568 | lora_ptr=None
2025-10-09 08:49:48 (federatedscope.core.fed_runner:211) INFO: Server has been set up ... 
2025-10-09 08:49:50 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:49:53 (federatedscope.core.fed_runner:275) INFO: Client 1 has been set up ... 
2025-10-09 08:49:53 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:49:56 (federatedscope.core.fed_runner:275) INFO: Client 2 has been set up ... 
2025-10-09 08:49:56 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:49:58 (federatedscope.core.fed_runner:275) INFO: Client 3 has been set up ... 
2025-10-09 08:49:59 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:02 (federatedscope.core.fed_runner:275) INFO: Client 4 has been set up ... 
2025-10-09 08:50:02 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:04 (federatedscope.core.fed_runner:275) INFO: Client 5 has been set up ... 
2025-10-09 08:50:05 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:08 (federatedscope.core.fed_runner:275) INFO: Client 6 has been set up ... 
2025-10-09 08:50:08 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:10 (federatedscope.core.fed_runner:275) INFO: Client 7 has been set up ... 
2025-10-09 08:50:11 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:13 (federatedscope.core.fed_runner:275) INFO: Client 8 has been set up ... 
2025-10-09 08:50:13 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:17 (federatedscope.core.fed_runner:275) INFO: Client 9 has been set up ... 
2025-10-09 08:50:18 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:20 (federatedscope.core.fed_runner:275) INFO: Client 10 has been set up ... 
2025-10-09 08:50:20 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:23 (federatedscope.core.fed_runner:275) INFO: Client 11 has been set up ... 
2025-10-09 08:50:23 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:26 (federatedscope.core.fed_runner:275) INFO: Client 12 has been set up ... 
2025-10-09 08:50:26 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:29 (federatedscope.core.fed_runner:275) INFO: Client 13 has been set up ... 
2025-10-09 08:50:29 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:32 (federatedscope.core.fed_runner:275) INFO: Client 14 has been set up ... 
2025-10-09 08:50:32 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:34 (federatedscope.core.fed_runner:275) INFO: Client 15 has been set up ... 
2025-10-09 08:50:35 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:37 (federatedscope.core.fed_runner:275) INFO: Client 16 has been set up ... 
2025-10-09 08:50:37 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:41 (federatedscope.core.fed_runner:275) INFO: Client 17 has been set up ... 
2025-10-09 08:50:41 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:44 (federatedscope.core.fed_runner:275) INFO: Client 18 has been set up ... 
2025-10-09 08:50:44 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:47 (federatedscope.core.fed_runner:275) INFO: Client 19 has been set up ... 
2025-10-09 08:50:47 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:50 (federatedscope.core.fed_runner:275) INFO: Client 20 has been set up ... 
2025-10-09 08:50:50 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:52 (federatedscope.core.fed_runner:275) INFO: Client 21 has been set up ... 
2025-10-09 08:50:53 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:55 (federatedscope.core.fed_runner:275) INFO: Client 22 has been set up ... 
2025-10-09 08:50:55 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:50:58 (federatedscope.core.fed_runner:275) INFO: Client 23 has been set up ... 
2025-10-09 08:50:59 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:01 (federatedscope.core.fed_runner:275) INFO: Client 24 has been set up ... 
2025-10-09 08:51:01 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:04 (federatedscope.core.fed_runner:275) INFO: Client 25 has been set up ... 
2025-10-09 08:51:04 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:08 (federatedscope.core.fed_runner:275) INFO: Client 26 has been set up ... 
2025-10-09 08:51:08 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:11 (federatedscope.core.fed_runner:275) INFO: Client 27 has been set up ... 
2025-10-09 08:51:11 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:13 (federatedscope.core.fed_runner:275) INFO: Client 28 has been set up ... 
2025-10-09 08:51:14 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:16 (federatedscope.core.fed_runner:275) INFO: Client 29 has been set up ... 
2025-10-09 08:51:16 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:19 (federatedscope.core.fed_runner:275) INFO: Client 30 has been set up ... 
2025-10-09 08:51:19 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:22 (federatedscope.core.fed_runner:275) INFO: Client 31 has been set up ... 
2025-10-09 08:51:22 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:25 (federatedscope.core.fed_runner:275) INFO: Client 32 has been set up ... 
2025-10-09 08:51:25 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:28 (federatedscope.core.fed_runner:275) INFO: Client 33 has been set up ... 
2025-10-09 08:51:28 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:31 (federatedscope.core.fed_runner:275) INFO: Client 34 has been set up ... 
2025-10-09 08:51:32 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:34 (federatedscope.core.fed_runner:275) INFO: Client 35 has been set up ... 
2025-10-09 08:51:34 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:37 (federatedscope.core.fed_runner:275) INFO: Client 36 has been set up ... 
2025-10-09 08:51:37 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:40 (federatedscope.core.fed_runner:275) INFO: Client 37 has been set up ... 
2025-10-09 08:51:40 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:43 (federatedscope.core.fed_runner:275) INFO: Client 38 has been set up ... 
2025-10-09 08:51:43 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:45 (federatedscope.core.fed_runner:275) INFO: Client 39 has been set up ... 
2025-10-09 08:51:46 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:48 (federatedscope.core.fed_runner:275) INFO: Client 40 has been set up ... 
2025-10-09 08:51:48 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:51 (federatedscope.core.fed_runner:275) INFO: Client 41 has been set up ... 
2025-10-09 08:51:51 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:54 (federatedscope.core.fed_runner:275) INFO: Client 42 has been set up ... 
2025-10-09 08:51:54 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:51:58 (federatedscope.core.fed_runner:275) INFO: Client 43 has been set up ... 
2025-10-09 08:51:58 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:01 (federatedscope.core.fed_runner:275) INFO: Client 44 has been set up ... 
2025-10-09 08:52:01 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:03 (federatedscope.core.fed_runner:275) INFO: Client 45 has been set up ... 
2025-10-09 08:52:04 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:06 (federatedscope.core.fed_runner:275) INFO: Client 46 has been set up ... 
2025-10-09 08:52:06 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:09 (federatedscope.core.fed_runner:275) INFO: Client 47 has been set up ... 
2025-10-09 08:52:09 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:11 (federatedscope.core.fed_runner:275) INFO: Client 48 has been set up ... 
2025-10-09 08:52:12 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:14 (federatedscope.core.fed_runner:275) INFO: Client 49 has been set up ... 
2025-10-09 08:52:15 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:17 (federatedscope.core.fed_runner:275) INFO: Client 50 has been set up ... 
2025-10-09 08:52:17 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:21 (federatedscope.core.fed_runner:275) INFO: Client 51 has been set up ... 
2025-10-09 08:52:21 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:23 (federatedscope.core.fed_runner:275) INFO: Client 52 has been set up ... 
2025-10-09 08:52:24 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 08:52:26 (federatedscope.core.fed_runner:275) INFO: Client 53 has been set up ... 
2025-10-09 08:52:26 (federatedscope.core.trainers.trainer:569) INFO: Model meta-info: <class 'federatedscope.llm.model.adapter_builder.AdapterModel'>.
2025-10-09 08:52:26 (federatedscope.core.trainers.trainer:584) INFO: Num of original para names: 3360.
2025-10-09 08:52:26 (federatedscope.core.trainers.trainer:585) INFO: Num of original trainable para names: 3650.
2025-10-09 08:52:26 (federatedscope.core.trainers.trainer:587) INFO: Num of preserved para names in local update: 3360. 
Preserved para names in local update: {'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_7.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_8.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_7.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_8.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_3.weight'}.
2025-10-09 08:52:26 (federatedscope.core.trainers.trainer:591) INFO: Num of filtered para names in local update: 0. 
Filtered para names in local update: set().
2025-10-09 08:52:26 (federatedscope.core.trainers.trainer:599) INFO: After register default hooks,
	the hooks_in_train is:
	{
	  "on_fit_start": [
	    "_hook_on_fit_start_numerical_precision",
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init",
	    "_hook_on_fit_start_calculate_model_size"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward",
	    "_hook_on_batch_forward_regularizer",
	    "_hook_on_batch_forward_flop_count"
	  ],
	  "on_batch_backward": [
	    "_hook_on_batch_backward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_on_fit_end_free_space"
	  ]
	};
	the hooks_in_eval is:
            t{
	  "on_fit_start": [
	    "_hook_on_fit_start_numerical_precision",
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_on_fit_end_free_space"
	  ]
	}
2025-10-09 08:52:26 (federatedscope.llm.llm_local.server:147) INFO: Waited all clients join, start now...
2025-10-09 08:52:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=0 aidx=0 | s=3 (candidates=3)
2025-10-09 08:52:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 08:52:27 (federatedscope.llm.llm_local.server:161) INFO: ----------- Starting training (Round #0) -------------
2025-10-09 08:52:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:52:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:52:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-09 08:52:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 08:52:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140159704981568 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:52:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:52:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:52:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:52:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:53:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:53:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.507202, avg_loss=0.715640, seen=480, correct=245, accuracy=0.510417
2025-10-09 08:53:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:53:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:53:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:53:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=1970MB allocated=1844MB
2025-10-09 08:53:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.73548412322998, 'train_avg_loss': 0.6894623676935832, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 08:53:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.5072021484375, 'train_avg_loss': 0.7156400044759115, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 08:53:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 343.5072021484375, 'train_avg_loss': 0.7156400044759115, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 08:53:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:53:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:53:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-09 08:53:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 08:53:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:53:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:53:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:53:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:53:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:54:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:54:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.818420, avg_loss=0.728788, seen=480, correct=239, accuracy=0.497917
2025-10-09 08:54:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:54:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:54:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:54:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=1914MB allocated=1852MB
2025-10-09 08:54:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.20781219005585, 'train_avg_loss': 0.7350651015837987, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 08:54:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.81842041015625, 'train_avg_loss': 0.7287883758544922, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 08:54:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 349.81842041015625, 'train_avg_loss': 0.7287883758544922, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 08:54:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:54:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:54:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-09 08:54:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 08:54:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:54:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:54:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:54:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:54:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:54:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:54:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.106598, avg_loss=0.716889, seen=480, correct=247, accuracy=0.514583
2025-10-09 08:54:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:54:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:54:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:54:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=1994MB allocated=1861MB
2025-10-09 08:54:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.35116511583328, 'train_avg_loss': 0.7112597092986107, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 08:54:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.1065979003906, 'train_avg_loss': 0.7168887456258138, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 08:54:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 344.1065979003906, 'train_avg_loss': 0.7168887456258138, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 08:54:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #1) -------------
2025-10-09 08:54:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=1 aidx=0 | s=3 (candidates=3)
2025-10-09 08:54:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-09 08:54:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:54:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:54:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-09 08:54:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 08:54:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:54:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:54:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:54:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:54:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:55:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:55:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.385162, avg_loss=0.700802, seen=480, correct=244, accuracy=0.508333
2025-10-09 08:55:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:55:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:55:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:55:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=1992MB allocated=1869MB
2025-10-09 08:55:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.13114798069, 'train_avg_loss': 0.69275956650575, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 08:55:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.3851623535156, 'train_avg_loss': 0.7008024215698242, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 08:55:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 336.3851623535156, 'train_avg_loss': 0.7008024215698242, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 08:55:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:55:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:55:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-09 08:55:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 08:55:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:55:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:55:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:55:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:55:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:56:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:56:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.703796, avg_loss=0.688966, seen=480, correct=267, accuracy=0.556250
2025-10-09 08:56:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:56:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:56:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:56:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2008MB allocated=1869MB
2025-10-09 08:56:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5049124956131, 'train_avg_loss': 0.6708742707967759, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 08:56:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.70379638671875, 'train_avg_loss': 0.6889662424723307, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 08:56:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 330.70379638671875, 'train_avg_loss': 0.6889662424723307, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 08:56:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:56:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:56:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-09 08:56:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 08:56:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:56:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:56:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:56:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:56:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:56:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:56:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.041077, avg_loss=0.712586, seen=480, correct=220, accuracy=0.458333
2025-10-09 08:56:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:56:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:56:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:56:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=1992MB allocated=1869MB
2025-10-09 08:56:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.07169830799103, 'train_avg_loss': 0.7339308192332585, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-09 08:56:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.04107666015625, 'train_avg_loss': 0.7125855763753255, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-09 08:56:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 342.04107666015625, 'train_avg_loss': 0.7125855763753255, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-09 08:56:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #2) -------------
2025-10-09 08:56:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=2 aidx=0 | s=3 (candidates=3)
2025-10-09 08:56:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 08:56:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 08:56:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:56:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:57:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:57:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.687683, avg_loss=0.688933, seen=480, correct=267, accuracy=0.556250
2025-10-09 08:57:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:57:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:57:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:57:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=1982MB allocated=1794MB
2025-10-09 08:57:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.57040596008301, 'train_avg_loss': 0.6797533830006918, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 08:57:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.68768310546875, 'train_avg_loss': 0.6889326731363933, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 08:57:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 330.68768310546875, 'train_avg_loss': 0.6889326731363933, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 08:57:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:57:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:57:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-09 08:57:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 08:57:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:57:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:57:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:57:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:57:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:58:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:58:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.460876, avg_loss=0.694710, seen=480, correct=248, accuracy=0.516667
2025-10-09 08:58:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:58:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:58:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:58:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=1920MB allocated=1794MB
2025-10-09 08:58:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26306587457657, 'train_avg_loss': 0.6855255489548048, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 08:58:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.46087646484375, 'train_avg_loss': 0.6947101593017578, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 08:58:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 333.46087646484375, 'train_avg_loss': 0.6947101593017578, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 08:58:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:58:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:58:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-09 08:58:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 08:58:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:58:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:58:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:58:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:58:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:59:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:59:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.472687, avg_loss=0.703068, seen=480, correct=230, accuracy=0.479167
2025-10-09 08:59:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:59:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:59:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:59:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=1908MB allocated=1794MB
2025-10-09 08:59:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.45049595832825, 'train_avg_loss': 0.7204207996527354, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 08:59:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.4726867675781, 'train_avg_loss': 0.7030680974324545, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 08:59:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 337.4726867675781, 'train_avg_loss': 0.7030680974324545, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 08:59:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #3) -------------
2025-10-09 08:59:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=3 aidx=0 | s=3 (candidates=3)
2025-10-09 08:59:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-09 08:59:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 08:59:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 08:59:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 08:59:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 08:59:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.902496, avg_loss=0.695630, seen=480, correct=251, accuracy=0.522917
2025-10-09 08:59:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 08:59:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 08:59:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 08:59:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=1920MB allocated=1794MB
2025-10-09 08:59:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.23512667417526, 'train_avg_loss': 0.6852927222847939, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 08:59:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9024963378906, 'train_avg_loss': 0.6956302007039388, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 08:59:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 333.9024963378906, 'train_avg_loss': 0.6956302007039388, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 08:59:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:00:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:00:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:00:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:00:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.400818, avg_loss=0.688335, seen=480, correct=261, accuracy=0.543750
2025-10-09 09:00:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:00:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:00:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:00:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=1980MB allocated=1794MB
2025-10-09 09:00:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36512249708176, 'train_avg_loss': 0.6780426874756813, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 09:00:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.40081787109375, 'train_avg_loss': 0.6883350372314453, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 09:00:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 330.40081787109375, 'train_avg_loss': 0.6883350372314453, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 09:00:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:00:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:00:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:01:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:01:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.227051, avg_loss=0.696306, seen=480, correct=235, accuracy=0.489583
2025-10-09 09:01:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:01:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:01:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:01:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=1908MB allocated=1794MB
2025-10-09 09:01:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.23240876197815, 'train_avg_loss': 0.7102700730164846, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 09:01:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.22705078125, 'train_avg_loss': 0.6963063557942708, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 09:01:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 334.22705078125, 'train_avg_loss': 0.6963063557942708, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 09:01:29 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #4) -------------
2025-10-09 09:01:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=4 aidx=0 | s=3 (candidates=3)
2025-10-09 09:01:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 09:01:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:01:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:01:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-09 09:01:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:01:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:01:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:01:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:01:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:01:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:02:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:02:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.066833, avg_loss=0.691806, seen=480, correct=259, accuracy=0.539583
2025-10-09 09:02:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:02:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:02:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:02:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=1920MB allocated=1794MB
2025-10-09 09:02:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78275382518768, 'train_avg_loss': 0.6815229485432307, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 09:02:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.06683349609375, 'train_avg_loss': 0.691805903116862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 09:02:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 332.06683349609375, 'train_avg_loss': 0.691805903116862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 09:02:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:02:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:02:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:02:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:02:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.110687, avg_loss=0.687731, seen=480, correct=251, accuracy=0.522917
2025-10-09 09:02:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:02:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:03:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:03:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=1908MB allocated=1794MB
2025-10-09 09:03:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43496245145798, 'train_avg_loss': 0.7036246870954831, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 09:03:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1106872558594, 'train_avg_loss': 0.6877305984497071, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 09:03:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 330.1106872558594, 'train_avg_loss': 0.6877305984497071, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 09:03:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:03:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:03:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:03:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:03:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.966553, avg_loss=0.689514, seen=480, correct=254, accuracy=0.529167
2025-10-09 09:03:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:03:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:03:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:03:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=1980MB allocated=1794MB
2025-10-09 09:03:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61819326877594, 'train_avg_loss': 0.6801516105731328, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 09:03:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.966552734375, 'train_avg_loss': 0.6895136515299479, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 09:03:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 330.966552734375, 'train_avg_loss': 0.6895136515299479, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 09:03:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #5) -------------
2025-10-09 09:03:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=5 aidx=0 | s=3 (candidates=3)
2025-10-09 09:03:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 2, 11] (from 3)
2025-10-09 09:03:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:03:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:03:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:04:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:04:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.566833, avg_loss=0.688681, seen=480, correct=248, accuracy=0.516667
2025-10-09 09:04:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:04:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:04:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:04:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=1908MB allocated=1794MB
2025-10-09 09:04:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36256206035614, 'train_avg_loss': 0.7030213505029679, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 09:04:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.56683349609375, 'train_avg_loss': 0.688680903116862, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 09:04:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 330.56683349609375, 'train_avg_loss': 0.688680903116862, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 09:04:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:04:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:04:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-09 09:04:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:04:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:04:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:04:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:04:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:04:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:05:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:05:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.035797, avg_loss=0.670908, seen=480, correct=292, accuracy=0.608333
2025-10-09 09:05:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:05:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:05:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:05:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=1980MB allocated=1794MB
2025-10-09 09:05:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.89446496963501, 'train_avg_loss': 0.6491205414136251, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-09 09:05:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.0357971191406, 'train_avg_loss': 0.6709079106648763, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 09:05:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 322.0357971191406, 'train_avg_loss': 0.6709079106648763, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 09:05:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:05:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:05:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-09 09:05:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:05:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:05:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:05:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:05:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:05:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:05:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:05:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.006592, avg_loss=0.689597, seen=480, correct=253, accuracy=0.527083
2025-10-09 09:05:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:05:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:05:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:05:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=1920MB allocated=1794MB
2025-10-09 09:05:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00579881668091, 'train_avg_loss': 0.6833816568056742, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 09:05:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.006591796875, 'train_avg_loss': 0.6895970662434896, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 09:05:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 331.006591796875, 'train_avg_loss': 0.6895970662434896, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 09:05:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #6) -------------
2025-10-09 09:05:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=6 aidx=0 | s=3 (candidates=3)
2025-10-09 09:05:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 11, 2] (from 3)
2025-10-09 09:05:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:05:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:05:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-09 09:05:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:05:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:05:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:05:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:05:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:05:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:06:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:06:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.547180, avg_loss=0.686557, seen=480, correct=252, accuracy=0.525000
2025-10-09 09:06:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:06:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:06:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:06:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=1908MB allocated=1794MB
2025-10-09 09:06:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91427558660507, 'train_avg_loss': 0.6992856298883756, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 09:06:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.54718017578125, 'train_avg_loss': 0.686556625366211, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 09:06:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 329.54718017578125, 'train_avg_loss': 0.686556625366211, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 09:06:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:06:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:06:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-09 09:06:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:06:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:06:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:06:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:06:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:06:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:07:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:07:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.589355, avg_loss=0.682478, seen=480, correct=261, accuracy=0.543750
2025-10-09 09:07:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:07:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:07:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:07:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=1920MB allocated=1794MB
2025-10-09 09:07:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31017792224884, 'train_avg_loss': 0.6775848160187403, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 09:07:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.58935546875, 'train_avg_loss': 0.6824778238932292, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 09:07:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 327.58935546875, 'train_avg_loss': 0.6824778238932292, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 09:07:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:07:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:07:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:07:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:07:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.385193, avg_loss=0.669552, seen=480, correct=285, accuracy=0.593750
2025-10-09 09:07:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:07:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:07:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:08:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=1980MB allocated=1794MB
2025-10-09 09:08:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.98893570899963, 'train_avg_loss': 0.6415744642416636, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 09:08:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.38519287109375, 'train_avg_loss': 0.6695524851481119, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 09:08:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 321.38519287109375, 'train_avg_loss': 0.6695524851481119, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 09:08:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #7) -------------
2025-10-09 09:08:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=7 aidx=0 | s=3 (candidates=3)
2025-10-09 09:08:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 8, 11] (from 3)
2025-10-09 09:08:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:08:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:08:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-09 09:08:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:08:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:08:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:08:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:08:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:08:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:08:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:08:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.651855, avg_loss=0.653441, seen=480, correct=303, accuracy=0.631250
2025-10-09 09:08:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:08:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:08:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:08:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=1980MB allocated=1794MB
2025-10-09 09:08:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.47630774974823, 'train_avg_loss': 0.6123025645812352, 'train_seen': 120, 'train_correct': 91, 'train_acc': 0.7583333333333333}}
2025-10-09 09:08:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.65185546875, 'train_avg_loss': 0.6534413655598958, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 09:08:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 313.65185546875, 'train_avg_loss': 0.6534413655598958, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 09:08:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:08:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:08:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:09:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:09:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.685181, avg_loss=0.682677, seen=480, correct=265, accuracy=0.552083
2025-10-09 09:09:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:09:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:09:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:09:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=1908MB allocated=1794MB
2025-10-09 09:09:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3387656211853, 'train_avg_loss': 0.7028230468432108, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 09:09:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6851806640625, 'train_avg_loss': 0.6826774597167968, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 09:09:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 327.6851806640625, 'train_avg_loss': 0.6826774597167968, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 09:09:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:09:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:09:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:10:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:10:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.277679, avg_loss=0.679745, seen=480, correct=268, accuracy=0.558333
2025-10-09 09:10:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:10:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:10:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:10:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=1920MB allocated=1794MB
2025-10-09 09:10:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.89459085464478, 'train_avg_loss': 0.6824549237887064, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 09:10:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.2776794433594, 'train_avg_loss': 0.6797451655069987, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 09:10:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 326.2776794433594, 'train_avg_loss': 0.6797451655069987, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 09:10:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #8) -------------
2025-10-09 09:10:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=8 aidx=0 | s=3 (candidates=3)
2025-10-09 09:10:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 8, 11] (from 3)
2025-10-09 09:10:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:10:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:10:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-09 09:10:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:10:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:10:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:10:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:10:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:10:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:10:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:10:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.234589, avg_loss=0.648405, seen=480, correct=296, accuracy=0.616667
2025-10-09 09:10:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:10:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:10:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:10:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=1980MB allocated=1794MB
2025-10-09 09:10:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.88585126399994, 'train_avg_loss': 0.5990487605333328, 'train_seen': 120, 'train_correct': 90, 'train_acc': 0.75}}
2025-10-09 09:10:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.2345886230469, 'train_avg_loss': 0.648405392964681, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 09:10:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 311.2345886230469, 'train_avg_loss': 0.648405392964681, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 09:10:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:10:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:10:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:11:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:11:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.676086, avg_loss=0.680575, seen=480, correct=270, accuracy=0.562500
2025-10-09 09:11:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:11:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:11:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:11:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=1908MB allocated=1794MB
2025-10-09 09:11:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.76200836896896, 'train_avg_loss': 0.6980167364080747, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 09:11:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.67608642578125, 'train_avg_loss': 0.680575180053711, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 09:11:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 326.67608642578125, 'train_avg_loss': 0.680575180053711, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 09:11:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:11:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:11:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-09 09:11:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:11:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:11:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:11:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:11:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:11:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:12:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:12:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.695984, avg_loss=0.672283, seen=480, correct=278, accuracy=0.579167
2025-10-09 09:12:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:12:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:12:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:12:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=1920MB allocated=1794MB
2025-10-09 09:12:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.30701225996017, 'train_avg_loss': 0.6775584354996681, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:12:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.69598388671875, 'train_avg_loss': 0.6722832997639974, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 09:12:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 322.69598388671875, 'train_avg_loss': 0.6722832997639974, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 09:12:20 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #9) -------------
2025-10-09 09:12:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=9 aidx=0 | s=3 (candidates=3)
2025-10-09 09:12:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 2, 11] (from 3)
2025-10-09 09:12:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:12:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:12:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:13:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:13:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.007690, avg_loss=0.677099, seen=480, correct=277, accuracy=0.577083
2025-10-09 09:13:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:13:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:13:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:13:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=1908MB allocated=1794MB
2025-10-09 09:13:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37361490726471, 'train_avg_loss': 0.6947801242272059, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 09:13:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0076904296875, 'train_avg_loss': 0.6770993550618489, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 09:13:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 325.0076904296875, 'train_avg_loss': 0.6770993550618489, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 09:13:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:13:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:13:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-09 09:13:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:13:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:13:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:13:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:13:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:13:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:13:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:13:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.169403, avg_loss=0.646186, seen=480, correct=307, accuracy=0.639583
2025-10-09 09:13:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:13:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:13:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:13:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=1980MB allocated=1794MB
2025-10-09 09:13:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.40612703561783, 'train_avg_loss': 0.5867177252968152, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 09:13:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.1694030761719, 'train_avg_loss': 0.6461862564086914, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 09:13:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 310.1694030761719, 'train_avg_loss': 0.6461862564086914, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 09:13:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:13:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:13:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:14:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:14:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.378815, avg_loss=0.663289, seen=480, correct=294, accuracy=0.612500
2025-10-09 09:14:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:14:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:14:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:14:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=1920MB allocated=1794MB
2025-10-09 09:14:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.32211339473724, 'train_avg_loss': 0.6776842782894771, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 09:14:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.3788146972656, 'train_avg_loss': 0.66328919728597, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 09:14:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 318.3788146972656, 'train_avg_loss': 0.66328919728597, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 09:14:33 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #10) -------------
2025-10-09 09:14:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=10 aidx=0 | s=3 (candidates=3)
2025-10-09 09:14:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 09:14:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:14:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:14:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:15:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:15:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.820343, avg_loss=0.641292, seen=480, correct=306, accuracy=0.637500
2025-10-09 09:15:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:15:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:15:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:15:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=1980MB allocated=1794MB
2025-10-09 09:15:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.6660236120224, 'train_avg_loss': 0.57221686343352, 'train_seen': 120, 'train_correct': 96, 'train_acc': 0.8}}
2025-10-09 09:15:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.8203430175781, 'train_avg_loss': 0.6412923812866211, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 09:15:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 307.8203430175781, 'train_avg_loss': 0.6412923812866211, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 09:15:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:15:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:15:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:16:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:16:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.011841, avg_loss=0.652108, seen=480, correct=300, accuracy=0.625000
2025-10-09 09:16:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:16:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:16:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:16:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=1920MB allocated=1794MB
2025-10-09 09:16:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58709412813187, 'train_avg_loss': 0.6798924510677655, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:16:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.0118408203125, 'train_avg_loss': 0.6521080017089844, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 09:16:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 313.0118408203125, 'train_avg_loss': 0.6521080017089844, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 09:16:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:16:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:16:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:16:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:16:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.083282, avg_loss=0.673090, seen=480, correct=291, accuracy=0.606250
2025-10-09 09:16:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:16:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:16:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:16:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=1908MB allocated=1794MB
2025-10-09 09:16:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.89620369672775, 'train_avg_loss': 0.6908016974727312, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 09:16:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0832824707031, 'train_avg_loss': 0.6730901718139648, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 09:16:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 323.0832824707031, 'train_avg_loss': 0.6730901718139648, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 09:16:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #11) -------------
2025-10-09 09:16:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=11 aidx=0 | s=3 (candidates=3)
2025-10-09 09:16:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 09:16:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:16:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:16:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:17:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:17:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.298523, avg_loss=0.642289, seen=480, correct=298, accuracy=0.620833
2025-10-09 09:17:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:17:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:17:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:17:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=1980MB allocated=1794MB
2025-10-09 09:17:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.58907896280289, 'train_avg_loss': 0.5632423246900241, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 09:17:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.29852294921875, 'train_avg_loss': 0.6422885894775391, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 09:17:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 308.29852294921875, 'train_avg_loss': 0.6422885894775391, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 09:17:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:17:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:17:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-09 09:17:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:17:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:17:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:17:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:17:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:17:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:18:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:18:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.341614, avg_loss=0.650712, seen=480, correct=302, accuracy=0.629167
2025-10-09 09:18:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:18:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:18:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:18:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=1920MB allocated=1794MB
2025-10-09 09:18:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51112282276154, 'train_avg_loss': 0.6792593568563461, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:18:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.34161376953125, 'train_avg_loss': 0.6507116953531901, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 09:18:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 312.34161376953125, 'train_avg_loss': 0.6507116953531901, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 09:18:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:18:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:18:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:19:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:19:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.864807, avg_loss=0.662218, seen=480, correct=305, accuracy=0.635417
2025-10-09 09:19:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:19:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:19:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:19:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=1908MB allocated=1794MB
2025-10-09 09:19:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.8111914396286, 'train_avg_loss': 0.6817599286635717, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 09:19:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.86480712890625, 'train_avg_loss': 0.6622183481852214, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 09:19:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 317.86480712890625, 'train_avg_loss': 0.6622183481852214, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 09:19:09 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #12) -------------
2025-10-09 09:19:10 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=12 aidx=0 | s=3 (candidates=3)
2025-10-09 09:19:10 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 09:19:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:19:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:19:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-09 09:19:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:19:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:19:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:19:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:19:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:19:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:19:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:19:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.985474, avg_loss=0.649970, seen=480, correct=299, accuracy=0.622917
2025-10-09 09:19:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:19:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:19:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:19:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=1920MB allocated=1794MB
2025-10-09 09:19:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3515152335167, 'train_avg_loss': 0.6779292936126391, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 09:19:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.9854736328125, 'train_avg_loss': 0.649969736735026, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 09:19:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 311.9854736328125, 'train_avg_loss': 0.649969736735026, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 09:19:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:20:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:20:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:20:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:20:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.884888, avg_loss=0.647677, seen=480, correct=315, accuracy=0.656250
2025-10-09 09:20:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:20:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:20:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:20:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=1908MB allocated=1794MB
2025-10-09 09:20:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.91449916362762, 'train_avg_loss': 0.6659541596968969, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 09:20:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8848876953125, 'train_avg_loss': 0.6476768493652344, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 09:20:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 310.8848876953125, 'train_avg_loss': 0.6476768493652344, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 09:20:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:20:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:20:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-09 09:20:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:20:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:20:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:20:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:20:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:20:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:21:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:21:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.338409, avg_loss=0.640288, seen=480, correct=288, accuracy=0.600000
2025-10-09 09:21:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:21:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:21:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:21:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=1980MB allocated=1794MB
2025-10-09 09:21:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 66.64774137735367, 'train_avg_loss': 0.5553978448112805, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 09:21:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.3384094238281, 'train_avg_loss': 0.6402883529663086, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 09:21:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 307.3384094238281, 'train_avg_loss': 0.6402883529663086, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 09:21:29 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #13) -------------
2025-10-09 09:21:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=13 aidx=0 | s=3 (candidates=3)
2025-10-09 09:21:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 09:21:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:21:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:21:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:22:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:22:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.430603, avg_loss=0.646730, seen=480, correct=300, accuracy=0.625000
2025-10-09 09:22:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:22:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:22:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:22:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=1920MB allocated=1794MB
2025-10-09 09:22:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51490885019302, 'train_avg_loss': 0.6792909070849419, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:22:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.43060302734375, 'train_avg_loss': 0.6467304229736328, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 09:22:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 310.43060302734375, 'train_avg_loss': 0.6467304229736328, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 09:22:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:22:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:22:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:22:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:22:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.227966, avg_loss=0.648392, seen=480, correct=312, accuracy=0.650000
2025-10-09 09:22:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:22:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:23:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:23:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=1908MB allocated=1794MB
2025-10-09 09:23:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.1418896317482, 'train_avg_loss': 0.6678490802645684, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 09:23:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.22796630859375, 'train_avg_loss': 0.648391596476237, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 09:23:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 311.22796630859375, 'train_avg_loss': 0.648391596476237, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 09:23:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:23:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:23:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:23:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:23:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.259674, avg_loss=0.615124, seen=480, correct=307, accuracy=0.639583
2025-10-09 09:23:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:23:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:23:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:23:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=1980MB allocated=1794MB
2025-10-09 09:23:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 61.59288287162781, 'train_avg_loss': 0.5132740239302317, 'train_seen': 120, 'train_correct': 100, 'train_acc': 0.8333333333333334}}
2025-10-09 09:23:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.2596740722656, 'train_avg_loss': 0.6151243209838867, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 09:23:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 295.2596740722656, 'train_avg_loss': 0.6151243209838867, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 09:23:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #14) -------------
2025-10-09 09:23:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=14 aidx=0 | s=3 (candidates=3)
2025-10-09 09:23:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 09:23:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:23:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:23:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:24:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:24:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.833984, avg_loss=0.647571, seen=480, correct=296, accuracy=0.616667
2025-10-09 09:24:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:24:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:24:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:24:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=1920MB allocated=1794MB
2025-10-09 09:24:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.78102868795395, 'train_avg_loss': 0.6898419057329496, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 09:24:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.833984375, 'train_avg_loss': 0.64757080078125, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 09:24:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 310.833984375, 'train_avg_loss': 0.64757080078125, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 09:24:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:24:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:24:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:25:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:25:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.685913, avg_loss=0.651429, seen=480, correct=303, accuracy=0.631250
2025-10-09 09:25:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:25:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:25:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:25:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=1908MB allocated=1794MB
2025-10-09 09:25:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.92884594202042, 'train_avg_loss': 0.6744070495168368, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 09:25:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.6859130859375, 'train_avg_loss': 0.6514289855957032, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 09:25:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 312.6859130859375, 'train_avg_loss': 0.6514289855957032, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 09:25:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:25:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:25:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:25:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:25:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=281.481232, avg_loss=0.586419, seen=480, correct=320, accuracy=0.666667
2025-10-09 09:25:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:25:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:25:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:25:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=1980MB allocated=1794MB
2025-10-09 09:25:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 55.6625372171402, 'train_avg_loss': 0.46385447680950165, 'train_seen': 120, 'train_correct': 99, 'train_acc': 0.825}}
2025-10-09 09:25:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 281.4812316894531, 'train_avg_loss': 0.5864192326863606, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-09 09:25:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 281.4812316894531, 'train_avg_loss': 0.5864192326863606, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-09 09:25:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #15) -------------
2025-10-09 09:26:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=15 aidx=0 | s=3 (candidates=3)
2025-10-09 09:26:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-09 09:26:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:26:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:26:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:26:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:26:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.517212, avg_loss=0.651078, seen=480, correct=299, accuracy=0.622917
2025-10-09 09:26:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:26:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:26:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:26:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=1920MB allocated=1794MB
2025-10-09 09:26:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73923271894455, 'train_avg_loss': 0.6978269393245379, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:26:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.5172119140625, 'train_avg_loss': 0.6510775248209636, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 09:26:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 312.5172119140625, 'train_avg_loss': 0.6510775248209636, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 09:26:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:26:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:26:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:27:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:27:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=265.641907, avg_loss=0.553421, seen=480, correct=345, accuracy=0.718750
2025-10-09 09:27:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:27:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:27:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:27:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=1980MB allocated=1794MB
2025-10-09 09:27:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 49.19089776277542, 'train_avg_loss': 0.4099241480231285, 'train_seen': 120, 'train_correct': 102, 'train_acc': 0.85}}
2025-10-09 09:27:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 265.64190673828125, 'train_avg_loss': 0.5534206390380859, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 09:27:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 265.64190673828125, 'train_avg_loss': 0.5534206390380859, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 09:27:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:27:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:27:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-09 09:27:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:27:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:27:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:27:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:27:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:27:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:28:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:28:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.475037, avg_loss=0.655156, seen=480, correct=299, accuracy=0.622917
2025-10-09 09:28:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:28:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:28:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:28:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=1908MB allocated=1794MB
2025-10-09 09:28:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.03508114814758, 'train_avg_loss': 0.6752923429012299, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 09:28:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.47503662109375, 'train_avg_loss': 0.6551563262939453, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 09:28:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 314.47503662109375, 'train_avg_loss': 0.6551563262939453, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 09:28:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #16) -------------
2025-10-09 09:28:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=16 aidx=0 | s=3 (candidates=3)
2025-10-09 09:28:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 11, 2] (from 3)
2025-10-09 09:28:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:28:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:28:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:28:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:28:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.327637, avg_loss=0.631933, seen=480, correct=322, accuracy=0.670833
2025-10-09 09:28:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:28:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:28:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:28:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=1908MB allocated=1794MB
2025-10-09 09:28:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.77711009979248, 'train_avg_loss': 0.6481425841649373, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 09:28:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.32763671875, 'train_avg_loss': 0.6319325764973959, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 09:28:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 303.32763671875, 'train_avg_loss': 0.6319325764973959, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 09:28:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:29:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:29:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:29:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:29:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.692871, avg_loss=0.645193, seen=480, correct=300, accuracy=0.625000
2025-10-09 09:29:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:29:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:29:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:29:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=1920MB allocated=1794MB
2025-10-09 09:29:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.69966812431812, 'train_avg_loss': 0.6724972343693177, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 09:29:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.69287109375, 'train_avg_loss': 0.6451934814453125, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 09:29:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 309.69287109375, 'train_avg_loss': 0.6451934814453125, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 09:29:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:29:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:29:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:30:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:30:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=267.268585, avg_loss=0.556810, seen=480, correct=334, accuracy=0.695833
2025-10-09 09:30:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:30:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:30:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:30:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=1980MB allocated=1794MB
2025-10-09 09:30:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 49.542654275894165, 'train_avg_loss': 0.412855452299118, 'train_seen': 120, 'train_correct': 101, 'train_acc': 0.8416666666666667}}
2025-10-09 09:30:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 267.2685852050781, 'train_avg_loss': 0.5568095525105794, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 09:30:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 267.2685852050781, 'train_avg_loss': 0.5568095525105794, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 09:30:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #17) -------------
2025-10-09 09:30:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=17 aidx=0 | s=3 (candidates=3)
2025-10-09 09:30:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 09:30:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:30:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:30:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:31:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:31:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.400726, avg_loss=0.652918, seen=480, correct=296, accuracy=0.616667
2025-10-09 09:31:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:31:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:31:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:31:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=1920MB allocated=1794MB
2025-10-09 09:31:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.20344313979149, 'train_avg_loss': 0.693362026164929, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 09:31:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4007263183594, 'train_avg_loss': 0.6529181798299154, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 09:31:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 313.4007263183594, 'train_avg_loss': 0.6529181798299154, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 09:31:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:31:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:31:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:31:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:31:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.625122, avg_loss=0.640886, seen=480, correct=305, accuracy=0.635417
2025-10-09 09:31:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:31:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:31:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:31:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=1908MB allocated=1794MB
2025-10-09 09:31:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.54380449652672, 'train_avg_loss': 0.662865037471056, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 09:31:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.6251220703125, 'train_avg_loss': 0.6408856709798177, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 09:31:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 307.6251220703125, 'train_avg_loss': 0.6408856709798177, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 09:31:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:31:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:31:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:32:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:32:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=250.474762, avg_loss=0.521822, seen=480, correct=357, accuracy=0.743750
2025-10-09 09:32:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:32:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:32:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:32:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=1980MB allocated=1794MB
2025-10-09 09:32:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 42.83199381828308, 'train_avg_loss': 0.35693328181902567, 'train_seen': 120, 'train_correct': 106, 'train_acc': 0.8833333333333333}}
2025-10-09 09:32:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 250.47476196289062, 'train_avg_loss': 0.5218224207560221, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-09 09:32:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 250.47476196289062, 'train_avg_loss': 0.5218224207560221, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-09 09:32:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #18) -------------
2025-10-09 09:32:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=18 aidx=0 | s=3 (candidates=3)
2025-10-09 09:32:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 09:32:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 09:32:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:32:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:33:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:33:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=236.825241, avg_loss=0.493386, seen=480, correct=358, accuracy=0.745833
2025-10-09 09:33:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:33:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:33:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:33:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=1980MB allocated=1794MB
2025-10-09 09:33:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 37.55860389769077, 'train_avg_loss': 0.3129883658140898, 'train_seen': 120, 'train_correct': 104, 'train_acc': 0.8666666666666667}}
2025-10-09 09:33:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 236.8252410888672, 'train_avg_loss': 0.49338591893514, 'train_seen': 480, 'train_correct': 358, 'train_acc': 0.7458333333333333}}
2025-10-09 09:33:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 236.8252410888672, 'train_avg_loss': 0.49338591893514, 'train_seen': 480, 'train_correct': 358, 'train_acc': 0.7458333333333333}}
2025-10-09 09:33:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:33:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:33:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-09 09:33:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 09:33:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:33:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:33:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:33:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:33:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:34:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:34:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.656219, avg_loss=0.659700, seen=480, correct=302, accuracy=0.629167
2025-10-09 09:34:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:34:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:34:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:34:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=1920MB allocated=1794MB
2025-10-09 09:34:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.59631188213825, 'train_avg_loss': 0.7133025990178188, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 09:34:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.6562194824219, 'train_avg_loss': 0.6597004572550456, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 09:34:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 316.6562194824219, 'train_avg_loss': 0.6597004572550456, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 09:34:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:34:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:34:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-09 09:34:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 09:34:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:34:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:34:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:34:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:34:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:34:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:34:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.746979, avg_loss=0.649473, seen=480, correct=306, accuracy=0.637500
2025-10-09 09:34:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:34:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:34:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:34:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=1908MB allocated=1794MB
2025-10-09 09:34:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09234061837196, 'train_avg_loss': 0.684102838486433, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 09:34:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.7469787597656, 'train_avg_loss': 0.6494728724161783, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 09:34:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 311.7469787597656, 'train_avg_loss': 0.6494728724161783, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 09:34:49 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #19) -------------
2025-10-09 09:34:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=19 aidx=1 | s=1 (candidates=1)
2025-10-09 09:34:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:34:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:34:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:34:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-09 09:34:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:34:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:34:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:34:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:34:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:34:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:35:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:35:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=352.829773, avg_loss=0.735062, seen=480, correct=220, accuracy=0.458333
2025-10-09 09:35:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:35:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:35:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:35:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=1994MB allocated=1877MB
2025-10-09 09:35:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78120404481888, 'train_avg_loss': 0.681510033706824, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 09:35:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 352.82977294921875, 'train_avg_loss': 0.7350620269775391, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-09 09:35:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 352.82977294921875, 'train_avg_loss': 0.7350620269775391, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-09 09:35:33 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #20) -------------
2025-10-09 09:35:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=20 aidx=1 | s=1 (candidates=1)
2025-10-09 09:35:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:35:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:35:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:35:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:36:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:36:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.723755, avg_loss=0.691091, seen=480, correct=262, accuracy=0.545833
2025-10-09 09:36:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:36:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:36:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:36:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2014MB allocated=1877MB
2025-10-09 09:36:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.56970226764679, 'train_avg_loss': 0.6547475188970566, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 09:36:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.7237548828125, 'train_avg_loss': 0.6910911560058594, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 09:36:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 331.7237548828125, 'train_avg_loss': 0.6910911560058594, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 09:36:18 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #21) -------------
2025-10-09 09:36:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=21 aidx=1 | s=1 (candidates=1)
2025-10-09 09:36:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:36:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:36:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:36:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-09 09:36:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:36:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:36:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:36:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:36:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:36:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:37:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:37:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.894165, avg_loss=0.662280, seen=480, correct=284, accuracy=0.591667
2025-10-09 09:37:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:37:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:37:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:37:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=1928MB allocated=1802MB
2025-10-09 09:37:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.6182672381401, 'train_avg_loss': 0.6384855603178342, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 09:37:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8941650390625, 'train_avg_loss': 0.6622795104980469, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 09:37:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 317.8941650390625, 'train_avg_loss': 0.6622795104980469, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 09:37:04 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #22) -------------
2025-10-09 09:37:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=22 aidx=1 | s=1 (candidates=1)
2025-10-09 09:37:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:37:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:37:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:37:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:37:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:37:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.128387, avg_loss=0.635684, seen=480, correct=314, accuracy=0.654167
2025-10-09 09:37:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:37:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:37:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:37:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=1928MB allocated=1802MB
2025-10-09 09:37:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.82779771089554, 'train_avg_loss': 0.6235649809241295, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 09:37:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.1283874511719, 'train_avg_loss': 0.6356841405232747, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 09:37:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 305.1283874511719, 'train_avg_loss': 0.6356841405232747, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 09:37:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #23) -------------
2025-10-09 09:37:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=23 aidx=1 | s=1 (candidates=1)
2025-10-09 09:37:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:37:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:37:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:37:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-09 09:37:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:37:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:37:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:37:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:37:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:37:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:38:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:38:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.397156, avg_loss=0.607077, seen=480, correct=329, accuracy=0.685417
2025-10-09 09:38:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:38:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:38:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:38:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=1928MB allocated=1802MB
2025-10-09 09:38:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.38434380292892, 'train_avg_loss': 0.6115361983577411, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 09:38:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.39715576171875, 'train_avg_loss': 0.6070774078369141, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-09 09:38:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 291.39715576171875, 'train_avg_loss': 0.6070774078369141, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-09 09:38:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #24) -------------
2025-10-09 09:38:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=24 aidx=1 | s=1 (candidates=1)
2025-10-09 09:38:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:38:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:38:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:38:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-09 09:38:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:38:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:38:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:38:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:38:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:38:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:39:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:39:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=276.980225, avg_loss=0.577042, seen=480, correct=343, accuracy=0.714583
2025-10-09 09:39:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:39:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:39:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:39:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=1928MB allocated=1802MB
2025-10-09 09:39:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.31073009967804, 'train_avg_loss': 0.602589417497317, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 09:39:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 276.980224609375, 'train_avg_loss': 0.5770421346028646, 'train_seen': 480, 'train_correct': 343, 'train_acc': 0.7145833333333333}}
2025-10-09 09:39:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 276.980224609375, 'train_avg_loss': 0.5770421346028646, 'train_seen': 480, 'train_correct': 343, 'train_acc': 0.7145833333333333}}
2025-10-09 09:39:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #25) -------------
2025-10-09 09:39:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=25 aidx=1 | s=1 (candidates=1)
2025-10-09 09:39:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:39:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:39:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:39:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-09 09:39:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:39:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:39:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:39:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:39:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:39:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:39:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:39:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=263.007996, avg_loss=0.547933, seen=480, correct=344, accuracy=0.716667
2025-10-09 09:39:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:39:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:39:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:39:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=1928MB allocated=1802MB
2025-10-09 09:39:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.58665703237057, 'train_avg_loss': 0.5965554752697547, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 09:39:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 263.00799560546875, 'train_avg_loss': 0.5479333241780598, 'train_seen': 480, 'train_correct': 344, 'train_acc': 0.7166666666666667}}
2025-10-09 09:39:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 263.00799560546875, 'train_avg_loss': 0.5479333241780598, 'train_seen': 480, 'train_correct': 344, 'train_acc': 0.7166666666666667}}
2025-10-09 09:39:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #26) -------------
2025-10-09 09:39:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=26 aidx=1 | s=1 (candidates=1)
2025-10-09 09:39:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:39:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:40:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:40:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-09 09:40:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:40:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:40:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:40:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:40:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:40:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:40:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:40:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=250.001221, avg_loss=0.520836, seen=480, correct=355, accuracy=0.739583
2025-10-09 09:40:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:40:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:40:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:40:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=1928MB allocated=1802MB
2025-10-09 09:40:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.53490714728832, 'train_avg_loss': 0.579457559560736, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 09:40:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 250.001220703125, 'train_avg_loss': 0.5208358764648438, 'train_seen': 480, 'train_correct': 355, 'train_acc': 0.7395833333333334}}
2025-10-09 09:40:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 250.001220703125, 'train_avg_loss': 0.5208358764648438, 'train_seen': 480, 'train_correct': 355, 'train_acc': 0.7395833333333334}}
2025-10-09 09:40:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #27) -------------
2025-10-09 09:40:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=27 aidx=1 | s=1 (candidates=1)
2025-10-09 09:40:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:40:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:40:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:40:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:41:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:41:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=235.984222, avg_loss=0.491634, seen=480, correct=360, accuracy=0.750000
2025-10-09 09:41:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:41:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:41:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:41:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=1928MB allocated=1802MB
2025-10-09 09:41:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.98113538324833, 'train_avg_loss': 0.5665094615270694, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 09:41:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 235.98422241210938, 'train_avg_loss': 0.49163379669189455, 'train_seen': 480, 'train_correct': 360, 'train_acc': 0.75}}
2025-10-09 09:41:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 235.98422241210938, 'train_avg_loss': 0.49163379669189455, 'train_seen': 480, 'train_correct': 360, 'train_acc': 0.75}}
2025-10-09 09:41:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #28) -------------
2025-10-09 09:41:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=28 aidx=1 | s=1 (candidates=1)
2025-10-09 09:41:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:41:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:41:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:41:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:42:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:42:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=222.107849, avg_loss=0.462725, seen=480, correct=378, accuracy=0.787500
2025-10-09 09:42:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:42:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:42:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:42:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=1928MB allocated=1802MB
2025-10-09 09:42:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 65.54482065141201, 'train_avg_loss': 0.5462068387617668, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 09:42:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 222.10784912109375, 'train_avg_loss': 0.4627246856689453, 'train_seen': 480, 'train_correct': 378, 'train_acc': 0.7875}}
2025-10-09 09:42:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 222.10784912109375, 'train_avg_loss': 0.4627246856689453, 'train_seen': 480, 'train_correct': 378, 'train_acc': 0.7875}}
2025-10-09 09:42:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #29) -------------
2025-10-09 09:42:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=29 aidx=1 | s=1 (candidates=1)
2025-10-09 09:42:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:42:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:42:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:42:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:42:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:42:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=205.016785, avg_loss=0.427118, seen=480, correct=384, accuracy=0.800000
2025-10-09 09:42:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:42:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:42:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:42:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=1928MB allocated=1802MB
2025-10-09 09:42:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 61.5678461715579, 'train_avg_loss': 0.5130653847629826, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-09 09:42:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 205.01678466796875, 'train_avg_loss': 0.42711830139160156, 'train_seen': 480, 'train_correct': 384, 'train_acc': 0.8}}
2025-10-09 09:42:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 205.01678466796875, 'train_avg_loss': 0.42711830139160156, 'train_seen': 480, 'train_correct': 384, 'train_acc': 0.8}}
2025-10-09 09:42:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #30) -------------
2025-10-09 09:42:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=30 aidx=1 | s=1 (candidates=1)
2025-10-09 09:42:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:42:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:42:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:42:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-09 09:42:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:42:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:42:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:42:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:42:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:42:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:43:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:43:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=189.401337, avg_loss=0.394586, seen=480, correct=395, accuracy=0.822917
2025-10-09 09:43:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:43:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:43:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:43:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=1928MB allocated=1802MB
2025-10-09 09:43:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 58.30345772206783, 'train_avg_loss': 0.4858621476838986, 'train_seen': 120, 'train_correct': 89, 'train_acc': 0.7416666666666667}}
2025-10-09 09:43:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 189.40133666992188, 'train_avg_loss': 0.39458611806233723, 'train_seen': 480, 'train_correct': 395, 'train_acc': 0.8229166666666666}}
2025-10-09 09:43:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 189.40133666992188, 'train_avg_loss': 0.39458611806233723, 'train_seen': 480, 'train_correct': 395, 'train_acc': 0.8229166666666666}}
2025-10-09 09:43:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #31) -------------
2025-10-09 09:43:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=31 aidx=1 | s=1 (candidates=1)
2025-10-09 09:43:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:43:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:43:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:43:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:44:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:44:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=172.844162, avg_loss=0.360092, seen=480, correct=404, accuracy=0.841667
2025-10-09 09:44:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:44:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:44:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:44:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=1928MB allocated=1802MB
2025-10-09 09:44:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 54.978732105344534, 'train_avg_loss': 0.4581561008778711, 'train_seen': 120, 'train_correct': 93, 'train_acc': 0.775}}
2025-10-09 09:44:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 172.8441619873047, 'train_avg_loss': 0.3600920041402181, 'train_seen': 480, 'train_correct': 404, 'train_acc': 0.8416666666666667}}
2025-10-09 09:44:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 172.8441619873047, 'train_avg_loss': 0.3600920041402181, 'train_seen': 480, 'train_correct': 404, 'train_acc': 0.8416666666666667}}
2025-10-09 09:44:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #32) -------------
2025-10-09 09:44:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=32 aidx=1 | s=1 (candidates=1)
2025-10-09 09:44:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:44:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:44:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:44:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:45:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:45:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=152.975891, avg_loss=0.318700, seen=480, correct=408, accuracy=0.850000
2025-10-09 09:45:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:45:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:45:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:45:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=1928MB allocated=1802MB
2025-10-09 09:45:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 51.444762360304594, 'train_avg_loss': 0.4287063530025383, 'train_seen': 120, 'train_correct': 93, 'train_acc': 0.775}}
2025-10-09 09:45:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 152.97589111328125, 'train_avg_loss': 0.3186997731526693, 'train_seen': 480, 'train_correct': 408, 'train_acc': 0.85}}
2025-10-09 09:45:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 152.97589111328125, 'train_avg_loss': 0.3186997731526693, 'train_seen': 480, 'train_correct': 408, 'train_acc': 0.85}}
2025-10-09 09:45:10 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #33) -------------
2025-10-09 09:45:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=33 aidx=1 | s=1 (candidates=1)
2025-10-09 09:45:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:45:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:45:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:45:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:45:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:45:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=130.244934, avg_loss=0.271344, seen=480, correct=424, accuracy=0.883333
2025-10-09 09:45:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:45:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:45:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:45:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=1928MB allocated=1802MB
2025-10-09 09:45:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 44.58522342517972, 'train_avg_loss': 0.37154352854316436, 'train_seen': 120, 'train_correct': 99, 'train_acc': 0.825}}
2025-10-09 09:45:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 130.24493408203125, 'train_avg_loss': 0.27134361267089846, 'train_seen': 480, 'train_correct': 424, 'train_acc': 0.8833333333333333}}
2025-10-09 09:45:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 130.24493408203125, 'train_avg_loss': 0.27134361267089846, 'train_seen': 480, 'train_correct': 424, 'train_acc': 0.8833333333333333}}
2025-10-09 09:45:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #34) -------------
2025-10-09 09:45:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=34 aidx=1 | s=1 (candidates=1)
2025-10-09 09:45:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:45:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:45:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:45:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:46:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:46:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=109.452728, avg_loss=0.228027, seen=480, correct=435, accuracy=0.906250
2025-10-09 09:46:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:46:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:46:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:46:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=1928MB allocated=1802MB
2025-10-09 09:46:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 40.51156282611191, 'train_avg_loss': 0.3375963568842659, 'train_seen': 120, 'train_correct': 104, 'train_acc': 0.8666666666666667}}
2025-10-09 09:46:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 109.45272827148438, 'train_avg_loss': 0.2280265172322591, 'train_seen': 480, 'train_correct': 435, 'train_acc': 0.90625}}
2025-10-09 09:46:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 109.45272827148438, 'train_avg_loss': 0.2280265172322591, 'train_seen': 480, 'train_correct': 435, 'train_acc': 0.90625}}
2025-10-09 09:46:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #35) -------------
2025-10-09 09:46:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=35 aidx=1 | s=1 (candidates=1)
2025-10-09 09:46:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:46:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:46:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:46:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-09 09:46:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:46:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:46:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:46:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:46:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:46:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:47:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:47:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=88.116295, avg_loss=0.183576, seen=480, correct=447, accuracy=0.931250
2025-10-09 09:47:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:47:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:47:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:47:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=1928MB allocated=1802MB
2025-10-09 09:47:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 33.125929199159145, 'train_avg_loss': 0.2760494099929929, 'train_seen': 120, 'train_correct': 107, 'train_acc': 0.8916666666666667}}
2025-10-09 09:47:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 88.11629486083984, 'train_avg_loss': 0.18357561429341634, 'train_seen': 480, 'train_correct': 447, 'train_acc': 0.93125}}
2025-10-09 09:47:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 88.11629486083984, 'train_avg_loss': 0.18357561429341634, 'train_seen': 480, 'train_correct': 447, 'train_acc': 0.93125}}
2025-10-09 09:47:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #36) -------------
2025-10-09 09:47:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=36 aidx=1 | s=1 (candidates=1)
2025-10-09 09:47:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:47:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:47:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:47:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:48:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:48:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=76.693581, avg_loss=0.159778, seen=480, correct=455, accuracy=0.947917
2025-10-09 09:48:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:48:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:48:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:48:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=1928MB allocated=1802MB
2025-10-09 09:48:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 29.165818687994033, 'train_avg_loss': 0.24304848906661694, 'train_seen': 120, 'train_correct': 110, 'train_acc': 0.9166666666666666}}
2025-10-09 09:48:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 76.6935806274414, 'train_avg_loss': 0.15977829297383625, 'train_seen': 480, 'train_correct': 455, 'train_acc': 0.9479166666666666}}
2025-10-09 09:48:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 76.6935806274414, 'train_avg_loss': 0.15977829297383625, 'train_seen': 480, 'train_correct': 455, 'train_acc': 0.9479166666666666}}
2025-10-09 09:48:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #37) -------------
2025-10-09 09:48:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=37 aidx=1 | s=1 (candidates=1)
2025-10-09 09:48:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4] (from 1)
2025-10-09 09:48:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:48:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:48:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-09 09:48:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-09 09:48:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:48:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:48:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:48:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:48:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:48:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:48:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=55.785343, avg_loss=0.116219, seen=480, correct=464, accuracy=0.966667
2025-10-09 09:48:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:48:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:48:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:48:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=1928MB allocated=1802MB
2025-10-09 09:48:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 24.135630971984938, 'train_avg_loss': 0.20113025809987448, 'train_seen': 120, 'train_correct': 112, 'train_acc': 0.9333333333333333}}
2025-10-09 09:48:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 55.785343170166016, 'train_avg_loss': 0.11621946493784586, 'train_seen': 480, 'train_correct': 464, 'train_acc': 0.9666666666666667}}
2025-10-09 09:48:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 55.785343170166016, 'train_avg_loss': 0.11621946493784586, 'train_seen': 480, 'train_correct': 464, 'train_acc': 0.9666666666666667}}
2025-10-09 09:48:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #38) -------------
2025-10-09 09:48:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=38 aidx=2 | s=1 (candidates=1)
2025-10-09 09:48:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:48:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:48:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:48:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-09 09:48:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:48:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:48:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:48:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:48:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:48:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:49:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:49:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=352.533386, avg_loss=0.734445, seen=480, correct=232, accuracy=0.483333
2025-10-09 09:49:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:49:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:49:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:49:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2030MB allocated=1886MB
2025-10-09 09:49:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.7310802936554, 'train_avg_loss': 0.714425669113795, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 09:49:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 352.53338623046875, 'train_avg_loss': 0.7344445546468099, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-09 09:49:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 352.53338623046875, 'train_avg_loss': 0.7344445546468099, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-09 09:49:34 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #39) -------------
2025-10-09 09:49:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=39 aidx=2 | s=1 (candidates=1)
2025-10-09 09:49:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:49:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:49:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:49:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:50:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:50:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.366882, avg_loss=0.713264, seen=480, correct=263, accuracy=0.547917
2025-10-09 09:50:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:50:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:50:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:50:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2034MB allocated=1886MB
2025-10-09 09:50:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.78252732753754, 'train_avg_loss': 0.6981877277294795, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:50:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.36688232421875, 'train_avg_loss': 0.7132643381754558, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 09:50:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 342.36688232421875, 'train_avg_loss': 0.7132643381754558, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 09:50:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #40) -------------
2025-10-09 09:50:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=40 aidx=2 | s=1 (candidates=1)
2025-10-09 09:50:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:50:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:50:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:50:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-09 09:50:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:50:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:50:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:50:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:50:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:50:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:51:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:51:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.342285, avg_loss=0.696546, seen=480, correct=262, accuracy=0.545833
2025-10-09 09:51:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:51:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:51:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:51:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=1968MB allocated=1810MB
2025-10-09 09:51:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.64159286022186, 'train_avg_loss': 0.6886799405018489, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 09:51:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.34228515625, 'train_avg_loss': 0.6965464274088542, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 09:51:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 334.34228515625, 'train_avg_loss': 0.6965464274088542, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 09:51:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #41) -------------
2025-10-09 09:51:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=41 aidx=2 | s=1 (candidates=1)
2025-10-09 09:51:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:51:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:51:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:51:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-09 09:51:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:51:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:51:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:51:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:51:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:51:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:51:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:51:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.671265, avg_loss=0.682648, seen=480, correct=273, accuracy=0.568750
2025-10-09 09:51:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:51:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:51:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:51:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=1968MB allocated=1810MB
2025-10-09 09:51:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.85431081056595, 'train_avg_loss': 0.6737859234213829, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 09:51:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6712646484375, 'train_avg_loss': 0.6826484680175782, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 09:51:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 327.6712646484375, 'train_avg_loss': 0.6826484680175782, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 09:51:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #42) -------------
2025-10-09 09:51:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=42 aidx=2 | s=1 (candidates=1)
2025-10-09 09:51:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:51:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:51:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:51:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:52:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:52:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.146149, avg_loss=0.671138, seen=480, correct=286, accuracy=0.595833
2025-10-09 09:52:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:52:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:52:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:52:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=1968MB allocated=1810MB
2025-10-09 09:52:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.57415968179703, 'train_avg_loss': 0.6631179973483086, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 09:52:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1461486816406, 'train_avg_loss': 0.671137809753418, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 09:52:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 322.1461486816406, 'train_avg_loss': 0.671137809753418, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 09:52:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #43) -------------
2025-10-09 09:52:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=43 aidx=2 | s=1 (candidates=1)
2025-10-09 09:52:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:52:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:52:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:52:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:53:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:53:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.918579, avg_loss=0.660247, seen=480, correct=295, accuracy=0.614583
2025-10-09 09:53:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:53:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:53:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:53:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=1968MB allocated=1810MB
2025-10-09 09:53:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.11984008550644, 'train_avg_loss': 0.6509986673792203, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 09:53:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.9185791015625, 'train_avg_loss': 0.6602470397949218, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 09:53:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 316.9185791015625, 'train_avg_loss': 0.6602470397949218, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 09:53:23 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #44) -------------
2025-10-09 09:53:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=44 aidx=2 | s=1 (candidates=1)
2025-10-09 09:53:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:53:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:53:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:53:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:54:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:54:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.300232, avg_loss=0.646459, seen=480, correct=305, accuracy=0.635417
2025-10-09 09:54:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:54:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:54:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:54:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=1968MB allocated=1810MB
2025-10-09 09:54:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.12253302335739, 'train_avg_loss': 0.6426877751946449, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 09:54:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.30023193359375, 'train_avg_loss': 0.6464588165283203, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 09:54:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 310.30023193359375, 'train_avg_loss': 0.6464588165283203, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 09:54:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #45) -------------
2025-10-09 09:54:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=45 aidx=2 | s=1 (candidates=1)
2025-10-09 09:54:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:54:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:54:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:54:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:54:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:54:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.212830, avg_loss=0.635860, seen=480, correct=312, accuracy=0.650000
2025-10-09 09:54:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:54:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:54:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:54:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=1968MB allocated=1810MB
2025-10-09 09:54:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.54791069030762, 'train_avg_loss': 0.6295659224192302, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 09:54:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.21282958984375, 'train_avg_loss': 0.6358600616455078, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 09:54:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 305.21282958984375, 'train_avg_loss': 0.6358600616455078, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 09:54:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #46) -------------
2025-10-09 09:54:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=46 aidx=2 | s=1 (candidates=1)
2025-10-09 09:54:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:54:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:54:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:54:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:55:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:55:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.474854, avg_loss=0.621823, seen=480, correct=322, accuracy=0.670833
2025-10-09 09:55:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:55:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:55:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:55:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=1968MB allocated=1810MB
2025-10-09 09:55:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.95355612039566, 'train_avg_loss': 0.6162796343366305, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 09:55:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.474853515625, 'train_avg_loss': 0.6218226114908855, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 09:55:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 298.474853515625, 'train_avg_loss': 0.6218226114908855, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 09:55:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #47) -------------
2025-10-09 09:55:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=47 aidx=2 | s=1 (candidates=1)
2025-10-09 09:55:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:55:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:55:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:55:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:56:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:56:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.619263, avg_loss=0.607540, seen=480, correct=335, accuracy=0.697917
2025-10-09 09:56:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:56:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:56:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:56:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=1968MB allocated=1810MB
2025-10-09 09:56:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.524120926857, 'train_avg_loss': 0.604367674390475, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 09:56:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.6192626953125, 'train_avg_loss': 0.6075401306152344, 'train_seen': 480, 'train_correct': 335, 'train_acc': 0.6979166666666666}}
2025-10-09 09:56:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 291.6192626953125, 'train_avg_loss': 0.6075401306152344, 'train_seen': 480, 'train_correct': 335, 'train_acc': 0.6979166666666666}}
2025-10-09 09:56:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #48) -------------
2025-10-09 09:56:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=48 aidx=2 | s=1 (candidates=1)
2025-10-09 09:56:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:56:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:56:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:56:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-09 09:56:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:56:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:56:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:56:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:56:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:56:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:57:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:57:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=284.957336, avg_loss=0.593661, seen=480, correct=341, accuracy=0.710417
2025-10-09 09:57:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:57:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:57:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:57:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=1968MB allocated=1810MB
2025-10-09 09:57:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.79163646697998, 'train_avg_loss': 0.5899303038914998, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 09:57:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 284.95733642578125, 'train_avg_loss': 0.593661117553711, 'train_seen': 480, 'train_correct': 341, 'train_acc': 0.7104166666666667}}
2025-10-09 09:57:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 284.95733642578125, 'train_avg_loss': 0.593661117553711, 'train_seen': 480, 'train_correct': 341, 'train_acc': 0.7104166666666667}}
2025-10-09 09:57:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #49) -------------
2025-10-09 09:57:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=49 aidx=2 | s=1 (candidates=1)
2025-10-09 09:57:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:57:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:57:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:57:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-09 09:57:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:57:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:57:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:57:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:57:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:57:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:57:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:57:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=277.789764, avg_loss=0.578729, seen=480, correct=343, accuracy=0.714583
2025-10-09 09:57:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:57:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:57:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:57:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=1968MB allocated=1810MB
2025-10-09 09:57:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.94857388734818, 'train_avg_loss': 0.5745714490612348, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 09:57:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 277.7897644042969, 'train_avg_loss': 0.5787286758422852, 'train_seen': 480, 'train_correct': 343, 'train_acc': 0.7145833333333333}}
2025-10-09 09:57:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 277.7897644042969, 'train_avg_loss': 0.5787286758422852, 'train_seen': 480, 'train_correct': 343, 'train_acc': 0.7145833333333333}}
2025-10-09 09:57:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #50) -------------
2025-10-09 09:57:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=50 aidx=2 | s=1 (candidates=1)
2025-10-09 09:57:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:57:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:58:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:58:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:58:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:58:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=268.856598, avg_loss=0.560118, seen=480, correct=349, accuracy=0.727083
2025-10-09 09:58:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:58:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:58:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:58:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=1968MB allocated=1810MB
2025-10-09 09:58:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.1367540359497, 'train_avg_loss': 0.5594729502995809, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-09 09:58:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 268.8565979003906, 'train_avg_loss': 0.5601179122924804, 'train_seen': 480, 'train_correct': 349, 'train_acc': 0.7270833333333333}}
2025-10-09 09:58:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 268.8565979003906, 'train_avg_loss': 0.5601179122924804, 'train_seen': 480, 'train_correct': 349, 'train_acc': 0.7270833333333333}}
2025-10-09 09:58:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #51) -------------
2025-10-09 09:58:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=51 aidx=2 | s=1 (candidates=1)
2025-10-09 09:58:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:58:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:58:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:58:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 09:59:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 09:59:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=260.073853, avg_loss=0.541821, seen=480, correct=354, accuracy=0.737500
2025-10-09 09:59:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 09:59:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:59:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 09:59:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=1968MB allocated=1810MB
2025-10-09 09:59:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 64.60961177945137, 'train_avg_loss': 0.5384134314954281, 'train_seen': 120, 'train_correct': 90, 'train_acc': 0.75}}
2025-10-09 09:59:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 260.0738525390625, 'train_avg_loss': 0.5418205261230469, 'train_seen': 480, 'train_correct': 354, 'train_acc': 0.7375}}
2025-10-09 09:59:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 260.0738525390625, 'train_avg_loss': 0.5418205261230469, 'train_seen': 480, 'train_correct': 354, 'train_acc': 0.7375}}
2025-10-09 09:59:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #52) -------------
2025-10-09 09:59:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=52 aidx=2 | s=1 (candidates=1)
2025-10-09 09:59:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 09:59:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 09:59:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 09:59:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:00:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:00:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=251.416901, avg_loss=0.523785, seen=480, correct=357, accuracy=0.743750
2025-10-09 10:00:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:00:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:00:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:00:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=1968MB allocated=1810MB
2025-10-09 10:00:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 62.134269654750824, 'train_avg_loss': 0.5177855804562569, 'train_seen': 120, 'train_correct': 88, 'train_acc': 0.7333333333333333}}
2025-10-09 10:00:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 251.41690063476562, 'train_avg_loss': 0.5237852096557617, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-09 10:00:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 251.41690063476562, 'train_avg_loss': 0.5237852096557617, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-09 10:00:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #53) -------------
2025-10-09 10:00:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=53 aidx=2 | s=1 (candidates=1)
2025-10-09 10:00:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 10:00:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 10:00:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:00:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:00:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:00:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=240.153610, avg_loss=0.500320, seen=480, correct=365, accuracy=0.760417
2025-10-09 10:00:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:00:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:00:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:00:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=1968MB allocated=1810MB
2025-10-09 10:00:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 61.00167629122734, 'train_avg_loss': 0.5083473024268945, 'train_seen': 120, 'train_correct': 91, 'train_acc': 0.7583333333333333}}
2025-10-09 10:00:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 240.1536102294922, 'train_avg_loss': 0.500320021311442, 'train_seen': 480, 'train_correct': 365, 'train_acc': 0.7604166666666666}}
2025-10-09 10:00:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 240.1536102294922, 'train_avg_loss': 0.500320021311442, 'train_seen': 480, 'train_correct': 365, 'train_acc': 0.7604166666666666}}
2025-10-09 10:01:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #54) -------------
2025-10-09 10:01:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=54 aidx=2 | s=1 (candidates=1)
2025-10-09 10:01:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 10:01:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 10:01:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:01:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:01:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:01:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=228.825104, avg_loss=0.476719, seen=480, correct=372, accuracy=0.775000
2025-10-09 10:01:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:01:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:01:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:01:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=1968MB allocated=1810MB
2025-10-09 10:01:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 58.83298559486866, 'train_avg_loss': 0.49027487995723884, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 10:01:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 228.82510375976562, 'train_avg_loss': 0.47671896616617837, 'train_seen': 480, 'train_correct': 372, 'train_acc': 0.775}}
2025-10-09 10:01:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 228.82510375976562, 'train_avg_loss': 0.47671896616617837, 'train_seen': 480, 'train_correct': 372, 'train_acc': 0.775}}
2025-10-09 10:01:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #55) -------------
2025-10-09 10:01:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=55 aidx=2 | s=1 (candidates=1)
2025-10-09 10:01:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 10:01:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 10:01:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:01:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:02:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:02:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=215.876007, avg_loss=0.449742, seen=480, correct=384, accuracy=0.800000
2025-10-09 10:02:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:02:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:02:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:02:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=1968MB allocated=1810MB
2025-10-09 10:02:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 57.07475666701794, 'train_avg_loss': 0.4756229722251495, 'train_seen': 120, 'train_correct': 93, 'train_acc': 0.775}}
2025-10-09 10:02:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 215.87600708007812, 'train_avg_loss': 0.4497416814168294, 'train_seen': 480, 'train_correct': 384, 'train_acc': 0.8}}
2025-10-09 10:02:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 215.87600708007812, 'train_avg_loss': 0.4497416814168294, 'train_seen': 480, 'train_correct': 384, 'train_acc': 0.8}}
2025-10-09 10:02:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #56) -------------
2025-10-09 10:02:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=56 aidx=2 | s=1 (candidates=1)
2025-10-09 10:02:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5] (from 1)
2025-10-09 10:02:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-09 10:02:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:02:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:03:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:03:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=204.484894, avg_loss=0.426010, seen=480, correct=392, accuracy=0.816667
2025-10-09 10:03:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:03:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:03:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:03:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=1968MB allocated=1810MB
2025-10-09 10:03:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 54.43728217482567, 'train_avg_loss': 0.4536440181235472, 'train_seen': 120, 'train_correct': 96, 'train_acc': 0.8}}
2025-10-09 10:03:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 204.48489379882812, 'train_avg_loss': 0.42601019541422525, 'train_seen': 480, 'train_correct': 392, 'train_acc': 0.8166666666666667}}
2025-10-09 10:03:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 204.48489379882812, 'train_avg_loss': 0.42601019541422525, 'train_seen': 480, 'train_correct': 392, 'train_acc': 0.8166666666666667}}
2025-10-09 10:03:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #57) -------------
2025-10-09 10:03:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=57 aidx=3 | s=5 (candidates=12)
2025-10-09 10:03:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[51, 36, 22, 28, 16] (from 12)
2025-10-09 10:03:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:03:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:03:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-09 10:03:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 10:03:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:03:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:03:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:03:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:03:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:04:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:04:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.527161, avg_loss=0.705265, seen=480, correct=261, accuracy=0.543750
2025-10-09 10:04:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:04:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:04:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:04:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2030MB allocated=1895MB
2025-10-09 10:04:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.7978817820549, 'train_avg_loss': 0.7149823481837908, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:04:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.52716064453125, 'train_avg_loss': 0.7052649180094401, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:04:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 338.52716064453125, 'train_avg_loss': 0.7052649180094401, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:04:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:04:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:04:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-09 10:04:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:04:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:04:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:04:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:04:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:04:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:04:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:04:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.975250, avg_loss=0.710365, seen=480, correct=250, accuracy=0.520833
2025-10-09 10:04:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:04:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:04:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:04:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=1994MB allocated=1903MB
2025-10-09 10:04:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.44521915912628, 'train_avg_loss': 0.7203768263260524, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:04:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.9752502441406, 'train_avg_loss': 0.710365104675293, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 10:04:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 340.9752502441406, 'train_avg_loss': 0.710365104675293, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 10:04:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:04:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:04:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-09 10:04:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:04:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:04:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:04:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:04:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:04:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:05:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:05:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.232971, avg_loss=0.708819, seen=480, correct=254, accuracy=0.529167
2025-10-09 10:05:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:05:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:05:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:05:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2026MB allocated=1911MB
2025-10-09 10:05:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.86378818750381, 'train_avg_loss': 0.6905315682291985, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 10:05:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.23297119140625, 'train_avg_loss': 0.7088186899820964, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:05:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 340.23297119140625, 'train_avg_loss': 0.7088186899820964, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:05:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:05:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:05:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-09 10:05:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:05:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:05:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:05:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:05:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:05:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:06:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:06:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.276459, avg_loss=0.708909, seen=480, correct=254, accuracy=0.529167
2025-10-09 10:06:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:06:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:06:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:06:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2002MB allocated=1920MB
2025-10-09 10:06:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.8943812251091, 'train_avg_loss': 0.7074531768759091, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:06:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.2764587402344, 'train_avg_loss': 0.708909289042155, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:06:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 340.2764587402344, 'train_avg_loss': 0.708909289042155, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:06:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:06:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:06:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-09 10:06:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 10:06:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:06:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:06:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:06:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:06:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:06:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:06:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.706024, avg_loss=0.705638, seen=480, correct=244, accuracy=0.508333
2025-10-09 10:06:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:06:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:07:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:07:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2058MB allocated=1928MB
2025-10-09 10:07:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.53979557752609, 'train_avg_loss': 0.6794982964793841, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 10:07:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.7060241699219, 'train_avg_loss': 0.7056375503540039, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 10:07:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 338.7060241699219, 'train_avg_loss': 0.7056375503540039, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 10:07:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #58) -------------
2025-10-09 10:07:02 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=58 aidx=3 | s=5 (candidates=12)
2025-10-09 10:07:02 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 48, 15, 36, 50] (from 12)
2025-10-09 10:07:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:07:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:07:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-09 10:07:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 10:07:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:07:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:07:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:07:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:07:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:07:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:07:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.834686, avg_loss=0.695489, seen=480, correct=258, accuracy=0.537500
2025-10-09 10:07:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:07:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:07:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:07:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2156MB allocated=2012MB
2025-10-09 10:07:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.11343652009964, 'train_avg_loss': 0.7176119710008303, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:07:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.8346862792969, 'train_avg_loss': 0.6954889297485352, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 10:07:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 333.8346862792969, 'train_avg_loss': 0.6954889297485352, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 10:07:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:07:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:07:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-09 10:07:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:07:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:07:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:07:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:07:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:07:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:08:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:08:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.924591, avg_loss=0.714426, seen=480, correct=245, accuracy=0.510417
2025-10-09 10:08:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:08:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:08:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:08:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2116MB allocated=2021MB
2025-10-09 10:08:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.1026605963707, 'train_avg_loss': 0.7175221716364225, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:08:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.9245910644531, 'train_avg_loss': 0.7144262313842773, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 10:08:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 342.9245910644531, 'train_avg_loss': 0.7144262313842773, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 10:08:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:08:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:08:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-09 10:08:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:08:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:08:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:08:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:08:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:08:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:09:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:09:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.037567, avg_loss=0.693828, seen=480, correct=255, accuracy=0.531250
2025-10-09 10:09:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:09:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:09:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:09:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2118MB allocated=2029MB
2025-10-09 10:09:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.18506681919098, 'train_avg_loss': 0.7182088901599248, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:09:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0375671386719, 'train_avg_loss': 0.693828264872233, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 10:09:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 333.0375671386719, 'train_avg_loss': 0.693828264872233, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 10:09:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:09:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:09:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-09 10:09:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:09:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:09:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:09:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:09:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:09:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:10:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:10:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.839203, avg_loss=0.691332, seen=480, correct=262, accuracy=0.545833
2025-10-09 10:10:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:10:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:10:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:10:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2090MB allocated=1954MB
2025-10-09 10:10:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.74605178833008, 'train_avg_loss': 0.6895504315694173, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 10:10:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8392028808594, 'train_avg_loss': 0.6913316726684571, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:10:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 331.8392028808594, 'train_avg_loss': 0.6913316726684571, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:10:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:10:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:10:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:10:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:10:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.546967, avg_loss=0.705306, seen=480, correct=254, accuracy=0.529167
2025-10-09 10:10:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:10:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:10:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:10:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2116MB allocated=2038MB
2025-10-09 10:10:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.56842160224915, 'train_avg_loss': 0.7297368466854095, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:10:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.5469665527344, 'train_avg_loss': 0.7053061803181966, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:10:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 338.5469665527344, 'train_avg_loss': 0.7053061803181966, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:10:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #59) -------------
2025-10-09 10:10:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=59 aidx=3 | s=5 (candidates=12)
2025-10-09 10:10:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 6, 51, 16, 20] (from 12)
2025-10-09 10:10:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:10:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:10:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:11:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:11:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.941620, avg_loss=0.695712, seen=480, correct=233, accuracy=0.485417
2025-10-09 10:11:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:11:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:11:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:11:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2092MB allocated=1962MB
2025-10-09 10:11:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.10391759872437, 'train_avg_loss': 0.7008659799893697, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 10:11:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9416198730469, 'train_avg_loss': 0.6957117080688476, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 10:11:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 333.9416198730469, 'train_avg_loss': 0.6957117080688476, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 10:11:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:11:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:11:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-09 10:11:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 10:11:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:11:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:11:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:11:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:11:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:12:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:12:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.931061, avg_loss=0.710273, seen=480, correct=242, accuracy=0.504167
2025-10-09 10:12:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:12:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:12:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:12:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2154MB allocated=2046MB
2025-10-09 10:12:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.080779671669, 'train_avg_loss': 0.7173398305972417, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 10:12:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.9310607910156, 'train_avg_loss': 0.7102730433146159, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 10:12:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 340.9310607910156, 'train_avg_loss': 0.7102730433146159, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 10:12:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 10:12:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:12:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:13:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:13:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.064575, avg_loss=0.691801, seen=480, correct=270, accuracy=0.562500
2025-10-09 10:13:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:13:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:13:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:13:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2134MB allocated=1971MB
2025-10-09 10:13:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.97165513038635, 'train_avg_loss': 0.6914304594198862, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:13:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0645751953125, 'train_avg_loss': 0.6918011983235677, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:13:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 332.0645751953125, 'train_avg_loss': 0.6918011983235677, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:13:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 10:13:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:13:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:13:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:13:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.075623, avg_loss=0.695991, seen=480, correct=251, accuracy=0.522917
2025-10-09 10:13:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:13:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:13:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:13:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2128MB allocated=1971MB
2025-10-09 10:13:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.64293587207794, 'train_avg_loss': 0.6886911322673162, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:13:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.07562255859375, 'train_avg_loss': 0.6959908803304037, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 10:13:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 334.07562255859375, 'train_avg_loss': 0.6959908803304037, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 10:13:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:13:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:13:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-09 10:13:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 10:13:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:13:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:13:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:13:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:13:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:14:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:14:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.341248, avg_loss=0.690294, seen=480, correct=260, accuracy=0.541667
2025-10-09 10:14:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:14:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:14:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:14:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2122MB allocated=1971MB
2025-10-09 10:14:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1158275604248, 'train_avg_loss': 0.70929856300354, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:14:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.34124755859375, 'train_avg_loss': 0.6902942657470703, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 10:14:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 331.34124755859375, 'train_avg_loss': 0.6902942657470703, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 10:14:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #60) -------------
2025-10-09 10:14:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=60 aidx=3 | s=5 (candidates=12)
2025-10-09 10:14:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 43, 50, 48, 40] (from 12)
2025-10-09 10:14:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:14:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:14:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:15:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:15:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.339508, avg_loss=0.692374, seen=480, correct=246, accuracy=0.512500
2025-10-09 10:15:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:15:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:15:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:15:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2034MB allocated=1895MB
2025-10-09 10:15:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.12697833776474, 'train_avg_loss': 0.6927248194813729, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 10:15:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.3395080566406, 'train_avg_loss': 0.6923739751180013, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 10:15:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 332.3395080566406, 'train_avg_loss': 0.6923739751180013, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 10:15:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:15:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:15:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-09 10:15:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 10:15:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:15:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:15:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:15:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:15:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:16:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:16:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.128448, avg_loss=0.687768, seen=480, correct=270, accuracy=0.562500
2025-10-09 10:16:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:16:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:16:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:16:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2138MB allocated=1979MB
2025-10-09 10:16:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.65682637691498, 'train_avg_loss': 0.7054735531409582, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:16:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1284484863281, 'train_avg_loss': 0.6877676010131836, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:16:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 330.1284484863281, 'train_avg_loss': 0.6877676010131836, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:16:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:16:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:16:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:16:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:16:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.285553, avg_loss=0.696428, seen=480, correct=261, accuracy=0.543750
2025-10-09 10:16:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:16:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:16:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:16:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2034MB allocated=1904MB
2025-10-09 10:16:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.84929460287094, 'train_avg_loss': 0.7070774550239245, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:16:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2855529785156, 'train_avg_loss': 0.6964282353719076, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:16:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 334.2855529785156, 'train_avg_loss': 0.6964282353719076, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:16:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:16:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:16:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-09 10:16:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:16:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:16:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:16:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:16:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:16:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:17:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:17:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.191986, avg_loss=0.702483, seen=480, correct=239, accuracy=0.497917
2025-10-09 10:17:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:17:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:17:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:17:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2048MB allocated=1904MB
2025-10-09 10:17:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.76999843120575, 'train_avg_loss': 0.7147499869267145, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 10:17:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.1919860839844, 'train_avg_loss': 0.7024833043416341, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 10:17:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 337.1919860839844, 'train_avg_loss': 0.7024833043416341, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 10:17:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:17:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:17:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-09 10:17:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 10:17:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:17:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:17:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:17:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:17:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:18:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:18:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.114166, avg_loss=0.704405, seen=480, correct=242, accuracy=0.504167
2025-10-09 10:18:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:18:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:18:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:18:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2082MB allocated=1988MB
2025-10-09 10:18:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.70180988311768, 'train_avg_loss': 0.7225150823593139, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 10:18:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.1141662597656, 'train_avg_loss': 0.7044045130411783, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 10:18:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 338.1141662597656, 'train_avg_loss': 0.7044045130411783, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 10:18:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #61) -------------
2025-10-09 10:18:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=61 aidx=3 | s=5 (candidates=12)
2025-10-09 10:18:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 28, 15, 16, 48] (from 12)
2025-10-09 10:18:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:18:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:18:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:19:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:19:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.813538, avg_loss=0.687112, seen=480, correct=254, accuracy=0.529167
2025-10-09 10:19:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:19:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:19:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:19:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2132MB allocated=1988MB
2025-10-09 10:19:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.35345005989075, 'train_avg_loss': 0.6862787504990896, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:19:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.81353759765625, 'train_avg_loss': 0.6871115366617838, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:19:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 329.81353759765625, 'train_avg_loss': 0.6871115366617838, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:19:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:19:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:19:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:19:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:19:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.575775, avg_loss=0.690783, seen=480, correct=250, accuracy=0.520833
2025-10-09 10:19:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:19:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:20:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:20:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2132MB allocated=1988MB
2025-10-09 10:20:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.7903687953949, 'train_avg_loss': 0.6899197399616241, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:20:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5757751464844, 'train_avg_loss': 0.6907828648885092, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 10:20:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 331.5757751464844, 'train_avg_loss': 0.6907828648885092, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 10:20:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:20:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:20:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:20:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:20:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.141876, avg_loss=0.689879, seen=480, correct=260, accuracy=0.541667
2025-10-09 10:20:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:20:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:20:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:20:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2132MB allocated=1988MB
2025-10-09 10:20:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.89316028356552, 'train_avg_loss': 0.707443002363046, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:20:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1418762207031, 'train_avg_loss': 0.6898789087931315, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 10:20:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 331.1418762207031, 'train_avg_loss': 0.6898789087931315, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 10:20:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:20:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:20:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-09 10:20:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 10:20:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:20:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:20:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:20:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:20:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:21:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:21:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.805664, avg_loss=0.693345, seen=480, correct=257, accuracy=0.535417
2025-10-09 10:21:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:21:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:21:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:21:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2158MB allocated=1988MB
2025-10-09 10:21:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.60099178552628, 'train_avg_loss': 0.6716749315460523, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 10:21:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8056640625, 'train_avg_loss': 0.6933451334635417, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 10:21:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 332.8056640625, 'train_avg_loss': 0.6933451334635417, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 10:21:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:21:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:21:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:22:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:22:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.298889, avg_loss=0.698539, seen=480, correct=237, accuracy=0.493750
2025-10-09 10:22:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:22:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:22:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:22:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2134MB allocated=1988MB
2025-10-09 10:22:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1938362121582, 'train_avg_loss': 0.7099486351013183, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 10:22:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.29888916015625, 'train_avg_loss': 0.6985393524169922, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 10:22:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 335.29888916015625, 'train_avg_loss': 0.6985393524169922, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 10:22:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #62) -------------
2025-10-09 10:22:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=62 aidx=3 | s=5 (candidates=12)
2025-10-09 10:22:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 22, 16, 40, 43] (from 12)
2025-10-09 10:22:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:22:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:22:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:23:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:23:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.996246, avg_loss=0.687492, seen=480, correct=251, accuracy=0.522917
2025-10-09 10:23:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:23:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:23:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:23:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2054MB allocated=1912MB
2025-10-09 10:23:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.27717179059982, 'train_avg_loss': 0.6856430982549985, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:23:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.9962463378906, 'train_avg_loss': 0.6874921798706055, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 10:23:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 329.9962463378906, 'train_avg_loss': 0.6874921798706055, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 10:23:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:23:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:23:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-09 10:23:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:23:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:23:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:23:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:23:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:23:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:23:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:23:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.425537, avg_loss=0.692553, seen=480, correct=264, accuracy=0.550000
2025-10-09 10:23:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:23:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:23:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:23:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2062MB allocated=1912MB
2025-10-09 10:23:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66168177127838, 'train_avg_loss': 0.6805140147606532, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 10:23:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.425537109375, 'train_avg_loss': 0.6925532023111979, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 10:23:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 332.425537109375, 'train_avg_loss': 0.6925532023111979, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 10:23:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:23:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:23:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-09 10:23:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 10:23:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:23:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:23:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:23:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:23:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:24:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:24:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.641632, avg_loss=0.693003, seen=480, correct=249, accuracy=0.518750
2025-10-09 10:24:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:24:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:24:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:24:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2080MB allocated=1912MB
2025-10-09 10:24:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7293347120285, 'train_avg_loss': 0.6727444559335709, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:24:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.6416320800781, 'train_avg_loss': 0.6930034001668294, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 10:24:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 332.6416320800781, 'train_avg_loss': 0.6930034001668294, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 10:24:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 10:24:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:24:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:25:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:25:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.806549, avg_loss=0.697514, seen=480, correct=237, accuracy=0.493750
2025-10-09 10:25:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:25:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:25:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:25:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2054MB allocated=1912MB
2025-10-09 10:25:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2818318605423, 'train_avg_loss': 0.7106819321711858, 'train_seen': 120, 'train_correct': 51, 'train_acc': 0.425}}
2025-10-09 10:25:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.8065490722656, 'train_avg_loss': 0.6975136439005534, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 10:25:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 334.8065490722656, 'train_avg_loss': 0.6975136439005534, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 10:25:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:25:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:25:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-09 10:25:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 10:25:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:25:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:25:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:25:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:25:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:25:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:25:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.517029, avg_loss=0.686494, seen=480, correct=258, accuracy=0.537500
2025-10-09 10:25:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:25:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:25:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:25:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2098MB allocated=1912MB
2025-10-09 10:25:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1514219045639, 'train_avg_loss': 0.7095951825380326, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 10:25:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.51702880859375, 'train_avg_loss': 0.6864938100179037, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 10:25:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 329.51702880859375, 'train_avg_loss': 0.6864938100179037, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 10:25:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #63) -------------
2025-10-09 10:25:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=63 aidx=3 | s=5 (candidates=12)
2025-10-09 10:25:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 40, 36, 48, 15] (from 12)
2025-10-09 10:26:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:26:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:26:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-09 10:26:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:26:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:26:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:26:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:26:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:26:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:26:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:26:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.447235, avg_loss=0.688432, seen=480, correct=262, accuracy=0.545833
2025-10-09 10:26:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:26:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:26:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:26:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2062MB allocated=1912MB
2025-10-09 10:26:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5348824262619, 'train_avg_loss': 0.6794573535521825, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 10:26:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4472351074219, 'train_avg_loss': 0.6884317398071289, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:26:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 330.4472351074219, 'train_avg_loss': 0.6884317398071289, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:26:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:26:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:26:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-09 10:26:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 10:26:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:26:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:26:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:26:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:26:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:27:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:27:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.583801, avg_loss=0.694966, seen=480, correct=247, accuracy=0.514583
2025-10-09 10:27:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:27:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:27:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:27:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2054MB allocated=1912MB
2025-10-09 10:27:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.92401015758514, 'train_avg_loss': 0.7077000846465429, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 10:27:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.58380126953125, 'train_avg_loss': 0.6949662526448568, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 10:27:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 333.58380126953125, 'train_avg_loss': 0.6949662526448568, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 10:27:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:27:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:27:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-09 10:27:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:27:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:27:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:27:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:27:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:27:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:28:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:28:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.164215, avg_loss=0.683675, seen=480, correct=263, accuracy=0.547917
2025-10-09 10:28:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:28:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:28:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:28:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2054MB allocated=1912MB
2025-10-09 10:28:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50513523817062, 'train_avg_loss': 0.6792094603180885, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:28:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1642150878906, 'train_avg_loss': 0.6836754480997721, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:28:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 328.1642150878906, 'train_avg_loss': 0.6836754480997721, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:28:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:28:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:28:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:28:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:28:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.873260, avg_loss=0.691403, seen=480, correct=249, accuracy=0.518750
2025-10-09 10:28:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:28:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:28:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:28:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2068MB allocated=1912MB
2025-10-09 10:28:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.34113562107086, 'train_avg_loss': 0.6945094635089238, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:28:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8732604980469, 'train_avg_loss': 0.6914026260375976, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 10:28:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 331.8732604980469, 'train_avg_loss': 0.6914026260375976, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 10:28:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:28:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:28:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-09 10:29:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:29:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:29:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:29:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:29:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:29:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:29:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:29:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.408142, avg_loss=0.686267, seen=480, correct=258, accuracy=0.537500
2025-10-09 10:29:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:29:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:29:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:29:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2054MB allocated=1912MB
2025-10-09 10:29:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43557572364807, 'train_avg_loss': 0.7036297976970672, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 10:29:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.40814208984375, 'train_avg_loss': 0.6862669626871745, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 10:29:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 329.40814208984375, 'train_avg_loss': 0.6862669626871745, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 10:29:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #64) -------------
2025-10-09 10:29:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=64 aidx=3 | s=5 (candidates=12)
2025-10-09 10:29:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 6, 36, 22, 28] (from 12)
2025-10-09 10:29:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:29:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:29:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:30:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:30:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.303040, avg_loss=0.690215, seen=480, correct=247, accuracy=0.514583
2025-10-09 10:30:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:30:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:30:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:30:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2066MB allocated=1912MB
2025-10-09 10:30:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.07424426078796, 'train_avg_loss': 0.7006187021732331, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 10:30:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.30303955078125, 'train_avg_loss': 0.6902146657307943, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 10:30:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 331.30303955078125, 'train_avg_loss': 0.6902146657307943, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 10:30:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:30:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:30:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-09 10:30:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 10:30:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:30:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:30:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:30:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:30:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:31:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:31:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.566284, avg_loss=0.692846, seen=480, correct=252, accuracy=0.525000
2025-10-09 10:31:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:31:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:31:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:31:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2054MB allocated=1912MB
2025-10-09 10:31:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.97874784469604, 'train_avg_loss': 0.6998228987058004, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 10:31:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5662841796875, 'train_avg_loss': 0.6928464253743489, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 10:31:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 332.5662841796875, 'train_avg_loss': 0.6928464253743489, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 10:31:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:31:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:31:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-09 10:31:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:31:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:31:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:31:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:31:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:31:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:31:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:31:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.137085, avg_loss=0.685702, seen=480, correct=266, accuracy=0.554167
2025-10-09 10:31:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:31:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:31:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:31:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2054MB allocated=1912MB
2025-10-09 10:31:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66770762205124, 'train_avg_loss': 0.6805642301837603, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 10:31:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1370849609375, 'train_avg_loss': 0.6857022603352865, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:31:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 329.1370849609375, 'train_avg_loss': 0.6857022603352865, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:31:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:31:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:31:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:32:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:32:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.808228, avg_loss=0.685017, seen=480, correct=266, accuracy=0.554167
2025-10-09 10:32:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:32:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:32:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:32:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2062MB allocated=1912MB
2025-10-09 10:32:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.32468831539154, 'train_avg_loss': 0.6777057359615962, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:32:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.8082275390625, 'train_avg_loss': 0.6850171407063802, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:32:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 328.8082275390625, 'train_avg_loss': 0.6850171407063802, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:32:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:32:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:32:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-09 10:32:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:32:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:32:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:32:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:32:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:32:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:33:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:33:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.170624, avg_loss=0.687855, seen=480, correct=262, accuracy=0.545833
2025-10-09 10:33:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:33:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:33:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:33:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2054MB allocated=1912MB
2025-10-09 10:33:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.51833438873291, 'train_avg_loss': 0.6876527865727743, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 10:33:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1706237792969, 'train_avg_loss': 0.6878554662068684, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:33:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 330.1706237792969, 'train_avg_loss': 0.6878554662068684, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:33:23 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #65) -------------
2025-10-09 10:33:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=65 aidx=3 | s=5 (candidates=12)
2025-10-09 10:33:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 50, 6, 28, 43] (from 12)
2025-10-09 10:33:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 10:33:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:33:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:34:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:34:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.636688, avg_loss=0.695076, seen=480, correct=252, accuracy=0.525000
2025-10-09 10:34:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:34:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:34:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:34:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2054MB allocated=1912MB
2025-10-09 10:34:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.98294174671173, 'train_avg_loss': 0.7081911812225977, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:34:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.6366882324219, 'train_avg_loss': 0.6950764338175456, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 10:34:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 333.6366882324219, 'train_avg_loss': 0.6950764338175456, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 10:34:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:34:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:34:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:34:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:34:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.370483, avg_loss=0.686189, seen=480, correct=272, accuracy=0.566667
2025-10-09 10:34:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:34:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:34:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:34:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2054MB allocated=1912MB
2025-10-09 10:34:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.82594549655914, 'train_avg_loss': 0.6985495458046596, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 10:34:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3704833984375, 'train_avg_loss': 0.6861885070800782, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 10:34:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 329.3704833984375, 'train_avg_loss': 0.6861885070800782, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 10:34:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:34:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:34:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-09 10:34:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 10:34:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:34:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:34:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:34:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:34:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:35:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:35:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.772156, avg_loss=0.695359, seen=480, correct=253, accuracy=0.527083
2025-10-09 10:35:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:35:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:35:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:35:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2054MB allocated=1912MB
2025-10-09 10:35:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.2114839553833, 'train_avg_loss': 0.7017623662948609, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 10:35:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.77215576171875, 'train_avg_loss': 0.6953586578369141, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 10:35:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 333.77215576171875, 'train_avg_loss': 0.6953586578369141, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 10:35:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:35:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:35:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:36:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:36:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.433350, avg_loss=0.677986, seen=480, correct=273, accuracy=0.568750
2025-10-09 10:36:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:36:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:36:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:36:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2054MB allocated=1912MB
2025-10-09 10:36:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.85648727416992, 'train_avg_loss': 0.682137393951416, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:36:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.433349609375, 'train_avg_loss': 0.6779861450195312, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 10:36:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 325.433349609375, 'train_avg_loss': 0.6779861450195312, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 10:36:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 10:36:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:36:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:36:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:36:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.479797, avg_loss=0.678083, seen=480, correct=276, accuracy=0.575000
2025-10-09 10:36:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:36:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:37:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:37:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2098MB allocated=1912MB
2025-10-09 10:37:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.82484209537506, 'train_avg_loss': 0.6985403507947922, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:37:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.47979736328125, 'train_avg_loss': 0.6780829111735026, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 10:37:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 325.47979736328125, 'train_avg_loss': 0.6780829111735026, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 10:37:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #66) -------------
2025-10-09 10:37:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=66 aidx=3 | s=5 (candidates=12)
2025-10-09 10:37:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 15, 22, 48, 50] (from 12)
2025-10-09 10:37:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:37:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:37:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:37:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:37:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.039978, avg_loss=0.677167, seen=480, correct=262, accuracy=0.545833
2025-10-09 10:37:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:37:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:37:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:37:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2054MB allocated=1912MB
2025-10-09 10:37:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.95658445358276, 'train_avg_loss': 0.6829715371131897, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 10:37:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.03997802734375, 'train_avg_loss': 0.6771666208902994, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:37:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 325.03997802734375, 'train_avg_loss': 0.6771666208902994, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:37:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:37:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:37:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-09 10:37:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:37:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:37:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:37:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:37:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:37:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:38:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:38:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.993286, avg_loss=0.677069, seen=480, correct=261, accuracy=0.543750
2025-10-09 10:38:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:38:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:38:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:38:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2054MB allocated=1912MB
2025-10-09 10:38:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.82971692085266, 'train_avg_loss': 0.6985809743404389, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 10:38:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.9932861328125, 'train_avg_loss': 0.677069346110026, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:38:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 324.9932861328125, 'train_avg_loss': 0.677069346110026, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:38:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:38:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:38:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:39:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:39:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.030884, avg_loss=0.681314, seen=480, correct=268, accuracy=0.558333
2025-10-09 10:39:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:39:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:39:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:39:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2062MB allocated=1912MB
2025-10-09 10:39:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.82364356517792, 'train_avg_loss': 0.6735303630431493, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 10:39:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.0308837890625, 'train_avg_loss': 0.6813143412272136, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 10:39:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 327.0308837890625, 'train_avg_loss': 0.6813143412272136, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 10:39:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:39:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:39:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:40:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:40:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.014282, avg_loss=0.685446, seen=480, correct=254, accuracy=0.529167
2025-10-09 10:40:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:40:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:40:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:40:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2066MB allocated=1912MB
2025-10-09 10:40:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.1453109383583, 'train_avg_loss': 0.6928775911529859, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:40:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0142822265625, 'train_avg_loss': 0.6854464213053385, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:40:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 329.0142822265625, 'train_avg_loss': 0.6854464213053385, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 10:40:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:40:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:40:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:40:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:40:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.815582, avg_loss=0.687116, seen=480, correct=270, accuracy=0.562500
2025-10-09 10:40:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:40:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:40:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:40:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2054MB allocated=1912MB
2025-10-09 10:40:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.27486687898636, 'train_avg_loss': 0.7022905573248863, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:40:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8155822753906, 'train_avg_loss': 0.6871157964070638, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:40:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 329.8155822753906, 'train_avg_loss': 0.6871157964070638, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:40:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #67) -------------
2025-10-09 10:40:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=67 aidx=3 | s=5 (candidates=12)
2025-10-09 10:40:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 28, 6, 15, 40] (from 12)
2025-10-09 10:40:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:40:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:40:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:41:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:41:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.581482, avg_loss=0.682461, seen=480, correct=276, accuracy=0.575000
2025-10-09 10:41:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:41:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:41:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:41:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2062MB allocated=1912MB
2025-10-09 10:41:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.47493487596512, 'train_avg_loss': 0.6789577906330426, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 10:41:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.58148193359375, 'train_avg_loss': 0.6824614206949869, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 10:41:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 327.58148193359375, 'train_avg_loss': 0.6824614206949869, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 10:41:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:41:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:41:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:42:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:42:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.347260, avg_loss=0.675723, seen=480, correct=276, accuracy=0.575000
2025-10-09 10:42:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:42:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:42:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:42:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2054MB allocated=1912MB
2025-10-09 10:42:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50570070743561, 'train_avg_loss': 0.6792141725619634, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:42:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.3472595214844, 'train_avg_loss': 0.6757234573364258, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 10:42:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 324.3472595214844, 'train_avg_loss': 0.6757234573364258, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 10:42:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 10:42:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:42:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:42:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:42:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.988617, avg_loss=0.693726, seen=480, correct=257, accuracy=0.535417
2025-10-09 10:42:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:42:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:42:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:42:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2054MB allocated=1912MB
2025-10-09 10:42:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91598403453827, 'train_avg_loss': 0.6992998669544855, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 10:42:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.9886169433594, 'train_avg_loss': 0.6937262852986653, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 10:42:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 332.9886169433594, 'train_avg_loss': 0.6937262852986653, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 10:42:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:42:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:42:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-09 10:42:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:42:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:42:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:42:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:42:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:42:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:43:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:43:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.166809, avg_loss=0.677431, seen=480, correct=263, accuracy=0.547917
2025-10-09 10:43:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:43:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:43:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:43:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2054MB allocated=1912MB
2025-10-09 10:43:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.87979334592819, 'train_avg_loss': 0.6989982778827349, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 10:43:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.16680908203125, 'train_avg_loss': 0.6774308522542317, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:43:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 325.16680908203125, 'train_avg_loss': 0.6774308522542317, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:43:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 10:43:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:43:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:44:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:44:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.895477, avg_loss=0.693532, seen=480, correct=248, accuracy=0.516667
2025-10-09 10:44:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:44:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:44:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:44:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2054MB allocated=1912MB
2025-10-09 10:44:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.37462377548218, 'train_avg_loss': 0.7114551981290181, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 10:44:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8954772949219, 'train_avg_loss': 0.6935322443644206, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 10:44:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 332.8954772949219, 'train_avg_loss': 0.6935322443644206, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 10:44:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #68) -------------
2025-10-09 10:44:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=68 aidx=3 | s=5 (candidates=12)
2025-10-09 10:44:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 40, 48, 15, 36] (from 12)
2025-10-09 10:44:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 10:44:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:44:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:45:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:45:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.981689, avg_loss=0.674962, seen=480, correct=278, accuracy=0.579167
2025-10-09 10:45:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:45:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:45:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:45:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2054MB allocated=1912MB
2025-10-09 10:45:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.69867074489594, 'train_avg_loss': 0.6724889228741328, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 10:45:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.981689453125, 'train_avg_loss': 0.6749618530273438, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 10:45:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 323.981689453125, 'train_avg_loss': 0.6749618530273438, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 10:45:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:45:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:45:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-09 10:45:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 10:45:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:45:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:45:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:45:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:45:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:45:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:45:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.886017, avg_loss=0.689346, seen=480, correct=261, accuracy=0.543750
2025-10-09 10:45:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:45:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:45:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:45:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2054MB allocated=1912MB
2025-10-09 10:45:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.56363797187805, 'train_avg_loss': 0.7046969830989838, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 10:45:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8860168457031, 'train_avg_loss': 0.6893458684285482, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:45:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 330.8860168457031, 'train_avg_loss': 0.6893458684285482, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:45:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:45:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:45:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:46:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:46:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.547546, avg_loss=0.682391, seen=480, correct=265, accuracy=0.552083
2025-10-09 10:46:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:46:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:46:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:46:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2066MB allocated=1912MB
2025-10-09 10:46:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.69654703140259, 'train_avg_loss': 0.6974712252616883, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:46:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.54754638671875, 'train_avg_loss': 0.6823907216389974, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 10:46:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 327.54754638671875, 'train_avg_loss': 0.6823907216389974, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 10:46:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:46:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:46:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:47:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:47:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.922516, avg_loss=0.679005, seen=480, correct=266, accuracy=0.554167
2025-10-09 10:47:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:47:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:47:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:47:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2054MB allocated=1912MB
2025-10-09 10:47:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.46123367547989, 'train_avg_loss': 0.6955102806289991, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:47:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.9225158691406, 'train_avg_loss': 0.679005241394043, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:47:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 325.9225158691406, 'train_avg_loss': 0.679005241394043, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:47:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:47:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:47:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-09 10:47:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:47:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:47:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:47:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:47:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:47:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:48:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:48:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.732361, avg_loss=0.684859, seen=480, correct=268, accuracy=0.558333
2025-10-09 10:48:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:48:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:48:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:48:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2054MB allocated=1912MB
2025-10-09 10:48:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.96278762817383, 'train_avg_loss': 0.6746898969014485, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 10:48:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.73236083984375, 'train_avg_loss': 0.6848590850830079, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 10:48:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 328.73236083984375, 'train_avg_loss': 0.6848590850830079, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 10:48:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #69) -------------
2025-10-09 10:48:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=69 aidx=3 | s=5 (candidates=12)
2025-10-09 10:48:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 51, 50, 48, 15] (from 12)
2025-10-09 10:48:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:48:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:48:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-09 10:48:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 10:48:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:48:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:48:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:48:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:48:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:48:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:48:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.044739, avg_loss=0.685510, seen=480, correct=266, accuracy=0.554167
2025-10-09 10:48:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:48:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:48:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:48:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2080MB allocated=1912MB
2025-10-09 10:48:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.83544689416885, 'train_avg_loss': 0.6652953907847404, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 10:48:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.04473876953125, 'train_avg_loss': 0.6855098724365234, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:48:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 329.04473876953125, 'train_avg_loss': 0.6855098724365234, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 10:48:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 10:48:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:48:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:49:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:49:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.557037, avg_loss=0.678244, seen=480, correct=274, accuracy=0.570833
2025-10-09 10:49:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:49:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:49:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:49:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2072MB allocated=1912MB
2025-10-09 10:49:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26257908344269, 'train_avg_loss': 0.6855214923620224, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:49:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.5570373535156, 'train_avg_loss': 0.6782438278198242, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 10:49:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 325.5570373535156, 'train_avg_loss': 0.6782438278198242, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 10:49:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:49:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:49:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:50:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:50:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.120514, avg_loss=0.681501, seen=480, correct=262, accuracy=0.545833
2025-10-09 10:50:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:50:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:50:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:50:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2054MB allocated=1912MB
2025-10-09 10:50:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.39804691076279, 'train_avg_loss': 0.6949837242563566, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 10:50:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.1205139160156, 'train_avg_loss': 0.6815010706583658, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:50:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 327.1205139160156, 'train_avg_loss': 0.6815010706583658, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 10:50:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:50:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:50:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:51:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:51:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.474304, avg_loss=0.680155, seen=480, correct=261, accuracy=0.543750
2025-10-09 10:51:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:51:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:51:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:51:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2068MB allocated=1912MB
2025-10-09 10:51:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.72956454753876, 'train_avg_loss': 0.6894130378961563, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:51:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.47430419921875, 'train_avg_loss': 0.6801548004150391, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:51:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 326.47430419921875, 'train_avg_loss': 0.6801548004150391, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:51:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 10:51:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:51:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:51:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:51:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.001709, avg_loss=0.679170, seen=480, correct=270, accuracy=0.562500
2025-10-09 10:51:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:51:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:51:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:51:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2054MB allocated=1912MB
2025-10-09 10:51:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.18778431415558, 'train_avg_loss': 0.6932315359512965, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:51:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.001708984375, 'train_avg_loss': 0.6791702270507812, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:51:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 326.001708984375, 'train_avg_loss': 0.6791702270507812, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:51:47 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #70) -------------
2025-10-09 10:51:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=70 aidx=3 | s=5 (candidates=12)
2025-10-09 10:51:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 51, 43, 50, 48] (from 12)
2025-10-09 10:51:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 10:51:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:51:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:52:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:52:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.632477, avg_loss=0.682568, seen=480, correct=267, accuracy=0.556250
2025-10-09 10:52:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:52:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:52:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:52:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2080MB allocated=1912MB
2025-10-09 10:52:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.67124092578888, 'train_avg_loss': 0.655593674381574, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 10:52:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6324768066406, 'train_avg_loss': 0.6825676600138346, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 10:52:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 327.6324768066406, 'train_avg_loss': 0.6825676600138346, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 10:52:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 10:52:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:52:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:53:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:53:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.642395, avg_loss=0.674255, seen=480, correct=271, accuracy=0.564583
2025-10-09 10:53:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:53:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:53:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:53:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2072MB allocated=1912MB
2025-10-09 10:53:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.55397355556488, 'train_avg_loss': 0.6879497796297074, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 10:53:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.64239501953125, 'train_avg_loss': 0.6742549896240234, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 10:53:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 323.64239501953125, 'train_avg_loss': 0.6742549896240234, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 10:53:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:53:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:53:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-09 10:53:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 10:53:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:53:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:53:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:53:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:53:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:54:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:54:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.250610, avg_loss=0.665105, seen=480, correct=293, accuracy=0.610417
2025-10-09 10:54:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:54:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:54:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:54:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2098MB allocated=1912MB
2025-10-09 10:54:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.47694200277328, 'train_avg_loss': 0.6873078500231107, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:54:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.2506103515625, 'train_avg_loss': 0.6651054382324219, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 10:54:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 319.2506103515625, 'train_avg_loss': 0.6651054382324219, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 10:54:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:54:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:54:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:54:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:54:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.581268, avg_loss=0.680378, seen=480, correct=277, accuracy=0.577083
2025-10-09 10:54:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:54:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:54:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:54:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2054MB allocated=1912MB
2025-10-09 10:54:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.65253168344498, 'train_avg_loss': 0.6887710973620415, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 10:54:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.5812683105469, 'train_avg_loss': 0.6803776423136393, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 10:54:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 326.5812683105469, 'train_avg_loss': 0.6803776423136393, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 10:54:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 10:54:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:54:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:55:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:55:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.303833, avg_loss=0.681883, seen=480, correct=261, accuracy=0.543750
2025-10-09 10:55:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:55:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:55:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:55:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2068MB allocated=1912MB
2025-10-09 10:55:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73557806015015, 'train_avg_loss': 0.6977964838345846, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 10:55:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.3038330078125, 'train_avg_loss': 0.6818829854329427, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:55:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 327.3038330078125, 'train_avg_loss': 0.6818829854329427, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 10:55:34 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #71) -------------
2025-10-09 10:55:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=71 aidx=3 | s=5 (candidates=12)
2025-10-09 10:55:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 36, 20, 51, 6] (from 12)
2025-10-09 10:55:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:55:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:55:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-09 10:55:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 10:55:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:55:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:55:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:55:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:55:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:56:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:56:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.683472, avg_loss=0.676424, seen=480, correct=286, accuracy=0.595833
2025-10-09 10:56:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:56:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:56:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:56:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2062MB allocated=1912MB
2025-10-09 10:56:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.80363655090332, 'train_avg_loss': 0.6733636379241943, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:56:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.6834716796875, 'train_avg_loss': 0.6764238993326823, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 10:56:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 324.6834716796875, 'train_avg_loss': 0.6764238993326823, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 10:56:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 10:56:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:56:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:56:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:56:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.698059, avg_loss=0.680621, seen=480, correct=273, accuracy=0.568750
2025-10-09 10:56:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:56:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:56:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:56:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2054MB allocated=1912MB
2025-10-09 10:56:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.89033722877502, 'train_avg_loss': 0.6657528102397918, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:56:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.69805908203125, 'train_avg_loss': 0.6806209564208985, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 10:56:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 326.69805908203125, 'train_avg_loss': 0.6806209564208985, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 10:57:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 10:57:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:57:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:57:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:57:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.056488, avg_loss=0.673034, seen=480, correct=289, accuracy=0.602083
2025-10-09 10:57:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:57:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:57:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:57:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2064MB allocated=1912MB
2025-10-09 10:57:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36386227607727, 'train_avg_loss': 0.6780321856339773, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:57:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0564880371094, 'train_avg_loss': 0.6730343500773112, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 10:57:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 323.0564880371094, 'train_avg_loss': 0.6730343500773112, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 10:57:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 10:57:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:57:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:58:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:58:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.177979, avg_loss=0.677454, seen=480, correct=263, accuracy=0.547917
2025-10-09 10:58:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:58:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:58:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:58:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2074MB allocated=1912MB
2025-10-09 10:58:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.46630185842514, 'train_avg_loss': 0.6872191821535428, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 10:58:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.177978515625, 'train_avg_loss': 0.677454121907552, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:58:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 325.177978515625, 'train_avg_loss': 0.677454121907552, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:58:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 10:58:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:58:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:59:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:59:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.222229, avg_loss=0.687963, seen=480, correct=263, accuracy=0.547917
2025-10-09 10:59:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:59:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:59:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:59:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2054MB allocated=1912MB
2025-10-09 10:59:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.76481682062149, 'train_avg_loss': 0.6897068068385124, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 10:59:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.22222900390625, 'train_avg_loss': 0.6879629770914714, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:59:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 330.22222900390625, 'train_avg_loss': 0.6879629770914714, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 10:59:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #72) -------------
2025-10-09 10:59:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=72 aidx=3 | s=5 (candidates=12)
2025-10-09 10:59:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 51, 22, 40, 16] (from 12)
2025-10-09 10:59:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 10:59:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 10:59:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 10:59:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 10:59:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.965637, avg_loss=0.679095, seen=480, correct=270, accuracy=0.562500
2025-10-09 10:59:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 10:59:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 10:59:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 10:59:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2054MB allocated=1912MB
2025-10-09 10:59:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.61055207252502, 'train_avg_loss': 0.6967546006043752, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 10:59:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.96563720703125, 'train_avg_loss': 0.6790950775146485, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:59:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 325.96563720703125, 'train_avg_loss': 0.6790950775146485, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 10:59:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 11:00:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:00:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:00:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:00:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.366028, avg_loss=0.675763, seen=480, correct=272, accuracy=0.566667
2025-10-09 11:00:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:00:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:00:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:00:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2074MB allocated=1912MB
2025-10-09 11:00:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.9558230638504, 'train_avg_loss': 0.6829651921987534, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:00:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.36602783203125, 'train_avg_loss': 0.6757625579833985, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 11:00:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 324.36602783203125, 'train_avg_loss': 0.6757625579833985, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 11:00:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:00:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:00:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:01:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:01:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.081512, avg_loss=0.675170, seen=480, correct=277, accuracy=0.577083
2025-10-09 11:01:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:01:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:01:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:01:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2062MB allocated=1912MB
2025-10-09 11:01:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5959529876709, 'train_avg_loss': 0.6799662748972575, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 11:01:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0815124511719, 'train_avg_loss': 0.6751698176066081, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 11:01:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 324.0815124511719, 'train_avg_loss': 0.6751698176066081, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 11:01:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:01:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:01:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-09 11:01:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 11:01:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:01:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:01:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:01:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:01:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:02:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:02:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.418549, avg_loss=0.684205, seen=480, correct=272, accuracy=0.566667
2025-10-09 11:02:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:02:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:02:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:02:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2054MB allocated=1912MB
2025-10-09 11:02:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.79254102706909, 'train_avg_loss': 0.6982711752255758, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:02:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4185485839844, 'train_avg_loss': 0.6842053095499675, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 11:02:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 328.4185485839844, 'train_avg_loss': 0.6842053095499675, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 11:02:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:02:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:02:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-09 11:02:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 11:02:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:02:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:02:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:02:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:02:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:02:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:02:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.429871, avg_loss=0.682146, seen=480, correct=267, accuracy=0.556250
2025-10-09 11:02:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:02:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:02:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:02:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2080MB allocated=1912MB
2025-10-09 11:02:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.4705827832222, 'train_avg_loss': 0.6622548565268517, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:02:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.42987060546875, 'train_avg_loss': 0.6821455637613932, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 11:02:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 327.42987060546875, 'train_avg_loss': 0.6821455637613932, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 11:02:54 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #73) -------------
2025-10-09 11:02:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=73 aidx=3 | s=5 (candidates=12)
2025-10-09 11:02:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 16, 22, 43, 48] (from 12)
2025-10-09 11:02:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:02:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:02:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:03:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:03:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.340088, avg_loss=0.669459, seen=480, correct=278, accuracy=0.579167
2025-10-09 11:03:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:03:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:03:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:03:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2054MB allocated=1912MB
2025-10-09 11:03:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.25355702638626, 'train_avg_loss': 0.6937796418865522, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:03:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.340087890625, 'train_avg_loss': 0.669458516438802, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 11:03:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 321.340087890625, 'train_avg_loss': 0.669458516438802, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 11:03:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 11:03:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:03:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:04:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:04:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.128479, avg_loss=0.673184, seen=480, correct=277, accuracy=0.577083
2025-10-09 11:04:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:04:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:04:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:04:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2080MB allocated=1912MB
2025-10-09 11:04:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.36932981014252, 'train_avg_loss': 0.6530777484178543, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 11:04:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.12847900390625, 'train_avg_loss': 0.673184331258138, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 11:04:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 323.12847900390625, 'train_avg_loss': 0.673184331258138, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 11:04:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:04:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:04:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-09 11:04:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:04:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:04:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:04:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:04:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:04:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:05:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:05:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.977722, avg_loss=0.672870, seen=480, correct=287, accuracy=0.597917
2025-10-09 11:05:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:05:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:05:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:05:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2062MB allocated=1912MB
2025-10-09 11:05:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90785121917725, 'train_avg_loss': 0.682565426826477, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 11:05:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.97772216796875, 'train_avg_loss': 0.6728702545166015, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 11:05:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 322.97772216796875, 'train_avg_loss': 0.6728702545166015, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 11:05:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:05:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:05:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-09 11:05:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:05:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:05:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:05:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:05:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:05:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:05:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:05:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.760651, avg_loss=0.664085, seen=480, correct=288, accuracy=0.600000
2025-10-09 11:05:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:05:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:05:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:05:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2098MB allocated=1912MB
2025-10-09 11:05:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90018081665039, 'train_avg_loss': 0.6825015068054199, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:05:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.7606506347656, 'train_avg_loss': 0.6640846888224284, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 11:05:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 318.7606506347656, 'train_avg_loss': 0.6640846888224284, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 11:05:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:05:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:05:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:06:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:06:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.823364, avg_loss=0.672549, seen=480, correct=273, accuracy=0.568750
2025-10-09 11:06:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:06:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:06:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:06:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2066MB allocated=1912MB
2025-10-09 11:06:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.13140743970871, 'train_avg_loss': 0.6844283953309059, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:06:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.8233642578125, 'train_avg_loss': 0.6725486755371094, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 11:06:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 322.8233642578125, 'train_avg_loss': 0.6725486755371094, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 11:06:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #74) -------------
2025-10-09 11:06:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=74 aidx=3 | s=5 (candidates=12)
2025-10-09 11:06:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 50, 6, 48, 51] (from 12)
2025-10-09 11:06:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:06:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:06:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-09 11:06:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:06:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:06:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:06:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:06:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:06:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:07:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:07:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.924622, avg_loss=0.668593, seen=480, correct=297, accuracy=0.618750
2025-10-09 11:07:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:07:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:07:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:07:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2062MB allocated=1912MB
2025-10-09 11:07:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.56928813457489, 'train_avg_loss': 0.6714107344547907, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 11:07:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.92462158203125, 'train_avg_loss': 0.6685929616292318, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:07:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 320.92462158203125, 'train_avg_loss': 0.6685929616292318, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:07:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 11:07:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:07:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:08:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:08:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.484406, avg_loss=0.678093, seen=480, correct=284, accuracy=0.591667
2025-10-09 11:08:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:08:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:08:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:08:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2054MB allocated=1912MB
2025-10-09 11:08:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.57814508676529, 'train_avg_loss': 0.6964845423897107, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 11:08:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4844055175781, 'train_avg_loss': 0.6780925114949544, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 11:08:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 325.4844055175781, 'train_avg_loss': 0.6780925114949544, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 11:08:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:08:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:08:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:08:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:08:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.238190, avg_loss=0.675496, seen=480, correct=281, accuracy=0.585417
2025-10-09 11:08:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:08:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:08:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:08:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2054MB allocated=1912MB
2025-10-09 11:08:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.13844859600067, 'train_avg_loss': 0.6761537383000056, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 11:08:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.2381896972656, 'train_avg_loss': 0.67549622853597, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 11:08:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 324.2381896972656, 'train_avg_loss': 0.67549622853597, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 11:08:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:08:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:08:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:09:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:09:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.910645, avg_loss=0.660231, seen=480, correct=290, accuracy=0.604167
2025-10-09 11:09:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:09:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:09:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:09:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2066MB allocated=1912MB
2025-10-09 11:09:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.46040546894073, 'train_avg_loss': 0.6788367122411728, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 11:09:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.91064453125, 'train_avg_loss': 0.6602305094401042, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 11:09:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 316.91064453125, 'train_avg_loss': 0.6602305094401042, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 11:09:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:09:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:09:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-09 11:09:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 11:09:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:09:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:09:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:09:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:09:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:10:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:10:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.623291, avg_loss=0.672132, seen=480, correct=282, accuracy=0.587500
2025-10-09 11:10:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:10:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:10:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:10:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2074MB allocated=1912MB
2025-10-09 11:10:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.12056052684784, 'train_avg_loss': 0.6843380043903987, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 11:10:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.623291015625, 'train_avg_loss': 0.6721318562825521, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 11:10:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 322.623291015625, 'train_avg_loss': 0.6721318562825521, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 11:10:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #75) -------------
2025-10-09 11:10:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=75 aidx=3 | s=5 (candidates=12)
2025-10-09 11:10:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 43, 15, 6, 28] (from 12)
2025-10-09 11:10:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:10:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:10:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:11:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:11:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.005402, avg_loss=0.662511, seen=480, correct=297, accuracy=0.618750
2025-10-09 11:11:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:11:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:11:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:11:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2062MB allocated=1912MB
2025-10-09 11:11:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.05288124084473, 'train_avg_loss': 0.667107343673706, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 11:11:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.0054016113281, 'train_avg_loss': 0.6625112533569336, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:11:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 318.0054016113281, 'train_avg_loss': 0.6625112533569336, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:11:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:11:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:11:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-09 11:11:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:11:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:11:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:11:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:11:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:11:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:11:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:11:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.078003, avg_loss=0.658496, seen=480, correct=298, accuracy=0.620833
2025-10-09 11:11:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:11:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:11:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:11:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2098MB allocated=1912MB
2025-10-09 11:11:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.65052497386932, 'train_avg_loss': 0.680421041448911, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:11:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.0780029296875, 'train_avg_loss': 0.658495839436849, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 11:11:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 316.0780029296875, 'train_avg_loss': 0.658495839436849, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 11:11:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:11:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:11:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:12:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:12:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.191589, avg_loss=0.667066, seen=480, correct=283, accuracy=0.589583
2025-10-09 11:12:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:12:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:12:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:12:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2054MB allocated=1912MB
2025-10-09 11:12:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.22529083490372, 'train_avg_loss': 0.6935440902908643, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:12:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.19158935546875, 'train_avg_loss': 0.6670658111572265, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 11:12:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 320.19158935546875, 'train_avg_loss': 0.6670658111572265, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 11:12:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:12:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:12:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:13:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:13:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.557312, avg_loss=0.676161, seen=480, correct=271, accuracy=0.564583
2025-10-09 11:13:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:13:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:13:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:13:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2054MB allocated=1912MB
2025-10-09 11:13:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.55180025100708, 'train_avg_loss': 0.6712650020917257, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:13:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.55731201171875, 'train_avg_loss': 0.6761610666910808, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 11:13:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 324.55731201171875, 'train_avg_loss': 0.6761610666910808, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 11:13:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:13:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:13:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-09 11:13:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 11:13:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:13:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:13:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:13:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:13:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:14:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:14:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.311279, avg_loss=0.661065, seen=480, correct=301, accuracy=0.627083
2025-10-09 11:14:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:14:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:14:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:14:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2054MB allocated=1912MB
2025-10-09 11:14:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.27908933162689, 'train_avg_loss': 0.6606590777635575, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 11:14:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.311279296875, 'train_avg_loss': 0.6610651652018229, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 11:14:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 317.311279296875, 'train_avg_loss': 0.6610651652018229, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 11:14:04 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #76) -------------
2025-10-09 11:14:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=76 aidx=3 | s=5 (candidates=12)
2025-10-09 11:14:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 36, 48, 6, 43] (from 12)
2025-10-09 11:14:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:14:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:14:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-09 11:14:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 11:14:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:14:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:14:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:14:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:14:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:14:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:14:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.698029, avg_loss=0.655621, seen=480, correct=297, accuracy=0.618750
2025-10-09 11:14:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:14:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:14:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:14:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2064MB allocated=1912MB
2025-10-09 11:14:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.39450192451477, 'train_avg_loss': 0.6699541827042897, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:14:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.6980285644531, 'train_avg_loss': 0.6556208928426107, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:14:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 314.6980285644531, 'train_avg_loss': 0.6556208928426107, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:14:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 11:14:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:14:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:15:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:15:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.701263, avg_loss=0.676461, seen=480, correct=272, accuracy=0.566667
2025-10-09 11:15:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:15:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:15:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:15:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2054MB allocated=1912MB
2025-10-09 11:15:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.99898612499237, 'train_avg_loss': 0.6499915510416031, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 11:15:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7012634277344, 'train_avg_loss': 0.6764609654744466, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 11:15:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 324.7012634277344, 'train_avg_loss': 0.6764609654744466, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 11:15:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:15:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:15:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-09 11:15:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:15:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:15:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:15:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:15:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:15:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:16:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:16:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.855743, avg_loss=0.655949, seen=480, correct=293, accuracy=0.610417
2025-10-09 11:16:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:16:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:16:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:16:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2066MB allocated=1912MB
2025-10-09 11:16:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.07010453939438, 'train_avg_loss': 0.6839175378282865, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:16:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.8557434082031, 'train_avg_loss': 0.6559494654337565, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 11:16:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 314.8557434082031, 'train_avg_loss': 0.6559494654337565, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 11:16:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:16:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:16:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:16:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:16:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.862823, avg_loss=0.674714, seen=480, correct=276, accuracy=0.575000
2025-10-09 11:16:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:16:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:16:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:16:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2054MB allocated=1912MB
2025-10-09 11:16:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.44565469026566, 'train_avg_loss': 0.6703804557522138, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 11:16:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.8628234863281, 'train_avg_loss': 0.6747142155965169, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 11:16:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 323.8628234863281, 'train_avg_loss': 0.6747142155965169, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 11:17:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:17:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:17:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:17:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:17:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.372528, avg_loss=0.657026, seen=480, correct=299, accuracy=0.622917
2025-10-09 11:17:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:17:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:17:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:17:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2098MB allocated=1912MB
2025-10-09 11:17:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.6458683013916, 'train_avg_loss': 0.68038223584493, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:17:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.3725280761719, 'train_avg_loss': 0.6570261001586915, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 11:17:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 315.3725280761719, 'train_avg_loss': 0.6570261001586915, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 11:17:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #77) -------------
2025-10-09 11:17:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=77 aidx=3 | s=5 (candidates=12)
2025-10-09 11:17:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 15, 50, 51, 48] (from 12)
2025-10-09 11:17:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 11:17:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:17:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:18:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:18:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.635193, avg_loss=0.649240, seen=480, correct=293, accuracy=0.610417
2025-10-09 11:18:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:18:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:18:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:18:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2064MB allocated=1912MB
2025-10-09 11:18:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.83889877796173, 'train_avg_loss': 0.6736574898163478, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 11:18:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.63519287109375, 'train_avg_loss': 0.649239985148112, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 11:18:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 311.63519287109375, 'train_avg_loss': 0.649239985148112, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 11:18:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:18:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:18:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:19:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:19:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.776611, avg_loss=0.662035, seen=480, correct=289, accuracy=0.602083
2025-10-09 11:19:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:19:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:19:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:19:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2054MB allocated=1912MB
2025-10-09 11:19:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.91501730680466, 'train_avg_loss': 0.6909584775567055, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:19:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.776611328125, 'train_avg_loss': 0.6620346069335937, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 11:19:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 317.776611328125, 'train_avg_loss': 0.6620346069335937, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 11:19:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 11:19:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:19:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:19:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:19:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.016632, avg_loss=0.677118, seen=480, correct=277, accuracy=0.577083
2025-10-09 11:19:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:19:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:19:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:19:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2054MB allocated=1912MB
2025-10-09 11:19:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.04462003707886, 'train_avg_loss': 0.7003718336423238, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:19:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0166320800781, 'train_avg_loss': 0.6771179835001627, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 11:19:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 325.0166320800781, 'train_avg_loss': 0.6771179835001627, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 11:19:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:20:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:20:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-09 11:20:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 11:20:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:20:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:20:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:20:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:20:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:20:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:20:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.810547, avg_loss=0.660022, seen=480, correct=293, accuracy=0.610417
2025-10-09 11:20:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:20:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:20:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:20:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2074MB allocated=1912MB
2025-10-09 11:20:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.54270529747009, 'train_avg_loss': 0.6795225441455841, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 11:20:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.810546875, 'train_avg_loss': 0.66002197265625, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 11:20:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 316.810546875, 'train_avg_loss': 0.66002197265625, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 11:20:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:20:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:20:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:21:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:21:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.325500, avg_loss=0.654845, seen=480, correct=295, accuracy=0.614583
2025-10-09 11:21:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:21:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:21:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:21:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2066MB allocated=1912MB
2025-10-09 11:21:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.86321073770523, 'train_avg_loss': 0.6905267561475436, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:21:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.32550048828125, 'train_avg_loss': 0.6548447926839193, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 11:21:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 314.32550048828125, 'train_avg_loss': 0.6548447926839193, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 11:21:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #78) -------------
2025-10-09 11:21:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=78 aidx=3 | s=5 (candidates=12)
2025-10-09 11:21:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 50, 36, 28, 22] (from 12)
2025-10-09 11:21:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 11:21:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:21:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:22:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:22:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.675568, avg_loss=0.657657, seen=480, correct=294, accuracy=0.612500
2025-10-09 11:22:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:22:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:22:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:22:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2080MB allocated=1912MB
2025-10-09 11:22:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.50379401445389, 'train_avg_loss': 0.6291982834537824, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 11:22:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.6755676269531, 'train_avg_loss': 0.6576574325561524, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 11:22:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 315.6755676269531, 'train_avg_loss': 0.6576574325561524, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 11:22:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 11:22:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:22:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:22:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:22:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.239502, avg_loss=0.677582, seen=480, correct=284, accuracy=0.591667
2025-10-09 11:22:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:22:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:22:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:22:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2054MB allocated=1912MB
2025-10-09 11:22:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.05854791402817, 'train_avg_loss': 0.700487899283568, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 11:22:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.239501953125, 'train_avg_loss': 0.6775822957356771, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 11:22:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 325.239501953125, 'train_avg_loss': 0.6775822957356771, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 11:22:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:22:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:22:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-09 11:22:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 11:22:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:22:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:22:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:22:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:22:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:23:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:23:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.021545, avg_loss=0.677128, seen=480, correct=273, accuracy=0.568750
2025-10-09 11:23:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:23:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:23:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:23:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2054MB allocated=1912MB
2025-10-09 11:23:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.86129152774811, 'train_avg_loss': 0.6488440960645676, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:23:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.02154541015625, 'train_avg_loss': 0.6771282196044922, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 11:23:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 325.02154541015625, 'train_avg_loss': 0.6771282196044922, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 11:23:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 11:23:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:23:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:24:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:24:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.049500, avg_loss=0.645936, seen=480, correct=301, accuracy=0.627083
2025-10-09 11:24:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:24:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:24:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:24:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2054MB allocated=1912MB
2025-10-09 11:24:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.37056213617325, 'train_avg_loss': 0.6447546844681104, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:24:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.04949951171875, 'train_avg_loss': 0.6459364573160807, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 11:24:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 310.04949951171875, 'train_avg_loss': 0.6459364573160807, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 11:24:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:24:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:24:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-09 11:24:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:24:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:24:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:24:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:24:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:24:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:25:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:25:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.776672, avg_loss=0.657868, seen=480, correct=305, accuracy=0.635417
2025-10-09 11:25:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:25:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:25:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:25:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2062MB allocated=1912MB
2025-10-09 11:25:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.151691198349, 'train_avg_loss': 0.6679307599862416, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 11:25:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.77667236328125, 'train_avg_loss': 0.6578680674235026, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 11:25:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 315.77667236328125, 'train_avg_loss': 0.6578680674235026, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 11:25:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #79) -------------
2025-10-09 11:25:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=79 aidx=3 | s=5 (candidates=12)
2025-10-09 11:25:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 48, 22, 43, 50] (from 12)
2025-10-09 11:25:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:25:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:25:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:25:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:25:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.965454, avg_loss=0.677011, seen=480, correct=280, accuracy=0.583333
2025-10-09 11:25:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:25:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:25:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:25:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2054MB allocated=1912MB
2025-10-09 11:25:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.80197304487228, 'train_avg_loss': 0.6650164420406024, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:25:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.9654541015625, 'train_avg_loss': 0.6770113627115886, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 11:25:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 324.9654541015625, 'train_avg_loss': 0.6770113627115886, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 11:25:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:25:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:25:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:26:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:26:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.345581, avg_loss=0.642387, seen=480, correct=300, accuracy=0.625000
2025-10-09 11:26:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:26:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:26:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:26:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2066MB allocated=1912MB
2025-10-09 11:26:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26896572113037, 'train_avg_loss': 0.6855747143427531, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:26:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.3455810546875, 'train_avg_loss': 0.6423866271972656, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 11:26:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 308.3455810546875, 'train_avg_loss': 0.6423866271972656, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 11:26:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:26:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:26:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-09 11:26:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:26:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:26:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:26:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:26:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:26:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:27:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:27:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.823914, avg_loss=0.624633, seen=480, correct=327, accuracy=0.681250
2025-10-09 11:27:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:27:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:27:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:27:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2062MB allocated=1912MB
2025-10-09 11:27:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.333571434021, 'train_avg_loss': 0.6361130952835083, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 11:27:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.82391357421875, 'train_avg_loss': 0.6246331532796224, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-09 11:27:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 299.82391357421875, 'train_avg_loss': 0.6246331532796224, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-09 11:27:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:27:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:27:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:28:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:28:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.274872, avg_loss=0.644323, seen=480, correct=303, accuracy=0.631250
2025-10-09 11:28:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:28:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:28:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:28:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2098MB allocated=1912MB
2025-10-09 11:28:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.86672139167786, 'train_avg_loss': 0.6655560115973155, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 11:28:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.2748718261719, 'train_avg_loss': 0.6443226496378581, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 11:28:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 309.2748718261719, 'train_avg_loss': 0.6443226496378581, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 11:28:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 11:28:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:28:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:28:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:28:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.714966, avg_loss=0.678573, seen=480, correct=284, accuracy=0.591667
2025-10-09 11:28:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:28:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:28:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:28:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2054MB allocated=1912MB
2025-10-09 11:28:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.7004406452179, 'train_avg_loss': 0.6975036720434825, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:28:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7149658203125, 'train_avg_loss': 0.6785728454589843, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 11:28:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 325.7149658203125, 'train_avg_loss': 0.6785728454589843, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 11:28:47 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #80) -------------
2025-10-09 11:28:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=80 aidx=3 | s=5 (candidates=12)
2025-10-09 11:28:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 36, 15, 20, 50] (from 12)
2025-10-09 11:28:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:28:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:28:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:29:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:29:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.763977, avg_loss=0.676592, seen=480, correct=273, accuracy=0.568750
2025-10-09 11:29:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:29:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:29:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:29:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2054MB allocated=1912MB
2025-10-09 11:29:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.489561855793, 'train_avg_loss': 0.6624130154649417, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 11:29:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.76397705078125, 'train_avg_loss': 0.6765916188557942, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 11:29:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 324.76397705078125, 'train_avg_loss': 0.6765916188557942, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 11:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:29:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:29:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-09 11:29:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 11:29:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:29:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:29:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:29:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:29:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:30:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:30:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.250671, avg_loss=0.675522, seen=480, correct=274, accuracy=0.570833
2025-10-09 11:30:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:30:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:30:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:30:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2054MB allocated=1912MB
2025-10-09 11:30:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.16488513350487, 'train_avg_loss': 0.6430407094458739, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 11:30:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.25067138671875, 'train_avg_loss': 0.6755222320556641, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 11:30:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 324.25067138671875, 'train_avg_loss': 0.6755222320556641, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 11:30:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:30:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:30:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:30:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:30:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.494934, avg_loss=0.661448, seen=480, correct=292, accuracy=0.608333
2025-10-09 11:30:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:30:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:30:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:30:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2054MB allocated=1912MB
2025-10-09 11:30:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.09474033117294, 'train_avg_loss': 0.6924561694264412, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:30:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.49493408203125, 'train_avg_loss': 0.6614477793375652, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 11:30:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 317.49493408203125, 'train_avg_loss': 0.6614477793375652, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 11:30:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:30:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:30:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-09 11:30:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 11:30:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:30:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:30:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:30:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:30:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:31:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:31:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.349335, avg_loss=0.648644, seen=480, correct=296, accuracy=0.616667
2025-10-09 11:31:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:31:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:31:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:31:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2064MB allocated=1912MB
2025-10-09 11:31:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5448225736618, 'train_avg_loss': 0.671206854780515, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 11:31:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.3493347167969, 'train_avg_loss': 0.6486444473266602, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 11:31:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 311.3493347167969, 'train_avg_loss': 0.6486444473266602, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 11:31:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 11:31:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:31:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:32:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:32:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.436707, avg_loss=0.667576, seen=480, correct=283, accuracy=0.589583
2025-10-09 11:32:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:32:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:32:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:32:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2054MB allocated=1912MB
2025-10-09 11:32:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.07200735807419, 'train_avg_loss': 0.6922667279839516, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 11:32:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.43670654296875, 'train_avg_loss': 0.6675764719645182, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 11:32:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 320.43670654296875, 'train_avg_loss': 0.6675764719645182, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 11:32:20 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #81) -------------
2025-10-09 11:32:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=81 aidx=3 | s=5 (candidates=12)
2025-10-09 11:32:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 43, 48, 28, 20] (from 12)
2025-10-09 11:32:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:32:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:32:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:33:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:33:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.524963, avg_loss=0.678177, seen=480, correct=267, accuracy=0.556250
2025-10-09 11:33:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:33:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:33:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:33:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2054MB allocated=1912MB
2025-10-09 11:33:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.4491600394249, 'train_avg_loss': 0.6620763336618741, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 11:33:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.52496337890625, 'train_avg_loss': 0.678177007039388, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 11:33:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 325.52496337890625, 'train_avg_loss': 0.678177007039388, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 11:33:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:33:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:33:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-09 11:33:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:33:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:33:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:33:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:33:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:33:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:33:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:33:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.956146, avg_loss=0.641575, seen=480, correct=315, accuracy=0.656250
2025-10-09 11:33:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:33:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:33:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:33:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2098MB allocated=1912MB
2025-10-09 11:33:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.61020517349243, 'train_avg_loss': 0.655085043112437, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:33:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.9561462402344, 'train_avg_loss': 0.641575304667155, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 11:33:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 307.9561462402344, 'train_avg_loss': 0.641575304667155, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 11:33:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:33:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:33:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:34:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:34:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.122620, avg_loss=0.639839, seen=480, correct=311, accuracy=0.647917
2025-10-09 11:34:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:34:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:34:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:34:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2066MB allocated=1912MB
2025-10-09 11:34:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.07426154613495, 'train_avg_loss': 0.6756188462177912, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 11:34:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.12261962890625, 'train_avg_loss': 0.6398387908935547, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 11:34:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 307.12261962890625, 'train_avg_loss': 0.6398387908935547, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 11:34:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:34:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:34:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-09 11:34:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 11:34:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:34:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:34:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:34:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:34:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:35:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:35:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.187561, avg_loss=0.646224, seen=480, correct=297, accuracy=0.618750
2025-10-09 11:35:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:35:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:35:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:35:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2054MB allocated=1912MB
2025-10-09 11:35:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.5191758275032, 'train_avg_loss': 0.64599313189586, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 11:35:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.18756103515625, 'train_avg_loss': 0.6462240854899088, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:35:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 310.18756103515625, 'train_avg_loss': 0.6462240854899088, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:35:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:35:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:35:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-09 11:35:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 11:35:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:35:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:35:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:35:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:35:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:36:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:36:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.544037, avg_loss=0.649050, seen=480, correct=297, accuracy=0.618750
2025-10-09 11:36:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:36:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:36:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:36:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2064MB allocated=1912MB
2025-10-09 11:36:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7756798863411, 'train_avg_loss': 0.6731306657195091, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 11:36:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.5440368652344, 'train_avg_loss': 0.6490500768025717, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:36:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 311.5440368652344, 'train_avg_loss': 0.6490500768025717, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 11:36:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #82) -------------
2025-10-09 11:36:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=82 aidx=3 | s=5 (candidates=12)
2025-10-09 11:36:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 43, 51, 36, 22] (from 12)
2025-10-09 11:36:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:36:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:36:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-09 11:36:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 11:36:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:36:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:36:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:36:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:36:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:36:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:36:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.423035, avg_loss=0.684215, seen=480, correct=281, accuracy=0.585417
2025-10-09 11:36:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:36:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:36:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:36:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2054MB allocated=1912MB
2025-10-09 11:36:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.43788540363312, 'train_avg_loss': 0.7119823783636093, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 11:36:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.42303466796875, 'train_avg_loss': 0.6842146555582682, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 11:36:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 328.42303466796875, 'train_avg_loss': 0.6842146555582682, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 11:36:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:36:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:36:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:37:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:37:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.570557, avg_loss=0.630355, seen=480, correct=308, accuracy=0.641667
2025-10-09 11:37:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:37:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:37:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:37:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2098MB allocated=1912MB
2025-10-09 11:37:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.85140705108643, 'train_avg_loss': 0.6570950587590535, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 11:37:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.570556640625, 'train_avg_loss': 0.6303553263346354, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 11:37:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 302.570556640625, 'train_avg_loss': 0.6303553263346354, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 11:37:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 11:37:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:37:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:38:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:38:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.281433, avg_loss=0.663086, seen=480, correct=276, accuracy=0.575000
2025-10-09 11:38:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:38:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:38:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:38:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2074MB allocated=1912MB
2025-10-09 11:38:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99432963132858, 'train_avg_loss': 0.6832860802610715, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 11:38:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.28143310546875, 'train_avg_loss': 0.6630863189697266, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 11:38:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 318.28143310546875, 'train_avg_loss': 0.6630863189697266, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 11:38:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 11:38:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:38:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:38:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:38:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.319092, avg_loss=0.681915, seen=480, correct=279, accuracy=0.581250
2025-10-09 11:38:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:38:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:38:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:39:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2054MB allocated=1912MB
2025-10-09 11:39:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.12373220920563, 'train_avg_loss': 0.6343644350767136, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 11:39:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.319091796875, 'train_avg_loss': 0.6819147745768229, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 11:39:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 327.319091796875, 'train_avg_loss': 0.6819147745768229, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 11:39:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:39:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:39:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:39:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:39:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.516418, avg_loss=0.623993, seen=480, correct=327, accuracy=0.681250
2025-10-09 11:39:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:39:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:39:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:39:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2062MB allocated=1912MB
2025-10-09 11:39:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.36792147159576, 'train_avg_loss': 0.6447326789299647, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 11:39:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.51641845703125, 'train_avg_loss': 0.6239925384521484, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-09 11:39:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 299.51641845703125, 'train_avg_loss': 0.6239925384521484, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-09 11:39:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #83) -------------
2025-10-09 11:39:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=83 aidx=3 | s=5 (candidates=12)
2025-10-09 11:39:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 40, 28, 20, 48] (from 12)
2025-10-09 11:39:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:39:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:39:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:40:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:40:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.507690, avg_loss=0.667724, seen=480, correct=288, accuracy=0.600000
2025-10-09 11:40:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:40:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:40:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:40:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2054MB allocated=1912MB
2025-10-09 11:40:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.83825713396072, 'train_avg_loss': 0.698652142783006, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 11:40:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.5076904296875, 'train_avg_loss': 0.6677243550618489, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 11:40:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 320.5076904296875, 'train_avg_loss': 0.6677243550618489, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 11:40:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 11:40:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:40:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:41:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:41:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.949219, avg_loss=0.687394, seen=480, correct=280, accuracy=0.583333
2025-10-09 11:41:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:41:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:41:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:41:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2054MB allocated=1912MB
2025-10-09 11:41:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.38106042146683, 'train_avg_loss': 0.7115088368455569, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 11:41:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.94921875, 'train_avg_loss': 0.6873942057291667, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 11:41:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 329.94921875, 'train_avg_loss': 0.6873942057291667, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 11:41:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:41:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:41:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-09 11:41:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 11:41:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:41:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:41:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:41:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:41:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:41:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:41:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.646790, avg_loss=0.649264, seen=480, correct=299, accuracy=0.622917
2025-10-09 11:41:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:41:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:41:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:41:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2054MB allocated=1912MB
2025-10-09 11:41:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.62927070260048, 'train_avg_loss': 0.6469105891883373, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:41:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.64678955078125, 'train_avg_loss': 0.649264144897461, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 11:41:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 311.64678955078125, 'train_avg_loss': 0.649264144897461, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 11:41:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 11:41:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:41:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:42:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:42:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.816650, avg_loss=0.632951, seen=480, correct=301, accuracy=0.627083
2025-10-09 11:42:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:42:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:42:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:42:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2064MB allocated=1912MB
2025-10-09 11:42:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.4378189444542, 'train_avg_loss': 0.653648491203785, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 11:42:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.816650390625, 'train_avg_loss': 0.6329513549804687, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 11:42:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 303.816650390625, 'train_avg_loss': 0.6329513549804687, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 11:42:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:42:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:42:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-09 11:42:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:42:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:42:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:42:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:42:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:42:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:43:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:43:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.618317, avg_loss=0.638788, seen=480, correct=296, accuracy=0.616667
2025-10-09 11:43:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:43:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:43:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:43:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2066MB allocated=1912MB
2025-10-09 11:43:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00864207744598, 'train_avg_loss': 0.7000720173120498, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 11:43:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.6183166503906, 'train_avg_loss': 0.6387881596883138, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 11:43:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 306.6183166503906, 'train_avg_loss': 0.6387881596883138, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 11:43:24 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #84) -------------
2025-10-09 11:43:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=84 aidx=3 | s=5 (candidates=12)
2025-10-09 11:43:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 22, 43, 50, 15] (from 12)
2025-10-09 11:43:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 11:43:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:43:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:44:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:44:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.801270, avg_loss=0.680836, seen=480, correct=278, accuracy=0.579167
2025-10-09 11:44:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:44:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:44:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:44:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2054MB allocated=1912MB
2025-10-09 11:44:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.22346723079681, 'train_avg_loss': 0.6351955602566401, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 11:44:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.80126953125, 'train_avg_loss': 0.6808359781901042, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 11:44:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 326.80126953125, 'train_avg_loss': 0.6808359781901042, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 11:44:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:44:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:44:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:44:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:44:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.134338, avg_loss=0.589863, seen=480, correct=333, accuracy=0.693750
2025-10-09 11:44:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:44:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:44:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:44:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2062MB allocated=1912MB
2025-10-09 11:44:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.45129531621933, 'train_avg_loss': 0.6204274609684944, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:44:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.13433837890625, 'train_avg_loss': 0.5898632049560547, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-09 11:44:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 283.13433837890625, 'train_avg_loss': 0.5898632049560547, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-09 11:44:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:44:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:44:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-09 11:44:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:44:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:44:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:44:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:44:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:44:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:45:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:45:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.683502, avg_loss=0.630591, seen=480, correct=305, accuracy=0.635417
2025-10-09 11:45:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:45:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:45:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:45:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2098MB allocated=1912MB
2025-10-09 11:45:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.91184586286545, 'train_avg_loss': 0.6575987155238787, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 11:45:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.6835021972656, 'train_avg_loss': 0.6305906295776367, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 11:45:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 302.6835021972656, 'train_avg_loss': 0.6305906295776367, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 11:45:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 11:45:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:45:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:46:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:46:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.932495, avg_loss=0.658193, seen=480, correct=285, accuracy=0.593750
2025-10-09 11:46:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:46:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:46:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:46:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2054MB allocated=1912MB
2025-10-09 11:46:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.59720623493195, 'train_avg_loss': 0.6799767186244329, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 11:46:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.9324951171875, 'train_avg_loss': 0.6581926981608073, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 11:46:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 315.9324951171875, 'train_avg_loss': 0.6581926981608073, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 11:46:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:46:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:46:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:47:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:47:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.273773, avg_loss=0.667237, seen=480, correct=289, accuracy=0.602083
2025-10-09 11:47:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:47:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:47:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:47:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2054MB allocated=1912MB
2025-10-09 11:47:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.34850138425827, 'train_avg_loss': 0.6945708448688189, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:47:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.2737731933594, 'train_avg_loss': 0.6672370274861653, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 11:47:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 320.2737731933594, 'train_avg_loss': 0.6672370274861653, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 11:47:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #85) -------------
2025-10-09 11:47:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=85 aidx=3 | s=5 (candidates=12)
2025-10-09 11:47:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 20, 43, 40, 28] (from 12)
2025-10-09 11:47:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:47:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:47:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:47:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:47:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.975586, avg_loss=0.656199, seen=480, correct=289, accuracy=0.602083
2025-10-09 11:47:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:47:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:47:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:47:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2054MB allocated=1912MB
2025-10-09 11:47:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78937155008316, 'train_avg_loss': 0.681578096250693, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 11:47:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.9755859375, 'train_avg_loss': 0.6561991373697916, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 11:47:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 314.9755859375, 'train_avg_loss': 0.6561991373697916, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 11:47:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 11:47:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:47:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:48:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:48:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.394714, avg_loss=0.636239, seen=480, correct=310, accuracy=0.645833
2025-10-09 11:48:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:48:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:48:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:48:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2064MB allocated=1912MB
2025-10-09 11:48:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.69786298274994, 'train_avg_loss': 0.6558155248562495, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:48:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.39471435546875, 'train_avg_loss': 0.6362389882405599, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 11:48:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 305.39471435546875, 'train_avg_loss': 0.6362389882405599, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 11:48:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:48:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:48:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:49:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:49:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.880676, avg_loss=0.635168, seen=480, correct=304, accuracy=0.633333
2025-10-09 11:49:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:49:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:49:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:49:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2098MB allocated=1912MB
2025-10-09 11:49:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.10420393943787, 'train_avg_loss': 0.6592016994953156, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 11:49:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.88067626953125, 'train_avg_loss': 0.6351680755615234, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 11:49:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 304.88067626953125, 'train_avg_loss': 0.6351680755615234, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 11:49:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:49:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:49:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-09 11:49:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 11:49:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:49:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:49:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:49:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:49:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:50:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:50:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.555359, avg_loss=0.680324, seen=480, correct=276, accuracy=0.575000
2025-10-09 11:50:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:50:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:50:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:50:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2054MB allocated=1912MB
2025-10-09 11:50:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.92786794900894, 'train_avg_loss': 0.6993988995750745, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 11:50:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.55535888671875, 'train_avg_loss': 0.6803236643473307, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 11:50:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 326.55535888671875, 'train_avg_loss': 0.6803236643473307, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 11:50:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:50:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:50:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-09 11:50:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 11:50:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:50:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:50:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:50:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:50:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:50:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:50:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.177582, avg_loss=0.642037, seen=480, correct=303, accuracy=0.631250
2025-10-09 11:50:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:50:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:50:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:50:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2054MB allocated=1912MB
2025-10-09 11:50:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.4838474392891, 'train_avg_loss': 0.6373653953274091, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:50:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.1775817871094, 'train_avg_loss': 0.6420366287231445, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 11:50:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 308.1775817871094, 'train_avg_loss': 0.6420366287231445, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 11:50:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #86) -------------
2025-10-09 11:50:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=86 aidx=3 | s=5 (candidates=12)
2025-10-09 11:50:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 15, 22, 43] (from 12)
2025-10-09 11:50:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:50:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:50:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-09 11:50:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:50:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:50:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:50:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:50:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:50:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:51:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:51:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.770386, avg_loss=0.620355, seen=480, correct=312, accuracy=0.650000
2025-10-09 11:51:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:51:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:51:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:51:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2066MB allocated=1912MB
2025-10-09 11:51:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.97575521469116, 'train_avg_loss': 0.6831312934557597, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 11:51:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.7703857421875, 'train_avg_loss': 0.620354970296224, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 11:51:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 297.7703857421875, 'train_avg_loss': 0.620354970296224, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 11:51:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 11:51:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:51:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:52:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:52:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.983215, avg_loss=0.654132, seen=480, correct=287, accuracy=0.597917
2025-10-09 11:52:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:52:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:52:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:52:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2080MB allocated=1912MB
2025-10-09 11:52:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.69744217395782, 'train_avg_loss': 0.6224786847829819, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:52:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.98321533203125, 'train_avg_loss': 0.6541316986083985, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 11:52:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 313.98321533203125, 'train_avg_loss': 0.6541316986083985, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 11:52:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 11:52:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:52:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:53:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:53:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.532593, avg_loss=0.653193, seen=480, correct=292, accuracy=0.608333
2025-10-09 11:53:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:53:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:53:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:53:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2054MB allocated=1912MB
2025-10-09 11:53:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.34601837396622, 'train_avg_loss': 0.6778834864497185, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 11:53:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.5325927734375, 'train_avg_loss': 0.6531929016113281, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 11:53:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 313.5325927734375, 'train_avg_loss': 0.6531929016113281, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 11:53:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:53:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:53:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-09 11:53:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:53:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:53:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:53:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:53:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:53:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:53:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:53:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=284.123413, avg_loss=0.591924, seen=480, correct=345, accuracy=0.718750
2025-10-09 11:53:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:53:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:53:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:53:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2062MB allocated=1912MB
2025-10-09 11:53:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.07021939754486, 'train_avg_loss': 0.6172518283128738, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 11:53:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 284.1234130859375, 'train_avg_loss': 0.5919237772623698, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 11:53:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 284.1234130859375, 'train_avg_loss': 0.5919237772623698, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 11:53:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:53:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:53:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-09 11:53:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:53:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:53:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:53:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:53:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:53:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:54:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:54:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.944275, avg_loss=0.635301, seen=480, correct=308, accuracy=0.641667
2025-10-09 11:54:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:54:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:54:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:54:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2098MB allocated=1912MB
2025-10-09 11:54:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.83037149906158, 'train_avg_loss': 0.6569197624921799, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:54:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.94427490234375, 'train_avg_loss': 0.6353005727132162, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 11:54:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 304.94427490234375, 'train_avg_loss': 0.6353005727132162, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 11:54:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #87) -------------
2025-10-09 11:54:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=87 aidx=3 | s=5 (candidates=12)
2025-10-09 11:54:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 6, 48, 16, 43] (from 12)
2025-10-09 11:54:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 11:54:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:54:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:55:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:55:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.091003, avg_loss=0.627273, seen=480, correct=311, accuracy=0.647917
2025-10-09 11:55:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:55:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:55:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:55:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2054MB allocated=1912MB
2025-10-09 11:55:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.79692536592484, 'train_avg_loss': 0.6233077113827069, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:55:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.09100341796875, 'train_avg_loss': 0.6272729237874349, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 11:55:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 301.09100341796875, 'train_avg_loss': 0.6272729237874349, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 11:55:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:55:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:55:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-09 11:55:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 11:55:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:55:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:55:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:55:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:55:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:55:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:55:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.293884, avg_loss=0.679779, seen=480, correct=274, accuracy=0.570833
2025-10-09 11:55:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:55:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:55:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:56:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2054MB allocated=1912MB
2025-10-09 11:56:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.44195109605789, 'train_avg_loss': 0.6620162591338158, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 11:56:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.29388427734375, 'train_avg_loss': 0.6797789255777995, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 11:56:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 326.29388427734375, 'train_avg_loss': 0.6797789255777995, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 11:56:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 11:56:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:56:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:56:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:56:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.000366, avg_loss=0.620834, seen=480, correct=309, accuracy=0.643750
2025-10-09 11:56:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:56:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:56:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:56:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2066MB allocated=1912MB
2025-10-09 11:56:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.71868598461151, 'train_avg_loss': 0.689322383205096, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 11:56:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.0003662109375, 'train_avg_loss': 0.6208340962727864, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 11:56:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 298.0003662109375, 'train_avg_loss': 0.6208340962727864, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 11:56:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 11:56:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:56:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:57:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:57:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.848328, avg_loss=0.645517, seen=480, correct=296, accuracy=0.616667
2025-10-09 11:57:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:57:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:57:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:57:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2080MB allocated=1912MB
2025-10-09 11:57:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.42564135789871, 'train_avg_loss': 0.6035470113158226, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 11:57:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.84832763671875, 'train_avg_loss': 0.6455173492431641, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 11:57:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 309.84832763671875, 'train_avg_loss': 0.6455173492431641, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 11:57:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 11:57:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:57:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:58:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:58:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.228943, avg_loss=0.615060, seen=480, correct=317, accuracy=0.660417
2025-10-09 11:58:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:58:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:58:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:58:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2098MB allocated=1912MB
2025-10-09 11:58:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.34456297755241, 'train_avg_loss': 0.6445380248129368, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 11:58:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.22894287109375, 'train_avg_loss': 0.615060297648112, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-09 11:58:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 295.22894287109375, 'train_avg_loss': 0.615060297648112, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-09 11:58:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #88) -------------
2025-10-09 11:58:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=88 aidx=3 | s=5 (candidates=12)
2025-10-09 11:58:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 51, 22, 48, 6] (from 12)
2025-10-09 11:58:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 11:58:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:58:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:58:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:58:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.646332, avg_loss=0.680513, seen=480, correct=281, accuracy=0.585417
2025-10-09 11:58:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:58:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:58:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:58:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2054MB allocated=1912MB
2025-10-09 11:58:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.21752965450287, 'train_avg_loss': 0.6351460804541905, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 11:58:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.6463317871094, 'train_avg_loss': 0.6805131912231446, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 11:58:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 326.6463317871094, 'train_avg_loss': 0.6805131912231446, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 11:58:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 11:58:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:58:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 11:59:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 11:59:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.514221, avg_loss=0.663571, seen=480, correct=278, accuracy=0.579167
2025-10-09 11:59:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 11:59:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:59:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 11:59:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2074MB allocated=1912MB
2025-10-09 11:59:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37693619728088, 'train_avg_loss': 0.6948078016440074, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 11:59:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.51422119140625, 'train_avg_loss': 0.663571294148763, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 11:59:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 318.51422119140625, 'train_avg_loss': 0.663571294148763, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 11:59:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 11:59:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 11:59:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:00:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:00:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.466644, avg_loss=0.596806, seen=480, correct=340, accuracy=0.708333
2025-10-09 12:00:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:00:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:00:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:00:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2062MB allocated=1912MB
2025-10-09 12:00:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.29750519990921, 'train_avg_loss': 0.61914587666591, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 12:00:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.4666442871094, 'train_avg_loss': 0.5968055089314779, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-09 12:00:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 286.4666442871094, 'train_avg_loss': 0.5968055089314779, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-09 12:00:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:00:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:00:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-09 12:00:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:00:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:00:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:00:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:00:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:00:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:01:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:01:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.385010, avg_loss=0.625802, seen=480, correct=316, accuracy=0.658333
2025-10-09 12:01:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:01:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:01:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:01:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2066MB allocated=1912MB
2025-10-09 12:01:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36449751257896, 'train_avg_loss': 0.7030374792714914, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 12:01:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.385009765625, 'train_avg_loss': 0.6258021036783854, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:01:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 300.385009765625, 'train_avg_loss': 0.6258021036783854, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:01:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 12:01:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:01:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:01:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:01:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.197723, avg_loss=0.685829, seen=480, correct=279, accuracy=0.581250
2025-10-09 12:01:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:01:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:01:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:01:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2054MB allocated=1912MB
2025-10-09 12:01:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.77658385038376, 'train_avg_loss': 0.6648048654198646, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 12:01:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1977233886719, 'train_avg_loss': 0.6858285903930664, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:01:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 329.1977233886719, 'train_avg_loss': 0.6858285903930664, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:01:52 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #89) -------------
2025-10-09 12:01:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=89 aidx=3 | s=5 (candidates=12)
2025-10-09 12:01:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 22, 51, 40] (from 12)
2025-10-09 12:01:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:01:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:01:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:02:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:02:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.666229, avg_loss=0.624305, seen=480, correct=315, accuracy=0.656250
2025-10-09 12:02:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:02:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:02:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:02:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2066MB allocated=1912MB
2025-10-09 12:02:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50716066360474, 'train_avg_loss': 0.6792263388633728, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 12:02:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.6662292480469, 'train_avg_loss': 0.6243046442667644, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 12:02:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 299.6662292480469, 'train_avg_loss': 0.6243046442667644, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 12:02:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:02:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:02:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-09 12:02:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:02:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:02:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:02:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:02:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:02:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:03:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:03:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.354614, avg_loss=0.654905, seen=480, correct=292, accuracy=0.608333
2025-10-09 12:03:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:03:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:03:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:03:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2080MB allocated=1912MB
2025-10-09 12:03:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.08675569295883, 'train_avg_loss': 0.6173896307746569, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:03:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.3546142578125, 'train_avg_loss': 0.6549054463704427, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 12:03:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 314.3546142578125, 'train_avg_loss': 0.6549054463704427, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 12:03:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:03:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:03:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-09 12:03:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 12:03:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:03:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:03:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:03:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:03:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:03:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:03:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.800659, avg_loss=0.607918, seen=480, correct=334, accuracy=0.695833
2025-10-09 12:03:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:03:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:04:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:04:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2062MB allocated=1912MB
2025-10-09 12:04:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.6558952331543, 'train_avg_loss': 0.6304657936096192, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 12:04:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.8006591796875, 'train_avg_loss': 0.6079180399576823, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 12:04:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 291.8006591796875, 'train_avg_loss': 0.6079180399576823, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 12:04:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:04:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:04:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-09 12:04:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 12:04:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:04:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:04:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:04:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:04:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:04:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:04:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.704132, avg_loss=0.663967, seen=480, correct=274, accuracy=0.570833
2025-10-09 12:04:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:04:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:04:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:04:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2074MB allocated=1912MB
2025-10-09 12:04:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.41254073381424, 'train_avg_loss': 0.6951045061151186, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 12:04:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.7041320800781, 'train_avg_loss': 0.6639669418334961, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 12:04:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 318.7041320800781, 'train_avg_loss': 0.6639669418334961, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 12:04:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:04:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:04:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-09 12:04:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:04:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:04:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:04:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:04:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:04:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:05:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:05:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.007904, avg_loss=0.672933, seen=480, correct=294, accuracy=0.612500
2025-10-09 12:05:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:05:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:05:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:05:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2054MB allocated=1912MB
2025-10-09 12:05:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.59545713663101, 'train_avg_loss': 0.6882954761385918, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 12:05:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0079040527344, 'train_avg_loss': 0.6729331334431966, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:05:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 323.0079040527344, 'train_avg_loss': 0.6729331334431966, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:05:31 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #90) -------------
2025-10-09 12:05:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=90 aidx=3 | s=5 (candidates=12)
2025-10-09 12:05:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 6, 16, 28, 22] (from 12)
2025-10-09 12:05:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:05:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:05:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-09 12:05:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:05:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:05:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:05:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:05:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:05:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:06:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:06:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.535370, avg_loss=0.655282, seen=480, correct=307, accuracy=0.639583
2025-10-09 12:06:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:06:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:06:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:06:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2054MB allocated=1912MB
2025-10-09 12:06:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.46972042322159, 'train_avg_loss': 0.6705810035268466, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 12:06:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.5353698730469, 'train_avg_loss': 0.6552820205688477, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 12:06:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 314.5353698730469, 'train_avg_loss': 0.6552820205688477, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 12:06:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:06:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:06:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-09 12:06:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 12:06:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:06:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:06:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:06:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:06:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:06:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:06:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.912659, avg_loss=0.668568, seen=480, correct=286, accuracy=0.595833
2025-10-09 12:06:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:06:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:07:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:07:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2054MB allocated=1912MB
2025-10-09 12:07:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.12989801168442, 'train_avg_loss': 0.6510824834307035, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 12:07:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.91265869140625, 'train_avg_loss': 0.6685680389404297, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 12:07:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 320.91265869140625, 'train_avg_loss': 0.6685680389404297, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 12:07:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:07:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:07:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:07:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:07:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.848633, avg_loss=0.651768, seen=480, correct=296, accuracy=0.616667
2025-10-09 12:07:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:07:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:07:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:07:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2080MB allocated=1912MB
2025-10-09 12:07:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.657182097435, 'train_avg_loss': 0.6138098508119583, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:07:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.8486328125, 'train_avg_loss': 0.6517679850260417, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 12:07:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 312.8486328125, 'train_avg_loss': 0.6517679850260417, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 12:07:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:07:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:07:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:08:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:08:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.058228, avg_loss=0.627205, seen=480, correct=316, accuracy=0.658333
2025-10-09 12:08:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:08:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:08:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:08:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2054MB allocated=1912MB
2025-10-09 12:08:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.67010539770126, 'train_avg_loss': 0.6222508783141772, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:08:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.0582275390625, 'train_avg_loss': 0.6272046407063802, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:08:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 301.0582275390625, 'train_avg_loss': 0.6272046407063802, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:08:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 12:08:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:08:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:09:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:09:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.664795, avg_loss=0.609718, seen=480, correct=333, accuracy=0.693750
2025-10-09 12:09:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:09:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:09:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:09:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2062MB allocated=1912MB
2025-10-09 12:09:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.34775054454803, 'train_avg_loss': 0.627897921204567, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 12:09:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.664794921875, 'train_avg_loss': 0.6097183227539062, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-09 12:09:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 292.664794921875, 'train_avg_loss': 0.6097183227539062, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-09 12:09:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #91) -------------
2025-10-09 12:09:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=91 aidx=3 | s=5 (candidates=12)
2025-10-09 12:09:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 50, 48, 15, 28] (from 12)
2025-10-09 12:09:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 12:09:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:09:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:09:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:09:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.775696, avg_loss=0.626616, seen=480, correct=304, accuracy=0.633333
2025-10-09 12:09:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:09:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:09:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:09:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2064MB allocated=1912MB
2025-10-09 12:09:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.9057787656784, 'train_avg_loss': 0.64921482304732, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 12:09:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.77569580078125, 'train_avg_loss': 0.6266160329182943, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 12:09:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 300.77569580078125, 'train_avg_loss': 0.6266160329182943, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 12:09:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:09:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:09:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:10:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:10:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.368317, avg_loss=0.659101, seen=480, correct=291, accuracy=0.606250
2025-10-09 12:10:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:10:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:10:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:10:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2054MB allocated=1912MB
2025-10-09 12:10:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.2756564617157, 'train_avg_loss': 0.6772971371809642, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 12:10:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.3683166503906, 'train_avg_loss': 0.6591006596883138, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 12:10:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 316.3683166503906, 'train_avg_loss': 0.6591006596883138, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 12:10:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:10:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:10:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:11:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:11:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.678192, avg_loss=0.628496, seen=480, correct=312, accuracy=0.650000
2025-10-09 12:11:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:11:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:11:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:11:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2066MB allocated=1912MB
2025-10-09 12:11:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.49445015192032, 'train_avg_loss': 0.7041204179326693, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:11:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.6781921386719, 'train_avg_loss': 0.6284962336222331, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:11:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 301.6781921386719, 'train_avg_loss': 0.6284962336222331, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:11:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 12:11:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:11:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:12:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:12:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.699738, avg_loss=0.657708, seen=480, correct=297, accuracy=0.618750
2025-10-09 12:12:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:12:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:12:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:12:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2054MB allocated=1912MB
2025-10-09 12:12:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61030101776123, 'train_avg_loss': 0.6884191751480102, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:12:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.6997375488281, 'train_avg_loss': 0.6577077865600586, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 12:12:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 315.6997375488281, 'train_avg_loss': 0.6577077865600586, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 12:12:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:12:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:12:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:12:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:12:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.819946, avg_loss=0.626708, seen=480, correct=312, accuracy=0.650000
2025-10-09 12:12:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:12:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:12:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:12:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2054MB allocated=1912MB
2025-10-09 12:12:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.774090051651, 'train_avg_loss': 0.6231174170970917, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 12:12:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.8199462890625, 'train_avg_loss': 0.6267082214355468, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:12:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 300.8199462890625, 'train_avg_loss': 0.6267082214355468, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:12:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #92) -------------
2025-10-09 12:12:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=92 aidx=3 | s=5 (candidates=12)
2025-10-09 12:12:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 16, 50, 36, 40] (from 12)
2025-10-09 12:12:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:12:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:12:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-09 12:12:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 12:12:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:12:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:12:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:12:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:12:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:13:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:13:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.372650, avg_loss=0.677860, seen=480, correct=279, accuracy=0.581250
2025-10-09 12:13:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:13:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:13:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:13:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2054MB allocated=1912MB
2025-10-09 12:13:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.12422776222229, 'train_avg_loss': 0.6510352313518524, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 12:13:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.3726501464844, 'train_avg_loss': 0.6778596878051758, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:13:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 325.3726501464844, 'train_avg_loss': 0.6778596878051758, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:13:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:13:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:13:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:14:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:14:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.884094, avg_loss=0.649759, seen=480, correct=301, accuracy=0.627083
2025-10-09 12:14:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:14:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:14:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:14:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2080MB allocated=1912MB
2025-10-09 12:14:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.0779709815979, 'train_avg_loss': 0.6089830915133159, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:14:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.88409423828125, 'train_avg_loss': 0.6497585296630859, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 12:14:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 311.88409423828125, 'train_avg_loss': 0.6497585296630859, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 12:14:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:14:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:14:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:14:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:14:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.834106, avg_loss=0.655904, seen=480, correct=296, accuracy=0.616667
2025-10-09 12:14:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:14:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:14:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:15:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2054MB allocated=1912MB
2025-10-09 12:15:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.58622959256172, 'train_avg_loss': 0.6715519132713477, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 12:15:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.8341064453125, 'train_avg_loss': 0.6559043884277344, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 12:15:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 314.8341064453125, 'train_avg_loss': 0.6559043884277344, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 12:15:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:15:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:15:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-09 12:15:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 12:15:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:15:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:15:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:15:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:15:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:15:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:15:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.709534, avg_loss=0.678562, seen=480, correct=279, accuracy=0.581250
2025-10-09 12:15:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:15:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:15:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:15:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2054MB allocated=1912MB
2025-10-09 12:15:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.39454215765, 'train_avg_loss': 0.62828785131375, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 12:15:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.70953369140625, 'train_avg_loss': 0.6785615285237631, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:15:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 325.70953369140625, 'train_avg_loss': 0.6785615285237631, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:15:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:15:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:15:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-09 12:15:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:15:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:15:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:15:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:15:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:15:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:16:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:16:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.951141, avg_loss=0.656148, seen=480, correct=298, accuracy=0.620833
2025-10-09 12:16:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:16:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:16:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:16:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2054MB allocated=1912MB
2025-10-09 12:16:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.77982008457184, 'train_avg_loss': 0.6648318340380986, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 12:16:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.9511413574219, 'train_avg_loss': 0.6561482111612956, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 12:16:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 314.9511413574219, 'train_avg_loss': 0.6561482111612956, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 12:16:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #93) -------------
2025-10-09 12:16:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=93 aidx=3 | s=5 (candidates=12)
2025-10-09 12:16:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 16, 22, 51, 6] (from 12)
2025-10-09 12:16:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:16:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:16:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:17:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:17:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.626862, avg_loss=0.607556, seen=480, correct=326, accuracy=0.679167
2025-10-09 12:17:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:17:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:17:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:17:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2054MB allocated=1912MB
2025-10-09 12:17:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.39376774430275, 'train_avg_loss': 0.6032813978691896, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:17:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.6268615722656, 'train_avg_loss': 0.6075559616088867, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 12:17:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 291.6268615722656, 'train_avg_loss': 0.6075559616088867, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 12:17:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:17:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:17:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:17:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:17:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.454803, avg_loss=0.650948, seen=480, correct=296, accuracy=0.616667
2025-10-09 12:17:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:17:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:17:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:17:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2080MB allocated=1912MB
2025-10-09 12:17:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.98258316516876, 'train_avg_loss': 0.6165215263764063, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 12:17:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.4548034667969, 'train_avg_loss': 0.6509475072224935, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 12:17:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 312.4548034667969, 'train_avg_loss': 0.6509475072224935, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 12:17:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:17:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:17:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-09 12:17:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 12:17:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:17:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:17:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:17:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:17:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:18:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:18:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=273.029755, avg_loss=0.568812, seen=480, correct=347, accuracy=0.722917
2025-10-09 12:18:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:18:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:18:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:18:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2062MB allocated=1912MB
2025-10-09 12:18:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.51900118589401, 'train_avg_loss': 0.6043250098824501, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 12:18:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 273.0297546386719, 'train_avg_loss': 0.5688119888305664, 'train_seen': 480, 'train_correct': 347, 'train_acc': 0.7229166666666667}}
2025-10-09 12:18:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 273.0297546386719, 'train_avg_loss': 0.5688119888305664, 'train_seen': 480, 'train_correct': 347, 'train_acc': 0.7229166666666667}}
2025-10-09 12:18:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:18:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:18:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-09 12:18:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 12:18:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:18:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:18:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:18:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:18:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:19:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:19:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.595154, avg_loss=0.661657, seen=480, correct=281, accuracy=0.585417
2025-10-09 12:19:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:19:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:19:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:19:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2074MB allocated=1912MB
2025-10-09 12:19:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50339150428772, 'train_avg_loss': 0.6791949292023977, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 12:19:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.59515380859375, 'train_avg_loss': 0.6616565704345703, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 12:19:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 317.59515380859375, 'train_avg_loss': 0.6616565704345703, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 12:19:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:19:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:19:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-09 12:19:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 12:19:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:19:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:19:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:19:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:19:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:19:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:19:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.451752, avg_loss=0.673858, seen=480, correct=282, accuracy=0.587500
2025-10-09 12:19:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:19:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:19:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:19:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2054MB allocated=1912MB
2025-10-09 12:19:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.82614177465439, 'train_avg_loss': 0.6485511814554532, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 12:19:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4517517089844, 'train_avg_loss': 0.6738578160603841, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 12:19:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 323.4517517089844, 'train_avg_loss': 0.6738578160603841, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 12:19:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #94) -------------
2025-10-09 12:19:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=94 aidx=3 | s=5 (candidates=12)
2025-10-09 12:19:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 48, 40, 43, 51] (from 12)
2025-10-09 12:20:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:20:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:20:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:20:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:20:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.230438, avg_loss=0.652563, seen=480, correct=293, accuracy=0.610417
2025-10-09 12:20:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:20:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:20:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:20:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2054MB allocated=1912MB
2025-10-09 12:20:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.73602944612503, 'train_avg_loss': 0.6728002453843752, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 12:20:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.2304382324219, 'train_avg_loss': 0.6525634129842123, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 12:20:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 313.2304382324219, 'train_avg_loss': 0.6525634129842123, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 12:20:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:20:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:20:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:21:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:21:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.463867, avg_loss=0.623883, seen=480, correct=303, accuracy=0.631250
2025-10-09 12:21:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:21:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:21:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:21:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2066MB allocated=1912MB
2025-10-09 12:21:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.98328945040703, 'train_avg_loss': 0.6831940787533919, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 12:21:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.4638671875, 'train_avg_loss': 0.623883056640625, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 12:21:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 299.4638671875, 'train_avg_loss': 0.623883056640625, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 12:21:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:21:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:21:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:22:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:22:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.262238, avg_loss=0.646380, seen=480, correct=301, accuracy=0.627083
2025-10-09 12:22:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:22:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:22:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:22:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2054MB allocated=1912MB
2025-10-09 12:22:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.8142597079277, 'train_avg_loss': 0.6567854975660642, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 12:22:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.2622375488281, 'train_avg_loss': 0.6463796615600585, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 12:22:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 310.2622375488281, 'train_avg_loss': 0.6463796615600585, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 12:22:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 12:22:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:22:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:22:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:22:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.712219, avg_loss=0.618150, seen=480, correct=322, accuracy=0.670833
2025-10-09 12:22:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:22:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:22:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:22:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2098MB allocated=1912MB
2025-10-09 12:22:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.82371550798416, 'train_avg_loss': 0.6401976292332013, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 12:22:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.71221923828125, 'train_avg_loss': 0.6181504567464192, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 12:22:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 296.71221923828125, 'train_avg_loss': 0.6181504567464192, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 12:22:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:22:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:22:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-09 12:22:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 12:22:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:22:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:22:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:22:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:22:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:23:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:23:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.985077, avg_loss=0.660386, seen=480, correct=283, accuracy=0.589583
2025-10-09 12:23:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:23:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:23:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:23:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2074MB allocated=1912MB
2025-10-09 12:23:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91619408130646, 'train_avg_loss': 0.6826349506775539, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 12:23:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.9850769042969, 'train_avg_loss': 0.6603855768839518, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 12:23:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 316.9850769042969, 'train_avg_loss': 0.6603855768839518, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 12:23:36 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #95) -------------
2025-10-09 12:23:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=95 aidx=3 | s=5 (candidates=12)
2025-10-09 12:23:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 16, 50, 28, 20] (from 12)
2025-10-09 12:23:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:23:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:23:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-09 12:23:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:23:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:23:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:23:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:23:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:23:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:24:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:24:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.060425, avg_loss=0.643876, seen=480, correct=297, accuracy=0.618750
2025-10-09 12:24:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:24:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:24:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:24:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2054MB allocated=1912MB
2025-10-09 12:24:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.33251690864563, 'train_avg_loss': 0.6527709742387136, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 12:24:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.0604248046875, 'train_avg_loss': 0.6438758850097657, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 12:24:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 309.0604248046875, 'train_avg_loss': 0.6438758850097657, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 12:24:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:24:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:24:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-09 12:24:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:24:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:24:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:24:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:24:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:24:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:25:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:25:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.815613, avg_loss=0.649616, seen=480, correct=297, accuracy=0.618750
2025-10-09 12:25:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:25:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:25:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:25:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2080MB allocated=1912MB
2025-10-09 12:25:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.61980873346329, 'train_avg_loss': 0.6134984061121941, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 12:25:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.81561279296875, 'train_avg_loss': 0.6496158599853515, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 12:25:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 311.81561279296875, 'train_avg_loss': 0.6496158599853515, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 12:25:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:25:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:25:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:25:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:25:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.155090, avg_loss=0.656573, seen=480, correct=290, accuracy=0.604167
2025-10-09 12:25:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:25:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:25:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:25:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2054MB allocated=1912MB
2025-10-09 12:25:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.14260631799698, 'train_avg_loss': 0.6845217193166415, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:25:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.15509033203125, 'train_avg_loss': 0.6565731048583985, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 12:25:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 315.15509033203125, 'train_avg_loss': 0.6565731048583985, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 12:25:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:25:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:25:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:26:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:26:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.745087, avg_loss=0.618219, seen=480, correct=312, accuracy=0.650000
2025-10-09 12:26:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:26:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:26:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:26:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2054MB allocated=1912MB
2025-10-09 12:26:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.59503945708275, 'train_avg_loss': 0.6132919954756896, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 12:26:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.7450866699219, 'train_avg_loss': 0.6182189305623372, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:26:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 296.7450866699219, 'train_avg_loss': 0.6182189305623372, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:26:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 12:26:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:26:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:27:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:27:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.737000, avg_loss=0.624452, seen=480, correct=312, accuracy=0.650000
2025-10-09 12:27:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:27:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:27:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:27:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2064MB allocated=1912MB
2025-10-09 12:27:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.96881002187729, 'train_avg_loss': 0.649740083515644, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 12:27:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.73699951171875, 'train_avg_loss': 0.6244520823160807, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:27:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 299.73699951171875, 'train_avg_loss': 0.6244520823160807, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 12:27:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #96) -------------
2025-10-09 12:27:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=96 aidx=3 | s=5 (candidates=12)
2025-10-09 12:27:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 36, 43, 48, 28] (from 12)
2025-10-09 12:27:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 12:27:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:27:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:28:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:28:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.626831, avg_loss=0.663806, seen=480, correct=294, accuracy=0.612500
2025-10-09 12:28:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:28:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:28:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:28:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2054MB allocated=1912MB
2025-10-09 12:28:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.93140780925751, 'train_avg_loss': 0.6410950650771459, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 12:28:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.6268310546875, 'train_avg_loss': 0.663805898030599, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:28:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 318.6268310546875, 'train_avg_loss': 0.663805898030599, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:28:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:28:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:28:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-09 12:28:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 12:28:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:28:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:28:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:28:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:28:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:28:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:28:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.976196, avg_loss=0.679117, seen=480, correct=276, accuracy=0.575000
2025-10-09 12:28:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:28:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:28:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:28:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2054MB allocated=1912MB
2025-10-09 12:28:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.56793385744095, 'train_avg_loss': 0.6297327821453412, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 12:28:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.9761962890625, 'train_avg_loss': 0.6791170756022136, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 12:28:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 325.9761962890625, 'train_avg_loss': 0.6791170756022136, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 12:28:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 12:28:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:28:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:29:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:29:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.739807, avg_loss=0.609875, seen=480, correct=318, accuracy=0.662500
2025-10-09 12:29:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:29:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:29:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:29:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2098MB allocated=1912MB
2025-10-09 12:29:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.48245412111282, 'train_avg_loss': 0.6540204510092735, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 12:29:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.73980712890625, 'train_avg_loss': 0.6098745981852214, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 12:29:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 292.73980712890625, 'train_avg_loss': 0.6098745981852214, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 12:29:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:29:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:29:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:30:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:30:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.755768, avg_loss=0.626575, seen=480, correct=305, accuracy=0.635417
2025-10-09 12:30:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:30:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:30:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:30:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2066MB allocated=1912MB
2025-10-09 12:30:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.84439328312874, 'train_avg_loss': 0.7070366106927395, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 12:30:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.7557678222656, 'train_avg_loss': 0.6265745162963867, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 12:30:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 300.7557678222656, 'train_avg_loss': 0.6265745162963867, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 12:30:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:30:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:30:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-09 12:30:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:30:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:30:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:30:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:30:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:30:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:30:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:30:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.666260, avg_loss=0.611805, seen=480, correct=314, accuracy=0.654167
2025-10-09 12:30:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:30:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:31:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:31:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2054MB allocated=1912MB
2025-10-09 12:31:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.23549193143845, 'train_avg_loss': 0.6102957660953204, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 12:31:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.666259765625, 'train_avg_loss': 0.611804707845052, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 12:31:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 293.666259765625, 'train_avg_loss': 0.611804707845052, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 12:31:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #97) -------------
2025-10-09 12:31:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=97 aidx=3 | s=5 (candidates=12)
2025-10-09 12:31:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 48, 51, 15, 16] (from 12)
2025-10-09 12:31:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 12:31:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:31:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:31:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:31:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.213806, avg_loss=0.675445, seen=480, correct=279, accuracy=0.581250
2025-10-09 12:31:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:31:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:31:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:31:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2054MB allocated=1912MB
2025-10-09 12:31:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.40629267692566, 'train_avg_loss': 0.6283857723077139, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 12:31:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.21380615234375, 'train_avg_loss': 0.6754454294840495, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:31:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 324.21380615234375, 'train_avg_loss': 0.6754454294840495, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 12:31:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:31:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:31:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:32:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:32:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.760620, avg_loss=0.624501, seen=480, correct=310, accuracy=0.645833
2025-10-09 12:32:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:32:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:32:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:32:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2066MB allocated=1912MB
2025-10-09 12:32:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.58898505568504, 'train_avg_loss': 0.7049082087973754, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 12:32:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.7606201171875, 'train_avg_loss': 0.6245012919108073, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 12:32:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 299.7606201171875, 'train_avg_loss': 0.6245012919108073, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 12:32:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 12:32:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:32:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:33:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:33:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.951904, avg_loss=0.649900, seen=480, correct=295, accuracy=0.614583
2025-10-09 12:33:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:33:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:33:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:33:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2074MB allocated=1912MB
2025-10-09 12:33:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.50019598007202, 'train_avg_loss': 0.6708349665006001, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:33:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.951904296875, 'train_avg_loss': 0.6498998006184896, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 12:33:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 311.951904296875, 'train_avg_loss': 0.6498998006184896, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 12:33:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 12:33:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:33:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:33:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:33:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.384460, avg_loss=0.652884, seen=480, correct=294, accuracy=0.612500
2025-10-09 12:33:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:33:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:33:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:33:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2054MB allocated=1912MB
2025-10-09 12:33:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.72946852445602, 'train_avg_loss': 0.6894122377038002, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 12:33:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.38446044921875, 'train_avg_loss': 0.6528842926025391, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:33:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 313.38446044921875, 'train_avg_loss': 0.6528842926025391, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:33:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:33:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:33:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:34:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:34:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.042572, avg_loss=0.648005, seen=480, correct=302, accuracy=0.629167
2025-10-09 12:34:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:34:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:34:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:34:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2080MB allocated=1912MB
2025-10-09 12:34:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.21144300699234, 'train_avg_loss': 0.6100953583916028, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 12:34:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.0425720214844, 'train_avg_loss': 0.6480053583780925, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 12:34:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 311.0425720214844, 'train_avg_loss': 0.6480053583780925, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 12:34:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #98) -------------
2025-10-09 12:34:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=98 aidx=3 | s=5 (candidates=12)
2025-10-09 12:34:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 48, 50, 36, 40] (from 12)
2025-10-09 12:34:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:34:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:34:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-09 12:34:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:34:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:34:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:34:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:34:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:34:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:35:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:35:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.503418, avg_loss=0.638549, seen=480, correct=301, accuracy=0.627083
2025-10-09 12:35:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:35:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:35:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:35:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2080MB allocated=1912MB
2025-10-09 12:35:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.98634675145149, 'train_avg_loss': 0.5998862229287625, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:35:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.50341796875, 'train_avg_loss': 0.6385487874348958, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 12:35:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 306.50341796875, 'train_avg_loss': 0.6385487874348958, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 12:35:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:35:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:35:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:36:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:36:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.480286, avg_loss=0.626001, seen=480, correct=306, accuracy=0.637500
2025-10-09 12:36:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:36:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:36:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:36:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2066MB allocated=1912MB
2025-10-09 12:36:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.31546139717102, 'train_avg_loss': 0.6942955116430919, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:36:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.48028564453125, 'train_avg_loss': 0.6260005950927734, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 12:36:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 300.48028564453125, 'train_avg_loss': 0.6260005950927734, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 12:36:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:36:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:36:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-09 12:36:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:36:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:36:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:36:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:36:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:36:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:36:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:36:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.833832, avg_loss=0.651737, seen=480, correct=287, accuracy=0.597917
2025-10-09 12:36:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:36:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:36:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:36:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2054MB allocated=1912MB
2025-10-09 12:36:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.86870837211609, 'train_avg_loss': 0.6822392364343007, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 12:36:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.8338317871094, 'train_avg_loss': 0.6517371495564779, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 12:36:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 312.8338317871094, 'train_avg_loss': 0.6517371495564779, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 12:36:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:36:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:36:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-09 12:36:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 12:36:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:37:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:37:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:37:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:37:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:37:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:37:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.549988, avg_loss=0.674062, seen=480, correct=274, accuracy=0.570833
2025-10-09 12:37:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:37:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:37:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:37:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2054MB allocated=1912MB
2025-10-09 12:37:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.25164812803268, 'train_avg_loss': 0.635430401066939, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 12:37:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.54998779296875, 'train_avg_loss': 0.6740624745686848, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 12:37:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 323.54998779296875, 'train_avg_loss': 0.6740624745686848, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 12:37:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:37:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:37:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:38:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:38:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.954681, avg_loss=0.639489, seen=480, correct=307, accuracy=0.639583
2025-10-09 12:38:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:38:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:38:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:38:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2054MB allocated=1912MB
2025-10-09 12:38:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.15235513448715, 'train_avg_loss': 0.6596029594540596, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 12:38:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.9546813964844, 'train_avg_loss': 0.6394889195760091, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 12:38:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 306.9546813964844, 'train_avg_loss': 0.6394889195760091, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 12:38:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #99) -------------
2025-10-09 12:38:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=99 aidx=3 | s=5 (candidates=12)
2025-10-09 12:38:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 6, 16, 50, 48] (from 12)
2025-10-09 12:38:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:38:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:38:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-09 12:38:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 12:38:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:38:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:38:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:38:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:38:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:39:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:39:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.822632, avg_loss=0.653797, seen=480, correct=294, accuracy=0.612500
2025-10-09 12:39:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:39:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:39:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:39:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2054MB allocated=1912MB
2025-10-09 12:39:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32915198802948, 'train_avg_loss': 0.6860762665669123, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 12:39:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.8226318359375, 'train_avg_loss': 0.6537971496582031, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:39:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 313.8226318359375, 'train_avg_loss': 0.6537971496582031, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:39:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 12:39:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:39:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:39:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:39:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.234863, avg_loss=0.662989, seen=480, correct=287, accuracy=0.597917
2025-10-09 12:39:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:39:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:39:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:39:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2054MB allocated=1912MB
2025-10-09 12:39:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.90084940195084, 'train_avg_loss': 0.6408404116829236, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 12:39:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.23486328125, 'train_avg_loss': 0.6629892985026041, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 12:39:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 318.23486328125, 'train_avg_loss': 0.6629892985026041, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 12:39:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:39:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:39:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-09 12:40:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:40:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:40:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:40:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:40:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:40:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:40:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:40:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.337799, avg_loss=0.636120, seen=480, correct=308, accuracy=0.641667
2025-10-09 12:40:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:40:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:40:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:40:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2080MB allocated=1912MB
2025-10-09 12:40:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.99906489253044, 'train_avg_loss': 0.5999922074377537, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 12:40:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.3377990722656, 'train_avg_loss': 0.6361204147338867, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 12:40:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 305.3377990722656, 'train_avg_loss': 0.6361204147338867, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 12:40:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:40:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:40:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:41:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:41:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.342957, avg_loss=0.650714, seen=480, correct=292, accuracy=0.608333
2025-10-09 12:41:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:41:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:41:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:41:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2054MB allocated=1912MB
2025-10-09 12:41:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.50786769390106, 'train_avg_loss': 0.6875655641158421, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 12:41:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.34295654296875, 'train_avg_loss': 0.6507144927978515, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 12:41:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 312.34295654296875, 'train_avg_loss': 0.6507144927978515, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 12:41:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:41:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:41:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-09 12:41:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:41:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:41:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:41:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:41:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:41:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:42:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:42:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.961060, avg_loss=0.624919, seen=480, correct=304, accuracy=0.633333
2025-10-09 12:42:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:42:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:42:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:42:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2066MB allocated=1912MB
2025-10-09 12:42:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.2702017724514, 'train_avg_loss': 0.702251681437095, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:42:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.9610595703125, 'train_avg_loss': 0.6249188741048177, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 12:42:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 299.9610595703125, 'train_avg_loss': 0.6249188741048177, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 12:42:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #100) -------------
2025-10-09 12:42:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=100 aidx=3 | s=5 (candidates=12)
2025-10-09 12:42:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 43, 22, 36] (from 12)
2025-10-09 12:42:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:42:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:42:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-09 12:42:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:42:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:42:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:42:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:42:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:42:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:42:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:42:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=289.851227, avg_loss=0.603857, seen=480, correct=315, accuracy=0.656250
2025-10-09 12:42:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:42:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:42:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:42:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2066MB allocated=1912MB
2025-10-09 12:42:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66618826985359, 'train_avg_loss': 0.6805515689154465, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:42:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 289.8512268066406, 'train_avg_loss': 0.6038567225138346, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 12:42:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 289.8512268066406, 'train_avg_loss': 0.6038567225138346, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 12:42:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:42:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:42:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:43:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:43:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.131104, avg_loss=0.631523, seen=480, correct=310, accuracy=0.645833
2025-10-09 12:43:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:43:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:43:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:43:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2080MB allocated=1912MB
2025-10-09 12:43:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.4083643257618, 'train_avg_loss': 0.5950697027146816, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 12:43:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.131103515625, 'train_avg_loss': 0.6315231323242188, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 12:43:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 303.131103515625, 'train_avg_loss': 0.6315231323242188, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 12:43:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:43:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:43:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-09 12:43:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 12:43:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:43:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:43:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:43:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:43:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:44:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:44:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.527039, avg_loss=0.615681, seen=480, correct=321, accuracy=0.668750
2025-10-09 12:44:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:44:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:44:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:44:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2098MB allocated=1912MB
2025-10-09 12:44:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.64833882451057, 'train_avg_loss': 0.6470694902042547, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 12:44:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.52703857421875, 'train_avg_loss': 0.6156813303629557, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 12:44:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 295.52703857421875, 'train_avg_loss': 0.6156813303629557, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 12:44:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:44:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:44:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-09 12:44:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 12:44:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:44:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:44:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:44:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:44:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:45:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:45:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=277.959320, avg_loss=0.579082, seen=480, correct=345, accuracy=0.718750
2025-10-09 12:45:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:45:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:45:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:45:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2062MB allocated=1912MB
2025-10-09 12:45:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.34225738048553, 'train_avg_loss': 0.6111854781707128, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 12:45:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 277.9593200683594, 'train_avg_loss': 0.579081916809082, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 12:45:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 277.9593200683594, 'train_avg_loss': 0.579081916809082, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 12:45:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:45:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:45:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-09 12:45:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 12:45:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:45:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:45:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:45:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:45:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:45:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:45:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.842285, avg_loss=0.674671, seen=480, correct=288, accuracy=0.600000
2025-10-09 12:45:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:45:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:45:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:45:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2054MB allocated=1912MB
2025-10-09 12:45:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.76550030708313, 'train_avg_loss': 0.6313791692256927, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 12:45:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.84228515625, 'train_avg_loss': 0.6746714274088542, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 12:45:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 323.84228515625, 'train_avg_loss': 0.6746714274088542, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 12:45:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #101) -------------
2025-10-09 12:45:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=101 aidx=3 | s=5 (candidates=12)
2025-10-09 12:45:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 40, 50, 28, 48] (from 12)
2025-10-09 12:45:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:45:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:45:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-09 12:45:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 12:45:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:45:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:45:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:45:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:45:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:46:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:46:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=280.962891, avg_loss=0.585339, seen=480, correct=349, accuracy=0.727083
2025-10-09 12:46:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:46:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:46:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:46:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2062MB allocated=1912MB
2025-10-09 12:46:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.14842170476913, 'train_avg_loss': 0.6095701808730761, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 12:46:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 280.962890625, 'train_avg_loss': 0.58533935546875, 'train_seen': 480, 'train_correct': 349, 'train_acc': 0.7270833333333333}}
2025-10-09 12:46:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 280.962890625, 'train_avg_loss': 0.58533935546875, 'train_seen': 480, 'train_correct': 349, 'train_acc': 0.7270833333333333}}
2025-10-09 12:46:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:46:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:46:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:47:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:47:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.091370, avg_loss=0.629357, seen=480, correct=316, accuracy=0.658333
2025-10-09 12:47:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:47:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:47:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:47:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2054MB allocated=1912MB
2025-10-09 12:47:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.83845239877701, 'train_avg_loss': 0.6403204366564751, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 12:47:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.09136962890625, 'train_avg_loss': 0.6293570200602213, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:47:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 302.09136962890625, 'train_avg_loss': 0.6293570200602213, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:47:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 12:47:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:47:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:48:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:48:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.384155, avg_loss=0.650800, seen=480, correct=294, accuracy=0.612500
2025-10-09 12:48:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:48:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:48:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:48:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2054MB allocated=1912MB
2025-10-09 12:48:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0941036939621, 'train_avg_loss': 0.6841175307830175, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 12:48:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.3841552734375, 'train_avg_loss': 0.6508003234863281, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:48:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 312.3841552734375, 'train_avg_loss': 0.6508003234863281, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 12:48:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:48:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:48:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-09 12:48:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:48:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:48:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:48:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:48:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:48:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:48:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:48:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.830841, avg_loss=0.599648, seen=480, correct=332, accuracy=0.691667
2025-10-09 12:48:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:48:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:48:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:48:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2054MB allocated=1912MB
2025-10-09 12:48:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.5489451289177, 'train_avg_loss': 0.5962412094076475, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 12:48:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.8308410644531, 'train_avg_loss': 0.599647585550944, 'train_seen': 480, 'train_correct': 332, 'train_acc': 0.6916666666666667}}
2025-10-09 12:48:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 287.8308410644531, 'train_avg_loss': 0.599647585550944, 'train_seen': 480, 'train_correct': 332, 'train_acc': 0.6916666666666667}}
2025-10-09 12:48:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 12:48:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:48:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:49:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:49:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.131744, avg_loss=0.610691, seen=480, correct=321, accuracy=0.668750
2025-10-09 12:49:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:49:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:49:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:49:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2066MB allocated=1912MB
2025-10-09 12:49:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.60168099403381, 'train_avg_loss': 0.6716806749502818, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 12:49:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.1317443847656, 'train_avg_loss': 0.6106911341349284, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 12:49:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 293.1317443847656, 'train_avg_loss': 0.6106911341349284, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 12:49:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #102) -------------
2025-10-09 12:49:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=102 aidx=3 | s=5 (candidates=12)
2025-10-09 12:49:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[51, 28, 43, 16, 40] (from 12)
2025-10-09 12:49:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 12:49:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:49:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:50:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:50:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.915619, avg_loss=0.653991, seen=480, correct=278, accuracy=0.579167
2025-10-09 12:50:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:50:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:50:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:50:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2074MB allocated=1912MB
2025-10-09 12:50:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.25303238630295, 'train_avg_loss': 0.6604419365525246, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 12:50:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.9156188964844, 'train_avg_loss': 0.6539908727010091, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 12:50:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 313.9156188964844, 'train_avg_loss': 0.6539908727010091, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 12:50:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 12:50:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:50:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:51:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:51:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=285.954224, avg_loss=0.595738, seen=480, correct=334, accuracy=0.695833
2025-10-09 12:51:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:51:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:51:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:51:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2054MB allocated=1912MB
2025-10-09 12:51:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.23784136772156, 'train_avg_loss': 0.585315344731013, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-09 12:51:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 285.9542236328125, 'train_avg_loss': 0.5957379659016927, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 12:51:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 285.9542236328125, 'train_avg_loss': 0.5957379659016927, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 12:51:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:51:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:51:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-09 12:51:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 12:51:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:51:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:51:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:51:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:51:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:51:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:51:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.105286, avg_loss=0.614803, seen=480, correct=323, accuracy=0.672917
2025-10-09 12:51:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:51:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:51:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:51:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2098MB allocated=1912MB
2025-10-09 12:51:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.3558092713356, 'train_avg_loss': 0.6362984105944633, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 12:51:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.10528564453125, 'train_avg_loss': 0.6148026784261068, 'train_seen': 480, 'train_correct': 323, 'train_acc': 0.6729166666666667}}
2025-10-09 12:51:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 295.10528564453125, 'train_avg_loss': 0.6148026784261068, 'train_seen': 480, 'train_correct': 323, 'train_acc': 0.6729166666666667}}
2025-10-09 12:51:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 12:51:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:51:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:52:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:52:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.266052, avg_loss=0.627638, seen=480, correct=316, accuracy=0.658333
2025-10-09 12:52:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:52:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:52:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:52:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2080MB allocated=1912MB
2025-10-09 12:52:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.29337912797928, 'train_avg_loss': 0.5941114927331607, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 12:52:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.26605224609375, 'train_avg_loss': 0.6276376088460286, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:52:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 301.26605224609375, 'train_avg_loss': 0.6276376088460286, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 12:52:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 12:52:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:52:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:53:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:53:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.975128, avg_loss=0.631198, seen=480, correct=317, accuracy=0.660417
2025-10-09 12:53:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:53:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:53:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:53:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2054MB allocated=1912MB
2025-10-09 12:53:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.53163582086563, 'train_avg_loss': 0.6460969651738803, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 12:53:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.9751281738281, 'train_avg_loss': 0.6311981836954753, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-09 12:53:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 302.9751281738281, 'train_avg_loss': 0.6311981836954753, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-09 12:53:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #103) -------------
2025-10-09 12:53:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=103 aidx=4 | s=5 (candidates=7)
2025-10-09 12:53:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 7, 12, 35, 17] (from 7)
2025-10-09 12:53:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:53:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:53:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-09 12:53:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 12:53:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:53:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:53:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:53:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:53:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:54:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:54:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.785950, avg_loss=0.709971, seen=480, correct=235, accuracy=0.489583
2025-10-09 12:54:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:54:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:54:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:54:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2122MB allocated=1996MB
2025-10-09 12:54:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.12241053581238, 'train_avg_loss': 0.7093534211317698, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 12:54:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.78594970703125, 'train_avg_loss': 0.7099707285563152, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 12:54:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 340.78594970703125, 'train_avg_loss': 0.7099707285563152, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 12:54:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:54:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:54:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-09 12:54:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 12:54:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:54:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:54:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:54:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:54:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:54:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:54:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.267792, avg_loss=0.719308, seen=480, correct=237, accuracy=0.493750
2025-10-09 12:54:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:54:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:54:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:54:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2130MB allocated=2005MB
2025-10-09 12:54:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.2227748632431, 'train_avg_loss': 0.7268564571936925, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 12:54:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.2677917480469, 'train_avg_loss': 0.7193078994750977, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 12:54:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 345.2677917480469, 'train_avg_loss': 0.7193078994750977, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 12:54:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:54:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:54:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-09 12:54:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 12:54:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:54:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:54:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:54:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:54:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:55:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:55:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.016815, avg_loss=0.716702, seen=480, correct=244, accuracy=0.508333
2025-10-09 12:55:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:55:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:55:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:55:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2114MB allocated=2013MB
2025-10-09 12:55:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.38315153121948, 'train_avg_loss': 0.7115262627601624, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 12:55:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.0168151855469, 'train_avg_loss': 0.7167016983032226, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 12:55:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 344.0168151855469, 'train_avg_loss': 0.7167016983032226, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 12:55:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:55:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:55:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-09 12:55:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 12:55:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:55:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:55:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:55:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:55:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:56:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:56:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.189087, avg_loss=0.719144, seen=480, correct=247, accuracy=0.514583
2025-10-09 12:56:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:56:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:56:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:56:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2176MB allocated=2022MB
2025-10-09 12:56:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.1533630490303, 'train_avg_loss': 0.7346113587419192, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 12:56:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.1890869140625, 'train_avg_loss': 0.7191439310709635, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 12:56:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 345.1890869140625, 'train_avg_loss': 0.7191439310709635, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 12:56:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:56:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:56:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-09 12:56:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 12:56:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:56:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:56:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:56:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:56:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:57:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:57:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.392120, avg_loss=0.711234, seen=480, correct=242, accuracy=0.504167
2025-10-09 12:57:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:57:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:57:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:57:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2172MB allocated=2030MB
2025-10-09 12:57:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.58532321453094, 'train_avg_loss': 0.7298776934544245, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 12:57:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.3921203613281, 'train_avg_loss': 0.7112335840861003, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 12:57:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 341.3921203613281, 'train_avg_loss': 0.7112335840861003, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 12:57:14 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #104) -------------
2025-10-09 12:57:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=104 aidx=4 | s=5 (candidates=7)
2025-10-09 12:57:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 7, 12, 42, 33] (from 7)
2025-10-09 12:57:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 12:57:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:57:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:57:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:57:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.375977, avg_loss=0.704950, seen=480, correct=245, accuracy=0.510417
2025-10-09 12:57:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:57:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:58:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:58:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2190MB allocated=2030MB
2025-10-09 12:58:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.37171864509583, 'train_avg_loss': 0.7114309887091319, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 12:58:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.3759765625, 'train_avg_loss': 0.704949951171875, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 12:58:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 338.3759765625, 'train_avg_loss': 0.704949951171875, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 12:58:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 12:58:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:58:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:58:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:58:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.501343, avg_loss=0.707294, seen=480, correct=238, accuracy=0.495833
2025-10-09 12:58:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:58:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:58:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:58:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2184MB allocated=2030MB
2025-10-09 12:58:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.97145700454712, 'train_avg_loss': 0.7247621417045593, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 12:58:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.5013427734375, 'train_avg_loss': 0.7072944641113281, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 12:58:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 339.5013427734375, 'train_avg_loss': 0.7072944641113281, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 12:58:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 12:58:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:58:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 12:59:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 12:59:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.897247, avg_loss=0.710203, seen=480, correct=234, accuracy=0.487500
2025-10-09 12:59:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 12:59:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:59:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 12:59:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2172MB allocated=2030MB
2025-10-09 12:59:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.55688655376434, 'train_avg_loss': 0.7129740546147029, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 12:59:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.8972473144531, 'train_avg_loss': 0.7102025985717774, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 12:59:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 340.8972473144531, 'train_avg_loss': 0.7102025985717774, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 12:59:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 12:59:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 12:59:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:00:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:00:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.334595, avg_loss=0.704864, seen=480, correct=238, accuracy=0.495833
2025-10-09 13:00:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:00:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:00:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:00:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2174MB allocated=2030MB
2025-10-09 13:00:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5505074262619, 'train_avg_loss': 0.6962542285521826, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 13:00:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.3345947265625, 'train_avg_loss': 0.7048637390136718, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 13:00:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 338.3345947265625, 'train_avg_loss': 0.7048637390136718, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 13:00:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:00:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:00:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:01:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:01:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.621643, avg_loss=0.711712, seen=480, correct=245, accuracy=0.510417
2025-10-09 13:01:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:01:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:01:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:01:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2228MB allocated=2114MB
2025-10-09 13:01:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.00665134191513, 'train_avg_loss': 0.7167220945159595, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 13:01:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.62164306640625, 'train_avg_loss': 0.7117117563883464, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 13:01:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 341.62164306640625, 'train_avg_loss': 0.7117117563883464, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 13:01:04 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #105) -------------
2025-10-09 13:01:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=105 aidx=4 | s=5 (candidates=7)
2025-10-09 13:01:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 7, 42, 17, 35] (from 7)
2025-10-09 13:01:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:01:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:01:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:01:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:01:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.670166, avg_loss=0.697230, seen=480, correct=253, accuracy=0.527083
2025-10-09 13:01:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:01:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:01:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:01:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2192MB allocated=2039MB
2025-10-09 13:01:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.31059217453003, 'train_avg_loss': 0.7025882681210835, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 13:01:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.670166015625, 'train_avg_loss': 0.697229512532552, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 13:01:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 334.670166015625, 'train_avg_loss': 0.697229512532552, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 13:01:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:01:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:01:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:02:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:02:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.894592, avg_loss=0.703947, seen=480, correct=237, accuracy=0.493750
2025-10-09 13:02:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:02:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:02:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:02:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2202MB allocated=2039MB
2025-10-09 13:02:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.95799255371094, 'train_avg_loss': 0.7079832712809245, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:02:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.89459228515625, 'train_avg_loss': 0.7039470672607422, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 13:02:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 337.89459228515625, 'train_avg_loss': 0.7039470672607422, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 13:02:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:02:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:02:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:03:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:03:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.943390, avg_loss=0.697799, seen=480, correct=250, accuracy=0.520833
2025-10-09 13:03:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:03:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:03:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:03:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2198MB allocated=2039MB
2025-10-09 13:03:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.04658842086792, 'train_avg_loss': 0.6920549035072326, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 13:03:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9433898925781, 'train_avg_loss': 0.6977987289428711, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 13:03:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 334.9433898925781, 'train_avg_loss': 0.6977987289428711, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 13:03:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:03:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:03:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-09 13:03:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:03:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:03:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:03:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:03:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:03:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:04:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:04:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.738220, avg_loss=0.697371, seen=480, correct=245, accuracy=0.510417
2025-10-09 13:04:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:04:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:04:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:04:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2208MB allocated=2039MB
2025-10-09 13:04:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2742030620575, 'train_avg_loss': 0.7106183588504791, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-09 13:04:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.73822021484375, 'train_avg_loss': 0.6973712921142579, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 13:04:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 334.73822021484375, 'train_avg_loss': 0.6973712921142579, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 13:04:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:04:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:04:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-09 13:04:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:04:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:04:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:04:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:04:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:04:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:04:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:04:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.340698, avg_loss=0.704876, seen=480, correct=240, accuracy=0.500000
2025-10-09 13:04:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:04:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:04:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:04:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2242MB allocated=2039MB
2025-10-09 13:04:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.73106563091278, 'train_avg_loss': 0.7144255469242732, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 13:04:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.3406982421875, 'train_avg_loss': 0.704876454671224, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 13:04:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 338.3406982421875, 'train_avg_loss': 0.704876454671224, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 13:04:52 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #106) -------------
2025-10-09 13:04:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=106 aidx=4 | s=5 (candidates=7)
2025-10-09 13:04:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 7, 17, 35, 42] (from 7)
2025-10-09 13:04:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:04:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:04:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-09 13:04:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:04:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:04:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:04:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:04:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:04:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:05:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:05:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.411926, avg_loss=0.694608, seen=480, correct=243, accuracy=0.506250
2025-10-09 13:05:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:05:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:05:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:05:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2160MB allocated=2047MB
2025-10-09 13:05:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.65350097417831, 'train_avg_loss': 0.7054458414514859, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 13:05:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.41192626953125, 'train_avg_loss': 0.6946081797281901, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 13:05:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 333.41192626953125, 'train_avg_loss': 0.6946081797281901, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 13:05:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:05:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:05:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-09 13:05:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:05:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:05:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:05:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:05:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:05:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:06:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:06:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.250671, avg_loss=0.696356, seen=480, correct=249, accuracy=0.518750
2025-10-09 13:06:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:06:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:06:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:06:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2130MB allocated=1972MB
2025-10-09 13:06:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.7600748538971, 'train_avg_loss': 0.7063339571158092, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 13:06:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.25067138671875, 'train_avg_loss': 0.6963555653889973, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 13:06:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 334.25067138671875, 'train_avg_loss': 0.6963555653889973, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 13:06:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:06:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:06:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:07:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:07:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.863556, avg_loss=0.693466, seen=480, correct=255, accuracy=0.531250
2025-10-09 13:07:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:07:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:07:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:07:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2132MB allocated=1972MB
2025-10-09 13:07:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.85741591453552, 'train_avg_loss': 0.698811799287796, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 13:07:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8635559082031, 'train_avg_loss': 0.6934657414754232, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 13:07:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 332.8635559082031, 'train_avg_loss': 0.6934657414754232, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 13:07:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:07:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:07:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:07:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:07:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.335480, avg_loss=0.696532, seen=480, correct=258, accuracy=0.537500
2025-10-09 13:07:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:07:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:07:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:07:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2170MB allocated=1972MB
2025-10-09 13:07:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.60557234287262, 'train_avg_loss': 0.6967131028572718, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 13:07:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.3354797363281, 'train_avg_loss': 0.6965322494506836, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 13:07:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 334.3354797363281, 'train_avg_loss': 0.6965322494506836, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 13:07:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:07:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:07:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-09 13:08:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:08:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:08:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:08:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:08:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:08:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:08:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:08:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.937927, avg_loss=0.695704, seen=480, correct=259, accuracy=0.539583
2025-10-09 13:08:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:08:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:08:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:08:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2116MB allocated=1972MB
2025-10-09 13:08:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.7171927690506, 'train_avg_loss': 0.6893099397420883, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 13:08:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.93792724609375, 'train_avg_loss': 0.6957040150960286, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 13:08:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 333.93792724609375, 'train_avg_loss': 0.6957040150960286, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 13:08:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #107) -------------
2025-10-09 13:08:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=107 aidx=4 | s=5 (candidates=7)
2025-10-09 13:08:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 42, 12, 17, 33] (from 7)
2025-10-09 13:08:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:08:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:08:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-09 13:08:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:08:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:08:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:08:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:08:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:08:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:09:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:09:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.788147, avg_loss=0.693309, seen=480, correct=244, accuracy=0.508333
2025-10-09 13:09:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:09:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:09:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:09:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2130MB allocated=1972MB
2025-10-09 13:09:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47160148620605, 'train_avg_loss': 0.7039300123850505, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 13:09:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.78814697265625, 'train_avg_loss': 0.6933086395263672, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 13:09:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 332.78814697265625, 'train_avg_loss': 0.6933086395263672, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 13:09:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:09:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:09:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:10:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:10:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.055176, avg_loss=0.687615, seen=480, correct=260, accuracy=0.541667
2025-10-09 13:10:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:10:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:10:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:10:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2116MB allocated=1972MB
2025-10-09 13:10:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63074898719788, 'train_avg_loss': 0.6802562415599823, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:10:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.05517578125, 'train_avg_loss': 0.6876149495442708, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 13:10:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 330.05517578125, 'train_avg_loss': 0.6876149495442708, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 13:10:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:10:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:10:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:10:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:10:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.492065, avg_loss=0.701025, seen=480, correct=227, accuracy=0.472917
2025-10-09 13:10:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:10:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:10:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:10:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2118MB allocated=1972MB
2025-10-09 13:10:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47327065467834, 'train_avg_loss': 0.7039439221223195, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 13:10:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4920654296875, 'train_avg_loss': 0.7010251363118489, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-09 13:10:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 336.4920654296875, 'train_avg_loss': 0.7010251363118489, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-09 13:10:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:11:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:11:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:11:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:11:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.713440, avg_loss=0.691070, seen=480, correct=254, accuracy=0.529167
2025-10-09 13:11:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:11:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:11:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:11:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2134MB allocated=1972MB
2025-10-09 13:11:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.47363448143005, 'train_avg_loss': 0.6956136206785838, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 13:11:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.71343994140625, 'train_avg_loss': 0.6910696665445963, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 13:11:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 331.71343994140625, 'train_avg_loss': 0.6910696665445963, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 13:11:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:11:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:11:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:12:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:12:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.329254, avg_loss=0.690269, seen=480, correct=251, accuracy=0.522917
2025-10-09 13:12:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:12:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:12:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:12:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2116MB allocated=1972MB
2025-10-09 13:12:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.84341251850128, 'train_avg_loss': 0.6903617709875107, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 13:12:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3292541503906, 'train_avg_loss': 0.6902692794799805, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 13:12:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 331.3292541503906, 'train_avg_loss': 0.6902692794799805, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 13:12:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #108) -------------
2025-10-09 13:12:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=108 aidx=4 | s=5 (candidates=7)
2025-10-09 13:12:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 42, 35, 9, 17] (from 7)
2025-10-09 13:12:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:12:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:12:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:13:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:13:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.662109, avg_loss=0.682629, seen=480, correct=266, accuracy=0.554167
2025-10-09 13:13:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:13:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:13:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:13:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2116MB allocated=1972MB
2025-10-09 13:13:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.60238379240036, 'train_avg_loss': 0.6800198649366697, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 13:13:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.662109375, 'train_avg_loss': 0.68262939453125, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:13:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 327.662109375, 'train_avg_loss': 0.68262939453125, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:13:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:13:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:13:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:13:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:13:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.020386, avg_loss=0.685459, seen=480, correct=260, accuracy=0.541667
2025-10-09 13:13:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:13:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:13:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:13:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2116MB allocated=1972MB
2025-10-09 13:14:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.68729734420776, 'train_avg_loss': 0.6723941445350647, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:14:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0203857421875, 'train_avg_loss': 0.6854591369628906, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 13:14:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 329.0203857421875, 'train_avg_loss': 0.6854591369628906, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 13:14:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:14:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:14:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:14:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:14:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.095520, avg_loss=0.696032, seen=480, correct=252, accuracy=0.525000
2025-10-09 13:14:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:14:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:14:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:14:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2166MB allocated=1972MB
2025-10-09 13:14:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.63357329368591, 'train_avg_loss': 0.7052797774473826, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 13:14:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.09552001953125, 'train_avg_loss': 0.6960323333740235, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 13:14:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 334.09552001953125, 'train_avg_loss': 0.6960323333740235, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 13:14:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:14:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:14:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:15:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:15:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.042053, avg_loss=0.691754, seen=480, correct=246, accuracy=0.512500
2025-10-09 13:15:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:15:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:15:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:15:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2130MB allocated=1972MB
2025-10-09 13:15:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.07748281955719, 'train_avg_loss': 0.6923123568296432, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 13:15:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.04205322265625, 'train_avg_loss': 0.6917542775472005, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 13:15:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 332.04205322265625, 'train_avg_loss': 0.6917542775472005, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 13:15:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:15:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:15:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:16:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:16:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.075226, avg_loss=0.687657, seen=480, correct=250, accuracy=0.520833
2025-10-09 13:16:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:16:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:16:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:16:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2136MB allocated=1972MB
2025-10-09 13:16:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.51906698942184, 'train_avg_loss': 0.6959922249118488, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 13:16:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.0752258300781, 'train_avg_loss': 0.6876567204793295, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 13:16:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 330.0752258300781, 'train_avg_loss': 0.6876567204793295, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 13:16:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #109) -------------
2025-10-09 13:16:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=109 aidx=4 | s=5 (candidates=7)
2025-10-09 13:16:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 17, 33, 12, 9] (from 7)
2025-10-09 13:16:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:16:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:16:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:17:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:17:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.896637, avg_loss=0.693535, seen=480, correct=257, accuracy=0.535417
2025-10-09 13:17:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:17:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:17:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:17:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2124MB allocated=1972MB
2025-10-09 13:17:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.20416617393494, 'train_avg_loss': 0.7017013847827911, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 13:17:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8966369628906, 'train_avg_loss': 0.6935346603393555, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 13:17:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 332.8966369628906, 'train_avg_loss': 0.6935346603393555, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 13:17:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:17:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:17:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:17:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:17:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.877991, avg_loss=0.683079, seen=480, correct=266, accuracy=0.554167
2025-10-09 13:17:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:17:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:17:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:17:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2134MB allocated=1972MB
2025-10-09 13:17:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.21045738458633, 'train_avg_loss': 0.6850871448715528, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 13:17:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.87799072265625, 'train_avg_loss': 0.6830791473388672, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:17:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 327.87799072265625, 'train_avg_loss': 0.6830791473388672, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:17:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:17:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:17:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-09 13:17:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:17:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:17:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:17:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:17:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:17:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:18:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:18:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.029053, avg_loss=0.683394, seen=480, correct=262, accuracy=0.545833
2025-10-09 13:18:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:18:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:18:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:18:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2116MB allocated=1972MB
2025-10-09 13:18:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90651178359985, 'train_avg_loss': 0.6825542648633321, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 13:18:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.029052734375, 'train_avg_loss': 0.6833938598632813, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 13:18:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 328.029052734375, 'train_avg_loss': 0.6833938598632813, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 13:18:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:18:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:18:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-09 13:18:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:18:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:18:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:18:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:18:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:18:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:19:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:19:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.660492, avg_loss=0.703459, seen=480, correct=228, accuracy=0.475000
2025-10-09 13:19:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:19:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:19:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:19:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2118MB allocated=1972MB
2025-10-09 13:19:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.44924014806747, 'train_avg_loss': 0.7037436679005623, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:19:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.6604919433594, 'train_avg_loss': 0.703459358215332, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-09 13:19:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 337.6604919433594, 'train_avg_loss': 0.703459358215332, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-09 13:19:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:19:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:19:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:20:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:20:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.337280, avg_loss=0.692369, seen=480, correct=245, accuracy=0.510417
2025-10-09 13:20:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:20:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:20:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:20:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2128MB allocated=1972MB
2025-10-09 13:20:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.01617932319641, 'train_avg_loss': 0.7001348276933034, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 13:20:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.3372802734375, 'train_avg_loss': 0.6923693339029948, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 13:20:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 332.3372802734375, 'train_avg_loss': 0.6923693339029948, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 13:20:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #110) -------------
2025-10-09 13:20:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=110 aidx=4 | s=5 (candidates=7)
2025-10-09 13:20:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 7, 42, 35, 9] (from 7)
2025-10-09 13:20:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:20:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:20:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-09 13:20:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:20:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:20:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:20:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:20:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:20:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:20:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:20:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.920837, avg_loss=0.679002, seen=480, correct=263, accuracy=0.547917
2025-10-09 13:20:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:20:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:20:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:20:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2134MB allocated=1972MB
2025-10-09 13:20:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66377103328705, 'train_avg_loss': 0.6805314252773921, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 13:20:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.92083740234375, 'train_avg_loss': 0.6790017445882162, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 13:20:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 325.92083740234375, 'train_avg_loss': 0.6790017445882162, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 13:20:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:20:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:20:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:21:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:21:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.830994, avg_loss=0.691315, seen=480, correct=248, accuracy=0.516667
2025-10-09 13:21:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:21:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:21:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:21:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2124MB allocated=1972MB
2025-10-09 13:21:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12181389331818, 'train_avg_loss': 0.7010151157776515, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 13:21:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.83099365234375, 'train_avg_loss': 0.6913145701090495, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 13:21:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 331.83099365234375, 'train_avg_loss': 0.6913145701090495, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 13:21:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:21:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:21:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:22:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:22:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.490479, avg_loss=0.682272, seen=480, correct=268, accuracy=0.558333
2025-10-09 13:22:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:22:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:22:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:22:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2116MB allocated=1972MB
2025-10-09 13:22:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.61576974391937, 'train_avg_loss': 0.6717980811993282, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 13:22:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.490478515625, 'train_avg_loss': 0.6822718302408854, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 13:22:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 327.490478515625, 'train_avg_loss': 0.6822718302408854, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 13:22:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:22:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:22:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:23:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:23:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.097687, avg_loss=0.696037, seen=480, correct=254, accuracy=0.529167
2025-10-09 13:23:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:23:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:23:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:23:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2168MB allocated=1972MB
2025-10-09 13:23:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9834213256836, 'train_avg_loss': 0.6998618443806967, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 13:23:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0976867675781, 'train_avg_loss': 0.6960368474324544, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 13:23:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 334.0976867675781, 'train_avg_loss': 0.6960368474324544, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 13:23:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:23:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:23:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:23:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:23:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.502808, avg_loss=0.684381, seen=480, correct=256, accuracy=0.533333
2025-10-09 13:23:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:23:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:23:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:23:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2128MB allocated=1972MB
2025-10-09 13:23:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.15145206451416, 'train_avg_loss': 0.6929287672042846, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 13:23:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.5028076171875, 'train_avg_loss': 0.684380849202474, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 13:23:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 328.5028076171875, 'train_avg_loss': 0.684380849202474, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 13:23:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #111) -------------
2025-10-09 13:23:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=111 aidx=4 | s=5 (candidates=7)
2025-10-09 13:23:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 9, 7, 12, 17] (from 7)
2025-10-09 13:23:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:24:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:24:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-09 13:24:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:24:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:24:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:24:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:24:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:24:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:24:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:24:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.712494, avg_loss=0.682734, seen=480, correct=267, accuracy=0.556250
2025-10-09 13:24:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:24:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:24:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:24:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2116MB allocated=1972MB
2025-10-09 13:24:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.61835163831711, 'train_avg_loss': 0.6718195969859759, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 13:24:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.7124938964844, 'train_avg_loss': 0.6827343622843425, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 13:24:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 327.7124938964844, 'train_avg_loss': 0.6827343622843425, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 13:24:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:24:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:24:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:25:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:25:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.300049, avg_loss=0.675625, seen=480, correct=276, accuracy=0.575000
2025-10-09 13:25:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:25:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:25:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:25:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2130MB allocated=1972MB
2025-10-09 13:25:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.82280707359314, 'train_avg_loss': 0.6818567256132761, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 13:25:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.300048828125, 'train_avg_loss': 0.6756251017252605, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 13:25:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 324.300048828125, 'train_avg_loss': 0.6756251017252605, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 13:25:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:25:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:25:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:26:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:26:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.220764, avg_loss=0.690043, seen=480, correct=266, accuracy=0.554167
2025-10-09 13:26:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:26:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:26:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:26:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2124MB allocated=1972MB
2025-10-09 13:26:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.99307060241699, 'train_avg_loss': 0.6999422550201416, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 13:26:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.22076416015625, 'train_avg_loss': 0.6900432586669922, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:26:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 331.22076416015625, 'train_avg_loss': 0.6900432586669922, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:26:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:26:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:26:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:26:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:26:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.493011, avg_loss=0.696860, seen=480, correct=241, accuracy=0.502083
2025-10-09 13:26:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:26:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:26:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:26:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2118MB allocated=1972MB
2025-10-09 13:26:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5618788599968, 'train_avg_loss': 0.6963489904999733, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:26:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.4930114746094, 'train_avg_loss': 0.6968604405721028, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 13:26:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 334.4930114746094, 'train_avg_loss': 0.6968604405721028, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 13:26:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:26:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:26:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-09 13:26:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:26:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:26:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:26:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:26:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:26:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:27:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:27:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.435272, avg_loss=0.677990, seen=480, correct=272, accuracy=0.566667
2025-10-09 13:27:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:27:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:27:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:27:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2132MB allocated=1972MB
2025-10-09 13:27:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.39079201221466, 'train_avg_loss': 0.6782566001017888, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 13:27:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4352722167969, 'train_avg_loss': 0.6779901504516601, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:27:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 325.4352722167969, 'train_avg_loss': 0.6779901504516601, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:27:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #112) -------------
2025-10-09 13:27:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=112 aidx=4 | s=5 (candidates=7)
2025-10-09 13:27:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 7, 9, 42, 33] (from 7)
2025-10-09 13:27:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:27:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:27:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:28:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:28:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.956665, avg_loss=0.672826, seen=480, correct=281, accuracy=0.585417
2025-10-09 13:28:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:28:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:28:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:28:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2134MB allocated=1972MB
2025-10-09 13:28:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.66711807250977, 'train_avg_loss': 0.6722259839375814, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 13:28:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.9566650390625, 'train_avg_loss': 0.6728263854980469, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 13:28:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 322.9566650390625, 'train_avg_loss': 0.6728263854980469, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 13:28:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:28:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:28:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:29:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:29:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.681580, avg_loss=0.688920, seen=480, correct=271, accuracy=0.564583
2025-10-09 13:29:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:29:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:29:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:29:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2124MB allocated=1972MB
2025-10-09 13:29:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.29237627983093, 'train_avg_loss': 0.7024364689985911, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:29:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.68157958984375, 'train_avg_loss': 0.6889199574788412, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 13:29:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 330.68157958984375, 'train_avg_loss': 0.6889199574788412, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 13:29:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:29:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:29:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:29:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:29:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.299286, avg_loss=0.673540, seen=480, correct=275, accuracy=0.572917
2025-10-09 13:29:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:29:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:29:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:29:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2130MB allocated=1972MB
2025-10-09 13:29:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.17469161748886, 'train_avg_loss': 0.6847890968124072, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 13:29:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.2992858886719, 'train_avg_loss': 0.6735401789347331, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 13:29:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 323.2992858886719, 'train_avg_loss': 0.6735401789347331, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 13:29:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:29:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:29:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:30:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:30:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.572968, avg_loss=0.680360, seen=480, correct=272, accuracy=0.566667
2025-10-09 13:30:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:30:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:30:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:30:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2116MB allocated=1972MB
2025-10-09 13:30:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.13499891757965, 'train_avg_loss': 0.6677916576464971, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 13:30:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.5729675292969, 'train_avg_loss': 0.6803603490193685, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:30:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 326.5729675292969, 'train_avg_loss': 0.6803603490193685, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:30:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:30:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:30:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:31:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:31:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.777679, avg_loss=0.680787, seen=480, correct=263, accuracy=0.547917
2025-10-09 13:31:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:31:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:31:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:31:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2116MB allocated=1972MB
2025-10-09 13:31:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5985136628151, 'train_avg_loss': 0.6716542805234591, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 13:31:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.7776794433594, 'train_avg_loss': 0.6807868321736653, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 13:31:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 326.7776794433594, 'train_avg_loss': 0.6807868321736653, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 13:31:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #113) -------------
2025-10-09 13:31:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=113 aidx=4 | s=5 (candidates=7)
2025-10-09 13:31:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 12, 35, 42, 7] (from 7)
2025-10-09 13:31:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:31:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:31:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-09 13:31:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:31:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:31:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:31:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:31:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:31:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:32:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:32:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.244385, avg_loss=0.667176, seen=480, correct=285, accuracy=0.593750
2025-10-09 13:32:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:32:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:32:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:32:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2132MB allocated=1972MB
2025-10-09 13:32:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.76477485895157, 'train_avg_loss': 0.6730397904912631, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 13:32:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.244384765625, 'train_avg_loss': 0.6671758015950521, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 13:32:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 320.244384765625, 'train_avg_loss': 0.6671758015950521, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 13:32:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:32:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:32:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-09 13:32:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:32:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:32:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:32:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:32:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:32:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:32:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:32:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.540100, avg_loss=0.694875, seen=480, correct=252, accuracy=0.525000
2025-10-09 13:32:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:32:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:32:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:32:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2118MB allocated=1972MB
2025-10-09 13:32:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.77731996774673, 'train_avg_loss': 0.6981443330645561, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 13:32:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.54010009765625, 'train_avg_loss': 0.6948752085367839, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 13:32:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 333.54010009765625, 'train_avg_loss': 0.6948752085367839, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 13:32:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:32:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:32:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:33:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:33:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.163483, avg_loss=0.696174, seen=480, correct=247, accuracy=0.514583
2025-10-09 13:33:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:33:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:33:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:33:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2168MB allocated=1972MB
2025-10-09 13:33:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.94979619979858, 'train_avg_loss': 0.7079149683316549, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 13:33:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1634826660156, 'train_avg_loss': 0.6961739222208659, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 13:33:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 334.1634826660156, 'train_avg_loss': 0.6961739222208659, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 13:33:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:33:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:33:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-09 13:33:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:33:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:33:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:33:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:33:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:33:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:34:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:34:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.374237, avg_loss=0.677863, seen=480, correct=273, accuracy=0.568750
2025-10-09 13:34:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:34:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:34:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:34:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2116MB allocated=1972MB
2025-10-09 13:34:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.23532021045685, 'train_avg_loss': 0.6686276684204737, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 13:34:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.3742370605469, 'train_avg_loss': 0.6778629938761394, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 13:34:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 325.3742370605469, 'train_avg_loss': 0.6778629938761394, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 13:34:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:34:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:34:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:35:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:35:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.243317, avg_loss=0.690090, seen=480, correct=262, accuracy=0.545833
2025-10-09 13:35:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:35:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:35:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:35:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2124MB allocated=1972MB
2025-10-09 13:35:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73903048038483, 'train_avg_loss': 0.6978252540032069, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 13:35:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2433166503906, 'train_avg_loss': 0.6900902430216471, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 13:35:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 331.2433166503906, 'train_avg_loss': 0.6900902430216471, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 13:35:20 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #114) -------------
2025-10-09 13:35:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=114 aidx=4 | s=5 (candidates=7)
2025-10-09 13:35:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 9, 33, 42, 12] (from 7)
2025-10-09 13:35:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:35:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:35:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-09 13:35:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:35:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:35:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:35:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:35:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:35:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:36:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:36:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.026794, avg_loss=0.693806, seen=480, correct=256, accuracy=0.533333
2025-10-09 13:36:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:36:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:36:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:36:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2168MB allocated=1972MB
2025-10-09 13:36:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.44795346260071, 'train_avg_loss': 0.7037329455216725, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 13:36:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.02679443359375, 'train_avg_loss': 0.6938058217366536, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 13:36:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 333.02679443359375, 'train_avg_loss': 0.6938058217366536, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 13:36:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:36:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:36:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-09 13:36:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:36:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:36:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:36:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:36:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:36:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:36:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:36:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.591492, avg_loss=0.669982, seen=480, correct=277, accuracy=0.577083
2025-10-09 13:36:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:36:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:36:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:36:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2130MB allocated=1972MB
2025-10-09 13:36:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.68479615449905, 'train_avg_loss': 0.6723733012874921, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:36:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.59149169921875, 'train_avg_loss': 0.6699822743733724, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 13:36:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 321.59149169921875, 'train_avg_loss': 0.6699822743733724, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 13:36:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:36:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:36:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-09 13:36:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:36:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:36:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:36:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:36:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:37:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:37:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.673859, avg_loss=0.670154, seen=480, correct=284, accuracy=0.591667
2025-10-09 13:37:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:37:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:37:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:37:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2116MB allocated=1972MB
2025-10-09 13:37:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.72680276632309, 'train_avg_loss': 0.6643900230526925, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 13:37:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.6738586425781, 'train_avg_loss': 0.6701538721720378, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 13:37:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 321.6738586425781, 'train_avg_loss': 0.6701538721720378, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 13:37:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:37:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:37:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:38:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:38:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.358032, avg_loss=0.675746, seen=480, correct=272, accuracy=0.566667
2025-10-09 13:38:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:38:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:38:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:38:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2116MB allocated=1972MB
2025-10-09 13:38:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.64890503883362, 'train_avg_loss': 0.6637408753236135, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 13:38:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.3580322265625, 'train_avg_loss': 0.6757459004720052, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:38:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 324.3580322265625, 'train_avg_loss': 0.6757459004720052, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:38:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:38:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:38:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:39:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:39:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.808960, avg_loss=0.691269, seen=480, correct=254, accuracy=0.529167
2025-10-09 13:39:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:39:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:39:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:39:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2118MB allocated=1972MB
2025-10-09 13:39:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.93543952703476, 'train_avg_loss': 0.699461996058623, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:39:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8089599609375, 'train_avg_loss': 0.6912686665852864, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 13:39:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 331.8089599609375, 'train_avg_loss': 0.6912686665852864, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 13:39:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #115) -------------
2025-10-09 13:39:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=115 aidx=4 | s=5 (candidates=7)
2025-10-09 13:39:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 17, 33, 35, 9] (from 7)
2025-10-09 13:39:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:39:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:39:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-09 13:39:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:39:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:39:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:39:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:39:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:39:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:39:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:39:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.200409, avg_loss=0.683751, seen=480, correct=265, accuracy=0.552083
2025-10-09 13:39:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:39:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:39:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:39:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2118MB allocated=1972MB
2025-10-09 13:39:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.21726441383362, 'train_avg_loss': 0.6934772034486135, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 13:39:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2004089355469, 'train_avg_loss': 0.6837508519490559, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 13:39:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 328.2004089355469, 'train_avg_loss': 0.6837508519490559, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 13:39:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:39:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:39:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-09 13:39:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:39:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:39:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:39:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:39:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:39:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:40:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:40:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.823975, avg_loss=0.668383, seen=480, correct=287, accuracy=0.597917
2025-10-09 13:40:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:40:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:40:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:40:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2134MB allocated=1972MB
2025-10-09 13:40:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.18050038814545, 'train_avg_loss': 0.6681708365678787, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:40:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.823974609375, 'train_avg_loss': 0.6683832804361979, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 13:40:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 320.823974609375, 'train_avg_loss': 0.6683832804361979, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 13:40:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:40:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:40:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:41:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:41:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.194580, avg_loss=0.669155, seen=480, correct=274, accuracy=0.570833
2025-10-09 13:41:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:41:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:41:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:41:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2116MB allocated=1972MB
2025-10-09 13:41:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.54877519607544, 'train_avg_loss': 0.6629064599672954, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:41:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.194580078125, 'train_avg_loss': 0.6691553751627605, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 13:41:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 321.194580078125, 'train_avg_loss': 0.6691553751627605, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 13:41:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:41:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:41:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-09 13:41:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:41:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:41:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:41:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:41:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:41:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:41:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:41:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.157837, avg_loss=0.691995, seen=480, correct=261, accuracy=0.543750
2025-10-09 13:41:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:41:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:42:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:42:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2168MB allocated=1972MB
2025-10-09 13:42:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.68153142929077, 'train_avg_loss': 0.6973460952440897, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:42:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.1578369140625, 'train_avg_loss': 0.6919954935709636, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 13:42:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 332.1578369140625, 'train_avg_loss': 0.6919954935709636, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 13:42:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:42:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:42:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-09 13:42:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:42:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:42:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:42:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:42:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:42:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:42:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:42:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.360352, avg_loss=0.669501, seen=480, correct=270, accuracy=0.562500
2025-10-09 13:42:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:42:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:42:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:42:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2130MB allocated=1972MB
2025-10-09 13:42:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.29255652427673, 'train_avg_loss': 0.6774379710356394, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 13:42:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3603515625, 'train_avg_loss': 0.669500732421875, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 13:42:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 321.3603515625, 'train_avg_loss': 0.669500732421875, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 13:42:49 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #116) -------------
2025-10-09 13:42:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=116 aidx=4 | s=5 (candidates=7)
2025-10-09 13:42:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 35, 9, 42, 33] (from 7)
2025-10-09 13:42:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:42:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:42:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:43:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:43:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.071777, avg_loss=0.675150, seen=480, correct=282, accuracy=0.587500
2025-10-09 13:43:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:43:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:43:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:43:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2124MB allocated=1972MB
2025-10-09 13:43:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00006234645844, 'train_avg_loss': 0.7000005195538203, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 13:43:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.07177734375, 'train_avg_loss': 0.6751495361328125, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 13:43:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 324.07177734375, 'train_avg_loss': 0.6751495361328125, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 13:43:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:43:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:43:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:44:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:44:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.996521, avg_loss=0.691659, seen=480, correct=272, accuracy=0.566667
2025-10-09 13:44:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:44:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:44:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:44:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2168MB allocated=1972MB
2025-10-09 13:44:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.86250412464142, 'train_avg_loss': 0.6988542010386785, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 13:44:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.99652099609375, 'train_avg_loss': 0.691659418741862, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:44:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 331.99652099609375, 'train_avg_loss': 0.691659418741862, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 13:44:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:44:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:44:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:45:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:45:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.555267, avg_loss=0.661573, seen=480, correct=283, accuracy=0.589583
2025-10-09 13:45:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:45:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:45:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:45:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2130MB allocated=1972MB
2025-10-09 13:45:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.54329353570938, 'train_avg_loss': 0.6711941127975781, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 13:45:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.5552673339844, 'train_avg_loss': 0.6615734736124674, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 13:45:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 317.5552673339844, 'train_avg_loss': 0.6615734736124674, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 13:45:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:45:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:45:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-09 13:45:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:45:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:45:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:45:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:45:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:45:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:45:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:45:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.057434, avg_loss=0.673036, seen=480, correct=285, accuracy=0.593750
2025-10-09 13:45:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:45:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:45:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:45:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2116MB allocated=1972MB
2025-10-09 13:45:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.57046484947205, 'train_avg_loss': 0.6630872070789338, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 13:45:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.05743408203125, 'train_avg_loss': 0.6730363210042317, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 13:45:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 323.05743408203125, 'train_avg_loss': 0.6730363210042317, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 13:45:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:45:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:45:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-09 13:45:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:45:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:45:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:45:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:45:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:45:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:46:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:46:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.787598, avg_loss=0.670391, seen=480, correct=267, accuracy=0.556250
2025-10-09 13:46:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:46:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:46:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:46:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2116MB allocated=1972MB
2025-10-09 13:46:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.45435333251953, 'train_avg_loss': 0.6621196111043294, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:46:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.78759765625, 'train_avg_loss': 0.6703908284505208, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 13:46:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 321.78759765625, 'train_avg_loss': 0.6703908284505208, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 13:46:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #117) -------------
2025-10-09 13:46:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=117 aidx=4 | s=5 (candidates=7)
2025-10-09 13:46:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 9, 35, 12, 33] (from 7)
2025-10-09 13:46:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:46:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:46:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-09 13:46:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:46:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:46:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:46:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:46:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:46:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:47:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:47:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.716980, avg_loss=0.672327, seen=480, correct=278, accuracy=0.579167
2025-10-09 13:47:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:47:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:47:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:47:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2116MB allocated=1972MB
2025-10-09 13:47:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.09910506010056, 'train_avg_loss': 0.6591592088341713, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 13:47:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.71697998046875, 'train_avg_loss': 0.6723270416259766, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 13:47:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 322.71697998046875, 'train_avg_loss': 0.6723270416259766, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 13:47:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:47:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:47:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:47:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:47:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.699738, avg_loss=0.659791, seen=480, correct=289, accuracy=0.602083
2025-10-09 13:47:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:47:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:47:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:48:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2130MB allocated=1972MB
2025-10-09 13:48:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.52871334552765, 'train_avg_loss': 0.6627392778793971, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 13:48:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.6997375488281, 'train_avg_loss': 0.6597911198933919, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 13:48:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 316.6997375488281, 'train_avg_loss': 0.6597911198933919, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 13:48:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:48:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:48:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:48:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:48:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.515930, avg_loss=0.694825, seen=480, correct=262, accuracy=0.545833
2025-10-09 13:48:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:48:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:48:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:48:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2168MB allocated=1972MB
2025-10-09 13:48:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.13737738132477, 'train_avg_loss': 0.7011448115110397, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:48:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.51593017578125, 'train_avg_loss': 0.6948248545328776, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 13:48:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 333.51593017578125, 'train_avg_loss': 0.6948248545328776, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 13:48:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:48:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:48:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-09 13:48:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:48:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:48:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:48:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:48:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:48:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:49:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:49:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.329346, avg_loss=0.684019, seen=480, correct=266, accuracy=0.554167
2025-10-09 13:49:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:49:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:49:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:49:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2118MB allocated=1972MB
2025-10-09 13:49:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.31686753034592, 'train_avg_loss': 0.6943072294195493, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 13:49:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.329345703125, 'train_avg_loss': 0.6840194702148438, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:49:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 328.329345703125, 'train_avg_loss': 0.6840194702148438, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 13:49:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:49:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:49:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:50:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:50:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.273132, avg_loss=0.658902, seen=480, correct=295, accuracy=0.614583
2025-10-09 13:50:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:50:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:50:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:50:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2116MB allocated=1972MB
2025-10-09 13:50:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.13954073190689, 'train_avg_loss': 0.6511628394325574, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 13:50:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.27313232421875, 'train_avg_loss': 0.658902359008789, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 13:50:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 316.27313232421875, 'train_avg_loss': 0.658902359008789, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 13:50:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #118) -------------
2025-10-09 13:50:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=118 aidx=4 | s=5 (candidates=7)
2025-10-09 13:50:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 9, 35, 7, 33] (from 7)
2025-10-09 13:50:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 13:50:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:50:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:50:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:50:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.238770, avg_loss=0.658831, seen=480, correct=296, accuracy=0.616667
2025-10-09 13:50:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:50:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:50:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:50:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2132MB allocated=1972MB
2025-10-09 13:50:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.30675172805786, 'train_avg_loss': 0.6608895977338155, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 13:50:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.23876953125, 'train_avg_loss': 0.6588307698567708, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 13:50:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 316.23876953125, 'train_avg_loss': 0.6588307698567708, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 13:50:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:50:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:50:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:51:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:51:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.748749, avg_loss=0.659893, seen=480, correct=291, accuracy=0.606250
2025-10-09 13:51:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:51:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:51:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:51:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2130MB allocated=1972MB
2025-10-09 13:51:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.20453488826752, 'train_avg_loss': 0.6600377907355627, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 13:51:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.7487487792969, 'train_avg_loss': 0.6598932266235351, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 13:51:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 316.7487487792969, 'train_avg_loss': 0.6598932266235351, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 13:51:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 13:51:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:51:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:52:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:52:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.056183, avg_loss=0.695950, seen=480, correct=257, accuracy=0.535417
2025-10-09 13:52:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:52:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:52:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:52:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2168MB allocated=1972MB
2025-10-09 13:52:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.45857697725296, 'train_avg_loss': 0.7038214748104413, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:52:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0561828613281, 'train_avg_loss': 0.6959503809611003, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 13:52:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 334.0561828613281, 'train_avg_loss': 0.6959503809611003, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 13:52:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:52:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:52:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:53:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:53:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.883362, avg_loss=0.672674, seen=480, correct=278, accuracy=0.579167
2025-10-09 13:53:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:53:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:53:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:53:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2124MB allocated=1972MB
2025-10-09 13:53:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.29886388778687, 'train_avg_loss': 0.7024905323982239, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 13:53:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.88336181640625, 'train_avg_loss': 0.6726736704508464, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 13:53:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 322.88336181640625, 'train_avg_loss': 0.6726736704508464, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 13:53:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:53:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:53:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-09 13:53:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:53:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:53:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:53:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:53:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:53:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:53:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:53:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.806549, avg_loss=0.647514, seen=480, correct=304, accuracy=0.633333
2025-10-09 13:53:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:53:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:54:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:54:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2116MB allocated=1972MB
2025-10-09 13:54:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.16907519102097, 'train_avg_loss': 0.6430756265918414, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 13:54:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8065490722656, 'train_avg_loss': 0.6475136439005534, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 13:54:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 310.8065490722656, 'train_avg_loss': 0.6475136439005534, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 13:54:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #119) -------------
2025-10-09 13:54:02 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=119 aidx=4 | s=5 (candidates=7)
2025-10-09 13:54:02 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 33, 12, 7, 9] (from 7)
2025-10-09 13:54:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 13:54:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:54:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:54:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:54:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.827789, avg_loss=0.668391, seen=480, correct=285, accuracy=0.593750
2025-10-09 13:54:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:54:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:54:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:54:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2116MB allocated=1972MB
2025-10-09 13:54:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.47180742025375, 'train_avg_loss': 0.6539317285021146, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 13:54:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.8277893066406, 'train_avg_loss': 0.668391227722168, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 13:54:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 320.8277893066406, 'train_avg_loss': 0.668391227722168, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 13:54:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:54:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:54:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:55:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:55:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.351929, avg_loss=0.640317, seen=480, correct=310, accuracy=0.645833
2025-10-09 13:55:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:55:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:55:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:55:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2116MB allocated=1972MB
2025-10-09 13:55:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.46925503015518, 'train_avg_loss': 0.6372437919179599, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 13:55:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.3519287109375, 'train_avg_loss': 0.6403165181477865, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 13:55:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 307.3519287109375, 'train_avg_loss': 0.6403165181477865, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 13:55:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:55:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:55:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:56:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:56:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.741455, avg_loss=0.689045, seen=480, correct=270, accuracy=0.562500
2025-10-09 13:56:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:56:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:56:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:56:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2118MB allocated=1972MB
2025-10-09 13:56:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.75782859325409, 'train_avg_loss': 0.7063152382771174, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 13:56:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.741455078125, 'train_avg_loss': 0.689044698079427, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 13:56:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 330.741455078125, 'train_avg_loss': 0.689044698079427, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 13:56:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:56:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:56:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-09 13:56:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:56:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:56:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:56:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:56:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:56:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:57:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:57:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.738953, avg_loss=0.674456, seen=480, correct=282, accuracy=0.587500
2025-10-09 13:57:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:57:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:57:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:57:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2124MB allocated=1972MB
2025-10-09 13:57:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.67760580778122, 'train_avg_loss': 0.7056467150648434, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 13:57:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.73895263671875, 'train_avg_loss': 0.6744561513264974, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 13:57:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 323.73895263671875, 'train_avg_loss': 0.6744561513264974, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 13:57:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:57:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:57:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-09 13:57:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 13:57:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:57:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:57:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:57:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:57:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:57:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:57:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.886505, avg_loss=0.660180, seen=480, correct=293, accuracy=0.610417
2025-10-09 13:57:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:57:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:57:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:57:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2128MB allocated=1972MB
2025-10-09 13:57:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.3235382437706, 'train_avg_loss': 0.661029485364755, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 13:57:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.8865051269531, 'train_avg_loss': 0.6601802190144856, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 13:57:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 316.8865051269531, 'train_avg_loss': 0.6601802190144856, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 13:57:52 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #120) -------------
2025-10-09 13:57:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=120 aidx=4 | s=5 (candidates=7)
2025-10-09 13:57:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 12, 33, 42, 9] (from 7)
2025-10-09 13:57:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:57:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:57:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-09 13:57:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 13:57:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:57:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:57:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:57:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:57:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:58:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:58:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.393341, avg_loss=0.667486, seen=480, correct=286, accuracy=0.595833
2025-10-09 13:58:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:58:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:58:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:58:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2124MB allocated=1972MB
2025-10-09 13:58:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.86768871545792, 'train_avg_loss': 0.7072307392954826, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 13:58:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.3933410644531, 'train_avg_loss': 0.6674861272176107, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 13:58:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 320.3933410644531, 'train_avg_loss': 0.6674861272176107, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 13:58:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 13:58:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:58:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 13:59:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 13:59:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.931091, avg_loss=0.687356, seen=480, correct=270, accuracy=0.562500
2025-10-09 13:59:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 13:59:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:59:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 13:59:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2118MB allocated=1972MB
2025-10-09 13:59:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.82017457485199, 'train_avg_loss': 0.6985014547904332, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 13:59:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.93109130859375, 'train_avg_loss': 0.687356440226237, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 13:59:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 329.93109130859375, 'train_avg_loss': 0.687356440226237, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 13:59:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 13:59:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 13:59:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-09 13:59:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 13:59:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 13:59:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 13:59:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 13:59:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 13:59:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:00:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:00:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.760895, avg_loss=0.643252, seen=480, correct=299, accuracy=0.622917
2025-10-09 14:00:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:00:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:00:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:00:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2116MB allocated=1972MB
2025-10-09 14:00:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.37842190265656, 'train_avg_loss': 0.6281535158554713, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 14:00:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.7608947753906, 'train_avg_loss': 0.6432518641153971, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 14:00:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 308.7608947753906, 'train_avg_loss': 0.6432518641153971, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 14:00:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:00:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:00:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-09 14:00:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 14:00:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:00:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:00:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:00:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:00:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:00:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:00:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.869354, avg_loss=0.668478, seen=480, correct=283, accuracy=0.589583
2025-10-09 14:00:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:00:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:00:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:00:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2116MB allocated=1972MB
2025-10-09 14:00:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.93021768331528, 'train_avg_loss': 0.6577518140276273, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 14:00:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.8693542480469, 'train_avg_loss': 0.6684778213500977, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 14:00:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 320.8693542480469, 'train_avg_loss': 0.6684778213500977, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 14:00:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 14:00:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:00:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:01:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:01:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.889679, avg_loss=0.649770, seen=480, correct=300, accuracy=0.625000
2025-10-09 14:01:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:01:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:01:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:01:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2130MB allocated=1972MB
2025-10-09 14:01:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.08515232801437, 'train_avg_loss': 0.6507096027334531, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 14:01:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.8896789550781, 'train_avg_loss': 0.6497701644897461, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 14:01:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 311.8896789550781, 'train_avg_loss': 0.6497701644897461, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 14:01:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #121) -------------
2025-10-09 14:01:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=121 aidx=4 | s=5 (candidates=7)
2025-10-09 14:01:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 42, 17, 33, 9] (from 7)
2025-10-09 14:01:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:01:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:01:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-09 14:01:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:01:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:01:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:01:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:01:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:01:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:02:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:02:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.199127, avg_loss=0.702498, seen=480, correct=258, accuracy=0.537500
2025-10-09 14:02:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:02:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:02:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:02:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2168MB allocated=1972MB
2025-10-09 14:02:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.55599004030228, 'train_avg_loss': 0.7129665836691856, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 14:02:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.1991271972656, 'train_avg_loss': 0.70249818166097, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 14:02:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 337.1991271972656, 'train_avg_loss': 0.70249818166097, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 14:02:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 14:02:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:02:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:03:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:03:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.135376, avg_loss=0.671115, seen=480, correct=285, accuracy=0.593750
2025-10-09 14:03:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:03:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:03:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:03:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2116MB allocated=1972MB
2025-10-09 14:03:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.07741540670395, 'train_avg_loss': 0.6589784617225329, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 14:03:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1353759765625, 'train_avg_loss': 0.6711153666178385, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 14:03:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 322.1353759765625, 'train_avg_loss': 0.6711153666178385, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 14:03:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:03:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:03:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:03:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:03:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.671753, avg_loss=0.659733, seen=480, correct=305, accuracy=0.635417
2025-10-09 14:03:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:03:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:03:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:03:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2132MB allocated=1972MB
2025-10-09 14:03:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.37365019321442, 'train_avg_loss': 0.6531137516101201, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 14:03:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.6717529296875, 'train_avg_loss': 0.6597328186035156, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 14:03:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 316.6717529296875, 'train_avg_loss': 0.6597328186035156, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 14:03:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:03:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:03:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:04:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:04:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.288574, avg_loss=0.644351, seen=480, correct=298, accuracy=0.620833
2025-10-09 14:04:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:04:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:04:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:04:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2116MB allocated=1972MB
2025-10-09 14:04:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.22301459312439, 'train_avg_loss': 0.6268584549427032, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 14:04:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.28857421875, 'train_avg_loss': 0.6443511962890625, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 14:04:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 309.28857421875, 'train_avg_loss': 0.6443511962890625, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 14:04:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 14:04:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:04:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:05:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:05:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.437531, avg_loss=0.642578, seen=480, correct=300, accuracy=0.625000
2025-10-09 14:05:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:05:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:05:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:05:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2128MB allocated=1972MB
2025-10-09 14:05:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.94434607028961, 'train_avg_loss': 0.6495362172524134, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 14:05:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.4375305175781, 'train_avg_loss': 0.6425781885782877, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 14:05:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 308.4375305175781, 'train_avg_loss': 0.6425781885782877, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 14:05:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #122) -------------
2025-10-09 14:05:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=122 aidx=4 | s=5 (candidates=7)
2025-10-09 14:05:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 17, 33, 12, 9] (from 7)
2025-10-09 14:05:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:05:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:05:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-09 14:05:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:05:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:05:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:05:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:05:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:05:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:06:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:06:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.059021, avg_loss=0.706373, seen=480, correct=266, accuracy=0.554167
2025-10-09 14:06:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:06:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:06:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:06:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2168MB allocated=1972MB
2025-10-09 14:06:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.34049409627914, 'train_avg_loss': 0.7195041174689929, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 14:06:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.05902099609375, 'train_avg_loss': 0.7063729604085286, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 14:06:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 339.05902099609375, 'train_avg_loss': 0.7063729604085286, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 14:06:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:06:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:06:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-09 14:06:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:06:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:06:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:06:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:06:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:06:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:06:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:06:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.681488, avg_loss=0.657670, seen=480, correct=303, accuracy=0.631250
2025-10-09 14:06:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:06:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:06:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:06:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2134MB allocated=1972MB
2025-10-09 14:06:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.1355339884758, 'train_avg_loss': 0.6427961165706316, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 14:06:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.6814880371094, 'train_avg_loss': 0.6576697667439778, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 14:06:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 315.6814880371094, 'train_avg_loss': 0.6576697667439778, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 14:06:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:06:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:06:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-09 14:06:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:06:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:07:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:07:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:07:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:07:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:07:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:07:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.409119, avg_loss=0.646686, seen=480, correct=297, accuracy=0.618750
2025-10-09 14:07:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:07:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:07:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:07:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2116MB allocated=1972MB
2025-10-09 14:07:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.96851968765259, 'train_avg_loss': 0.6247376640637715, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 14:07:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.40911865234375, 'train_avg_loss': 0.6466856638590495, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:07:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 310.40911865234375, 'train_avg_loss': 0.6466856638590495, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:07:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 14:07:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:07:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:08:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:08:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.982361, avg_loss=0.691630, seen=480, correct=270, accuracy=0.562500
2025-10-09 14:08:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:08:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:08:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:08:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2118MB allocated=1972MB
2025-10-09 14:08:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.83141595125198, 'train_avg_loss': 0.7069284662604332, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 14:08:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.98236083984375, 'train_avg_loss': 0.6916299184163411, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 14:08:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 331.98236083984375, 'train_avg_loss': 0.6916299184163411, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 14:08:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 14:08:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:08:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:09:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:09:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.699799, avg_loss=0.626458, seen=480, correct=312, accuracy=0.650000
2025-10-09 14:09:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:09:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:09:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:09:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2130MB allocated=1972MB
2025-10-09 14:09:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.11572015285492, 'train_avg_loss': 0.6342976679404576, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 14:09:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.6997985839844, 'train_avg_loss': 0.6264579137166341, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 14:09:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 300.6997985839844, 'train_avg_loss': 0.6264579137166341, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 14:09:14 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #123) -------------
2025-10-09 14:09:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=123 aidx=4 | s=5 (candidates=7)
2025-10-09 14:09:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 42, 17, 12, 33] (from 7)
2025-10-09 14:09:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 14:09:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:09:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:09:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:09:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.466919, avg_loss=0.671806, seen=480, correct=278, accuracy=0.579167
2025-10-09 14:09:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:09:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:09:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:09:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2124MB allocated=1972MB
2025-10-09 14:09:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.32454240322113, 'train_avg_loss': 0.7193711866935094, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 14:09:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.4669189453125, 'train_avg_loss': 0.6718060811360677, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 14:09:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 322.4669189453125, 'train_avg_loss': 0.6718060811360677, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 14:09:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 14:10:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:10:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:10:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:10:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.783844, avg_loss=0.674550, seen=480, correct=291, accuracy=0.606250
2025-10-09 14:10:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:10:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:10:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:10:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2116MB allocated=1972MB
2025-10-09 14:10:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.01543843746185, 'train_avg_loss': 0.6584619869788487, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 14:10:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.7838439941406, 'train_avg_loss': 0.674549674987793, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 14:10:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 323.7838439941406, 'train_avg_loss': 0.674549674987793, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 14:10:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:10:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:10:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-09 14:10:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:10:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:10:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:10:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:10:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:10:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:11:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:11:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.558899, avg_loss=0.661581, seen=480, correct=299, accuracy=0.622917
2025-10-09 14:11:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:11:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:11:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:11:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2134MB allocated=1972MB
2025-10-09 14:11:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.41353794932365, 'train_avg_loss': 0.6451128162443638, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 14:11:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.55889892578125, 'train_avg_loss': 0.6615810394287109, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 14:11:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 317.55889892578125, 'train_avg_loss': 0.6615810394287109, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 14:11:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 14:11:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:11:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:12:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:12:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.022186, avg_loss=0.695880, seen=480, correct=268, accuracy=0.558333
2025-10-09 14:12:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:12:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:12:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:12:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2118MB allocated=1972MB
2025-10-09 14:12:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.33590567111969, 'train_avg_loss': 0.7111325472593307, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 14:12:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0221862792969, 'train_avg_loss': 0.6958795547485351, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 14:12:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 334.0221862792969, 'train_avg_loss': 0.6958795547485351, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 14:12:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:12:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:12:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:12:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:12:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.525146, avg_loss=0.649011, seen=480, correct=297, accuracy=0.618750
2025-10-09 14:12:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:12:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:12:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:12:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2116MB allocated=1972MB
2025-10-09 14:12:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.23493883013725, 'train_avg_loss': 0.6269578235844772, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 14:12:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.525146484375, 'train_avg_loss': 0.6490107218424479, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:12:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 311.525146484375, 'train_avg_loss': 0.6490107218424479, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:12:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #124) -------------
2025-10-09 14:12:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=124 aidx=4 | s=5 (candidates=7)
2025-10-09 14:12:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 35, 33, 12, 17] (from 7)
2025-10-09 14:12:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 14:12:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:12:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:13:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:13:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.772125, avg_loss=0.616192, seen=480, correct=314, accuracy=0.654167
2025-10-09 14:13:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:13:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:13:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:13:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2130MB allocated=1972MB
2025-10-09 14:13:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.08348765969276, 'train_avg_loss': 0.609029063830773, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 14:13:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.7721252441406, 'train_avg_loss': 0.6161919275919596, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 14:13:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 295.7721252441406, 'train_avg_loss': 0.6161919275919596, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 14:13:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:13:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:13:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:14:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:14:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.488495, avg_loss=0.711434, seen=480, correct=268, accuracy=0.558333
2025-10-09 14:14:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:14:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:14:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:14:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2168MB allocated=1972MB
2025-10-09 14:14:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.74988353252411, 'train_avg_loss': 0.7229156961043676, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 14:14:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.4884948730469, 'train_avg_loss': 0.7114343643188477, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 14:14:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 341.4884948730469, 'train_avg_loss': 0.7114343643188477, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 14:14:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:14:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:14:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-09 14:14:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:14:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:14:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:14:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:14:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:14:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:15:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:15:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.522766, avg_loss=0.630256, seen=480, correct=314, accuracy=0.654167
2025-10-09 14:15:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:15:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:15:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:15:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2116MB allocated=1972MB
2025-10-09 14:15:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.49646338820457, 'train_avg_loss': 0.6208038615683714, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 14:15:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.52276611328125, 'train_avg_loss': 0.6302557627360026, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 14:15:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 302.52276611328125, 'train_avg_loss': 0.6302557627360026, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 14:15:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:15:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:15:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-09 14:15:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 14:15:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:15:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:15:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:15:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:15:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:15:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:15:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.496460, avg_loss=0.688534, seen=480, correct=273, accuracy=0.568750
2025-10-09 14:15:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:15:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:15:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:15:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2118MB allocated=1972MB
2025-10-09 14:15:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.3121630847454, 'train_avg_loss': 0.7192680257062117, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 14:15:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4964599609375, 'train_avg_loss': 0.6885342915852865, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 14:15:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 330.4964599609375, 'train_avg_loss': 0.6885342915852865, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 14:15:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:15:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:15:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-09 14:15:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:15:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:15:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:15:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:15:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:15:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:16:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:16:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.991821, avg_loss=0.656233, seen=480, correct=301, accuracy=0.627083
2025-10-09 14:16:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:16:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:16:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:16:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2134MB allocated=1972MB
2025-10-09 14:16:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.72822564840317, 'train_avg_loss': 0.6560685470700264, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 14:16:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.9918212890625, 'train_avg_loss': 0.6562329610188802, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 14:16:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 314.9918212890625, 'train_avg_loss': 0.6562329610188802, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 14:16:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #125) -------------
2025-10-09 14:16:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=125 aidx=4 | s=5 (candidates=7)
2025-10-09 14:16:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 7, 33, 35, 42] (from 7)
2025-10-09 14:16:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 14:16:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:16:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:17:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:17:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.593109, avg_loss=0.692902, seen=480, correct=273, accuracy=0.568750
2025-10-09 14:17:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:17:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:17:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:17:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2118MB allocated=1972MB
2025-10-09 14:17:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.0846216082573, 'train_avg_loss': 0.7173718467354775, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 14:17:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5931091308594, 'train_avg_loss': 0.6929023106892903, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 14:17:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 332.5931091308594, 'train_avg_loss': 0.6929023106892903, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 14:17:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 14:17:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:17:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:18:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:18:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.406708, avg_loss=0.669597, seen=480, correct=283, accuracy=0.589583
2025-10-09 14:18:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:18:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:18:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:18:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2124MB allocated=1972MB
2025-10-09 14:18:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.103750705719, 'train_avg_loss': 0.7175312558809916, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 14:18:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.4067077636719, 'train_avg_loss': 0.669597307840983, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 14:18:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 321.4067077636719, 'train_avg_loss': 0.669597307840983, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 14:18:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:18:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:18:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:18:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:18:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.077881, avg_loss=0.633496, seen=480, correct=307, accuracy=0.639583
2025-10-09 14:18:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:18:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:18:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:18:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2116MB allocated=1972MB
2025-10-09 14:18:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.5443606376648, 'train_avg_loss': 0.61286967198054, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 14:18:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.077880859375, 'train_avg_loss': 0.633495585123698, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 14:18:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 304.077880859375, 'train_avg_loss': 0.633495585123698, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 14:18:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:18:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:18:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:19:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:19:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.833649, avg_loss=0.707987, seen=480, correct=264, accuracy=0.550000
2025-10-09 14:19:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:19:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:19:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:19:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2168MB allocated=1972MB
2025-10-09 14:19:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.20309329032898, 'train_avg_loss': 0.7266924440860748, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 14:19:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.8336486816406, 'train_avg_loss': 0.7079867680867513, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 14:19:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 339.8336486816406, 'train_avg_loss': 0.7079867680867513, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 14:19:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:19:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:19:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-09 14:19:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 14:19:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:19:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:19:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:19:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:19:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:20:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:20:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.701660, avg_loss=0.668128, seen=480, correct=292, accuracy=0.608333
2025-10-09 14:20:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:20:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:20:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:20:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2116MB allocated=1972MB
2025-10-09 14:20:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.90269404649734, 'train_avg_loss': 0.6491891170541445, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 14:20:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.70166015625, 'train_avg_loss': 0.6681284586588542, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 14:20:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 320.70166015625, 'train_avg_loss': 0.6681284586588542, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 14:20:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #126) -------------
2025-10-09 14:20:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=126 aidx=4 | s=5 (candidates=7)
2025-10-09 14:20:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 33, 9, 7, 42] (from 7)
2025-10-09 14:20:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:20:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:20:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:21:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:21:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.644012, avg_loss=0.638842, seen=480, correct=297, accuracy=0.618750
2025-10-09 14:21:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:21:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:21:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:21:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2134MB allocated=1972MB
2025-10-09 14:21:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.74618542194366, 'train_avg_loss': 0.6312182118495305, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 14:21:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.6440124511719, 'train_avg_loss': 0.6388416926066081, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:21:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 306.6440124511719, 'train_avg_loss': 0.6388416926066081, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:21:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:21:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:21:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:21:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:21:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.078461, avg_loss=0.635580, seen=480, correct=313, accuracy=0.652083
2025-10-09 14:21:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:21:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:21:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:21:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2116MB allocated=1972MB
2025-10-09 14:21:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.51205253601074, 'train_avg_loss': 0.6209337711334229, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-09 14:21:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.0784606933594, 'train_avg_loss': 0.6355801264444987, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-09 14:21:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 305.0784606933594, 'train_avg_loss': 0.6355801264444987, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-09 14:21:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 14:21:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:21:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:22:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:22:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.782288, avg_loss=0.622463, seen=480, correct=316, accuracy=0.658333
2025-10-09 14:22:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:22:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:22:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:22:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2130MB allocated=1972MB
2025-10-09 14:22:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.58579611778259, 'train_avg_loss': 0.6298816343148549, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 14:22:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.78228759765625, 'train_avg_loss': 0.6224630991617839, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 14:22:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 298.78228759765625, 'train_avg_loss': 0.6224630991617839, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 14:22:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:22:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:22:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-09 14:22:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 14:22:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:22:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:22:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:22:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:22:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:23:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:23:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.471436, avg_loss=0.665565, seen=480, correct=283, accuracy=0.589583
2025-10-09 14:23:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:23:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:23:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:23:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2124MB allocated=1972MB
2025-10-09 14:23:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2526428103447, 'train_avg_loss': 0.7104386900862057, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 14:23:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.471435546875, 'train_avg_loss': 0.6655654907226562, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 14:23:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 319.471435546875, 'train_avg_loss': 0.6655654907226562, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 14:23:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 14:23:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:23:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:24:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:24:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.484741, avg_loss=0.653093, seen=480, correct=299, accuracy=0.622917
2025-10-09 14:24:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:24:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:24:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:24:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2116MB allocated=1972MB
2025-10-09 14:24:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.33658450841904, 'train_avg_loss': 0.6361382042368253, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 14:24:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4847412109375, 'train_avg_loss': 0.6530932108561198, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 14:24:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 313.4847412109375, 'train_avg_loss': 0.6530932108561198, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 14:24:09 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #127) -------------
2025-10-09 14:24:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=127 aidx=4 | s=5 (candidates=7)
2025-10-09 14:24:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 12, 35, 9, 17] (from 7)
2025-10-09 14:24:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:24:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:24:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:24:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:24:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.878510, avg_loss=0.635164, seen=480, correct=309, accuracy=0.643750
2025-10-09 14:24:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:24:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:24:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:24:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2116MB allocated=1972MB
2025-10-09 14:24:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.7986011505127, 'train_avg_loss': 0.6233216762542725, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 14:24:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.8785095214844, 'train_avg_loss': 0.6351635615030925, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 14:24:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 304.8785095214844, 'train_avg_loss': 0.6351635615030925, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 14:24:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 14:24:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:24:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:25:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:25:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.336761, avg_loss=0.690285, seen=480, correct=271, accuracy=0.564583
2025-10-09 14:25:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:25:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:25:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:25:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2118MB allocated=1972MB
2025-10-09 14:25:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.56225633621216, 'train_avg_loss': 0.7046854694684347, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 14:25:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3367614746094, 'train_avg_loss': 0.6902849197387695, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 14:25:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 331.3367614746094, 'train_avg_loss': 0.6902849197387695, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 14:25:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:25:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:25:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:26:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:26:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.204224, avg_loss=0.698342, seen=480, correct=263, accuracy=0.547917
2025-10-09 14:26:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:26:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:26:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:26:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2168MB allocated=1972MB
2025-10-09 14:26:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.34298932552338, 'train_avg_loss': 0.7111915777126948, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 14:26:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.2042236328125, 'train_avg_loss': 0.6983421325683594, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 14:26:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 335.2042236328125, 'train_avg_loss': 0.6983421325683594, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 14:26:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-09 14:26:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:26:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:27:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:27:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.834900, avg_loss=0.624656, seen=480, correct=317, accuracy=0.660417
2025-10-09 14:27:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:27:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:27:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:27:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2130MB allocated=1972MB
2025-10-09 14:27:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.11861515045166, 'train_avg_loss': 0.6426551262537639, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 14:27:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.83489990234375, 'train_avg_loss': 0.6246560414632162, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-09 14:27:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 299.83489990234375, 'train_avg_loss': 0.6246560414632162, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-09 14:27:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:27:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:27:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:27:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:27:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.992737, avg_loss=0.641652, seen=480, correct=297, accuracy=0.618750
2025-10-09 14:27:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:27:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:27:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:27:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2132MB allocated=1972MB
2025-10-09 14:27:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.98805177211761, 'train_avg_loss': 0.6415670981009801, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 14:27:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.99273681640625, 'train_avg_loss': 0.6416515350341797, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:27:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 307.99273681640625, 'train_avg_loss': 0.6416515350341797, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 14:27:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #128) -------------
2025-10-09 14:27:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=128 aidx=4 | s=5 (candidates=7)
2025-10-09 14:27:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 17, 42, 35, 7] (from 7)
2025-10-09 14:27:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:27:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:27:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-09 14:27:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:27:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:27:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:27:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:27:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:27:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:28:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:28:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.196777, avg_loss=0.635827, seen=480, correct=308, accuracy=0.641667
2025-10-09 14:28:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:28:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:28:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:28:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2116MB allocated=1972MB
2025-10-09 14:28:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.21220716834068, 'train_avg_loss': 0.610101726402839, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-09 14:28:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.19677734375, 'train_avg_loss': 0.6358266194661458, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 14:28:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 305.19677734375, 'train_avg_loss': 0.6358266194661458, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 14:28:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:28:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:28:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:29:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:29:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.278320, avg_loss=0.625580, seen=480, correct=306, accuracy=0.637500
2025-10-09 14:29:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:29:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:29:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:29:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2134MB allocated=1972MB
2025-10-09 14:29:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.76457357406616, 'train_avg_loss': 0.623038113117218, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 14:29:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.2783203125, 'train_avg_loss': 0.625579833984375, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 14:29:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 300.2783203125, 'train_avg_loss': 0.625579833984375, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 14:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-09 14:29:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:29:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:30:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:30:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.248138, avg_loss=0.642184, seen=480, correct=301, accuracy=0.627083
2025-10-09 14:30:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:30:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:30:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:30:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2116MB allocated=1972MB
2025-10-09 14:30:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.27519649267197, 'train_avg_loss': 0.6189599707722664, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 14:30:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.2481384277344, 'train_avg_loss': 0.6421836217244467, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 14:30:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 308.2481384277344, 'train_avg_loss': 0.6421836217244467, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 14:30:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:30:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:30:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:30:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:30:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.774567, avg_loss=0.701614, seen=480, correct=264, accuracy=0.550000
2025-10-09 14:30:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:30:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:30:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:30:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2170MB allocated=1972MB
2025-10-09 14:30:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.50593519210815, 'train_avg_loss': 0.720882793267568, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 14:30:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.7745666503906, 'train_avg_loss': 0.7016136805216472, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 14:30:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 336.7745666503906, 'train_avg_loss': 0.7016136805216472, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 14:31:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:31:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:31:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-09 14:31:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 14:31:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:31:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:31:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:31:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:31:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:31:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:31:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.909546, avg_loss=0.668562, seen=480, correct=286, accuracy=0.595833
2025-10-09 14:31:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:31:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:31:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:31:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2124MB allocated=1972MB
2025-10-09 14:31:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.0360295176506, 'train_avg_loss': 0.708633579313755, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 14:31:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.9095458984375, 'train_avg_loss': 0.6685615539550781, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 14:31:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 320.9095458984375, 'train_avg_loss': 0.6685615539550781, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 14:31:46 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #129) -------------
2025-10-09 14:31:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=129 aidx=4 | s=5 (candidates=7)
2025-10-09 14:31:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 33, 7, 12, 17] (from 7)
2025-10-09 14:31:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:31:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:31:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-09 14:31:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-09 14:31:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:31:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:31:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:31:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:31:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:32:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:32:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.054169, avg_loss=0.698030, seen=480, correct=266, accuracy=0.554167
2025-10-09 14:32:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:32:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:32:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:32:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2168MB allocated=1972MB
2025-10-09 14:32:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.73342895507812, 'train_avg_loss': 0.7144452412923177, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 14:32:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.0541687011719, 'train_avg_loss': 0.6980295181274414, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 14:32:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 335.0541687011719, 'train_avg_loss': 0.6980295181274414, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 14:32:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-09 14:32:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:32:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:33:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:33:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.103058, avg_loss=0.633548, seen=480, correct=307, accuracy=0.639583
2025-10-09 14:33:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:33:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:33:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:33:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2116MB allocated=1972MB
2025-10-09 14:33:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.58009946346283, 'train_avg_loss': 0.6215008288621903, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-09 14:33:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.1030578613281, 'train_avg_loss': 0.6335480372111003, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 14:33:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 304.1030578613281, 'train_avg_loss': 0.6335480372111003, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 14:33:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:33:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:33:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-09 14:33:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-09 14:33:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:33:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:33:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:33:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:33:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:33:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:33:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.790802, avg_loss=0.651648, seen=480, correct=292, accuracy=0.608333
2025-10-09 14:33:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:33:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:34:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:34:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2124MB allocated=1972MB
2025-10-09 14:34:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.9704619050026, 'train_avg_loss': 0.6914205158750216, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 14:34:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.7908020019531, 'train_avg_loss': 0.6516475041707357, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 14:34:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 312.7908020019531, 'train_avg_loss': 0.6516475041707357, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 14:34:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-09 14:34:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:34:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:34:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:34:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.472168, avg_loss=0.686400, seen=480, correct=272, accuracy=0.566667
2025-10-09 14:34:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:34:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:34:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:34:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2118MB allocated=1972MB
2025-10-09 14:34:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.9039198756218, 'train_avg_loss': 0.715865998963515, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 14:34:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.47216796875, 'train_avg_loss': 0.6864003499348958, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 14:34:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 329.47216796875, 'train_avg_loss': 0.6864003499348958, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 14:34:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:34:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:34:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-09 14:34:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-09 14:34:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:34:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:34:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:34:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:34:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:35:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:35:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.249847, avg_loss=0.627604, seen=480, correct=309, accuracy=0.643750
2025-10-09 14:35:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:35:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:35:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:35:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2134MB allocated=1972MB
2025-10-09 14:35:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.37291663885117, 'train_avg_loss': 0.6364409719904264, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 14:35:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.2498474121094, 'train_avg_loss': 0.6276038487752279, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 14:35:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 301.2498474121094, 'train_avg_loss': 0.6276038487752279, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 14:35:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #130) -------------
2025-10-09 14:35:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=130 aidx=5 | s=5 (candidates=6)
2025-10-09 14:35:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 31, 3, 37, 41] (from 6)
2025-10-09 14:35:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:35:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:35:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-09 14:35:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:35:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:35:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:35:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:35:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:35:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:36:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:36:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.504028, avg_loss=0.709383, seen=480, correct=259, accuracy=0.539583
2025-10-09 14:36:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:36:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:36:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:36:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2162MB allocated=2056MB
2025-10-09 14:36:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.32327455282211, 'train_avg_loss': 0.7110272879401843, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 14:36:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.5040283203125, 'train_avg_loss': 0.7093833923339844, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 14:36:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 340.5040283203125, 'train_avg_loss': 0.7093833923339844, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 14:36:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:36:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:36:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-09 14:36:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 14:36:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:36:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:36:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:36:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:36:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:36:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:36:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.420166, avg_loss=0.713375, seen=480, correct=236, accuracy=0.491667
2025-10-09 14:36:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:36:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:36:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2188MB allocated=2064MB
2025-10-09 14:36:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9665407538414, 'train_avg_loss': 0.6997211729486783, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 14:36:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.420166015625, 'train_avg_loss': 0.7133753458658855, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 14:36:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 342.420166015625, 'train_avg_loss': 0.7133753458658855, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 14:36:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:36:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:36:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-09 14:36:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 14:36:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:36:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:36:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:36:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:36:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:37:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:37:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.148773, avg_loss=0.714893, seen=480, correct=236, accuracy=0.491667
2025-10-09 14:37:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:37:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:37:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:37:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2228MB allocated=2073MB
2025-10-09 14:37:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.91421335935593, 'train_avg_loss': 0.7076184446612994, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 14:37:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.1487731933594, 'train_avg_loss': 0.7148932774861654, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 14:37:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 343.1487731933594, 'train_avg_loss': 0.7148932774861654, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 14:37:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:37:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:37:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-09 14:37:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 14:37:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:37:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:37:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:37:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:37:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:38:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:38:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.286133, avg_loss=0.719346, seen=480, correct=258, accuracy=0.537500
2025-10-09 14:38:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:38:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:38:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:38:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2180MB allocated=2081MB
2025-10-09 14:38:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 93.68363976478577, 'train_avg_loss': 0.7806969980398814, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 14:38:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.2861328125, 'train_avg_loss': 0.7193461100260417, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 14:38:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 345.2861328125, 'train_avg_loss': 0.7193461100260417, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 14:38:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:38:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:38:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-09 14:38:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 14:38:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:38:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:38:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:38:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:38:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:39:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:39:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.636749, avg_loss=0.728410, seen=480, correct=231, accuracy=0.481250
2025-10-09 14:39:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:39:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:39:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:39:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2200MB allocated=2089MB
2025-10-09 14:39:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.95290368795395, 'train_avg_loss': 0.7162741973996163, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 14:39:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.6367492675781, 'train_avg_loss': 0.7284098943074544, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-09 14:39:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 349.6367492675781, 'train_avg_loss': 0.7284098943074544, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-09 14:39:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #131) -------------
2025-10-09 14:39:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=131 aidx=5 | s=5 (candidates=6)
2025-10-09 14:39:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 21, 41, 32, 31] (from 6)
2025-10-09 14:39:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 14:39:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:39:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:39:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:39:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.900574, avg_loss=0.701876, seen=480, correct=255, accuracy=0.531250
2025-10-09 14:39:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:39:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:39:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:39:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2252MB allocated=2089MB
2025-10-09 14:39:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.4731610417366, 'train_avg_loss': 0.7539430086811384, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 14:39:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.90057373046875, 'train_avg_loss': 0.7018761952718099, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 14:39:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 336.90057373046875, 'train_avg_loss': 0.7018761952718099, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 14:39:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:39:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:39:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-09 14:39:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 14:39:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:39:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:39:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:39:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:39:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:40:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:40:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.640839, avg_loss=0.695085, seen=480, correct=261, accuracy=0.543750
2025-10-09 14:40:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:40:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:40:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:40:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2316MB allocated=2174MB
2025-10-09 14:40:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.97530633211136, 'train_avg_loss': 0.7081275527675946, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 14:40:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.6408386230469, 'train_avg_loss': 0.695085080464681, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 14:40:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 333.6408386230469, 'train_avg_loss': 0.695085080464681, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 14:40:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:40:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:40:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-09 14:40:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 14:40:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:40:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:40:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:40:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:40:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:41:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:41:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.645294, avg_loss=0.709678, seen=480, correct=237, accuracy=0.493750
2025-10-09 14:41:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:41:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:41:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:41:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2252MB allocated=2098MB
2025-10-09 14:41:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.99694210290909, 'train_avg_loss': 0.691641184190909, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 14:41:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.6452941894531, 'train_avg_loss': 0.7096776962280273, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 14:41:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 340.6452941894531, 'train_avg_loss': 0.7096776962280273, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 14:41:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:41:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:41:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:42:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:42:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.480316, avg_loss=0.705167, seen=480, correct=243, accuracy=0.506250
2025-10-09 14:42:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:42:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:42:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:42:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2252MB allocated=2098MB
2025-10-09 14:42:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.8597981929779, 'train_avg_loss': 0.6988316516081492, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 14:42:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.4803161621094, 'train_avg_loss': 0.7051673253377279, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 14:42:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 338.4803161621094, 'train_avg_loss': 0.7051673253377279, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 14:42:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 14:42:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:42:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:42:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:42:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.669434, avg_loss=0.709728, seen=480, correct=237, accuracy=0.493750
2025-10-09 14:42:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:42:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:42:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:42:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2254MB allocated=2098MB
2025-10-09 14:42:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47803491353989, 'train_avg_loss': 0.703983624279499, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 14:42:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.66943359375, 'train_avg_loss': 0.7097279866536458, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 14:42:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 340.66943359375, 'train_avg_loss': 0.7097279866536458, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 14:42:54 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #132) -------------
2025-10-09 14:42:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=132 aidx=5 | s=5 (candidates=6)
2025-10-09 14:42:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 37, 21, 3, 32] (from 6)
2025-10-09 14:42:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:42:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:42:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-09 14:42:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 14:42:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:42:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:42:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:42:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:42:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:43:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:43:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.243774, avg_loss=0.702591, seen=480, correct=247, accuracy=0.514583
2025-10-09 14:43:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:43:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:43:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:43:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2178MB allocated=2023MB
2025-10-09 14:43:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.47906565666199, 'train_avg_loss': 0.6873255471388499, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 14:43:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.2437744140625, 'train_avg_loss': 0.7025911966959636, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 14:43:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 337.2437744140625, 'train_avg_loss': 0.7025911966959636, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 14:43:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:43:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:43:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-09 14:43:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 14:43:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:43:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:43:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:43:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:43:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:44:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:44:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.648926, avg_loss=0.701352, seen=480, correct=257, accuracy=0.535417
2025-10-09 14:44:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:44:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:44:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:44:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2178MB allocated=2023MB
2025-10-09 14:44:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.13330841064453, 'train_avg_loss': 0.7511109034220378, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 14:44:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.64892578125, 'train_avg_loss': 0.7013519287109375, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 14:44:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 336.64892578125, 'train_avg_loss': 0.7013519287109375, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 14:44:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 14:44:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:44:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:45:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:45:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.738403, avg_loss=0.693205, seen=480, correct=260, accuracy=0.541667
2025-10-09 14:45:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:45:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:45:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:45:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2208MB allocated=2023MB
2025-10-09 14:45:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43895030021667, 'train_avg_loss': 0.7036579191684723, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 14:45:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.7384033203125, 'train_avg_loss': 0.6932050069173177, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 14:45:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 332.7384033203125, 'train_avg_loss': 0.6932050069173177, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 14:45:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 14:45:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:45:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:45:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:45:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.604156, avg_loss=0.703342, seen=480, correct=251, accuracy=0.522917
2025-10-09 14:45:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:45:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:45:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:45:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2200MB allocated=2023MB
2025-10-09 14:45:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.31236958503723, 'train_avg_loss': 0.6942697465419769, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 14:45:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.6041564941406, 'train_avg_loss': 0.7033419926961263, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 14:45:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 337.6041564941406, 'train_avg_loss': 0.7033419926961263, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 14:45:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:45:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:45:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-09 14:45:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:45:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:45:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:45:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:45:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:45:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:46:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:46:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.716248, avg_loss=0.701492, seen=480, correct=254, accuracy=0.529167
2025-10-09 14:46:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:46:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:46:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:46:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2178MB allocated=2023MB
2025-10-09 14:46:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.56727302074432, 'train_avg_loss': 0.6880606085062027, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 14:46:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.71624755859375, 'train_avg_loss': 0.701492182413737, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 14:46:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 336.71624755859375, 'train_avg_loss': 0.701492182413737, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 14:46:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #133) -------------
2025-10-09 14:46:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=133 aidx=5 | s=5 (candidates=6)
2025-10-09 14:46:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 41, 21, 31, 37] (from 6)
2025-10-09 14:46:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:46:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:46:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-09 14:46:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:46:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:46:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:46:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:46:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:46:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:47:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:47:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.578522, avg_loss=0.692872, seen=480, correct=257, accuracy=0.535417
2025-10-09 14:47:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:47:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:47:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:47:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2178MB allocated=2023MB
2025-10-09 14:47:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.697310090065, 'train_avg_loss': 0.6808109174172083, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 14:47:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5785217285156, 'train_avg_loss': 0.6928719202677409, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 14:47:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 332.5785217285156, 'train_avg_loss': 0.6928719202677409, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 14:47:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 14:47:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:47:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:48:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:48:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.059998, avg_loss=0.698042, seen=480, correct=248, accuracy=0.516667
2025-10-09 14:48:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:48:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:48:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:48:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2178MB allocated=2023MB
2025-10-09 14:48:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.69362193346024, 'train_avg_loss': 0.6807801827788353, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 14:48:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.05999755859375, 'train_avg_loss': 0.6980416615804036, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 14:48:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 335.05999755859375, 'train_avg_loss': 0.6980416615804036, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 14:48:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 14:48:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:48:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:48:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:48:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.493774, avg_loss=0.692695, seen=480, correct=260, accuracy=0.541667
2025-10-09 14:48:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:48:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:48:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:48:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2208MB allocated=2023MB
2025-10-09 14:48:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.23585653305054, 'train_avg_loss': 0.7019654711087545, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 14:48:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.4937744140625, 'train_avg_loss': 0.6926953633626302, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 14:48:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 332.4937744140625, 'train_avg_loss': 0.6926953633626302, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 14:48:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:48:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:48:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-09 14:48:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 14:48:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:48:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:48:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:48:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:48:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:49:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:49:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.232208, avg_loss=0.702567, seen=480, correct=237, accuracy=0.493750
2025-10-09 14:49:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:49:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:49:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:49:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2180MB allocated=2023MB
2025-10-09 14:49:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.35019993782043, 'train_avg_loss': 0.7029183328151702, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 14:49:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.2322082519531, 'train_avg_loss': 0.7025671005249023, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 14:49:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 337.2322082519531, 'train_avg_loss': 0.7025671005249023, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 14:49:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 14:49:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:49:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:50:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:50:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.338959, avg_loss=0.694456, seen=480, correct=254, accuracy=0.529167
2025-10-09 14:50:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:50:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:50:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:50:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2176MB allocated=2023MB
2025-10-09 14:50:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.2753916978836, 'train_avg_loss': 0.73562826414903, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 14:50:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.3389587402344, 'train_avg_loss': 0.6944561640421549, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 14:50:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 333.3389587402344, 'train_avg_loss': 0.6944561640421549, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 14:50:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #134) -------------
2025-10-09 14:50:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=134 aidx=5 | s=5 (candidates=6)
2025-10-09 14:50:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[31, 21, 41, 3, 32] (from 6)
2025-10-09 14:50:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 14:50:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:50:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:51:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:51:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.743591, avg_loss=0.707799, seen=480, correct=233, accuracy=0.485417
2025-10-09 14:51:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:51:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:51:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:51:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2180MB allocated=2023MB
2025-10-09 14:51:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.74856156110764, 'train_avg_loss': 0.7062380130092303, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 14:51:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.74359130859375, 'train_avg_loss': 0.7077991485595703, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 14:51:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 339.74359130859375, 'train_avg_loss': 0.7077991485595703, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 14:51:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 14:51:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:51:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:51:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:51:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.350525, avg_loss=0.692397, seen=480, correct=257, accuracy=0.535417
2025-10-09 14:51:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:51:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:51:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:51:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2208MB allocated=2023MB
2025-10-09 14:51:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.69102811813354, 'train_avg_loss': 0.7057585676511129, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 14:51:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.35052490234375, 'train_avg_loss': 0.6923969268798829, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 14:51:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 332.35052490234375, 'train_avg_loss': 0.6923969268798829, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 14:51:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 14:51:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:51:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:52:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:52:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.534760, avg_loss=0.696947, seen=480, correct=254, accuracy=0.529167
2025-10-09 14:52:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:52:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:52:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:52:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2176MB allocated=2023MB
2025-10-09 14:52:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.31792467832565, 'train_avg_loss': 0.6859827056527138, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 14:52:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.5347595214844, 'train_avg_loss': 0.6969474156697592, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 14:52:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 334.5347595214844, 'train_avg_loss': 0.6969474156697592, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 14:52:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 14:52:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:52:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:53:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:53:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.546021, avg_loss=0.701138, seen=480, correct=247, accuracy=0.514583
2025-10-09 14:53:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:53:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:53:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:53:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2198MB allocated=2023MB
2025-10-09 14:53:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.2893351316452, 'train_avg_loss': 0.6940777927637101, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 14:53:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.5460205078125, 'train_avg_loss': 0.7011375427246094, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 14:53:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 336.5460205078125, 'train_avg_loss': 0.7011375427246094, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 14:53:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:53:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:53:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:54:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:54:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.905457, avg_loss=0.695636, seen=480, correct=253, accuracy=0.527083
2025-10-09 14:54:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:54:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:54:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:54:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2176MB allocated=2023MB
2025-10-09 14:54:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.98750531673431, 'train_avg_loss': 0.683229210972786, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 14:54:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.90545654296875, 'train_avg_loss': 0.6956363677978515, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 14:54:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 333.90545654296875, 'train_avg_loss': 0.6956363677978515, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 14:54:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #135) -------------
2025-10-09 14:54:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=135 aidx=5 | s=5 (candidates=6)
2025-10-09 14:54:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 32, 31, 21, 3] (from 6)
2025-10-09 14:54:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 14:54:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:54:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:54:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:54:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.470276, avg_loss=0.696813, seen=480, correct=251, accuracy=0.522917
2025-10-09 14:54:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:54:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:54:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:54:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2176MB allocated=2023MB
2025-10-09 14:54:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.89553511142731, 'train_avg_loss': 0.6824627925952276, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 14:54:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.47027587890625, 'train_avg_loss': 0.6968130747477214, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 14:54:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 334.47027587890625, 'train_avg_loss': 0.6968130747477214, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 14:54:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:54:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:54:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:55:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:55:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.313049, avg_loss=0.688152, seen=480, correct=264, accuracy=0.550000
2025-10-09 14:55:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:55:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:55:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:55:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2176MB allocated=2023MB
2025-10-09 14:55:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.87527978420258, 'train_avg_loss': 0.6822939982016881, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 14:55:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.31304931640625, 'train_avg_loss': 0.6881521860758464, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 14:55:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 330.31304931640625, 'train_avg_loss': 0.6881521860758464, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 14:55:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 14:55:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:55:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:56:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:56:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.716248, avg_loss=0.699409, seen=480, correct=241, accuracy=0.502083
2025-10-09 14:56:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:56:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:56:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:56:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2180MB allocated=2023MB
2025-10-09 14:56:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.90367269515991, 'train_avg_loss': 0.6991972724596659, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 14:56:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.71624755859375, 'train_avg_loss': 0.6994088490804037, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 14:56:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 335.71624755859375, 'train_avg_loss': 0.6994088490804037, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 14:56:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:56:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:56:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-09 14:56:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 14:56:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:56:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:56:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:56:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:56:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:57:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:57:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.679810, avg_loss=0.691000, seen=480, correct=255, accuracy=0.531250
2025-10-09 14:57:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:57:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:57:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:57:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2208MB allocated=2023MB
2025-10-09 14:57:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91453242301941, 'train_avg_loss': 0.6992877701918284, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-09 14:57:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6798095703125, 'train_avg_loss': 0.6909996032714844, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 14:57:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 331.6798095703125, 'train_avg_loss': 0.6909996032714844, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 14:57:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 14:57:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:57:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:57:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:57:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.797974, avg_loss=0.699579, seen=480, correct=247, accuracy=0.514583
2025-10-09 14:57:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:57:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:57:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:57:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2198MB allocated=2023MB
2025-10-09 14:57:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37668132781982, 'train_avg_loss': 0.6948056777318319, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 14:57:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.7979736328125, 'train_avg_loss': 0.6995791117350261, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 14:57:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 335.7979736328125, 'train_avg_loss': 0.6995791117350261, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 14:57:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #136) -------------
2025-10-09 14:57:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=136 aidx=5 | s=5 (candidates=6)
2025-10-09 14:57:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 32, 37, 41, 31] (from 6)
2025-10-09 14:57:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:57:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:57:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-09 14:57:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 14:57:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:57:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:57:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:57:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:57:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:58:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:58:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.544312, avg_loss=0.692801, seen=480, correct=253, accuracy=0.527083
2025-10-09 14:58:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:58:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:58:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:58:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2198MB allocated=2023MB
2025-10-09 14:58:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.71145248413086, 'train_avg_loss': 0.6892621040344238, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 14:58:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5443115234375, 'train_avg_loss': 0.6928006490071614, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 14:58:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 332.5443115234375, 'train_avg_loss': 0.6928006490071614, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 14:58:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 14:58:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:58:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 14:59:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 14:59:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.406952, avg_loss=0.686264, seen=480, correct=265, accuracy=0.552083
2025-10-09 14:59:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 14:59:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:59:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 14:59:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2176MB allocated=2023MB
2025-10-09 14:59:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.25094509124756, 'train_avg_loss': 0.685424542427063, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 14:59:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4069519042969, 'train_avg_loss': 0.6862644831339518, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 14:59:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 329.4069519042969, 'train_avg_loss': 0.6862644831339518, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 14:59:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 14:59:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 14:59:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:00:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:00:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.060974, avg_loss=0.689710, seen=480, correct=270, accuracy=0.562500
2025-10-09 15:00:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:00:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:00:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:00:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2176MB allocated=2023MB
2025-10-09 15:00:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.7539871931076, 'train_avg_loss': 0.7229498932758968, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 15:00:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.06097412109375, 'train_avg_loss': 0.6897103627522786, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:00:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 331.06097412109375, 'train_avg_loss': 0.6897103627522786, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:00:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:00:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:00:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-09 15:00:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:00:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:00:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:00:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:00:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:00:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:00:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:00:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.683563, avg_loss=0.697257, seen=480, correct=250, accuracy=0.520833
2025-10-09 15:00:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:00:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:00:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:00:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2176MB allocated=2023MB
2025-10-09 15:00:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.53783702850342, 'train_avg_loss': 0.6878153085708618, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 15:00:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.6835632324219, 'train_avg_loss': 0.6972574234008789, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 15:00:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 334.6835632324219, 'train_avg_loss': 0.6972574234008789, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 15:00:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:00:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:00:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:01:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:01:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.971375, avg_loss=0.697857, seen=480, correct=237, accuracy=0.493750
2025-10-09 15:01:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:01:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:01:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:01:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2180MB allocated=2023MB
2025-10-09 15:01:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.78379905223846, 'train_avg_loss': 0.6981983254353206, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 15:01:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.97137451171875, 'train_avg_loss': 0.6978570302327474, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 15:01:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 334.97137451171875, 'train_avg_loss': 0.6978570302327474, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 15:01:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #137) -------------
2025-10-09 15:01:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=137 aidx=5 | s=5 (candidates=6)
2025-10-09 15:01:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 21, 37, 3, 31] (from 6)
2025-10-09 15:01:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:01:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:02:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:02:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.191254, avg_loss=0.696232, seen=480, correct=253, accuracy=0.527083
2025-10-09 15:02:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:02:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:02:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:02:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2176MB allocated=2023MB
2025-10-09 15:02:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91337156295776, 'train_avg_loss': 0.6826114296913147, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:02:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1912536621094, 'train_avg_loss': 0.6962317784627279, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 15:02:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 334.1912536621094, 'train_avg_loss': 0.6962317784627279, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 15:02:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:02:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:02:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:03:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:03:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.876282, avg_loss=0.689326, seen=480, correct=263, accuracy=0.547917
2025-10-09 15:03:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:03:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:03:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:03:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2208MB allocated=2023MB
2025-10-09 15:03:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.4992835521698, 'train_avg_loss': 0.6958273629347483, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 15:03:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.87628173828125, 'train_avg_loss': 0.6893255869547527, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 15:03:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 330.87628173828125, 'train_avg_loss': 0.6893255869547527, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 15:03:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:03:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:03:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:03:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:03:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.803741, avg_loss=0.689174, seen=480, correct=268, accuracy=0.558333
2025-10-09 15:03:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:03:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:03:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:03:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2176MB allocated=2023MB
2025-10-09 15:03:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.07012093067169, 'train_avg_loss': 0.7255843410889308, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 15:03:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8037414550781, 'train_avg_loss': 0.6891744613647461, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:03:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 330.8037414550781, 'train_avg_loss': 0.6891744613647461, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:03:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:03:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:03:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:04:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:04:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.421478, avg_loss=0.692545, seen=480, correct=256, accuracy=0.533333
2025-10-09 15:04:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:04:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:04:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:04:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2198MB allocated=2023MB
2025-10-09 15:04:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.77157664299011, 'train_avg_loss': 0.6897631386915842, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 15:04:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.4214782714844, 'train_avg_loss': 0.6925447463989258, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 15:04:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 332.4214782714844, 'train_avg_loss': 0.6925447463989258, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 15:04:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:04:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:04:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-09 15:04:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:04:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:04:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:04:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:04:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:04:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:05:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:05:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.953308, avg_loss=0.693653, seen=480, correct=242, accuracy=0.504167
2025-10-09 15:05:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:05:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:05:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:05:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2180MB allocated=2023MB
2025-10-09 15:05:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.4512026309967, 'train_avg_loss': 0.6954266885916393, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 15:05:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.95330810546875, 'train_avg_loss': 0.6936527252197265, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 15:05:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 332.95330810546875, 'train_avg_loss': 0.6936527252197265, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 15:05:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #138) -------------
2025-10-09 15:05:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=138 aidx=5 | s=5 (candidates=6)
2025-10-09 15:05:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 41, 32, 31, 3] (from 6)
2025-10-09 15:05:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:05:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:05:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-09 15:05:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:05:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:05:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:05:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:05:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:05:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:06:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:06:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.297974, avg_loss=0.690204, seen=480, correct=257, accuracy=0.535417
2025-10-09 15:06:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:06:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:06:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:06:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2208MB allocated=2023MB
2025-10-09 15:06:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3881973028183, 'train_avg_loss': 0.6949016441901524, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 15:06:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2979736328125, 'train_avg_loss': 0.690204111735026, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 15:06:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 331.2979736328125, 'train_avg_loss': 0.690204111735026, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 15:06:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:06:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:06:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-09 15:06:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:06:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:06:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:06:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:06:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:06:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:06:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:06:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.819061, avg_loss=0.693373, seen=480, correct=251, accuracy=0.522917
2025-10-09 15:06:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:06:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:06:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:06:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2176MB allocated=2023MB
2025-10-09 15:06:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91379821300507, 'train_avg_loss': 0.6826149851083756, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 15:06:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8190612792969, 'train_avg_loss': 0.6933730443318685, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:06:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 332.8190612792969, 'train_avg_loss': 0.6933730443318685, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:06:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:06:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:06:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-09 15:06:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:06:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:06:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:06:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:06:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:06:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:07:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:07:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.772186, avg_loss=0.682859, seen=480, correct=271, accuracy=0.564583
2025-10-09 15:07:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:07:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:07:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:07:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2176MB allocated=2023MB
2025-10-09 15:07:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63756799697876, 'train_avg_loss': 0.6803130666414897, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 15:07:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.7721862792969, 'train_avg_loss': 0.6828587214152019, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 15:07:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 327.7721862792969, 'train_avg_loss': 0.6828587214152019, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 15:07:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:07:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:07:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:08:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:08:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.643951, avg_loss=0.690925, seen=480, correct=253, accuracy=0.527083
2025-10-09 15:08:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:08:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:08:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:08:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2180MB allocated=2023MB
2025-10-09 15:08:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.17849946022034, 'train_avg_loss': 0.6931541621685028, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 15:08:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6439514160156, 'train_avg_loss': 0.6909248987833659, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 15:08:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 331.6439514160156, 'train_avg_loss': 0.6909248987833659, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 15:08:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:08:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:08:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:09:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:09:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.702087, avg_loss=0.695213, seen=480, correct=251, accuracy=0.522917
2025-10-09 15:09:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:09:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:09:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:09:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2198MB allocated=2023MB
2025-10-09 15:09:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.97535824775696, 'train_avg_loss': 0.691461318731308, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 15:09:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.70208740234375, 'train_avg_loss': 0.6952126820882162, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:09:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 333.70208740234375, 'train_avg_loss': 0.6952126820882162, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:09:04 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #139) -------------
2025-10-09 15:09:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=139 aidx=5 | s=5 (candidates=6)
2025-10-09 15:09:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 32, 41, 3, 37] (from 6)
2025-10-09 15:09:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:09:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:09:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:09:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:09:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.834473, avg_loss=0.691322, seen=480, correct=252, accuracy=0.525000
2025-10-09 15:09:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:09:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:09:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:09:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2208MB allocated=2023MB
2025-10-09 15:09:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.79386568069458, 'train_avg_loss': 0.6982822140057882, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 15:09:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.83447265625, 'train_avg_loss': 0.6913218180338542, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 15:09:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 331.83447265625, 'train_avg_loss': 0.6913218180338542, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 15:09:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:09:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:09:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:10:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:10:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.402893, avg_loss=0.684173, seen=480, correct=270, accuracy=0.562500
2025-10-09 15:10:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:10:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:10:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:10:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2176MB allocated=2023MB
2025-10-09 15:10:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0975478887558, 'train_avg_loss': 0.6841462324062983, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 15:10:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.40289306640625, 'train_avg_loss': 0.6841726938883463, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:10:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 328.40289306640625, 'train_avg_loss': 0.6841726938883463, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:10:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:10:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:10:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-09 15:10:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:10:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:10:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:10:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:10:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:10:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:11:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:11:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.593018, avg_loss=0.697069, seen=480, correct=251, accuracy=0.522917
2025-10-09 15:11:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:11:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:11:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:11:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2176MB allocated=2023MB
2025-10-09 15:11:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.63331663608551, 'train_avg_loss': 0.6886109719673793, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:11:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.593017578125, 'train_avg_loss': 0.6970687866210937, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:11:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 334.593017578125, 'train_avg_loss': 0.6970687866210937, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:11:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:11:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:11:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:11:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:11:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.505066, avg_loss=0.688552, seen=480, correct=254, accuracy=0.529167
2025-10-09 15:11:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:11:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:12:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:12:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2198MB allocated=2023MB
2025-10-09 15:12:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.08355021476746, 'train_avg_loss': 0.6840295851230621, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:12:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.50506591796875, 'train_avg_loss': 0.6885522206624349, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 15:12:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 330.50506591796875, 'train_avg_loss': 0.6885522206624349, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 15:12:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:12:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:12:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-09 15:12:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:12:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:12:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:12:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:12:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:12:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:12:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:12:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.204834, avg_loss=0.687927, seen=480, correct=266, accuracy=0.554167
2025-10-09 15:12:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:12:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:12:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:12:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2176MB allocated=2023MB
2025-10-09 15:12:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.82550138235092, 'train_avg_loss': 0.7235458448529244, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 15:12:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.204833984375, 'train_avg_loss': 0.6879267374674479, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 15:12:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 330.204833984375, 'train_avg_loss': 0.6879267374674479, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 15:12:47 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #140) -------------
2025-10-09 15:12:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=140 aidx=5 | s=5 (candidates=6)
2025-10-09 15:12:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 41, 32, 3, 31] (from 6)
2025-10-09 15:12:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:12:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:12:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-09 15:12:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:12:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:12:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:12:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:12:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:12:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:13:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:13:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.123169, avg_loss=0.685673, seen=480, correct=268, accuracy=0.558333
2025-10-09 15:13:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:13:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:13:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:13:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2176MB allocated=2023MB
2025-10-09 15:13:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.83591771125793, 'train_avg_loss': 0.7236326475938161, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 15:13:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1231689453125, 'train_avg_loss': 0.6856732686360677, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:13:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 329.1231689453125, 'train_avg_loss': 0.6856732686360677, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:13:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:13:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:13:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-09 15:13:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:13:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:13:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:13:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:13:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:13:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:14:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:14:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.789246, avg_loss=0.693311, seen=480, correct=254, accuracy=0.529167
2025-10-09 15:14:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:14:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:14:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:14:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2176MB allocated=2023MB
2025-10-09 15:14:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78008675575256, 'train_avg_loss': 0.6815007229646047, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 15:14:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.78924560546875, 'train_avg_loss': 0.6933109283447265, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 15:14:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 332.78924560546875, 'train_avg_loss': 0.6933109283447265, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 15:14:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:14:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:14:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:15:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:15:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.274048, avg_loss=0.690154, seen=480, correct=252, accuracy=0.525000
2025-10-09 15:15:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:15:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:15:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:15:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2176MB allocated=2023MB
2025-10-09 15:15:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.49892234802246, 'train_avg_loss': 0.6791576862335205, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 15:15:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2740478515625, 'train_avg_loss': 0.6901542663574218, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 15:15:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 331.2740478515625, 'train_avg_loss': 0.6901542663574218, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 15:15:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:15:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:15:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:15:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:15:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.325409, avg_loss=0.688178, seen=480, correct=267, accuracy=0.556250
2025-10-09 15:15:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:15:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:15:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:15:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2198MB allocated=2023MB
2025-10-09 15:15:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.13224768638611, 'train_avg_loss': 0.6844353973865509, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 15:15:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3254089355469, 'train_avg_loss': 0.6881779352823894, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:15:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 330.3254089355469, 'train_avg_loss': 0.6881779352823894, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:15:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:15:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:15:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:16:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:16:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.404510, avg_loss=0.698759, seen=480, correct=250, accuracy=0.520833
2025-10-09 15:16:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:16:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:16:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:16:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2180MB allocated=2023MB
2025-10-09 15:16:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.24004483222961, 'train_avg_loss': 0.7020003736019135, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 15:16:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.4045104980469, 'train_avg_loss': 0.698759396870931, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 15:16:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 335.4045104980469, 'train_avg_loss': 0.698759396870931, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 15:16:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #141) -------------
2025-10-09 15:16:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=141 aidx=5 | s=5 (candidates=6)
2025-10-09 15:16:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 31, 3, 41, 37] (from 6)
2025-10-09 15:16:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:16:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:16:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-09 15:16:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:16:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:16:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:16:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:16:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:16:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:17:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:17:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.637299, avg_loss=0.682578, seen=480, correct=268, accuracy=0.558333
2025-10-09 15:17:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:17:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:17:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:17:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2176MB allocated=2023MB
2025-10-09 15:17:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0390864610672, 'train_avg_loss': 0.6836590538422267, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:17:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6372985839844, 'train_avg_loss': 0.6825777053833008, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:17:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 327.6372985839844, 'train_avg_loss': 0.6825777053833008, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:17:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:17:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:17:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:18:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:18:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.640106, avg_loss=0.686750, seen=480, correct=260, accuracy=0.541667
2025-10-09 15:18:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:18:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:18:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:18:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2180MB allocated=2023MB
2025-10-09 15:18:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.53670990467072, 'train_avg_loss': 0.6878059158722559, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:18:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6401062011719, 'train_avg_loss': 0.6867502212524415, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 15:18:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 329.6401062011719, 'train_avg_loss': 0.6867502212524415, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 15:18:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:18:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:18:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-09 15:18:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:18:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:18:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:18:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:18:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:18:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:18:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:18:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.949768, avg_loss=0.687395, seen=480, correct=267, accuracy=0.556250
2025-10-09 15:18:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:18:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:18:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:18:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2198MB allocated=2023MB
2025-10-09 15:18:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.80651116371155, 'train_avg_loss': 0.6817209263642628, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:18:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.94976806640625, 'train_avg_loss': 0.6873953501383464, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:18:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 329.94976806640625, 'train_avg_loss': 0.6873953501383464, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:18:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:18:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:18:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:19:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:19:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.678040, avg_loss=0.693079, seen=480, correct=251, accuracy=0.522917
2025-10-09 15:19:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:19:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:19:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:19:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2176MB allocated=2023MB
2025-10-09 15:19:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.08986592292786, 'train_avg_loss': 0.6840822160243988, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:19:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.67803955078125, 'train_avg_loss': 0.6930792490641277, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:19:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 332.67803955078125, 'train_avg_loss': 0.6930792490641277, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 15:19:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:19:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:19:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:20:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:20:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.500122, avg_loss=0.684375, seen=480, correct=270, accuracy=0.562500
2025-10-09 15:20:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:20:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:20:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:20:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2176MB allocated=2023MB
2025-10-09 15:20:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.13605958223343, 'train_avg_loss': 0.7178004965186119, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 15:20:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.5001220703125, 'train_avg_loss': 0.684375254313151, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:20:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 328.5001220703125, 'train_avg_loss': 0.684375254313151, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:20:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #142) -------------
2025-10-09 15:20:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=142 aidx=5 | s=5 (candidates=6)
2025-10-09 15:20:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 32, 3, 31, 21] (from 6)
2025-10-09 15:20:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:20:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:20:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:21:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:21:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.318939, avg_loss=0.694414, seen=480, correct=258, accuracy=0.537500
2025-10-09 15:21:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:21:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:21:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:21:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2176MB allocated=2023MB
2025-10-09 15:21:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99369806051254, 'train_avg_loss': 0.6832808171709378, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:21:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.3189392089844, 'train_avg_loss': 0.6944144566853842, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 15:21:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 333.3189392089844, 'train_avg_loss': 0.6944144566853842, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 15:21:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:21:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:21:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:21:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:21:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.444275, avg_loss=0.686342, seen=480, correct=260, accuracy=0.541667
2025-10-09 15:21:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:21:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:21:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:21:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2176MB allocated=2023MB
2025-10-09 15:21:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.95146763324738, 'train_avg_loss': 0.6745955636103947, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 15:21:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.44427490234375, 'train_avg_loss': 0.6863422393798828, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 15:21:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 329.44427490234375, 'train_avg_loss': 0.6863422393798828, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 15:21:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:21:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:21:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:22:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:22:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.685516, avg_loss=0.688928, seen=480, correct=262, accuracy=0.545833
2025-10-09 15:22:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:22:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:22:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:22:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2198MB allocated=2023MB
2025-10-09 15:22:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26064705848694, 'train_avg_loss': 0.6855053921540578, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:22:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.6855163574219, 'train_avg_loss': 0.6889281590779622, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 15:22:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 330.6855163574219, 'train_avg_loss': 0.6889281590779622, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 15:22:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:22:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:22:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:23:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:23:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.956726, avg_loss=0.695743, seen=480, correct=257, accuracy=0.535417
2025-10-09 15:23:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:23:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:23:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:23:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2180MB allocated=2023MB
2025-10-09 15:23:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6915853023529, 'train_avg_loss': 0.6974298775196075, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 15:23:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.95672607421875, 'train_avg_loss': 0.695743179321289, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 15:23:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 333.95672607421875, 'train_avg_loss': 0.695743179321289, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 15:23:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:23:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:23:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:24:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:24:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.526154, avg_loss=0.690679, seen=480, correct=269, accuracy=0.560417
2025-10-09 15:24:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:24:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:24:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:24:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2208MB allocated=2023MB
2025-10-09 15:24:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.84284102916718, 'train_avg_loss': 0.6986903419097265, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 15:24:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5261535644531, 'train_avg_loss': 0.6906794865926107, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 15:24:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 331.5261535644531, 'train_avg_loss': 0.6906794865926107, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 15:24:09 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #143) -------------
2025-10-09 15:24:10 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=143 aidx=5 | s=5 (candidates=6)
2025-10-09 15:24:10 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 37, 41, 31, 3] (from 6)
2025-10-09 15:24:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:24:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:24:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-09 15:24:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:24:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:24:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:24:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:24:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:24:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:24:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:24:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.070374, avg_loss=0.683480, seen=480, correct=269, accuracy=0.560417
2025-10-09 15:24:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:24:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:24:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:24:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2176MB allocated=2023MB
2025-10-09 15:24:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.10908472537994, 'train_avg_loss': 0.6842423727114996, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 15:24:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.07037353515625, 'train_avg_loss': 0.6834799448649088, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 15:24:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 328.07037353515625, 'train_avg_loss': 0.6834799448649088, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 15:24:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:24:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:24:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:25:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:25:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.722748, avg_loss=0.678589, seen=480, correct=277, accuracy=0.577083
2025-10-09 15:25:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:25:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:25:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:25:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2176MB allocated=2023MB
2025-10-09 15:25:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.5139074921608, 'train_avg_loss': 0.7126158957680067, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 15:25:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7227478027344, 'train_avg_loss': 0.6785890579223632, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:25:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 325.7227478027344, 'train_avg_loss': 0.6785890579223632, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:25:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:25:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:25:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:26:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:26:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.266571, avg_loss=0.696389, seen=480, correct=249, accuracy=0.518750
2025-10-09 15:26:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:26:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:26:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:26:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2176MB allocated=2023MB
2025-10-09 15:26:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.4516031742096, 'train_avg_loss': 0.6870966931184133, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 15:26:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2665710449219, 'train_avg_loss': 0.6963886896769206, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 15:26:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 334.2665710449219, 'train_avg_loss': 0.6963886896769206, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 15:26:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:26:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:26:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:27:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:27:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.599854, avg_loss=0.688750, seen=480, correct=256, accuracy=0.533333
2025-10-09 15:27:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:27:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:27:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:27:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2180MB allocated=2023MB
2025-10-09 15:27:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.54027938842773, 'train_avg_loss': 0.6878356615702311, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 15:27:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.599853515625, 'train_avg_loss': 0.6887496948242188, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 15:27:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 330.599853515625, 'train_avg_loss': 0.6887496948242188, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 15:27:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:27:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:27:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:27:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:27:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.479645, avg_loss=0.686416, seen=480, correct=266, accuracy=0.554167
2025-10-09 15:27:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:27:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:27:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:27:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2198MB allocated=2023MB
2025-10-09 15:27:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91502773761749, 'train_avg_loss': 0.6826252311468124, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:27:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4796447753906, 'train_avg_loss': 0.6864159266153972, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 15:27:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 329.4796447753906, 'train_avg_loss': 0.6864159266153972, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 15:27:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #144) -------------
2025-10-09 15:27:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=144 aidx=5 | s=5 (candidates=6)
2025-10-09 15:27:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 41, 3, 31, 21] (from 6)
2025-10-09 15:27:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:27:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:27:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-09 15:27:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:27:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:27:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:27:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:27:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:27:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:28:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:28:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.816833, avg_loss=0.678785, seen=480, correct=276, accuracy=0.575000
2025-10-09 15:28:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:28:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:28:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:28:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2176MB allocated=2023MB
2025-10-09 15:28:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.20726072788239, 'train_avg_loss': 0.7183938393990199, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 15:28:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.81683349609375, 'train_avg_loss': 0.6787850697835286, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 15:28:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 325.81683349609375, 'train_avg_loss': 0.6787850697835286, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 15:28:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:28:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:28:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:29:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:29:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.347412, avg_loss=0.694474, seen=480, correct=252, accuracy=0.525000
2025-10-09 15:29:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:29:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:29:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:29:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2176MB allocated=2023MB
2025-10-09 15:29:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.42683386802673, 'train_avg_loss': 0.6868902822335561, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:29:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.347412109375, 'train_avg_loss': 0.6944737752278646, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 15:29:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 333.347412109375, 'train_avg_loss': 0.6944737752278646, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 15:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:29:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:29:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:30:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:30:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.123199, avg_loss=0.681507, seen=480, correct=272, accuracy=0.566667
2025-10-09 15:30:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:30:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:30:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:30:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2198MB allocated=2023MB
2025-10-09 15:30:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.46314251422882, 'train_avg_loss': 0.6788595209519068, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 15:30:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.1231994628906, 'train_avg_loss': 0.6815066655476888, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 15:30:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 327.1231994628906, 'train_avg_loss': 0.6815066655476888, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 15:30:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:30:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:30:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:30:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:30:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.225677, avg_loss=0.687970, seen=480, correct=253, accuracy=0.527083
2025-10-09 15:30:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:30:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:30:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:30:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2180MB allocated=2023MB
2025-10-09 15:30:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61573994159698, 'train_avg_loss': 0.6884644995133082, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 15:30:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.2256774902344, 'train_avg_loss': 0.6879701614379883, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 15:30:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 330.2256774902344, 'train_avg_loss': 0.6879701614379883, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 15:30:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:30:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:30:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-09 15:30:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:30:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:30:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:30:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:30:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:30:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:31:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:31:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.025787, avg_loss=0.685470, seen=480, correct=265, accuracy=0.552083
2025-10-09 15:31:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:31:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:31:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:31:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2208MB allocated=2023MB
2025-10-09 15:31:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37256824970245, 'train_avg_loss': 0.6947714020808538, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 15:31:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0257873535156, 'train_avg_loss': 0.6854703903198243, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 15:31:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 329.0257873535156, 'train_avg_loss': 0.6854703903198243, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 15:31:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #145) -------------
2025-10-09 15:31:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=145 aidx=5 | s=5 (candidates=6)
2025-10-09 15:31:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 21, 31, 3, 41] (from 6)
2025-10-09 15:31:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:31:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:31:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:32:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:32:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.001038, avg_loss=0.683335, seen=480, correct=267, accuracy=0.556250
2025-10-09 15:32:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:32:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:32:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:32:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2176MB allocated=2023MB
2025-10-09 15:32:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66833686828613, 'train_avg_loss': 0.6805694739023844, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:32:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.00103759765625, 'train_avg_loss': 0.6833354949951171, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:32:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 328.00103759765625, 'train_avg_loss': 0.6833354949951171, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:32:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:32:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:32:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-09 15:32:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:32:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:32:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:32:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:32:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:32:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:33:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:33:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.330261, avg_loss=0.679855, seen=480, correct=267, accuracy=0.556250
2025-10-09 15:33:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:33:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:33:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:33:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2208MB allocated=2023MB
2025-10-09 15:33:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.71201133728027, 'train_avg_loss': 0.6892667611440023, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 15:33:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.33026123046875, 'train_avg_loss': 0.6798547108968099, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:33:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 326.33026123046875, 'train_avg_loss': 0.6798547108968099, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:33:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:33:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:33:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:33:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:33:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.476868, avg_loss=0.688493, seen=480, correct=261, accuracy=0.543750
2025-10-09 15:33:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:33:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:33:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:33:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2180MB allocated=2023MB
2025-10-09 15:33:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24110305309296, 'train_avg_loss': 0.6853425254424413, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 15:33:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.47686767578125, 'train_avg_loss': 0.6884934743245442, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 15:33:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 330.47686767578125, 'train_avg_loss': 0.6884934743245442, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 15:33:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:33:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:33:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:34:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:34:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.668335, avg_loss=0.680559, seen=480, correct=281, accuracy=0.585417
2025-10-09 15:34:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:34:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:34:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:34:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2198MB allocated=2023MB
2025-10-09 15:34:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61998343467712, 'train_avg_loss': 0.6801665286223094, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 15:34:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.6683349609375, 'train_avg_loss': 0.6805590311686198, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 15:34:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 326.6683349609375, 'train_avg_loss': 0.6805590311686198, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 15:34:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:34:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:34:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:35:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:35:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.712463, avg_loss=0.695234, seen=480, correct=254, accuracy=0.529167
2025-10-09 15:35:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:35:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:35:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:35:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2176MB allocated=2023MB
2025-10-09 15:35:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24161231517792, 'train_avg_loss': 0.6853467692931493, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 15:35:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.71246337890625, 'train_avg_loss': 0.6952342987060547, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 15:35:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 333.71246337890625, 'train_avg_loss': 0.6952342987060547, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 15:35:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #146) -------------
2025-10-09 15:35:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=146 aidx=5 | s=5 (candidates=6)
2025-10-09 15:35:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 37, 41, 32, 31] (from 6)
2025-10-09 15:35:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:35:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:35:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:36:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:36:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.928406, avg_loss=0.681101, seen=480, correct=267, accuracy=0.556250
2025-10-09 15:36:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:36:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:36:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:36:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2208MB allocated=2023MB
2025-10-09 15:36:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.87024760246277, 'train_avg_loss': 0.6905853966871898, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 15:36:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.92840576171875, 'train_avg_loss': 0.6811008453369141, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:36:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 326.92840576171875, 'train_avg_loss': 0.6811008453369141, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 15:36:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:36:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:36:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:36:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:36:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.392273, avg_loss=0.679984, seen=480, correct=273, accuracy=0.568750
2025-10-09 15:36:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:36:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:36:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:36:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2176MB allocated=2023MB
2025-10-09 15:36:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.62608593702316, 'train_avg_loss': 0.7135507161418597, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 15:36:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.39227294921875, 'train_avg_loss': 0.6799839019775391, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 15:36:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 326.39227294921875, 'train_avg_loss': 0.6799839019775391, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 15:36:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:36:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:36:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-09 15:36:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:36:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:36:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:36:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:36:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:36:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:37:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:37:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.604645, avg_loss=0.692926, seen=480, correct=257, accuracy=0.535417
2025-10-09 15:37:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:37:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:37:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:37:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2176MB allocated=2023MB
2025-10-09 15:37:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.3788234591484, 'train_avg_loss': 0.6864901954929034, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 15:37:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.6046447753906, 'train_avg_loss': 0.6929263432820638, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 15:37:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 332.6046447753906, 'train_avg_loss': 0.6929263432820638, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 15:37:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:37:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:37:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-09 15:37:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:37:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:37:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:37:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:37:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:37:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:38:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:38:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.087036, avg_loss=0.679348, seen=480, correct=277, accuracy=0.577083
2025-10-09 15:38:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:38:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:38:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:38:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2176MB allocated=2023MB
2025-10-09 15:38:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.02311110496521, 'train_avg_loss': 0.6835259258747101, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:38:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.0870361328125, 'train_avg_loss': 0.6793479919433594, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:38:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 326.0870361328125, 'train_avg_loss': 0.6793479919433594, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:38:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:38:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:38:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-09 15:38:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:38:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:38:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:38:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:38:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:38:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:38:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:38:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.157532, avg_loss=0.685745, seen=480, correct=262, accuracy=0.545833
2025-10-09 15:38:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:38:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:38:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:39:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2180MB allocated=2023MB
2025-10-09 15:39:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.71600687503815, 'train_avg_loss': 0.6893000572919845, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 15:39:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.15753173828125, 'train_avg_loss': 0.6857448577880859, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 15:39:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 329.15753173828125, 'train_avg_loss': 0.6857448577880859, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 15:39:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #147) -------------
2025-10-09 15:39:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=147 aidx=5 | s=5 (candidates=6)
2025-10-09 15:39:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 37, 21, 3, 32] (from 6)
2025-10-09 15:39:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:39:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:39:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:39:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:39:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.766998, avg_loss=0.689098, seen=480, correct=255, accuracy=0.531250
2025-10-09 15:39:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:39:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:39:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:39:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2176MB allocated=2023MB
2025-10-09 15:39:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.88802301883698, 'train_avg_loss': 0.6824001918236414, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:39:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.7669982910156, 'train_avg_loss': 0.6890979131062825, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 15:39:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 330.7669982910156, 'train_avg_loss': 0.6890979131062825, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 15:39:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:39:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:39:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-09 15:39:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:39:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:39:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:39:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:39:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:39:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:40:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:40:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.652802, avg_loss=0.678443, seen=480, correct=280, accuracy=0.583333
2025-10-09 15:40:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:40:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:40:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:40:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2176MB allocated=2023MB
2025-10-09 15:40:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.64725214242935, 'train_avg_loss': 0.7137271011869113, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 15:40:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6528015136719, 'train_avg_loss': 0.6784433364868164, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 15:40:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 325.6528015136719, 'train_avg_loss': 0.6784433364868164, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 15:40:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:40:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:40:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:41:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:41:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.445618, avg_loss=0.680095, seen=480, correct=273, accuracy=0.568750
2025-10-09 15:41:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:41:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:41:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:41:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2208MB allocated=2023MB
2025-10-09 15:41:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.53497517108917, 'train_avg_loss': 0.6877914597590764, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 15:41:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.44561767578125, 'train_avg_loss': 0.6800950368245443, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 15:41:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 326.44561767578125, 'train_avg_loss': 0.6800950368245443, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 15:41:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:41:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:41:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:41:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:41:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.468842, avg_loss=0.682227, seen=480, correct=264, accuracy=0.550000
2025-10-09 15:41:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:41:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:41:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:41:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2198MB allocated=2023MB
2025-10-09 15:41:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31603252887726, 'train_avg_loss': 0.6776336044073105, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:41:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.4688415527344, 'train_avg_loss': 0.6822267532348633, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 15:41:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 327.4688415527344, 'train_avg_loss': 0.6822267532348633, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 15:41:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:41:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:41:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-09 15:41:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:41:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:41:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:41:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:41:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:41:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:42:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:42:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.280212, avg_loss=0.677667, seen=480, correct=281, accuracy=0.585417
2025-10-09 15:42:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:42:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:42:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:42:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2176MB allocated=2023MB
2025-10-09 15:42:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.17815732955933, 'train_avg_loss': 0.6764846444129944, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 15:42:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.28021240234375, 'train_avg_loss': 0.6776671091715495, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 15:42:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 325.28021240234375, 'train_avg_loss': 0.6776671091715495, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 15:42:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #148) -------------
2025-10-09 15:42:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=148 aidx=5 | s=5 (candidates=6)
2025-10-09 15:42:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 21, 37, 32, 31] (from 6)
2025-10-09 15:42:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:42:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:42:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:43:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:43:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.345123, avg_loss=0.686136, seen=480, correct=262, accuracy=0.545833
2025-10-09 15:43:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:43:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:43:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:43:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2176MB allocated=2023MB
2025-10-09 15:43:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78514915704727, 'train_avg_loss': 0.6815429096420605, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 15:43:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3451232910156, 'train_avg_loss': 0.6861356735229492, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 15:43:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 329.3451232910156, 'train_avg_loss': 0.6861356735229492, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 15:43:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:43:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:43:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:44:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:44:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.414490, avg_loss=0.680030, seen=480, correct=282, accuracy=0.587500
2025-10-09 15:44:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:44:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:44:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:44:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2208MB allocated=2023MB
2025-10-09 15:44:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.34078478813171, 'train_avg_loss': 0.6861732065677643, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:44:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.41448974609375, 'train_avg_loss': 0.6800301869710287, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 15:44:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 326.41448974609375, 'train_avg_loss': 0.6800301869710287, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 15:44:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:44:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:44:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:44:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:44:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.462280, avg_loss=0.680130, seen=480, correct=276, accuracy=0.575000
2025-10-09 15:44:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:44:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:44:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:45:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2176MB allocated=2023MB
2025-10-09 15:45:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.6199836730957, 'train_avg_loss': 0.7134998639424642, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 15:45:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.4622802734375, 'train_avg_loss': 0.6801297505696614, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 15:45:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 326.4622802734375, 'train_avg_loss': 0.6801297505696614, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 15:45:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:45:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:45:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:45:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:45:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.378082, avg_loss=0.671621, seen=480, correct=285, accuracy=0.593750
2025-10-09 15:45:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:45:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:45:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:45:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2176MB allocated=2023MB
2025-10-09 15:45:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.0283555984497, 'train_avg_loss': 0.6669029633204142, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 15:45:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.3780822753906, 'train_avg_loss': 0.6716210047403971, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 15:45:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 322.3780822753906, 'train_avg_loss': 0.6716210047403971, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 15:45:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:45:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:45:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-09 15:45:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:45:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:45:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:45:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:45:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:45:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:46:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:46:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.917969, avg_loss=0.681079, seen=480, correct=268, accuracy=0.558333
2025-10-09 15:46:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:46:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:46:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:46:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2180MB allocated=2023MB
2025-10-09 15:46:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00669872760773, 'train_avg_loss': 0.6833891560633977, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 15:46:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.91796875, 'train_avg_loss': 0.6810791015625, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:46:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 326.91796875, 'train_avg_loss': 0.6810791015625, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:46:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #149) -------------
2025-10-09 15:46:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=149 aidx=5 | s=5 (candidates=6)
2025-10-09 15:46:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 3, 41, 31, 21] (from 6)
2025-10-09 15:46:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:46:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:46:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:47:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:47:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.955811, avg_loss=0.679075, seen=480, correct=270, accuracy=0.562500
2025-10-09 15:47:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:47:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:47:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:47:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2176MB allocated=2023MB
2025-10-09 15:47:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.53681349754333, 'train_avg_loss': 0.7128067791461945, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 15:47:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.955810546875, 'train_avg_loss': 0.6790746053059896, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:47:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 325.955810546875, 'train_avg_loss': 0.6790746053059896, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:47:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:47:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:47:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-09 15:47:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:47:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:47:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:47:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:47:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:47:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:47:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:47:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.269073, avg_loss=0.681811, seen=480, correct=272, accuracy=0.566667
2025-10-09 15:47:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:47:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:47:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:48:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2198MB allocated=2023MB
2025-10-09 15:48:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50798439979553, 'train_avg_loss': 0.6792332033316294, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 15:48:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.2690734863281, 'train_avg_loss': 0.6818105697631835, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 15:48:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 327.2690734863281, 'train_avg_loss': 0.6818105697631835, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 15:48:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:48:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:48:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-09 15:48:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:48:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:48:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:48:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:48:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:48:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:48:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:48:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.365662, avg_loss=0.686178, seen=480, correct=260, accuracy=0.541667
2025-10-09 15:48:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:48:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:48:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:48:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2176MB allocated=2023MB
2025-10-09 15:48:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3649577498436, 'train_avg_loss': 0.67804131458203, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:48:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.36566162109375, 'train_avg_loss': 0.686178461710612, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 15:48:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 329.36566162109375, 'train_avg_loss': 0.686178461710612, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 15:48:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:48:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:48:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:49:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:49:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.874207, avg_loss=0.676821, seen=480, correct=273, accuracy=0.568750
2025-10-09 15:49:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:49:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:49:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:49:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2180MB allocated=2023MB
2025-10-09 15:49:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.39507818222046, 'train_avg_loss': 0.6782923181851704, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 15:49:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.87420654296875, 'train_avg_loss': 0.6768212636311849, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 15:49:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 324.87420654296875, 'train_avg_loss': 0.6768212636311849, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 15:49:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:49:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:49:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:50:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:50:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.744171, avg_loss=0.680717, seen=480, correct=277, accuracy=0.577083
2025-10-09 15:50:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:50:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:50:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:50:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2208MB allocated=2023MB
2025-10-09 15:50:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.34627866744995, 'train_avg_loss': 0.6862189888954162, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:50:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.7441711425781, 'train_avg_loss': 0.6807170232137044, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:50:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 326.7441711425781, 'train_avg_loss': 0.6807170232137044, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:50:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #150) -------------
2025-10-09 15:50:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=150 aidx=5 | s=5 (candidates=6)
2025-10-09 15:50:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 3, 41, 32, 37] (from 6)
2025-10-09 15:50:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:50:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:50:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-09 15:50:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:50:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:50:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:50:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:50:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:50:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:50:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:50:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.774170, avg_loss=0.674530, seen=480, correct=297, accuracy=0.618750
2025-10-09 15:50:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:50:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:51:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:51:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2208MB allocated=2023MB
2025-10-09 15:51:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.6732964515686, 'train_avg_loss': 0.6806108037630717, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 15:51:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.774169921875, 'train_avg_loss': 0.6745295206705729, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 15:51:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 323.774169921875, 'train_avg_loss': 0.6745295206705729, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 15:51:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:51:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:51:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-09 15:51:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:51:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:51:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:51:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:51:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:51:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:51:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:51:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.912262, avg_loss=0.681067, seen=480, correct=272, accuracy=0.566667
2025-10-09 15:51:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:51:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:51:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:51:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2198MB allocated=2023MB
2025-10-09 15:51:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.76448655128479, 'train_avg_loss': 0.6813707212607066, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:51:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.9122619628906, 'train_avg_loss': 0.6810672124226888, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 15:51:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 326.9122619628906, 'train_avg_loss': 0.6810672124226888, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 15:51:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:51:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:51:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:52:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:52:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.164398, avg_loss=0.687842, seen=480, correct=268, accuracy=0.558333
2025-10-09 15:52:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:52:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:52:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:52:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2176MB allocated=2023MB
2025-10-09 15:52:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.74300527572632, 'train_avg_loss': 0.6811917106310527, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 15:52:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1643981933594, 'train_avg_loss': 0.6878424962361653, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:52:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 330.1643981933594, 'train_avg_loss': 0.6878424962361653, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 15:52:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:52:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:52:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-09 15:52:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:52:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:52:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:52:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:52:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:52:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:53:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:53:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.895813, avg_loss=0.668533, seen=480, correct=281, accuracy=0.585417
2025-10-09 15:53:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:53:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:53:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:53:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2176MB allocated=2023MB
2025-10-09 15:53:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.90904039144516, 'train_avg_loss': 0.6659086699287097, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 15:53:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.89581298828125, 'train_avg_loss': 0.6685329437255859, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 15:53:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 320.89581298828125, 'train_avg_loss': 0.6685329437255859, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 15:53:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 15:53:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:53:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:53:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:53:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.750549, avg_loss=0.678647, seen=480, correct=279, accuracy=0.581250
2025-10-09 15:53:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:53:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:53:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:53:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2176MB allocated=2023MB
2025-10-09 15:53:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.85436987876892, 'train_avg_loss': 0.7154530823230744, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 15:53:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.75054931640625, 'train_avg_loss': 0.678646977742513, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 15:53:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 325.75054931640625, 'train_avg_loss': 0.678646977742513, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 15:53:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #151) -------------
2025-10-09 15:53:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=151 aidx=5 | s=5 (candidates=6)
2025-10-09 15:53:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 3, 41, 31, 21] (from 6)
2025-10-09 15:54:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:54:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:54:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-09 15:54:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:54:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:54:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:54:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:54:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:54:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:54:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:54:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.127045, avg_loss=0.673181, seen=480, correct=270, accuracy=0.562500
2025-10-09 15:54:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:54:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:54:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:54:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2176MB allocated=2023MB
2025-10-09 15:54:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.50013184547424, 'train_avg_loss': 0.6625010987122854, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 15:54:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.1270446777344, 'train_avg_loss': 0.6731813430786133, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:54:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 323.1270446777344, 'train_avg_loss': 0.6731813430786133, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 15:54:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:54:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:54:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:55:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:55:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.677826, avg_loss=0.680579, seen=480, correct=271, accuracy=0.564583
2025-10-09 15:55:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:55:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:55:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:55:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2198MB allocated=2023MB
2025-10-09 15:55:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.72669279575348, 'train_avg_loss': 0.6810557732979456, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 15:55:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.6778259277344, 'train_avg_loss': 0.6805788040161133, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 15:55:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 326.6778259277344, 'train_avg_loss': 0.6805788040161133, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 15:55:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:55:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:55:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:56:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:56:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.588867, avg_loss=0.686643, seen=480, correct=265, accuracy=0.552083
2025-10-09 15:56:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:56:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:56:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:56:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2176MB allocated=2023MB
2025-10-09 15:56:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.63521301746368, 'train_avg_loss': 0.671960108478864, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:56:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5888671875, 'train_avg_loss': 0.6866434733072917, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 15:56:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 329.5888671875, 'train_avg_loss': 0.6866434733072917, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 15:56:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:56:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:56:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:56:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:56:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.375122, avg_loss=0.684115, seen=480, correct=261, accuracy=0.543750
2025-10-09 15:56:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:56:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:57:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:57:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2180MB allocated=2023MB
2025-10-09 15:57:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90867674350739, 'train_avg_loss': 0.6825723061958949, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 15:57:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3751220703125, 'train_avg_loss': 0.6841148376464844, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 15:57:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 328.3751220703125, 'train_avg_loss': 0.6841148376464844, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 15:57:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:57:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:57:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-09 15:57:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-09 15:57:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:57:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:57:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:57:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:57:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:57:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:57:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.403625, avg_loss=0.675841, seen=480, correct=280, accuracy=0.583333
2025-10-09 15:57:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:57:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:57:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:57:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2208MB allocated=2023MB
2025-10-09 15:57:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32674932479858, 'train_avg_loss': 0.6860562443733216, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 15:57:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.40362548828125, 'train_avg_loss': 0.6758408864339193, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 15:57:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 324.40362548828125, 'train_avg_loss': 0.6758408864339193, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 15:57:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #152) -------------
2025-10-09 15:57:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=152 aidx=5 | s=5 (candidates=6)
2025-10-09 15:57:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 32, 31, 41, 37] (from 6)
2025-10-09 15:57:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:57:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:57:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-09 15:57:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-09 15:57:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:57:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:57:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:57:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:57:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:58:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:58:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.967773, avg_loss=0.679100, seen=480, correct=277, accuracy=0.577083
2025-10-09 15:58:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:58:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:58:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:58:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2198MB allocated=2023MB
2025-10-09 15:58:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.24203062057495, 'train_avg_loss': 0.6770169218381246, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 15:58:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.9677734375, 'train_avg_loss': 0.6790995279947917, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:58:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 325.9677734375, 'train_avg_loss': 0.6790995279947917, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 15:58:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:58:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:58:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-09 15:58:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-09 15:58:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:58:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:58:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:58:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:58:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:59:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:59:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.092133, avg_loss=0.666859, seen=480, correct=283, accuracy=0.589583
2025-10-09 15:59:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:59:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:59:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:59:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2176MB allocated=2023MB
2025-10-09 15:59:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.62579959630966, 'train_avg_loss': 0.6635483299692472, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 15:59:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.0921325683594, 'train_avg_loss': 0.6668586095174154, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 15:59:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 320.0921325683594, 'train_avg_loss': 0.6668586095174154, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 15:59:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:59:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:59:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-09 15:59:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-09 15:59:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:59:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:59:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:59:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:59:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 15:59:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 15:59:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.848663, avg_loss=0.678851, seen=480, correct=269, accuracy=0.560417
2025-10-09 15:59:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 15:59:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:59:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 15:59:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2180MB allocated=2023MB
2025-10-09 15:59:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.10373771190643, 'train_avg_loss': 0.6758644809325536, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 15:59:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.8486633300781, 'train_avg_loss': 0.6788513819376628, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 15:59:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 325.8486633300781, 'train_avg_loss': 0.6788513819376628, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 15:59:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-09 15:59:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 15:59:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:00:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:00:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.854980, avg_loss=0.687198, seen=480, correct=261, accuracy=0.543750
2025-10-09 16:00:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:00:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:00:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:00:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2176MB allocated=2023MB
2025-10-09 16:00:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.68056148290634, 'train_avg_loss': 0.6806713456908862, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 16:00:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.85498046875, 'train_avg_loss': 0.6871978759765625, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 16:00:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 329.85498046875, 'train_avg_loss': 0.6871978759765625, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 16:00:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-09 16:00:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:00:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:01:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:01:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.574341, avg_loss=0.672030, seen=480, correct=283, accuracy=0.589583
2025-10-09 16:01:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:01:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:01:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:01:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2176MB allocated=2023MB
2025-10-09 16:01:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1864041686058, 'train_avg_loss': 0.7098867014050484, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:01:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.5743408203125, 'train_avg_loss': 0.6720298767089844, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 16:01:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 322.5743408203125, 'train_avg_loss': 0.6720298767089844, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 16:01:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #153) -------------
2025-10-09 16:01:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=153 aidx=6 | s=5 (candidates=5)
2025-10-09 16:01:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 24, 25, 44, 27] (from 5)
2025-10-09 16:01:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:01:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:01:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-09 16:01:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:01:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:01:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:01:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:01:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:01:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:02:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:02:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.674805, avg_loss=0.715989, seen=480, correct=236, accuracy=0.491667
2025-10-09 16:02:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:02:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:02:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:02:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2222MB allocated=2106MB
2025-10-09 16:02:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.54036659002304, 'train_avg_loss': 0.7295030549168586, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 16:02:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.6748046875, 'train_avg_loss': 0.7159891764322917, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 16:02:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 343.6748046875, 'train_avg_loss': 0.7159891764322917, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 16:02:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:02:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:02:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-09 16:02:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:02:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:02:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:02:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:02:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:02:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:02:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:02:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=353.433563, avg_loss=0.736320, seen=480, correct=236, accuracy=0.491667
2025-10-09 16:02:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:02:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:02:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:03:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2222MB allocated=2115MB
2025-10-09 16:03:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.44735258817673, 'train_avg_loss': 0.7287279382348061, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 16:03:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 353.4335632324219, 'train_avg_loss': 0.7363199234008789, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 16:03:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 353.4335632324219, 'train_avg_loss': 0.7363199234008789, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 16:03:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:03:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:03:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-09 16:03:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:03:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:03:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:03:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:03:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:03:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:03:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:03:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.429840, avg_loss=0.727979, seen=480, correct=235, accuracy=0.489583
2025-10-09 16:03:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:03:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:03:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:03:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2242MB allocated=2124MB
2025-10-09 16:03:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.88178116083145, 'train_avg_loss': 0.7156815096735955, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:03:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.4298400878906, 'train_avg_loss': 0.7279788335164388, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 16:03:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 349.4298400878906, 'train_avg_loss': 0.7279788335164388, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 16:03:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:03:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:03:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-09 16:03:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:03:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:03:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:03:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:03:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:03:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:04:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:04:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=346.731476, avg_loss=0.722357, seen=480, correct=238, accuracy=0.495833
2025-10-09 16:04:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:04:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:04:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:04:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2242MB allocated=2132MB
2025-10-09 16:04:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.5202032327652, 'train_avg_loss': 0.70433502693971, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 16:04:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 346.7314758300781, 'train_avg_loss': 0.7223572413126628, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 16:04:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 346.7314758300781, 'train_avg_loss': 0.7223572413126628, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 16:04:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:04:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:04:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-09 16:04:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:04:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:04:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:04:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:04:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:04:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:05:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:05:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.822510, avg_loss=0.714214, seen=480, correct=239, accuracy=0.497917
2025-10-09 16:05:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:05:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:05:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:05:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2268MB allocated=2140MB
2025-10-09 16:05:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.52752476930618, 'train_avg_loss': 0.7127293730775516, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 16:05:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.822509765625, 'train_avg_loss': 0.7142135620117187, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 16:05:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 342.822509765625, 'train_avg_loss': 0.7142135620117187, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 16:05:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #154) -------------
2025-10-09 16:05:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=154 aidx=6 | s=5 (candidates=5)
2025-10-09 16:05:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 24, 25, 27, 30] (from 5)
2025-10-09 16:05:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:05:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:05:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:05:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:05:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.697449, avg_loss=0.709786, seen=480, correct=232, accuracy=0.483333
2025-10-09 16:05:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:05:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:05:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:06:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2312MB allocated=2140MB
2025-10-09 16:06:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.65375554561615, 'train_avg_loss': 0.688781296213468, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 16:06:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.69744873046875, 'train_avg_loss': 0.7097863515218099, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-09 16:06:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 340.69744873046875, 'train_avg_loss': 0.7097863515218099, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-09 16:06:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:06:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:06:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:06:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:06:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.947510, avg_loss=0.718641, seen=480, correct=228, accuracy=0.475000
2025-10-09 16:06:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:06:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:06:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:06:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2312MB allocated=2140MB
2025-10-09 16:06:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.80762898921967, 'train_avg_loss': 0.7150635749101639, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 16:06:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.947509765625, 'train_avg_loss': 0.7186406453450521, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-09 16:06:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 344.947509765625, 'train_avg_loss': 0.7186406453450521, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-09 16:06:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:06:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:06:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:07:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:07:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.775391, avg_loss=0.718282, seen=480, correct=233, accuracy=0.485417
2025-10-09 16:07:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:07:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:07:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:07:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2312MB allocated=2140MB
2025-10-09 16:07:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.04218089580536, 'train_avg_loss': 0.708684840798378, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 16:07:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.775390625, 'train_avg_loss': 0.7182820638020834, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 16:07:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 344.775390625, 'train_avg_loss': 0.7182820638020834, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 16:07:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:07:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:07:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-09 16:07:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:07:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:07:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:07:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:07:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:07:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:08:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:08:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.695190, avg_loss=0.703532, seen=480, correct=249, accuracy=0.518750
2025-10-09 16:08:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:08:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:08:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:08:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2316MB allocated=2140MB
2025-10-09 16:08:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.06405383348465, 'train_avg_loss': 0.7172004486123721, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 16:08:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.6951904296875, 'train_avg_loss': 0.7035316467285156, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 16:08:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 337.6951904296875, 'train_avg_loss': 0.7035316467285156, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 16:08:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:08:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:08:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:08:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:08:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.172974, avg_loss=0.706610, seen=480, correct=237, accuracy=0.493750
2025-10-09 16:08:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:08:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:08:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:08:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2312MB allocated=2140MB
2025-10-09 16:08:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.17139601707458, 'train_avg_loss': 0.7097616334756215, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 16:08:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.1729736328125, 'train_avg_loss': 0.706610361735026, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 16:08:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 339.1729736328125, 'train_avg_loss': 0.706610361735026, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 16:08:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #155) -------------
2025-10-09 16:08:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=155 aidx=6 | s=5 (candidates=5)
2025-10-09 16:08:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 24, 30, 44, 27] (from 5)
2025-10-09 16:09:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:09:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:09:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:09:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:09:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.476288, avg_loss=0.713492, seen=480, correct=234, accuracy=0.487500
2025-10-09 16:09:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:09:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:09:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:09:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2236MB allocated=2065MB
2025-10-09 16:09:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.69439601898193, 'train_avg_loss': 0.7057866334915162, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 16:09:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.4762878417969, 'train_avg_loss': 0.7134922663370769, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 16:09:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 342.4762878417969, 'train_avg_loss': 0.7134922663370769, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 16:09:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:09:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:09:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:10:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:10:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.684570, avg_loss=0.713926, seen=480, correct=230, accuracy=0.479167
2025-10-09 16:10:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:10:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:10:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:10:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2236MB allocated=2065MB
2025-10-09 16:10:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.63243913650513, 'train_avg_loss': 0.713603659470876, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 16:10:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.6845703125, 'train_avg_loss': 0.7139261881510417, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 16:10:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 342.6845703125, 'train_avg_loss': 0.7139261881510417, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 16:10:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:10:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:10:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:11:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:11:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.140045, avg_loss=0.698208, seen=480, correct=242, accuracy=0.504167
2025-10-09 16:11:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:11:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:11:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:11:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2236MB allocated=2065MB
2025-10-09 16:11:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.34741634130478, 'train_avg_loss': 0.7028951361775398, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:11:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.1400451660156, 'train_avg_loss': 0.6982084274291992, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 16:11:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 335.1400451660156, 'train_avg_loss': 0.6982084274291992, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 16:11:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:11:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:11:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:11:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:11:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.104706, avg_loss=0.704385, seen=480, correct=234, accuracy=0.487500
2025-10-09 16:11:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:11:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:11:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:11:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2236MB allocated=2065MB
2025-10-09 16:11:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.76768064498901, 'train_avg_loss': 0.6813973387082418, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 16:11:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.1047058105469, 'train_avg_loss': 0.7043848037719727, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 16:11:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 338.1047058105469, 'train_avg_loss': 0.7043848037719727, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 16:11:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:11:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:11:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-09 16:11:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:11:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:11:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:11:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:11:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:11:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:12:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:12:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.667969, avg_loss=0.701392, seen=480, correct=254, accuracy=0.529167
2025-10-09 16:12:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:12:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:12:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:12:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2236MB allocated=2065MB
2025-10-09 16:12:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.5936706662178, 'train_avg_loss': 0.7132805888851483, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 16:12:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.66796875, 'train_avg_loss': 0.7013916015625, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 16:12:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 336.66796875, 'train_avg_loss': 0.7013916015625, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 16:12:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #156) -------------
2025-10-09 16:12:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=156 aidx=6 | s=5 (candidates=5)
2025-10-09 16:12:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 44, 24, 30, 25] (from 5)
2025-10-09 16:12:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:12:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:12:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:13:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:13:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.574249, avg_loss=0.692863, seen=480, correct=259, accuracy=0.539583
2025-10-09 16:13:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:13:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:13:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:13:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2236MB allocated=2065MB
2025-10-09 16:13:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.33307981491089, 'train_avg_loss': 0.7027756651242574, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 16:13:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5742492675781, 'train_avg_loss': 0.6928630193074544, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 16:13:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 332.5742492675781, 'train_avg_loss': 0.6928630193074544, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 16:13:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:13:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:13:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-09 16:13:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:13:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:13:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:13:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:13:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:13:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:14:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:14:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.166443, avg_loss=0.700347, seen=480, correct=239, accuracy=0.497917
2025-10-09 16:14:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:14:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:14:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:14:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2236MB allocated=2065MB
2025-10-09 16:14:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.60059714317322, 'train_avg_loss': 0.6800049761931102, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 16:14:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.16644287109375, 'train_avg_loss': 0.7003467559814454, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 16:14:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 336.16644287109375, 'train_avg_loss': 0.7003467559814454, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 16:14:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:14:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:14:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:14:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:14:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.042206, avg_loss=0.708421, seen=480, correct=233, accuracy=0.485417
2025-10-09 16:14:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:14:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:14:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:14:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2236MB allocated=2065MB
2025-10-09 16:14:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.60006660223007, 'train_avg_loss': 0.7050005550185839, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 16:14:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.0422058105469, 'train_avg_loss': 0.708421262105306, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 16:14:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 340.0422058105469, 'train_avg_loss': 0.708421262105306, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-09 16:14:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:14:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:14:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:15:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:15:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.599365, avg_loss=0.694999, seen=480, correct=244, accuracy=0.508333
2025-10-09 16:15:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:15:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:15:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:15:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2236MB allocated=2065MB
2025-10-09 16:15:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.35580635070801, 'train_avg_loss': 0.7029650529225667, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 16:15:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.599365234375, 'train_avg_loss': 0.6949986775716146, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 16:15:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 333.599365234375, 'train_avg_loss': 0.6949986775716146, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 16:15:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:15:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:15:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-09 16:15:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:15:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:15:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:15:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:15:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:15:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:16:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:16:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.215363, avg_loss=0.708782, seen=480, correct=234, accuracy=0.487500
2025-10-09 16:16:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:16:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:16:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:16:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2236MB allocated=2065MB
2025-10-09 16:16:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.07596391439438, 'train_avg_loss': 0.7006330326199531, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 16:16:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.2153625488281, 'train_avg_loss': 0.7087820053100586, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 16:16:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 340.2153625488281, 'train_avg_loss': 0.7087820053100586, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 16:16:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #157) -------------
2025-10-09 16:16:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=157 aidx=6 | s=5 (candidates=5)
2025-10-09 16:16:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 27, 30, 25, 44] (from 5)
2025-10-09 16:16:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:16:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:16:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:17:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:17:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.066864, avg_loss=0.704306, seen=480, correct=231, accuracy=0.481250
2025-10-09 16:17:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:17:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:17:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:17:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2236MB allocated=2065MB
2025-10-09 16:17:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.337149143219, 'train_avg_loss': 0.7028095761934916, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 16:17:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.0668640136719, 'train_avg_loss': 0.7043059666951498, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-09 16:17:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 338.0668640136719, 'train_avg_loss': 0.7043059666951498, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-09 16:17:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:17:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:17:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-09 16:17:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:17:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:17:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:17:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:17:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:17:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:17:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:17:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.821167, avg_loss=0.695461, seen=480, correct=257, accuracy=0.535417
2025-10-09 16:17:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:17:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:17:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:17:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2236MB allocated=2065MB
2025-10-09 16:17:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.32214492559433, 'train_avg_loss': 0.7110178743799528, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 16:17:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.8211669921875, 'train_avg_loss': 0.6954607645670573, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 16:17:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 333.8211669921875, 'train_avg_loss': 0.6954607645670573, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 16:17:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:17:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:17:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:18:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:18:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.927673, avg_loss=0.693599, seen=480, correct=244, accuracy=0.508333
2025-10-09 16:18:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:18:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:18:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:18:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2236MB allocated=2065MB
2025-10-09 16:18:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.01209008693695, 'train_avg_loss': 0.7001007507244746, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 16:18:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.92767333984375, 'train_avg_loss': 0.6935993194580078, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 16:18:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 332.92767333984375, 'train_avg_loss': 0.6935993194580078, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 16:18:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:18:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:18:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:19:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:19:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.683441, avg_loss=0.701424, seen=480, correct=241, accuracy=0.502083
2025-10-09 16:19:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:19:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:19:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:19:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2236MB allocated=2065MB
2025-10-09 16:19:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.17503499984741, 'train_avg_loss': 0.693125291665395, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 16:19:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.6834411621094, 'train_avg_loss': 0.7014238357543945, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 16:19:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 336.6834411621094, 'train_avg_loss': 0.7014238357543945, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 16:19:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:19:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:19:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:19:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:19:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.690094, avg_loss=0.697271, seen=480, correct=245, accuracy=0.510417
2025-10-09 16:19:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:19:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:19:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:19:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2236MB allocated=2065MB
2025-10-09 16:19:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45232665538788, 'train_avg_loss': 0.678769388794899, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 16:19:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.6900939941406, 'train_avg_loss': 0.6972710291544596, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 16:19:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 334.6900939941406, 'train_avg_loss': 0.6972710291544596, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 16:19:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #158) -------------
2025-10-09 16:19:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=158 aidx=6 | s=5 (candidates=5)
2025-10-09 16:19:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 25, 24, 30, 44] (from 5)
2025-10-09 16:20:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:20:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:20:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:20:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:20:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.825500, avg_loss=0.691303, seen=480, correct=264, accuracy=0.550000
2025-10-09 16:20:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:20:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:20:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:20:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2236MB allocated=2065MB
2025-10-09 16:20:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.39670294523239, 'train_avg_loss': 0.6949725245436033, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 16:20:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.82550048828125, 'train_avg_loss': 0.6913031260172526, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 16:20:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 331.82550048828125, 'train_avg_loss': 0.6913031260172526, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 16:20:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:20:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:20:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-09 16:20:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:20:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:20:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:20:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:20:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:20:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:21:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:21:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.832458, avg_loss=0.695484, seen=480, correct=255, accuracy=0.531250
2025-10-09 16:21:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:21:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:21:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:21:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2236MB allocated=2065MB
2025-10-09 16:21:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.58534133434296, 'train_avg_loss': 0.6882111777861913, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 16:21:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.83245849609375, 'train_avg_loss': 0.6954842885335286, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:21:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 333.83245849609375, 'train_avg_loss': 0.6954842885335286, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:21:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:21:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:21:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-09 16:21:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:21:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:21:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:21:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:21:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:21:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:22:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:22:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.544128, avg_loss=0.703217, seen=480, correct=231, accuracy=0.481250
2025-10-09 16:22:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:22:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:22:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:22:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2236MB allocated=2065MB
2025-10-09 16:22:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.06723403930664, 'train_avg_loss': 0.7005602836608886, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:22:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.54412841796875, 'train_avg_loss': 0.7032169342041016, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-09 16:22:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 337.54412841796875, 'train_avg_loss': 0.7032169342041016, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-09 16:22:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:22:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:22:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:22:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:22:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.388184, avg_loss=0.690392, seen=480, correct=255, accuracy=0.531250
2025-10-09 16:22:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:22:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:22:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:22:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2236MB allocated=2065MB
2025-10-09 16:22:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.82312881946564, 'train_avg_loss': 0.7068594068288803, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-09 16:22:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.38818359375, 'train_avg_loss': 0.6903920491536458, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:22:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 331.38818359375, 'train_avg_loss': 0.6903920491536458, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:22:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:22:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:22:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:23:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:23:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.438232, avg_loss=0.692580, seen=480, correct=249, accuracy=0.518750
2025-10-09 16:23:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:23:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:23:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:23:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2236MB allocated=2065MB
2025-10-09 16:23:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.52804505825043, 'train_avg_loss': 0.6794003754854202, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 16:23:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.438232421875, 'train_avg_loss': 0.6925796508789063, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 16:23:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 332.438232421875, 'train_avg_loss': 0.6925796508789063, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 16:23:33 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #159) -------------
2025-10-09 16:23:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=159 aidx=6 | s=5 (candidates=5)
2025-10-09 16:23:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 30, 25, 27, 24] (from 5)
2025-10-09 16:23:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:23:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:23:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-09 16:23:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:23:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:23:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:23:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:23:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:23:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:24:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:24:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.700256, avg_loss=0.688959, seen=480, correct=248, accuracy=0.516667
2025-10-09 16:24:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:24:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:24:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:24:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2236MB allocated=2065MB
2025-10-09 16:24:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.88383138179779, 'train_avg_loss': 0.6740319281816483, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 16:24:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.70025634765625, 'train_avg_loss': 0.6889588673909505, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 16:24:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 330.70025634765625, 'train_avg_loss': 0.6889588673909505, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 16:24:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:24:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:24:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:25:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:25:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.738312, avg_loss=0.691121, seen=480, correct=261, accuracy=0.543750
2025-10-09 16:25:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:25:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:25:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:25:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2236MB allocated=2065MB
2025-10-09 16:25:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.64916431903839, 'train_avg_loss': 0.7054097026586532, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 16:25:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.7383117675781, 'train_avg_loss': 0.6911214828491211, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 16:25:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 331.7383117675781, 'train_avg_loss': 0.6911214828491211, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 16:25:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:25:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:25:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-09 16:25:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:25:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:25:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:25:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:25:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:25:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:25:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:25:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.596771, avg_loss=0.692910, seen=480, correct=268, accuracy=0.558333
2025-10-09 16:25:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:25:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:25:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:25:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2236MB allocated=2065MB
2025-10-09 16:25:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06125843524933, 'train_avg_loss': 0.6838438202937444, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 16:25:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5967712402344, 'train_avg_loss': 0.6929099400838216, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:25:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 332.5967712402344, 'train_avg_loss': 0.6929099400838216, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:25:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:25:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:25:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:26:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:26:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.397156, avg_loss=0.690411, seen=480, correct=266, accuracy=0.554167
2025-10-09 16:26:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:26:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:26:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:26:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2236MB allocated=2065MB
2025-10-09 16:26:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.75036978721619, 'train_avg_loss': 0.6895864148934682, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 16:26:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.39715576171875, 'train_avg_loss': 0.6904107411702474, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:26:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 331.39715576171875, 'train_avg_loss': 0.6904107411702474, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:26:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:26:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:26:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:27:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:27:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.221497, avg_loss=0.702545, seen=480, correct=230, accuracy=0.479167
2025-10-09 16:27:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:27:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:27:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:27:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2236MB allocated=2065MB
2025-10-09 16:27:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.90847039222717, 'train_avg_loss': 0.6992372532685598, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:27:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.22149658203125, 'train_avg_loss': 0.7025447845458984, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 16:27:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 337.22149658203125, 'train_avg_loss': 0.7025447845458984, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 16:27:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #160) -------------
2025-10-09 16:27:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=160 aidx=6 | s=5 (candidates=5)
2025-10-09 16:27:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 27, 25, 24, 44] (from 5)
2025-10-09 16:27:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:27:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:27:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:28:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:28:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.517120, avg_loss=0.690661, seen=480, correct=250, accuracy=0.520833
2025-10-09 16:28:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:28:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:28:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:28:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2236MB allocated=2065MB
2025-10-09 16:28:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.4792582988739, 'train_avg_loss': 0.7039938191572825, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-09 16:28:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5171203613281, 'train_avg_loss': 0.6906606674194335, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 16:28:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 331.5171203613281, 'train_avg_loss': 0.6906606674194335, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 16:28:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:28:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:28:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:28:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:28:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.965088, avg_loss=0.689511, seen=480, correct=264, accuracy=0.550000
2025-10-09 16:28:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:28:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:28:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:28:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2236MB allocated=2065MB
2025-10-09 16:28:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.0919941663742, 'train_avg_loss': 0.692433284719785, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 16:28:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.965087890625, 'train_avg_loss': 0.6895105997721355, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 16:28:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 330.965087890625, 'train_avg_loss': 0.6895105997721355, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 16:28:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:28:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:28:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-09 16:28:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:28:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:28:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:28:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:28:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:28:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:29:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:29:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.217102, avg_loss=0.694202, seen=480, correct=269, accuracy=0.560417
2025-10-09 16:29:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:29:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:29:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:29:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2236MB allocated=2065MB
2025-10-09 16:29:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.75163781642914, 'train_avg_loss': 0.6895969818035762, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 16:29:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.21710205078125, 'train_avg_loss': 0.6942022959391276, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 16:29:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 333.21710205078125, 'train_avg_loss': 0.6942022959391276, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 16:29:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:29:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:29:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:30:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:30:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.611145, avg_loss=0.697107, seen=480, correct=235, accuracy=0.489583
2025-10-09 16:30:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:30:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:30:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:30:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2236MB allocated=2065MB
2025-10-09 16:30:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.52558714151382, 'train_avg_loss': 0.6960465595126152, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 16:30:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.61114501953125, 'train_avg_loss': 0.6971065521240234, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 16:30:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 334.61114501953125, 'train_avg_loss': 0.6971065521240234, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 16:30:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:30:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:30:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:30:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:30:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.854156, avg_loss=0.687196, seen=480, correct=263, accuracy=0.547917
2025-10-09 16:30:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:30:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:30:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:30:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2236MB allocated=2065MB
2025-10-09 16:31:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.90899789333344, 'train_avg_loss': 0.674241649111112, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 16:31:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8541564941406, 'train_avg_loss': 0.687196159362793, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:31:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 329.8541564941406, 'train_avg_loss': 0.687196159362793, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:31:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #161) -------------
2025-10-09 16:31:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=161 aidx=6 | s=5 (candidates=5)
2025-10-09 16:31:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 27, 30, 24, 44] (from 5)
2025-10-09 16:31:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:31:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:31:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:31:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:31:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.631470, avg_loss=0.688816, seen=480, correct=262, accuracy=0.545833
2025-10-09 16:31:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:31:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:31:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:31:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2236MB allocated=2065MB
2025-10-09 16:31:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06789898872375, 'train_avg_loss': 0.6838991582393646, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 16:31:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.6314697265625, 'train_avg_loss': 0.6888155619303385, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 16:31:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 330.6314697265625, 'train_avg_loss': 0.6888155619303385, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 16:31:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:31:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:31:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:32:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:32:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.819977, avg_loss=0.689208, seen=480, correct=261, accuracy=0.543750
2025-10-09 16:32:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:32:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:32:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:32:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2236MB allocated=2065MB
2025-10-09 16:32:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.42758393287659, 'train_avg_loss': 0.6868965327739716, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 16:32:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8199768066406, 'train_avg_loss': 0.6892082850138347, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 16:32:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 330.8199768066406, 'train_avg_loss': 0.6892082850138347, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 16:32:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:32:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:32:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:33:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:33:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.317352, avg_loss=0.690244, seen=480, correct=259, accuracy=0.539583
2025-10-09 16:33:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:33:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:33:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:33:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2236MB allocated=2065MB
2025-10-09 16:33:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.77551102638245, 'train_avg_loss': 0.7064625918865204, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 16:33:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3173522949219, 'train_avg_loss': 0.690244483947754, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 16:33:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 331.3173522949219, 'train_avg_loss': 0.690244483947754, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 16:33:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:33:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:33:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:33:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:33:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.863770, avg_loss=0.697633, seen=480, correct=236, accuracy=0.491667
2025-10-09 16:33:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:33:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:33:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:33:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2236MB allocated=2065MB
2025-10-09 16:33:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.46643912792206, 'train_avg_loss': 0.6955536593993504, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 16:33:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.86376953125, 'train_avg_loss': 0.6976328531901042, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 16:33:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 334.86376953125, 'train_avg_loss': 0.6976328531901042, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 16:33:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:33:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:33:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-09 16:33:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:33:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:33:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:33:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:33:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:33:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:34:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:34:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.833832, avg_loss=0.682987, seen=480, correct=259, accuracy=0.539583
2025-10-09 16:34:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:34:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:34:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:34:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2236MB allocated=2065MB
2025-10-09 16:34:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.82523655891418, 'train_avg_loss': 0.6735436379909515, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 16:34:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8338317871094, 'train_avg_loss': 0.6829871495564779, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 16:34:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 327.8338317871094, 'train_avg_loss': 0.6829871495564779, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 16:34:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #162) -------------
2025-10-09 16:34:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=162 aidx=6 | s=5 (candidates=5)
2025-10-09 16:34:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 27, 24, 25, 30] (from 5)
2025-10-09 16:34:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:34:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:34:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:35:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:35:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.632843, avg_loss=0.678402, seen=480, correct=275, accuracy=0.572917
2025-10-09 16:35:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:35:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:35:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:35:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2236MB allocated=2065MB
2025-10-09 16:35:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.46131324768066, 'train_avg_loss': 0.6621776103973389, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 16:35:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6328430175781, 'train_avg_loss': 0.6784017562866211, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 16:35:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 325.6328430175781, 'train_avg_loss': 0.6784017562866211, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 16:35:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:35:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:35:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-09 16:35:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:35:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:35:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:35:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:35:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:35:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:36:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:36:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.551849, avg_loss=0.690733, seen=480, correct=251, accuracy=0.522917
2025-10-09 16:36:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:36:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:36:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:36:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2236MB allocated=2065MB
2025-10-09 16:36:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.11853474378586, 'train_avg_loss': 0.6926544561982155, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 16:36:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5518493652344, 'train_avg_loss': 0.6907330195109049, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 16:36:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 331.5518493652344, 'train_avg_loss': 0.6907330195109049, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 16:36:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:36:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:36:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:36:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:36:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.462952, avg_loss=0.696798, seen=480, correct=245, accuracy=0.510417
2025-10-09 16:36:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:36:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:36:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:36:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2236MB allocated=2065MB
2025-10-09 16:36:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.53698980808258, 'train_avg_loss': 0.6961415817340215, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 16:36:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.46295166015625, 'train_avg_loss': 0.6967978159586589, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 16:36:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 334.46295166015625, 'train_avg_loss': 0.6967978159586589, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 16:36:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:36:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:36:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-09 16:36:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:36:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:36:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:36:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:36:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:37:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:37:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.719574, avg_loss=0.688999, seen=480, correct=266, accuracy=0.554167
2025-10-09 16:37:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:37:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:37:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:37:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2236MB allocated=2065MB
2025-10-09 16:37:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.65896332263947, 'train_avg_loss': 0.6804913610219956, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 16:37:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.7195739746094, 'train_avg_loss': 0.6889991124471029, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:37:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 330.7195739746094, 'train_avg_loss': 0.6889991124471029, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:37:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:37:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:37:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-09 16:37:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:37:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:37:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:37:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:37:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:37:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:38:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:38:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.693512, avg_loss=0.686861, seen=480, correct=264, accuracy=0.550000
2025-10-09 16:38:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:38:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:38:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:38:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2236MB allocated=2065MB
2025-10-09 16:38:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.59920156002045, 'train_avg_loss': 0.7049933463335037, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 16:38:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6935119628906, 'train_avg_loss': 0.6868614832560221, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 16:38:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 329.6935119628906, 'train_avg_loss': 0.6868614832560221, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 16:38:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #163) -------------
2025-10-09 16:38:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=163 aidx=6 | s=5 (candidates=5)
2025-10-09 16:38:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 30, 27, 44, 24] (from 5)
2025-10-09 16:38:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:38:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:38:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-09 16:38:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:38:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:38:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:38:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:38:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:38:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:39:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:39:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.921021, avg_loss=0.689419, seen=480, correct=271, accuracy=0.564583
2025-10-09 16:39:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:39:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:39:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:39:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2236MB allocated=2065MB
2025-10-09 16:39:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.01181089878082, 'train_avg_loss': 0.6834317574898402, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 16:39:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9210205078125, 'train_avg_loss': 0.6894187927246094, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 16:39:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 330.9210205078125, 'train_avg_loss': 0.6894187927246094, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 16:39:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:39:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:39:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:39:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:39:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.570801, avg_loss=0.682439, seen=480, correct=265, accuracy=0.552083
2025-10-09 16:39:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:39:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:39:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:39:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2236MB allocated=2065MB
2025-10-09 16:39:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.83788001537323, 'train_avg_loss': 0.6986490001281103, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 16:39:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.57080078125, 'train_avg_loss': 0.6824391682942709, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 16:39:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 327.57080078125, 'train_avg_loss': 0.6824391682942709, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 16:39:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:39:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:39:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:40:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:40:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.541260, avg_loss=0.690711, seen=480, correct=268, accuracy=0.558333
2025-10-09 16:40:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:40:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:40:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:40:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2236MB allocated=2065MB
2025-10-09 16:40:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.25882196426392, 'train_avg_loss': 0.693823516368866, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 16:40:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.541259765625, 'train_avg_loss': 0.6907109578450521, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:40:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 331.541259765625, 'train_avg_loss': 0.6907109578450521, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:40:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:40:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:40:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-09 16:40:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:40:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:40:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:40:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:40:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:40:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:41:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:41:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.636169, avg_loss=0.676325, seen=480, correct=279, accuracy=0.581250
2025-10-09 16:41:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:41:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:41:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:41:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2236MB allocated=2065MB
2025-10-09 16:41:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.02534121274948, 'train_avg_loss': 0.6585445101062457, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 16:41:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.63616943359375, 'train_avg_loss': 0.6763253529866536, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 16:41:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 324.63616943359375, 'train_avg_loss': 0.6763253529866536, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 16:41:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:41:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:41:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-09 16:41:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:41:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:41:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:41:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:41:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:41:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:42:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:42:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.606079, avg_loss=0.695013, seen=480, correct=239, accuracy=0.497917
2025-10-09 16:42:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:42:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:42:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:42:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2236MB allocated=2065MB
2025-10-09 16:42:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5796474814415, 'train_avg_loss': 0.6964970623453458, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 16:42:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.6060791015625, 'train_avg_loss': 0.6950126647949219, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 16:42:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 333.6060791015625, 'train_avg_loss': 0.6950126647949219, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 16:42:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #164) -------------
2025-10-09 16:42:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=164 aidx=6 | s=5 (candidates=5)
2025-10-09 16:42:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 30, 24, 25, 44] (from 5)
2025-10-09 16:42:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:42:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:42:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:42:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:42:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.393707, avg_loss=0.688320, seen=480, correct=266, accuracy=0.554167
2025-10-09 16:42:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:42:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:42:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:42:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2236MB allocated=2065MB
2025-10-09 16:42:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.8880078792572, 'train_avg_loss': 0.69073339899381, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 16:42:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3937072753906, 'train_avg_loss': 0.6883202234903971, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:42:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 330.3937072753906, 'train_avg_loss': 0.6883202234903971, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:42:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:42:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:42:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-09 16:42:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:42:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:42:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:42:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:42:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:42:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:43:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:43:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.580292, avg_loss=0.684542, seen=480, correct=263, accuracy=0.547917
2025-10-09 16:43:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:43:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:43:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:43:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2236MB allocated=2065MB
2025-10-09 16:43:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.15270590782166, 'train_avg_loss': 0.7012725492318471, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 16:43:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.5802917480469, 'train_avg_loss': 0.6845422744750976, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:43:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 328.5802917480469, 'train_avg_loss': 0.6845422744750976, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:43:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:43:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:43:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-09 16:43:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:43:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:43:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:43:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:43:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:43:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:44:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:44:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.910339, avg_loss=0.689397, seen=480, correct=253, accuracy=0.527083
2025-10-09 16:44:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:44:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:44:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:44:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2236MB allocated=2065MB
2025-10-09 16:44:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.04356586933136, 'train_avg_loss': 0.6920297155777614, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:44:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.91033935546875, 'train_avg_loss': 0.6893965403238932, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 16:44:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 330.91033935546875, 'train_avg_loss': 0.6893965403238932, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 16:44:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:44:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:44:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-09 16:44:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:44:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:44:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:44:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:44:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:44:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:44:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:44:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.573059, avg_loss=0.690777, seen=480, correct=270, accuracy=0.562500
2025-10-09 16:44:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:44:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:45:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:45:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2236MB allocated=2065MB
2025-10-09 16:45:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.86339592933655, 'train_avg_loss': 0.6821949660778046, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 16:45:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.57305908203125, 'train_avg_loss': 0.6907772064208985, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 16:45:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 331.57305908203125, 'train_avg_loss': 0.6907772064208985, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 16:45:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:45:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:45:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-09 16:45:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:45:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:45:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:45:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:45:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:45:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:45:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:45:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.834564, avg_loss=0.676739, seen=480, correct=275, accuracy=0.572917
2025-10-09 16:45:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:45:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:45:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:45:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2236MB allocated=2065MB
2025-10-09 16:45:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.07814812660217, 'train_avg_loss': 0.6589845677216848, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 16:45:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.8345642089844, 'train_avg_loss': 0.6767386754353841, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 16:45:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 324.8345642089844, 'train_avg_loss': 0.6767386754353841, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 16:45:49 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #165) -------------
2025-10-09 16:45:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=165 aidx=6 | s=5 (candidates=5)
2025-10-09 16:45:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 25, 44, 30, 27] (from 5)
2025-10-09 16:45:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:45:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:45:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:46:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:46:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.277374, avg_loss=0.690161, seen=480, correct=246, accuracy=0.512500
2025-10-09 16:46:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:46:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:46:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:46:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2236MB allocated=2065MB
2025-10-09 16:46:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.90565979480743, 'train_avg_loss': 0.6908804982900619, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 16:46:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2773742675781, 'train_avg_loss': 0.6901611963907878, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 16:46:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 331.2773742675781, 'train_avg_loss': 0.6901611963907878, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 16:46:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:46:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:46:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-09 16:46:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:46:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:46:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:46:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:46:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:46:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:47:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:47:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.777283, avg_loss=0.689119, seen=480, correct=266, accuracy=0.554167
2025-10-09 16:47:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:47:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:47:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:47:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2236MB allocated=2065MB
2025-10-09 16:47:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99248856306076, 'train_avg_loss': 0.6832707380255063, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 16:47:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.77728271484375, 'train_avg_loss': 0.6891193389892578, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:47:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 330.77728271484375, 'train_avg_loss': 0.6891193389892578, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 16:47:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:47:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:47:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:47:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:47:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.514282, avg_loss=0.671905, seen=480, correct=278, accuracy=0.579167
2025-10-09 16:47:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:47:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:48:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:48:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2236MB allocated=2065MB
2025-10-09 16:48:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.29769718647003, 'train_avg_loss': 0.6524808098872502, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 16:48:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.5142822265625, 'train_avg_loss': 0.6719047546386718, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 16:48:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 322.5142822265625, 'train_avg_loss': 0.6719047546386718, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 16:48:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:48:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:48:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:48:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:48:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.852478, avg_loss=0.683026, seen=480, correct=256, accuracy=0.533333
2025-10-09 16:48:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:48:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:48:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:48:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2236MB allocated=2065MB
2025-10-09 16:48:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.33958673477173, 'train_avg_loss': 0.7028298894564311, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 16:48:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.85247802734375, 'train_avg_loss': 0.6830259958902994, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 16:48:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 327.85247802734375, 'train_avg_loss': 0.6830259958902994, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 16:48:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:48:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:48:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:49:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:49:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.067444, avg_loss=0.689724, seen=480, correct=263, accuracy=0.547917
2025-10-09 16:49:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:49:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:49:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:49:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2236MB allocated=2065MB
2025-10-09 16:49:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.52793145179749, 'train_avg_loss': 0.6877327620983124, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 16:49:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.06744384765625, 'train_avg_loss': 0.6897238413492839, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:49:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 331.06744384765625, 'train_avg_loss': 0.6897238413492839, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:49:33 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #166) -------------
2025-10-09 16:49:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=166 aidx=6 | s=5 (candidates=5)
2025-10-09 16:49:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 25, 24, 30, 44] (from 5)
2025-10-09 16:49:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:49:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:49:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:50:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:50:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.369965, avg_loss=0.684104, seen=480, correct=270, accuracy=0.562500
2025-10-09 16:50:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:50:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:50:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:50:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2236MB allocated=2065MB
2025-10-09 16:50:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.15631020069122, 'train_avg_loss': 0.6846359183390935, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 16:50:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3699645996094, 'train_avg_loss': 0.6841040929158528, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 16:50:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 328.3699645996094, 'train_avg_loss': 0.6841040929158528, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 16:50:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:50:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:50:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-09 16:50:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:50:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:50:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:50:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:50:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:50:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:50:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:50:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.790070, avg_loss=0.689146, seen=480, correct=275, accuracy=0.572917
2025-10-09 16:50:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:50:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:50:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:50:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2236MB allocated=2065MB
2025-10-09 16:50:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63661593198776, 'train_avg_loss': 0.6803051327665647, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 16:50:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.7900695800781, 'train_avg_loss': 0.6891459782918294, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 16:50:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 330.7900695800781, 'train_avg_loss': 0.6891459782918294, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 16:50:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:51:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:51:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:51:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:51:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.983643, avg_loss=0.691633, seen=480, correct=253, accuracy=0.527083
2025-10-09 16:51:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:51:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:51:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:51:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2236MB allocated=2065MB
2025-10-09 16:51:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.30384600162506, 'train_avg_loss': 0.6941987166802088, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 16:51:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.983642578125, 'train_avg_loss': 0.6916325887044271, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 16:51:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 331.983642578125, 'train_avg_loss': 0.6916325887044271, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 16:51:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:51:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:51:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-09 16:51:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:51:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:51:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:51:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:51:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:51:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:52:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:52:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.471313, avg_loss=0.682232, seen=480, correct=255, accuracy=0.531250
2025-10-09 16:52:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:52:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:52:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:52:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2236MB allocated=2065MB
2025-10-09 16:52:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12757420539856, 'train_avg_loss': 0.7010631183783214, 'train_seen': 120, 'train_correct': 50, 'train_acc': 0.4166666666666667}}
2025-10-09 16:52:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.4713134765625, 'train_avg_loss': 0.6822319030761719, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:52:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 327.4713134765625, 'train_avg_loss': 0.6822319030761719, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:52:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:52:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:52:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-09 16:52:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:52:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:52:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:52:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:52:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:52:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:53:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:53:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.731415, avg_loss=0.670274, seen=480, correct=281, accuracy=0.585417
2025-10-09 16:53:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:53:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:53:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:53:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2236MB allocated=2065MB
2025-10-09 16:53:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.68506795167923, 'train_avg_loss': 0.6557088995973269, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 16:53:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.7314147949219, 'train_avg_loss': 0.6702737808227539, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 16:53:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 321.7314147949219, 'train_avg_loss': 0.6702737808227539, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 16:53:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #167) -------------
2025-10-09 16:53:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=167 aidx=6 | s=5 (candidates=5)
2025-10-09 16:53:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 25, 27, 24, 44] (from 5)
2025-10-09 16:53:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:53:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:53:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-09 16:53:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:53:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:53:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:53:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:53:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:53:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:53:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:53:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.082336, avg_loss=0.683505, seen=480, correct=255, accuracy=0.531250
2025-10-09 16:53:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:53:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:53:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:53:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2236MB allocated=2065MB
2025-10-09 16:53:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.53292661905289, 'train_avg_loss': 0.7044410551587741, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 16:53:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.08233642578125, 'train_avg_loss': 0.683504867553711, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:53:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 328.08233642578125, 'train_avg_loss': 0.683504867553711, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:53:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:54:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:54:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:54:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:54:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.303802, avg_loss=0.686050, seen=480, correct=268, accuracy=0.558333
2025-10-09 16:54:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:54:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:54:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:54:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2236MB allocated=2065MB
2025-10-09 16:54:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.49906462430954, 'train_avg_loss': 0.6791588718692462, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 16:54:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3038024902344, 'train_avg_loss': 0.6860495885213216, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:54:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 329.3038024902344, 'train_avg_loss': 0.6860495885213216, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:54:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:54:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:54:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:55:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:55:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.093872, avg_loss=0.681446, seen=480, correct=277, accuracy=0.577083
2025-10-09 16:55:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:55:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:55:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:55:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2236MB allocated=2065MB
2025-10-09 16:55:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.18175482749939, 'train_avg_loss': 0.6765146235624949, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 16:55:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.0938720703125, 'train_avg_loss': 0.681445566813151, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 16:55:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 327.0938720703125, 'train_avg_loss': 0.681445566813151, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 16:55:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:55:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:55:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:56:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:56:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.104126, avg_loss=0.689800, seen=480, correct=250, accuracy=0.520833
2025-10-09 16:56:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:56:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:56:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:56:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2236MB allocated=2065MB
2025-10-09 16:56:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.01127088069916, 'train_avg_loss': 0.691760590672493, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 16:56:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1041259765625, 'train_avg_loss': 0.6898002624511719, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 16:56:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 331.1041259765625, 'train_avg_loss': 0.6898002624511719, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 16:56:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:56:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:56:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-09 16:56:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:56:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:56:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:56:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:56:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:56:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:56:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:56:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.217133, avg_loss=0.665036, seen=480, correct=291, accuracy=0.606250
2025-10-09 16:56:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:56:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:56:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:56:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2236MB allocated=2065MB
2025-10-09 16:56:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.40249359607697, 'train_avg_loss': 0.645020779967308, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 16:56:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.2171325683594, 'train_avg_loss': 0.6650356928507487, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 16:56:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 319.2171325683594, 'train_avg_loss': 0.6650356928507487, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 16:56:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #168) -------------
2025-10-09 16:56:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=168 aidx=6 | s=5 (candidates=5)
2025-10-09 16:56:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 25, 27, 24, 30] (from 5)
2025-10-09 16:56:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 16:56:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:56:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:57:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:57:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.736298, avg_loss=0.655701, seen=480, correct=296, accuracy=0.616667
2025-10-09 16:57:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:57:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:57:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:57:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2236MB allocated=2065MB
2025-10-09 16:57:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.13461220264435, 'train_avg_loss': 0.6344551016887029, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 16:57:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.7362976074219, 'train_avg_loss': 0.6557006200154623, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 16:57:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 314.7362976074219, 'train_avg_loss': 0.6557006200154623, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 16:57:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 16:57:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:57:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:58:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:58:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.451477, avg_loss=0.686357, seen=480, correct=268, accuracy=0.558333
2025-10-09 16:58:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:58:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:58:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:58:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2236MB allocated=2065MB
2025-10-09 16:58:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.1346988081932, 'train_avg_loss': 0.6761224900682767, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 16:58:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.45147705078125, 'train_avg_loss': 0.6863572438557942, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:58:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 329.45147705078125, 'train_avg_loss': 0.6863572438557942, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 16:58:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:58:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:58:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-09 16:58:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 16:58:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:58:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:58:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:58:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:58:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:59:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:59:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.670593, avg_loss=0.684730, seen=480, correct=263, accuracy=0.547917
2025-10-09 16:59:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:59:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:59:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:59:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2236MB allocated=2065MB
2025-10-09 16:59:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58167904615402, 'train_avg_loss': 0.6798473253846169, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 16:59:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.67059326171875, 'train_avg_loss': 0.6847304026285808, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:59:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 328.67059326171875, 'train_avg_loss': 0.6847304026285808, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 16:59:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:59:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:59:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-09 16:59:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 16:59:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:59:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:59:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:59:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:59:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 16:59:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 16:59:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.465393, avg_loss=0.688470, seen=480, correct=255, accuracy=0.531250
2025-10-09 16:59:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 16:59:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:59:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 16:59:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2236MB allocated=2065MB
2025-10-09 16:59:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.21389853954315, 'train_avg_loss': 0.6934491544961929, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 16:59:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.46539306640625, 'train_avg_loss': 0.6884695688883463, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:59:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 330.46539306640625, 'train_avg_loss': 0.6884695688883463, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 16:59:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 16:59:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 16:59:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:00:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:00:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.389648, avg_loss=0.684145, seen=480, correct=262, accuracy=0.545833
2025-10-09 17:00:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:00:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:00:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:00:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2236MB allocated=2065MB
2025-10-09 17:00:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.45120745897293, 'train_avg_loss': 0.7037600621581077, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 17:00:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3896484375, 'train_avg_loss': 0.6841451009114583, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:00:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 328.3896484375, 'train_avg_loss': 0.6841451009114583, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:00:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #169) -------------
2025-10-09 17:00:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=169 aidx=6 | s=5 (candidates=5)
2025-10-09 17:00:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 30, 25, 24, 44] (from 5)
2025-10-09 17:00:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 17:00:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:00:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:01:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:01:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.638306, avg_loss=0.684663, seen=480, correct=280, accuracy=0.583333
2025-10-09 17:01:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:01:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:01:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:01:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2236MB allocated=2065MB
2025-10-09 17:01:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.7708078622818, 'train_avg_loss': 0.6814233988523484, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 17:01:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.6383056640625, 'train_avg_loss': 0.6846631368001302, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 17:01:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 328.6383056640625, 'train_avg_loss': 0.6846631368001302, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 17:01:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:01:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:01:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-09 17:01:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 17:01:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:01:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:01:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:01:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:01:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:02:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:02:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.267334, avg_loss=0.673474, seen=480, correct=271, accuracy=0.564583
2025-10-09 17:02:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:02:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:02:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:02:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2236MB allocated=2065MB
2025-10-09 17:02:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.06219631433487, 'train_avg_loss': 0.6921849692861239, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 17:02:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.267333984375, 'train_avg_loss': 0.673473612467448, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 17:02:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 323.267333984375, 'train_avg_loss': 0.673473612467448, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 17:02:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 17:02:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:02:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:02:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:02:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.622986, avg_loss=0.686715, seen=480, correct=268, accuracy=0.558333
2025-10-09 17:02:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:02:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:02:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:02:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2236MB allocated=2065MB
2025-10-09 17:02:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.32280838489532, 'train_avg_loss': 0.6776900698741277, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 17:02:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.62298583984375, 'train_avg_loss': 0.6867145538330078, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:02:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 329.62298583984375, 'train_avg_loss': 0.6867145538330078, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:02:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 17:02:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:02:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:03:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:03:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.434387, avg_loss=0.690488, seen=480, correct=249, accuracy=0.518750
2025-10-09 17:03:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:03:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:03:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:03:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2236MB allocated=2065MB
2025-10-09 17:03:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49503588676453, 'train_avg_loss': 0.6957919657230377, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 17:03:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.43438720703125, 'train_avg_loss': 0.6904883066813151, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:03:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 331.43438720703125, 'train_avg_loss': 0.6904883066813151, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:03:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 17:03:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:03:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:04:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:04:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.526855, avg_loss=0.653181, seen=480, correct=301, accuracy=0.627083
2025-10-09 17:04:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:04:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:04:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:04:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2236MB allocated=2065MB
2025-10-09 17:04:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.93895041942596, 'train_avg_loss': 0.6244912534952164, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 17:04:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.52685546875, 'train_avg_loss': 0.6531809488932292, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 17:04:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 313.52685546875, 'train_avg_loss': 0.6531809488932292, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 17:04:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #170) -------------
2025-10-09 17:04:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=170 aidx=6 | s=5 (candidates=5)
2025-10-09 17:04:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 44, 25, 24, 27] (from 5)
2025-10-09 17:04:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:04:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:04:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-09 17:04:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 17:04:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:04:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:04:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:04:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:04:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:04:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:04:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.502716, avg_loss=0.673964, seen=480, correct=266, accuracy=0.554167
2025-10-09 17:04:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:04:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:04:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:05:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2236MB allocated=2065MB
2025-10-09 17:05:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.13962000608444, 'train_avg_loss': 0.7011635000507037, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 17:05:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.5027160644531, 'train_avg_loss': 0.673963991800944, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 17:05:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 323.5027160644531, 'train_avg_loss': 0.673963991800944, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 17:05:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 17:05:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:05:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:05:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:05:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.484283, avg_loss=0.642676, seen=480, correct=304, accuracy=0.633333
2025-10-09 17:05:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:05:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:05:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:05:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2236MB allocated=2065MB
2025-10-09 17:05:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.42163610458374, 'train_avg_loss': 0.6118469675381978, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 17:05:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.4842834472656, 'train_avg_loss': 0.6426755905151367, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 17:05:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 308.4842834472656, 'train_avg_loss': 0.6426755905151367, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 17:05:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:05:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:05:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-09 17:05:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 17:05:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:05:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:05:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:05:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:05:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:06:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:06:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.668488, avg_loss=0.686809, seen=480, correct=267, accuracy=0.556250
2025-10-09 17:06:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:06:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:06:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:06:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2236MB allocated=2065MB
2025-10-09 17:06:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51840388774872, 'train_avg_loss': 0.679320032397906, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 17:06:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6684875488281, 'train_avg_loss': 0.6868093490600586, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 17:06:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 329.6684875488281, 'train_avg_loss': 0.6868093490600586, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 17:06:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:06:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:06:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-09 17:06:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 17:06:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:06:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:06:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:06:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:06:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:07:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:07:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.355957, avg_loss=0.692408, seen=480, correct=253, accuracy=0.527083
2025-10-09 17:07:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:07:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:07:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:07:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2236MB allocated=2065MB
2025-10-09 17:07:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.21095532178879, 'train_avg_loss': 0.6934246276815732, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 17:07:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.35595703125, 'train_avg_loss': 0.6924082438151041, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 17:07:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 332.35595703125, 'train_avg_loss': 0.6924082438151041, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 17:07:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 17:07:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:07:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:07:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:07:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.536652, avg_loss=0.686535, seen=480, correct=269, accuracy=0.560417
2025-10-09 17:07:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:07:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:07:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:07:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2236MB allocated=2065MB
2025-10-09 17:07:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60695719718933, 'train_avg_loss': 0.6883913099765777, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 17:07:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5366516113281, 'train_avg_loss': 0.6865346908569336, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 17:07:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 329.5366516113281, 'train_avg_loss': 0.6865346908569336, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 17:07:54 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #171) -------------
2025-10-09 17:07:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=171 aidx=6 | s=5 (candidates=5)
2025-10-09 17:07:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 30, 25, 44, 24] (from 5)
2025-10-09 17:07:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-09 17:07:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:07:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:08:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:08:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.493500, avg_loss=0.676028, seen=480, correct=276, accuracy=0.575000
2025-10-09 17:08:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:08:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:08:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:08:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2236MB allocated=2065MB
2025-10-09 17:08:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.83758115768433, 'train_avg_loss': 0.6736465096473694, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 17:08:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.4934997558594, 'train_avg_loss': 0.6760281244913737, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 17:08:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 324.4934997558594, 'train_avg_loss': 0.6760281244913737, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 17:08:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:08:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:08:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-09 17:08:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-09 17:08:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:08:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:08:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:08:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:08:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:09:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:09:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.397705, avg_loss=0.673745, seen=480, correct=269, accuracy=0.560417
2025-10-09 17:09:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:09:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:09:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:09:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2236MB allocated=2065MB
2025-10-09 17:09:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.62275528907776, 'train_avg_loss': 0.696856294075648, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 17:09:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.397705078125, 'train_avg_loss': 0.6737452189127604, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 17:09:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 323.397705078125, 'train_avg_loss': 0.6737452189127604, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 17:09:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-09 17:09:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:09:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:10:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:10:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.126526, avg_loss=0.685680, seen=480, correct=268, accuracy=0.558333
2025-10-09 17:10:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:10:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:10:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:10:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2236MB allocated=2065MB
2025-10-09 17:10:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51277685165405, 'train_avg_loss': 0.6792731404304504, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 17:10:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.12652587890625, 'train_avg_loss': 0.6856802622477214, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:10:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 329.12652587890625, 'train_avg_loss': 0.6856802622477214, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:10:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-09 17:10:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:10:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:10:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:10:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.917633, avg_loss=0.645662, seen=480, correct=310, accuracy=0.645833
2025-10-09 17:10:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:10:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:10:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:10:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2236MB allocated=2065MB
2025-10-09 17:10:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.84092551469803, 'train_avg_loss': 0.615341045955817, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 17:10:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.9176330566406, 'train_avg_loss': 0.645661735534668, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 17:10:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 309.9176330566406, 'train_avg_loss': 0.645661735534668, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 17:10:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:10:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:10:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-09 17:10:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-09 17:10:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:10:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:10:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:10:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:10:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:11:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:11:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.144867, avg_loss=0.691968, seen=480, correct=244, accuracy=0.508333
2025-10-09 17:11:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:11:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:11:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:11:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2236MB allocated=2065MB
2025-10-09 17:11:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6871446967125, 'train_avg_loss': 0.6973928724726041, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 17:11:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.1448669433594, 'train_avg_loss': 0.6919684727986654, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:11:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 332.1448669433594, 'train_avg_loss': 0.6919684727986654, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:11:36 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #172) -------------
2025-10-09 17:11:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=172 aidx=7 | s=5 (candidates=6)
2025-10-09 17:11:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 34, 47, 29, 1] (from 6)
2025-10-09 17:11:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:11:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:11:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:12:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:12:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.567566, avg_loss=0.713682, seen=480, correct=235, accuracy=0.489583
2025-10-09 17:12:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:12:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:12:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:12:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2260MB allocated=2149MB
2025-10-09 17:12:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.98711919784546, 'train_avg_loss': 0.7082259933153788, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:12:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.56756591796875, 'train_avg_loss': 0.7136824289957683, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 17:12:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 342.56756591796875, 'train_avg_loss': 0.7136824289957683, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 17:12:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:12:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:12:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-09 17:12:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:12:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:12:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:12:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:12:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:12:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:13:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:13:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.431458, avg_loss=0.717566, seen=480, correct=236, accuracy=0.491667
2025-10-09 17:13:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:13:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:13:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:13:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2298MB allocated=2157MB
2025-10-09 17:13:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.56895357370377, 'train_avg_loss': 0.7130746131141981, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 17:13:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.43145751953125, 'train_avg_loss': 0.7175655364990234, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 17:13:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 344.43145751953125, 'train_avg_loss': 0.7175655364990234, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 17:13:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:13:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:13:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:13:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:13:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.184204, avg_loss=0.702467, seen=480, correct=264, accuracy=0.550000
2025-10-09 17:13:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:13:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:13:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:13:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2286MB allocated=2166MB
2025-10-09 17:13:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.53593474626541, 'train_avg_loss': 0.754466122885545, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 17:13:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.1842041015625, 'train_avg_loss': 0.7024670918782552, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 17:13:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 337.1842041015625, 'train_avg_loss': 0.7024670918782552, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 17:13:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:13:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:13:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-09 17:13:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:13:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:13:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:13:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:13:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:13:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:14:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:14:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.391479, avg_loss=0.719566, seen=480, correct=237, accuracy=0.493750
2025-10-09 17:14:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:14:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:14:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:14:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2354MB allocated=2174MB
2025-10-09 17:14:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.87947368621826, 'train_avg_loss': 0.7156622807184855, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 17:14:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.3914794921875, 'train_avg_loss': 0.7195655822753906, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 17:14:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 345.3914794921875, 'train_avg_loss': 0.7195655822753906, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 17:14:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:14:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:14:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-09 17:14:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:14:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:14:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:14:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:14:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:14:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:15:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:15:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=346.079529, avg_loss=0.720999, seen=480, correct=237, accuracy=0.493750
2025-10-09 17:15:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:15:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:15:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:15:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2302MB allocated=2183MB
2025-10-09 17:15:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.16333872079849, 'train_avg_loss': 0.701361156006654, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 17:15:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 346.07952880859375, 'train_avg_loss': 0.720999018351237, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 17:15:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 346.07952880859375, 'train_avg_loss': 0.720999018351237, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 17:15:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #173) -------------
2025-10-09 17:15:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=173 aidx=7 | s=5 (candidates=6)
2025-10-09 17:15:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 29, 1, 45, 47] (from 6)
2025-10-09 17:15:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:15:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:15:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:16:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:16:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.033081, avg_loss=0.712569, seen=480, correct=228, accuracy=0.475000
2025-10-09 17:16:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:16:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:16:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:16:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2352MB allocated=2183MB
2025-10-09 17:16:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47585737705231, 'train_avg_loss': 0.7039654781421025, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 17:16:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.0330810546875, 'train_avg_loss': 0.7125689188639323, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-09 17:16:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 342.0330810546875, 'train_avg_loss': 0.7125689188639323, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-09 17:16:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:16:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:16:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-09 17:16:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:16:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:16:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:16:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:16:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:16:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:16:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:16:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.281250, avg_loss=0.704753, seen=480, correct=242, accuracy=0.504167
2025-10-09 17:16:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:16:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:16:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:17:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2372MB allocated=2183MB
2025-10-09 17:17:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.93106216192245, 'train_avg_loss': 0.7160921846826871, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 17:17:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.28125, 'train_avg_loss': 0.7047526041666666, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 17:17:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 338.28125, 'train_avg_loss': 0.7047526041666666, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 17:17:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:17:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:17:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-09 17:17:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:17:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:17:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:17:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:17:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:17:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:17:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:17:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.773712, avg_loss=0.714112, seen=480, correct=245, accuracy=0.510417
2025-10-09 17:17:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:17:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:17:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:17:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2352MB allocated=2183MB
2025-10-09 17:17:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.67422485351562, 'train_avg_loss': 0.7139518737792969, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 17:17:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.7737121582031, 'train_avg_loss': 0.7141119003295898, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 17:17:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 342.7737121582031, 'train_avg_loss': 0.7141119003295898, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 17:17:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:17:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:17:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-09 17:17:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:17:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:17:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:17:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:17:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:17:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:18:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:18:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.720520, avg_loss=0.693168, seen=480, correct=263, accuracy=0.547917
2025-10-09 17:18:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:18:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:18:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:18:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2404MB allocated=2267MB
2025-10-09 17:18:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.76438385248184, 'train_avg_loss': 0.6980365321040154, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 17:18:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.72052001953125, 'train_avg_loss': 0.6931677500406901, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 17:18:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 332.72052001953125, 'train_avg_loss': 0.6931677500406901, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 17:18:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:18:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:18:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:19:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:19:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.859924, avg_loss=0.691375, seen=480, correct=259, accuracy=0.539583
2025-10-09 17:19:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:19:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:19:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:19:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2372MB allocated=2191MB
2025-10-09 17:19:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.71127307415009, 'train_avg_loss': 0.7059272756179173, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 17:19:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.85992431640625, 'train_avg_loss': 0.6913748423258463, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 17:19:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 331.85992431640625, 'train_avg_loss': 0.6913748423258463, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 17:19:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #174) -------------
2025-10-09 17:19:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=174 aidx=7 | s=5 (candidates=6)
2025-10-09 17:19:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 47, 34, 1, 45] (from 6)
2025-10-09 17:19:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:19:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:19:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:19:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:19:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.483459, avg_loss=0.705174, seen=480, correct=242, accuracy=0.504167
2025-10-09 17:19:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:19:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:20:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:20:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2302MB allocated=2116MB
2025-10-09 17:20:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.36015981435776, 'train_avg_loss': 0.7113346651196479, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:20:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.48345947265625, 'train_avg_loss': 0.7051738739013672, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 17:20:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 338.48345947265625, 'train_avg_loss': 0.7051738739013672, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 17:20:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:20:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:20:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:20:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:20:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.026062, avg_loss=0.685471, seen=480, correct=267, accuracy=0.556250
2025-10-09 17:20:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:20:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:20:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:20:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2296MB allocated=2116MB
2025-10-09 17:20:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.31769102811813, 'train_avg_loss': 0.7026474252343178, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 17:20:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.02606201171875, 'train_avg_loss': 0.6854709625244141, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 17:20:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 329.02606201171875, 'train_avg_loss': 0.6854709625244141, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 17:20:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:20:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:20:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:21:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:21:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.367493, avg_loss=0.711182, seen=480, correct=236, accuracy=0.491667
2025-10-09 17:21:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:21:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:21:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:21:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2296MB allocated=2116MB
2025-10-09 17:21:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.55113559961319, 'train_avg_loss': 0.7045927966634432, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:21:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.36749267578125, 'train_avg_loss': 0.7111822764078776, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 17:21:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 341.36749267578125, 'train_avg_loss': 0.7111822764078776, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 17:21:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:21:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:21:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-09 17:21:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:21:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:21:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:21:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:21:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:21:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:22:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:22:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.032288, avg_loss=0.708401, seen=480, correct=249, accuracy=0.518750
2025-10-09 17:22:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:22:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:22:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:22:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2296MB allocated=2116MB
2025-10-09 17:22:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12827527523041, 'train_avg_loss': 0.70106896062692, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:22:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.03228759765625, 'train_avg_loss': 0.7084005991617839, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:22:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 340.03228759765625, 'train_avg_loss': 0.7084005991617839, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:22:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:22:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:22:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:22:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:22:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.975281, avg_loss=0.691615, seen=480, correct=260, accuracy=0.541667
2025-10-09 17:22:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:22:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:22:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:22:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2296MB allocated=2116MB
2025-10-09 17:22:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9107745885849, 'train_avg_loss': 0.6992564549048742, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 17:22:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.97528076171875, 'train_avg_loss': 0.6916151682535807, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 17:22:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 331.97528076171875, 'train_avg_loss': 0.6916151682535807, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 17:22:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #175) -------------
2025-10-09 17:22:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=175 aidx=7 | s=5 (candidates=6)
2025-10-09 17:22:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 1, 47, 45, 29] (from 6)
2025-10-09 17:23:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:23:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:23:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:23:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:23:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.159729, avg_loss=0.704499, seen=480, correct=234, accuracy=0.487500
2025-10-09 17:23:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:23:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:23:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:23:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2296MB allocated=2116MB
2025-10-09 17:23:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.26126861572266, 'train_avg_loss': 0.6938439051310221, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 17:23:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.15972900390625, 'train_avg_loss': 0.7044994354248046, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 17:23:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 338.15972900390625, 'train_avg_loss': 0.7044994354248046, 'train_seen': 480, 'train_correct': 234, 'train_acc': 0.4875}}
2025-10-09 17:23:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:23:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:23:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:24:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:24:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.567871, avg_loss=0.705350, seen=480, correct=248, accuracy=0.516667
2025-10-09 17:24:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:24:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:24:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:24:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2296MB allocated=2116MB
2025-10-09 17:24:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.74003601074219, 'train_avg_loss': 0.6978336334228515, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 17:24:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.56787109375, 'train_avg_loss': 0.7053497314453125, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 17:24:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 338.56787109375, 'train_avg_loss': 0.7053497314453125, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 17:24:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:24:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:24:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:25:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:25:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.678711, avg_loss=0.686831, seen=480, correct=266, accuracy=0.554167
2025-10-09 17:25:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:25:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:25:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:25:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2296MB allocated=2116MB
2025-10-09 17:25:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.42010313272476, 'train_avg_loss': 0.7118341927727063, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 17:25:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6787109375, 'train_avg_loss': 0.6868306477864583, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 17:25:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 329.6787109375, 'train_avg_loss': 0.6868306477864583, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 17:25:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:25:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:25:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-09 17:25:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:25:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:25:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:25:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:25:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:25:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:26:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:26:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.153015, avg_loss=0.685735, seen=480, correct=266, accuracy=0.554167
2025-10-09 17:26:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:26:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:26:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:26:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2296MB allocated=2116MB
2025-10-09 17:26:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3830384016037, 'train_avg_loss': 0.6948586533466975, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 17:26:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.15301513671875, 'train_avg_loss': 0.6857354482014973, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 17:26:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 329.15301513671875, 'train_avg_loss': 0.6857354482014973, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 17:26:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:26:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:26:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:26:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:26:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.280884, avg_loss=0.704752, seen=480, correct=239, accuracy=0.497917
2025-10-09 17:26:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:26:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:26:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:26:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2302MB allocated=2116MB
2025-10-09 17:26:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.07059109210968, 'train_avg_loss': 0.700588259100914, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 17:26:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.2808837890625, 'train_avg_loss': 0.7047518412272136, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 17:26:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 338.2808837890625, 'train_avg_loss': 0.7047518412272136, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 17:26:49 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #176) -------------
2025-10-09 17:26:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=176 aidx=7 | s=5 (candidates=6)
2025-10-09 17:26:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 26, 45, 47, 29] (from 6)
2025-10-09 17:26:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:26:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:26:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:27:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:27:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.441681, avg_loss=0.703004, seen=480, correct=236, accuracy=0.491667
2025-10-09 17:27:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:27:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:27:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:27:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2296MB allocated=2116MB
2025-10-09 17:27:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.90395784378052, 'train_avg_loss': 0.6908663153648377, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 17:27:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.4416809082031, 'train_avg_loss': 0.7030035018920898, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 17:27:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 337.4416809082031, 'train_avg_loss': 0.7030035018920898, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 17:27:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:27:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:27:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:28:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:28:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.930756, avg_loss=0.701939, seen=480, correct=235, accuracy=0.489583
2025-10-09 17:28:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:28:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:28:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:28:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2296MB allocated=2116MB
2025-10-09 17:28:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.19382464885712, 'train_avg_loss': 0.6932818720738093, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 17:28:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9307556152344, 'train_avg_loss': 0.701939074198405, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 17:28:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 336.9307556152344, 'train_avg_loss': 0.701939074198405, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 17:28:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:28:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:28:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:28:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:28:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.097137, avg_loss=0.685619, seen=480, correct=258, accuracy=0.537500
2025-10-09 17:28:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:28:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:29:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:29:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2296MB allocated=2116MB
2025-10-09 17:29:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.11563682556152, 'train_avg_loss': 0.6926303068796794, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:29:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0971374511719, 'train_avg_loss': 0.685619036356608, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 17:29:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 329.0971374511719, 'train_avg_loss': 0.685619036356608, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 17:29:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:29:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:29:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-09 17:29:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:29:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:29:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:29:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:29:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:29:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:29:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:29:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.429382, avg_loss=0.686311, seen=480, correct=265, accuracy=0.552083
2025-10-09 17:29:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:29:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:29:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:29:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2296MB allocated=2116MB
2025-10-09 17:29:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.31750518083572, 'train_avg_loss': 0.7109792098402977, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 17:29:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.42938232421875, 'train_avg_loss': 0.6863112131754557, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 17:29:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 329.42938232421875, 'train_avg_loss': 0.6863112131754557, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 17:29:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:29:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:29:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:30:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:30:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.547455, avg_loss=0.696974, seen=480, correct=244, accuracy=0.508333
2025-10-09 17:30:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:30:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:30:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:30:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2302MB allocated=2116MB
2025-10-09 17:30:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.63379836082458, 'train_avg_loss': 0.6969483196735382, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 17:30:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.5474548339844, 'train_avg_loss': 0.6969738642374674, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:30:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 334.5474548339844, 'train_avg_loss': 0.6969738642374674, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:30:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #177) -------------
2025-10-09 17:30:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=177 aidx=7 | s=5 (candidates=6)
2025-10-09 17:30:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 34, 26, 45, 47] (from 6)
2025-10-09 17:30:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:30:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:30:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-09 17:30:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:30:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:30:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:30:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:30:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:30:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:31:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:31:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.467682, avg_loss=0.698891, seen=480, correct=243, accuracy=0.506250
2025-10-09 17:31:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:31:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:31:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:31:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2296MB allocated=2116MB
2025-10-09 17:31:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61500096321106, 'train_avg_loss': 0.6884583413600922, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 17:31:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.4676818847656, 'train_avg_loss': 0.6988910039265951, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 17:31:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 335.4676818847656, 'train_avg_loss': 0.6988910039265951, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 17:31:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:31:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:31:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:31:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:31:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.991882, avg_loss=0.702066, seen=480, correct=239, accuracy=0.497917
2025-10-09 17:31:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:31:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:31:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:31:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2296MB allocated=2116MB
2025-10-09 17:31:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.5456148982048, 'train_avg_loss': 0.7045467908183733, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 17:31:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.99188232421875, 'train_avg_loss': 0.7020664215087891, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 17:31:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 336.99188232421875, 'train_avg_loss': 0.7020664215087891, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 17:31:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:31:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:31:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:32:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:32:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.400574, avg_loss=0.698751, seen=480, correct=240, accuracy=0.500000
2025-10-09 17:32:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:32:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:32:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:32:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2296MB allocated=2116MB
2025-10-09 17:32:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.74172377586365, 'train_avg_loss': 0.6895143647988637, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 17:32:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.40057373046875, 'train_avg_loss': 0.6987511952718098, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 17:32:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 335.40057373046875, 'train_avg_loss': 0.6987511952718098, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 17:32:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:32:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:32:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:33:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:33:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.535645, avg_loss=0.684449, seen=480, correct=262, accuracy=0.545833
2025-10-09 17:33:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:33:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:33:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:33:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2296MB allocated=2116MB
2025-10-09 17:33:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.36790359020233, 'train_avg_loss': 0.6947325299183528, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 17:33:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.53564453125, 'train_avg_loss': 0.6844492594401042, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:33:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 328.53564453125, 'train_avg_loss': 0.6844492594401042, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:33:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:33:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:33:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:34:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:34:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.296478, avg_loss=0.683951, seen=480, correct=268, accuracy=0.558333
2025-10-09 17:34:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:34:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:34:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:34:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2296MB allocated=2116MB
2025-10-09 17:34:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2310082912445, 'train_avg_loss': 0.7102584024270375, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 17:34:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2964782714844, 'train_avg_loss': 0.6839509963989258, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:34:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 328.2964782714844, 'train_avg_loss': 0.6839509963989258, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:34:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #178) -------------
2025-10-09 17:34:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=178 aidx=7 | s=5 (candidates=6)
2025-10-09 17:34:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 45, 26, 1, 34] (from 6)
2025-10-09 17:34:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:34:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:34:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-09 17:34:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:34:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:34:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:34:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:34:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:34:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:34:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:34:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.554382, avg_loss=0.686572, seen=480, correct=258, accuracy=0.537500
2025-10-09 17:34:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:34:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:34:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:34:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2302MB allocated=2116MB
2025-10-09 17:34:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6147797703743, 'train_avg_loss': 0.6967898314197858, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:34:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.55438232421875, 'train_avg_loss': 0.6865716298421224, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 17:34:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 329.55438232421875, 'train_avg_loss': 0.6865716298421224, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 17:34:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:34:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:34:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:35:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:35:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.611450, avg_loss=0.684607, seen=480, correct=256, accuracy=0.533333
2025-10-09 17:35:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:35:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:35:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:35:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2296MB allocated=2116MB
2025-10-09 17:35:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.34419161081314, 'train_avg_loss': 0.6945349300901095, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 17:35:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.6114501953125, 'train_avg_loss': 0.684607187906901, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 17:35:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 328.6114501953125, 'train_avg_loss': 0.684607187906901, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 17:35:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:35:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:35:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-09 17:35:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:35:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:35:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:35:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:35:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:35:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:36:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:36:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.816406, avg_loss=0.697534, seen=480, correct=249, accuracy=0.518750
2025-10-09 17:36:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:36:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:36:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:36:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2296MB allocated=2116MB
2025-10-09 17:36:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.121861577034, 'train_avg_loss': 0.6843488464752833, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 17:36:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.81640625, 'train_avg_loss': 0.6975341796875, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:36:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 334.81640625, 'train_avg_loss': 0.6975341796875, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:36:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:36:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:36:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-09 17:36:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:36:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:36:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:36:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:36:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:36:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:37:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:37:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.238556, avg_loss=0.700497, seen=480, correct=249, accuracy=0.518750
2025-10-09 17:37:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:37:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:37:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:37:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2296MB allocated=2116MB
2025-10-09 17:37:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.14709341526031, 'train_avg_loss': 0.6928924451271693, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 17:37:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.2385559082031, 'train_avg_loss': 0.7004969914754232, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:37:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 336.2385559082031, 'train_avg_loss': 0.7004969914754232, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 17:37:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:37:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:37:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-09 17:37:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:37:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:37:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:37:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:37:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:37:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:37:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:37:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.092499, avg_loss=0.704359, seen=480, correct=240, accuracy=0.500000
2025-10-09 17:37:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:37:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:37:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:37:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2296MB allocated=2116MB
2025-10-09 17:37:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36013305187225, 'train_avg_loss': 0.7030011087656021, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 17:37:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.0924987792969, 'train_avg_loss': 0.7043593724568685, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 17:37:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 338.0924987792969, 'train_avg_loss': 0.7043593724568685, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 17:37:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #179) -------------
2025-10-09 17:37:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=179 aidx=7 | s=5 (candidates=6)
2025-10-09 17:37:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 29, 1, 45, 34] (from 6)
2025-10-09 17:37:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:37:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:37:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:38:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:38:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.255219, avg_loss=0.702615, seen=480, correct=244, accuracy=0.508333
2025-10-09 17:38:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:38:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:38:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:38:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2296MB allocated=2116MB
2025-10-09 17:38:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26649570465088, 'train_avg_loss': 0.6855541308720906, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 17:38:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.2552185058594, 'train_avg_loss': 0.7026150385538737, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:38:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 337.2552185058594, 'train_avg_loss': 0.7026150385538737, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:38:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:38:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:38:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:39:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:39:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.235535, avg_loss=0.681741, seen=480, correct=268, accuracy=0.558333
2025-10-09 17:39:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:39:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:39:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:39:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2302MB allocated=2116MB
2025-10-09 17:39:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.50639468431473, 'train_avg_loss': 0.6958866223692894, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 17:39:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.23553466796875, 'train_avg_loss': 0.6817406972249349, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:39:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 327.23553466796875, 'train_avg_loss': 0.6817406972249349, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 17:39:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:39:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:39:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:39:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:39:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.473877, avg_loss=0.700987, seen=480, correct=243, accuracy=0.506250
2025-10-09 17:39:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:39:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:40:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:40:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2296MB allocated=2116MB
2025-10-09 17:40:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.58959817886353, 'train_avg_loss': 0.6965799848238627, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:40:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.473876953125, 'train_avg_loss': 0.7009872436523438, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 17:40:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 336.473876953125, 'train_avg_loss': 0.7009872436523438, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 17:40:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:40:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:40:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:40:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:40:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.192047, avg_loss=0.685817, seen=480, correct=262, accuracy=0.545833
2025-10-09 17:40:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:40:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:40:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:40:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2296MB allocated=2116MB
2025-10-09 17:40:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.65699195861816, 'train_avg_loss': 0.688808266321818, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 17:40:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1920471191406, 'train_avg_loss': 0.685816764831543, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:40:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 329.1920471191406, 'train_avg_loss': 0.685816764831543, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:40:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:40:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:40:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-09 17:40:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:40:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:40:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:40:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:40:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:40:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:41:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:41:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.692810, avg_loss=0.699360, seen=480, correct=244, accuracy=0.508333
2025-10-09 17:41:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:41:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:41:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:41:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2296MB allocated=2116MB
2025-10-09 17:41:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.12428057193756, 'train_avg_loss': 0.6927023380994797, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:41:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.69281005859375, 'train_avg_loss': 0.6993600209554036, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:41:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 335.69281005859375, 'train_avg_loss': 0.6993600209554036, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:41:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #180) -------------
2025-10-09 17:41:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=180 aidx=7 | s=5 (candidates=6)
2025-10-09 17:41:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 29, 47, 1, 45] (from 6)
2025-10-09 17:41:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:41:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:41:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:42:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:42:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.585175, avg_loss=0.694969, seen=480, correct=255, accuracy=0.531250
2025-10-09 17:42:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:42:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:42:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:42:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2296MB allocated=2116MB
2025-10-09 17:42:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.64328074455261, 'train_avg_loss': 0.6886940062046051, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:42:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5851745605469, 'train_avg_loss': 0.694969113667806, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 17:42:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 333.5851745605469, 'train_avg_loss': 0.694969113667806, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 17:42:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:42:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:42:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:42:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:42:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.709229, avg_loss=0.682728, seen=480, correct=276, accuracy=0.575000
2025-10-09 17:42:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:42:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:42:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:42:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2302MB allocated=2116MB
2025-10-09 17:42:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.92968434095383, 'train_avg_loss': 0.6994140361746152, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 17:42:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.709228515625, 'train_avg_loss': 0.682727559407552, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 17:42:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 327.709228515625, 'train_avg_loss': 0.682727559407552, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 17:42:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:42:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:42:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:43:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:43:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.199677, avg_loss=0.681666, seen=480, correct=259, accuracy=0.539583
2025-10-09 17:43:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:43:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:43:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:43:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2296MB allocated=2116MB
2025-10-09 17:43:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50433349609375, 'train_avg_loss': 0.6792027791341145, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:43:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.1996765136719, 'train_avg_loss': 0.6816659927368164, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 17:43:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 327.1996765136719, 'train_avg_loss': 0.6816659927368164, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 17:43:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:43:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:43:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:44:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:44:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.476593, avg_loss=0.700993, seen=480, correct=240, accuracy=0.500000
2025-10-09 17:44:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:44:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:44:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:44:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2296MB allocated=2116MB
2025-10-09 17:44:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.77923703193665, 'train_avg_loss': 0.6981603085994721, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 17:44:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4765930175781, 'train_avg_loss': 0.7009929021199545, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 17:44:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 336.4765930175781, 'train_avg_loss': 0.7009929021199545, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 17:44:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:44:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:44:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:45:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:45:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.248627, avg_loss=0.685935, seen=480, correct=262, accuracy=0.545833
2025-10-09 17:45:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:45:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:45:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:45:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2296MB allocated=2116MB
2025-10-09 17:45:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.52980732917786, 'train_avg_loss': 0.6877483944098155, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:45:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2486267089844, 'train_avg_loss': 0.6859346389770508, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:45:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 329.2486267089844, 'train_avg_loss': 0.6859346389770508, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 17:45:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #181) -------------
2025-10-09 17:45:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=181 aidx=7 | s=5 (candidates=6)
2025-10-09 17:45:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 34, 45, 29, 1] (from 6)
2025-10-09 17:45:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:45:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:45:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-09 17:45:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:45:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:45:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:45:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:45:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:45:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:45:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:45:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.096802, avg_loss=0.698118, seen=480, correct=239, accuracy=0.497917
2025-10-09 17:45:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:45:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:45:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:45:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2296MB allocated=2116MB
2025-10-09 17:45:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.88006281852722, 'train_avg_loss': 0.6823338568210602, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 17:45:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.0968017578125, 'train_avg_loss': 0.6981183369954427, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 17:45:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 335.0968017578125, 'train_avg_loss': 0.6981183369954427, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 17:45:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:45:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:45:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:46:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:46:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.237305, avg_loss=0.690078, seen=480, correct=255, accuracy=0.531250
2025-10-09 17:46:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:46:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:46:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:46:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2296MB allocated=2116MB
2025-10-09 17:46:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.25203263759613, 'train_avg_loss': 0.6937669386466344, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 17:46:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2373046875, 'train_avg_loss': 0.6900777180989583, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 17:46:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 331.2373046875, 'train_avg_loss': 0.6900777180989583, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 17:46:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:46:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:46:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:47:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:47:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.280762, avg_loss=0.679752, seen=480, correct=272, accuracy=0.566667
2025-10-09 17:47:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:47:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:47:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:47:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2296MB allocated=2116MB
2025-10-09 17:47:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0221415758133, 'train_avg_loss': 0.6835178464651108, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:47:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.28076171875, 'train_avg_loss': 0.6797515869140625, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 17:47:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 326.28076171875, 'train_avg_loss': 0.6797515869140625, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 17:47:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:47:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:47:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-09 17:47:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:47:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:47:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:47:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:47:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:47:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:48:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:48:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.813904, avg_loss=0.689196, seen=480, correct=256, accuracy=0.533333
2025-10-09 17:48:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:48:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:48:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:48:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2302MB allocated=2116MB
2025-10-09 17:48:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.05155622959137, 'train_avg_loss': 0.6920963019132614, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 17:48:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.81390380859375, 'train_avg_loss': 0.6891956329345703, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 17:48:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 330.81390380859375, 'train_avg_loss': 0.6891956329345703, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 17:48:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:48:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:48:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:48:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:48:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.523956, avg_loss=0.694842, seen=480, correct=248, accuracy=0.516667
2025-10-09 17:48:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:48:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:48:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:48:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2296MB allocated=2116MB
2025-10-09 17:48:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24575483798981, 'train_avg_loss': 0.6853812903165817, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 17:48:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5239562988281, 'train_avg_loss': 0.6948415756225585, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 17:48:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 333.5239562988281, 'train_avg_loss': 0.6948415756225585, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 17:48:52 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #182) -------------
2025-10-09 17:48:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=182 aidx=7 | s=5 (candidates=6)
2025-10-09 17:48:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 47, 29, 1, 45] (from 6)
2025-10-09 17:48:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:48:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:48:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:49:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:49:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.415222, avg_loss=0.698782, seen=480, correct=246, accuracy=0.512500
2025-10-09 17:49:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:49:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:49:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:49:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2296MB allocated=2116MB
2025-10-09 17:49:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.59624195098877, 'train_avg_loss': 0.6799686829249064, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:49:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.41522216796875, 'train_avg_loss': 0.6987817128499348, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 17:49:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 335.41522216796875, 'train_avg_loss': 0.6987817128499348, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 17:49:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:49:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:49:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-09 17:49:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:49:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:49:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:49:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:49:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:49:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:50:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:50:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.689514, avg_loss=0.678520, seen=480, correct=277, accuracy=0.577083
2025-10-09 17:50:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:50:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:50:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:50:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2296MB allocated=2116MB
2025-10-09 17:50:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.37334531545639, 'train_avg_loss': 0.68644454429547, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 17:50:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.68951416015625, 'train_avg_loss': 0.6785198211669922, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 17:50:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 325.68951416015625, 'train_avg_loss': 0.6785198211669922, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 17:50:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:50:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:50:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:51:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:51:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.869629, avg_loss=0.683062, seen=480, correct=276, accuracy=0.575000
2025-10-09 17:51:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:51:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:51:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:51:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2302MB allocated=2116MB
2025-10-09 17:51:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.96421700716019, 'train_avg_loss': 0.6913684750596683, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 17:51:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.86962890625, 'train_avg_loss': 0.6830617268880208, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 17:51:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 327.86962890625, 'train_avg_loss': 0.6830617268880208, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 17:51:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:51:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:51:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-09 17:51:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:51:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:51:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:51:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:51:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:51:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:51:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:51:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.959259, avg_loss=0.691582, seen=480, correct=244, accuracy=0.508333
2025-10-09 17:51:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:51:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:51:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:51:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2296MB allocated=2116MB
2025-10-09 17:51:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.57780003547668, 'train_avg_loss': 0.6881483336289723, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 17:51:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.9592590332031, 'train_avg_loss': 0.6915817896525065, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:51:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 331.9592590332031, 'train_avg_loss': 0.6915817896525065, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 17:51:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:51:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:51:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:52:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:52:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.433136, avg_loss=0.677986, seen=480, correct=269, accuracy=0.560417
2025-10-09 17:52:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:52:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:52:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:52:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2296MB allocated=2116MB
2025-10-09 17:52:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.74204063415527, 'train_avg_loss': 0.6811836719512939, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 17:52:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4331359863281, 'train_avg_loss': 0.6779856999715169, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 17:52:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 325.4331359863281, 'train_avg_loss': 0.6779856999715169, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 17:52:36 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #183) -------------
2025-10-09 17:52:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=183 aidx=7 | s=5 (candidates=6)
2025-10-09 17:52:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 26, 1, 29, 47] (from 6)
2025-10-09 17:52:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:52:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:52:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:53:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:53:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.780975, avg_loss=0.674544, seen=480, correct=272, accuracy=0.566667
2025-10-09 17:53:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:53:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:53:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:53:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2296MB allocated=2116MB
2025-10-09 17:53:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.11887449026108, 'train_avg_loss': 0.6759906207521756, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 17:53:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.7809753417969, 'train_avg_loss': 0.6745436986287435, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 17:53:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 323.7809753417969, 'train_avg_loss': 0.6745436986287435, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 17:53:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:53:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:53:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:54:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:54:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.708710, avg_loss=0.695226, seen=480, correct=245, accuracy=0.510417
2025-10-09 17:54:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:54:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:54:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:54:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2296MB allocated=2116MB
2025-10-09 17:54:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.35344505310059, 'train_avg_loss': 0.6779453754425049, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 17:54:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.7087097167969, 'train_avg_loss': 0.6952264785766602, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 17:54:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 333.7087097167969, 'train_avg_loss': 0.6952264785766602, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 17:54:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:54:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:54:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:54:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:54:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.515930, avg_loss=0.690658, seen=480, correct=252, accuracy=0.525000
2025-10-09 17:54:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:54:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:54:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:54:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2296MB allocated=2116MB
2025-10-09 17:54:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.75042462348938, 'train_avg_loss': 0.6812535385290782, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 17:54:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.51593017578125, 'train_avg_loss': 0.6906581878662109, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 17:54:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 331.51593017578125, 'train_avg_loss': 0.6906581878662109, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 17:54:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 17:54:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:54:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:55:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:55:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.250366, avg_loss=0.685938, seen=480, correct=260, accuracy=0.541667
2025-10-09 17:55:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:55:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:55:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:55:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2302MB allocated=2116MB
2025-10-09 17:55:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.68337213993073, 'train_avg_loss': 0.6890281011660894, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 17:55:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2503662109375, 'train_avg_loss': 0.6859382629394531, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 17:55:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 329.2503662109375, 'train_avg_loss': 0.6859382629394531, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 17:55:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:55:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:55:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:56:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:56:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.764496, avg_loss=0.680759, seen=480, correct=271, accuracy=0.564583
2025-10-09 17:56:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:56:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:56:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:56:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2296MB allocated=2116MB
2025-10-09 17:56:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.65744930505753, 'train_avg_loss': 0.6971454108754794, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 17:56:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.7644958496094, 'train_avg_loss': 0.6807593663533529, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 17:56:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 326.7644958496094, 'train_avg_loss': 0.6807593663533529, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 17:56:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #184) -------------
2025-10-09 17:56:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=184 aidx=7 | s=5 (candidates=6)
2025-10-09 17:56:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[47, 45, 34, 1, 26] (from 6)
2025-10-09 17:56:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 17:56:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:56:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:57:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:57:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.621429, avg_loss=0.674211, seen=480, correct=272, accuracy=0.566667
2025-10-09 17:57:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:57:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:57:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:57:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2296MB allocated=2116MB
2025-10-09 17:57:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.33603954315186, 'train_avg_loss': 0.6861336628595988, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 17:57:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.6214294433594, 'train_avg_loss': 0.6742113113403321, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 17:57:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 323.6214294433594, 'train_avg_loss': 0.6742113113403321, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 17:57:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:57:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:57:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-09 17:57:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 17:57:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:57:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:57:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:57:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:57:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:57:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:57:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.652161, avg_loss=0.672192, seen=480, correct=278, accuracy=0.579167
2025-10-09 17:57:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:57:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:57:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:57:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2296MB allocated=2116MB
2025-10-09 17:57:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.00566869974136, 'train_avg_loss': 0.6750472391645114, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 17:57:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.65216064453125, 'train_avg_loss': 0.6721920013427735, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 17:57:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 322.65216064453125, 'train_avg_loss': 0.6721920013427735, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 17:57:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:57:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:57:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-09 17:57:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 17:57:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:57:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:57:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:57:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:57:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:58:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:58:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.414062, avg_loss=0.690446, seen=480, correct=253, accuracy=0.527083
2025-10-09 17:58:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:58:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:58:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:58:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2296MB allocated=2116MB
2025-10-09 17:58:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5724710226059, 'train_avg_loss': 0.6881039251883825, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 17:58:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.4140625, 'train_avg_loss': 0.6904459635416667, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 17:58:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 331.4140625, 'train_avg_loss': 0.6904459635416667, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 17:58:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 17:58:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:58:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:59:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:59:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.334808, avg_loss=0.692364, seen=480, correct=253, accuracy=0.527083
2025-10-09 17:59:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:59:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:59:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 17:59:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2296MB allocated=2116MB
2025-10-09 17:59:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0618896484375, 'train_avg_loss': 0.6838490804036458, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 17:59:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.3348083496094, 'train_avg_loss': 0.6923641840616862, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 17:59:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 332.3348083496094, 'train_avg_loss': 0.6923641840616862, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 17:59:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 17:59:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 17:59:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 17:59:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 17:59:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.923767, avg_loss=0.695675, seen=480, correct=248, accuracy=0.516667
2025-10-09 17:59:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 17:59:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:00:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:00:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2296MB allocated=2116MB
2025-10-09 18:00:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.03805887699127, 'train_avg_loss': 0.6753171573082606, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:00:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.92376708984375, 'train_avg_loss': 0.6956745147705078, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 18:00:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 333.92376708984375, 'train_avg_loss': 0.6956745147705078, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 18:00:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #185) -------------
2025-10-09 18:00:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=185 aidx=7 | s=5 (candidates=6)
2025-10-09 18:00:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 45, 29, 47, 1] (from 6)
2025-10-09 18:00:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:00:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:00:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:00:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:00:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.829895, avg_loss=0.689229, seen=480, correct=257, accuracy=0.535417
2025-10-09 18:00:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:00:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:00:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:00:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2296MB allocated=2116MB
2025-10-09 18:00:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.1439037322998, 'train_avg_loss': 0.6678658644358317, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 18:00:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.82989501953125, 'train_avg_loss': 0.6892289479573568, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 18:00:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 330.82989501953125, 'train_avg_loss': 0.6892289479573568, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 18:00:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:00:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:00:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:01:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:01:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.173553, avg_loss=0.671195, seen=480, correct=277, accuracy=0.577083
2025-10-09 18:01:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:01:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:01:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:01:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2296MB allocated=2116MB
2025-10-09 18:01:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.07488405704498, 'train_avg_loss': 0.6756240338087082, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 18:01:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1735534667969, 'train_avg_loss': 0.6711949030558269, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 18:01:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 322.1735534667969, 'train_avg_loss': 0.6711949030558269, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 18:01:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:01:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:01:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:02:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:02:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.837830, avg_loss=0.678829, seen=480, correct=279, accuracy=0.581250
2025-10-09 18:02:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:02:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:02:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:02:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2302MB allocated=2116MB
2025-10-09 18:02:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.29940819740295, 'train_avg_loss': 0.6858284016450246, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 18:02:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.83782958984375, 'train_avg_loss': 0.6788288116455078, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 18:02:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 325.83782958984375, 'train_avg_loss': 0.6788288116455078, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 18:02:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:02:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:02:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:03:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:03:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.865845, avg_loss=0.672637, seen=480, correct=284, accuracy=0.591667
2025-10-09 18:03:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:03:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:03:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:03:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2296MB allocated=2116MB
2025-10-09 18:03:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.6255475282669, 'train_avg_loss': 0.6802128960688909, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 18:03:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.8658447265625, 'train_avg_loss': 0.6726371765136718, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:03:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 322.8658447265625, 'train_avg_loss': 0.6726371765136718, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:03:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:03:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:03:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:03:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:03:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.600189, avg_loss=0.690834, seen=480, correct=247, accuracy=0.514583
2025-10-09 18:03:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:03:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:03:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:03:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2296MB allocated=2116MB
2025-10-09 18:03:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.08660697937012, 'train_avg_loss': 0.6840550581614177, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 18:03:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6001892089844, 'train_avg_loss': 0.6908337275187174, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 18:03:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 331.6001892089844, 'train_avg_loss': 0.6908337275187174, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 18:03:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #186) -------------
2025-10-09 18:03:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=186 aidx=7 | s=5 (candidates=6)
2025-10-09 18:03:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 45, 34, 29, 26] (from 6)
2025-10-09 18:03:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:03:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:03:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:04:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:04:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.616333, avg_loss=0.684617, seen=480, correct=258, accuracy=0.537500
2025-10-09 18:04:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:04:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:04:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:04:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2296MB allocated=2116MB
2025-10-09 18:04:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.46572744846344, 'train_avg_loss': 0.6788810620705287, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 18:04:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.6163330078125, 'train_avg_loss': 0.6846173604329427, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 18:04:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 328.6163330078125, 'train_avg_loss': 0.6846173604329427, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 18:04:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:04:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:04:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:05:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:05:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.686035, avg_loss=0.672263, seen=480, correct=275, accuracy=0.572917
2025-10-09 18:05:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:05:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:05:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:05:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2296MB allocated=2116MB
2025-10-09 18:05:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.9109423160553, 'train_avg_loss': 0.6742578526337941, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 18:05:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.68603515625, 'train_avg_loss': 0.6722625732421875, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 18:05:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 322.68603515625, 'train_avg_loss': 0.6722625732421875, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 18:05:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:05:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:05:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-09 18:05:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:05:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:05:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:05:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:05:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:05:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:05:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:05:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.747314, avg_loss=0.693224, seen=480, correct=254, accuracy=0.529167
2025-10-09 18:05:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:05:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:06:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:06:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2296MB allocated=2116MB
2025-10-09 18:06:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.06235492229462, 'train_avg_loss': 0.6921862910191218, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 18:06:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.747314453125, 'train_avg_loss': 0.6932235717773437, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:06:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 332.747314453125, 'train_avg_loss': 0.6932235717773437, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:06:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:06:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:06:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-09 18:06:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:06:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:06:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:06:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:06:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:06:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:06:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:06:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.712372, avg_loss=0.678567, seen=480, correct=282, accuracy=0.587500
2025-10-09 18:06:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:06:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:06:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:06:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2302MB allocated=2116MB
2025-10-09 18:06:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.18459784984589, 'train_avg_loss': 0.6848716487487158, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:06:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7123718261719, 'train_avg_loss': 0.6785674413045247, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 18:06:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 325.7123718261719, 'train_avg_loss': 0.6785674413045247, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 18:06:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:06:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:06:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:07:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:07:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.731567, avg_loss=0.689024, seen=480, correct=259, accuracy=0.539583
2025-10-09 18:07:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:07:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:07:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:07:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2296MB allocated=2116MB
2025-10-09 18:07:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.32580482959747, 'train_avg_loss': 0.6693817069133122, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 18:07:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.7315673828125, 'train_avg_loss': 0.6890240987141927, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 18:07:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 330.7315673828125, 'train_avg_loss': 0.6890240987141927, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 18:07:34 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #187) -------------
2025-10-09 18:07:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=187 aidx=7 | s=5 (candidates=6)
2025-10-09 18:07:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 45, 26, 34, 47] (from 6)
2025-10-09 18:07:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:07:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:07:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-09 18:07:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:07:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:07:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:07:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:07:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:07:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:08:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:08:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.645691, avg_loss=0.678429, seen=480, correct=276, accuracy=0.575000
2025-10-09 18:08:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:08:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:08:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:08:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2302MB allocated=2116MB
2025-10-09 18:08:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24586725234985, 'train_avg_loss': 0.6853822271029154, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 18:08:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.64569091796875, 'train_avg_loss': 0.6784285227457683, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 18:08:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 325.64569091796875, 'train_avg_loss': 0.6784285227457683, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 18:08:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:08:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:08:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:09:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:09:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.350525, avg_loss=0.671564, seen=480, correct=277, accuracy=0.577083
2025-10-09 18:09:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:09:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:09:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:09:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2296MB allocated=2116MB
2025-10-09 18:09:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.62820082902908, 'train_avg_loss': 0.6719016735752423, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 18:09:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.35052490234375, 'train_avg_loss': 0.6715635935465495, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 18:09:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 322.35052490234375, 'train_avg_loss': 0.6715635935465495, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 18:09:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:09:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:09:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:09:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:09:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.006836, avg_loss=0.683348, seen=480, correct=269, accuracy=0.560417
2025-10-09 18:09:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:09:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:09:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:09:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2296MB allocated=2116MB
2025-10-09 18:09:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.40686464309692, 'train_avg_loss': 0.6617238720258077, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 18:09:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0068359375, 'train_avg_loss': 0.6833475748697917, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 18:09:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 328.0068359375, 'train_avg_loss': 0.6833475748697917, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 18:09:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:09:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:09:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:10:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:10:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.710907, avg_loss=0.693148, seen=480, correct=252, accuracy=0.525000
2025-10-09 18:10:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:10:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:10:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:10:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2296MB allocated=2116MB
2025-10-09 18:10:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.17586690187454, 'train_avg_loss': 0.6931322241822878, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 18:10:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.7109069824219, 'train_avg_loss': 0.6931477228800456, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:10:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 332.7109069824219, 'train_avg_loss': 0.6931477228800456, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:10:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:10:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:10:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:11:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:11:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.728943, avg_loss=0.672352, seen=480, correct=288, accuracy=0.600000
2025-10-09 18:11:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:11:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:11:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:11:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2296MB allocated=2116MB
2025-10-09 18:11:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.41487085819244, 'train_avg_loss': 0.6784572571516037, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:11:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.72894287109375, 'train_avg_loss': 0.6723519643147786, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 18:11:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 322.72894287109375, 'train_avg_loss': 0.6723519643147786, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 18:11:14 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #188) -------------
2025-10-09 18:11:15 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=188 aidx=7 | s=5 (candidates=6)
2025-10-09 18:11:15 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 29, 47, 45, 1] (from 6)
2025-10-09 18:11:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:11:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:11:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-09 18:11:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:11:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:11:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:11:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:11:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:11:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:11:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:11:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.660431, avg_loss=0.690959, seen=480, correct=249, accuracy=0.518750
2025-10-09 18:11:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:11:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:11:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:11:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2296MB allocated=2116MB
2025-10-09 18:11:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.42299622297287, 'train_avg_loss': 0.6951916351914406, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 18:11:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6604309082031, 'train_avg_loss': 0.6909592310587566, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 18:11:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 331.6604309082031, 'train_avg_loss': 0.6909592310587566, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 18:11:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:11:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:11:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:12:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:12:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.710388, avg_loss=0.674397, seen=480, correct=272, accuracy=0.566667
2025-10-09 18:12:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:12:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:12:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:12:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2302MB allocated=2116MB
2025-10-09 18:12:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58173406124115, 'train_avg_loss': 0.6798477838436763, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:12:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.71038818359375, 'train_avg_loss': 0.6743966420491536, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 18:12:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 323.71038818359375, 'train_avg_loss': 0.6743966420491536, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 18:12:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:12:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:12:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:13:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:13:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.210632, avg_loss=0.665022, seen=480, correct=286, accuracy=0.595833
2025-10-09 18:13:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:13:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:13:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:13:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2296MB allocated=2116MB
2025-10-09 18:13:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.78776460886002, 'train_avg_loss': 0.6732313717405002, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:13:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.21063232421875, 'train_avg_loss': 0.6650221506754558, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 18:13:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 319.21063232421875, 'train_avg_loss': 0.6650221506754558, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 18:13:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:13:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:13:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-09 18:13:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:13:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:13:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:13:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:13:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:13:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:14:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:14:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.224609, avg_loss=0.669218, seen=480, correct=279, accuracy=0.581250
2025-10-09 18:14:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:14:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:14:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:14:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2296MB allocated=2116MB
2025-10-09 18:14:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.8581412434578, 'train_avg_loss': 0.6738178436954816, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:14:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.224609375, 'train_avg_loss': 0.6692179361979167, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 18:14:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 321.224609375, 'train_avg_loss': 0.6692179361979167, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 18:14:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:14:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:14:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:14:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:14:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.924164, avg_loss=0.685259, seen=480, correct=254, accuracy=0.529167
2025-10-09 18:14:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:14:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:14:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:14:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2296MB allocated=2116MB
2025-10-09 18:14:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.60868525505066, 'train_avg_loss': 0.6800723771254221, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 18:14:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.9241638183594, 'train_avg_loss': 0.6852586746215821, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:14:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 328.9241638183594, 'train_avg_loss': 0.6852586746215821, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:14:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #189) -------------
2025-10-09 18:14:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=189 aidx=7 | s=5 (candidates=6)
2025-10-09 18:14:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 1, 47, 45, 26] (from 6)
2025-10-09 18:14:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:14:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:14:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:15:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:15:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.026611, avg_loss=0.693805, seen=480, correct=246, accuracy=0.512500
2025-10-09 18:15:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:15:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:15:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:15:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2296MB allocated=2116MB
2025-10-09 18:15:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.41813617944717, 'train_avg_loss': 0.6951511348287265, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 18:15:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.026611328125, 'train_avg_loss': 0.693805440266927, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 18:15:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 333.026611328125, 'train_avg_loss': 0.693805440266927, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 18:15:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:15:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:15:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-09 18:15:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:15:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:15:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:15:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:15:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:15:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:16:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:16:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.303406, avg_loss=0.679799, seen=480, correct=272, accuracy=0.566667
2025-10-09 18:16:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:16:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:16:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:16:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2296MB allocated=2116MB
2025-10-09 18:16:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.19891023635864, 'train_avg_loss': 0.6766575853029887, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:16:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.30340576171875, 'train_avg_loss': 0.6797987620035807, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 18:16:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 326.30340576171875, 'train_avg_loss': 0.6797987620035807, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 18:16:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:16:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:16:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-09 18:16:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:16:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:16:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:16:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:16:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:16:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:17:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:17:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.496460, avg_loss=0.663534, seen=480, correct=294, accuracy=0.612500
2025-10-09 18:17:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:17:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:17:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:17:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2296MB allocated=2116MB
2025-10-09 18:17:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.61130821704865, 'train_avg_loss': 0.6717609018087387, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 18:17:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.4964599609375, 'train_avg_loss': 0.6635342915852864, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 18:17:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 318.4964599609375, 'train_avg_loss': 0.6635342915852864, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 18:17:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:17:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:17:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:17:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:17:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.451965, avg_loss=0.669692, seen=480, correct=284, accuracy=0.591667
2025-10-09 18:17:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:17:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:17:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:17:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2296MB allocated=2116MB
2025-10-09 18:17:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.365613758564, 'train_avg_loss': 0.6697134479880333, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 18:17:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.45196533203125, 'train_avg_loss': 0.6696915944417318, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:17:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 321.45196533203125, 'train_avg_loss': 0.6696915944417318, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:17:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:17:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:17:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:18:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:18:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.677002, avg_loss=0.680577, seen=480, correct=264, accuracy=0.550000
2025-10-09 18:18:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:18:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:18:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:18:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2296MB allocated=2116MB
2025-10-09 18:18:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.9265725016594, 'train_avg_loss': 0.6577214375138283, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 18:18:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.677001953125, 'train_avg_loss': 0.6805770874023438, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 18:18:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 326.677001953125, 'train_avg_loss': 0.6805770874023438, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 18:18:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #190) -------------
2025-10-09 18:18:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=190 aidx=7 | s=5 (candidates=6)
2025-10-09 18:18:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 29, 1, 45, 26] (from 6)
2025-10-09 18:18:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:18:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:18:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-09 18:18:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:18:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:18:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:18:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:18:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:18:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:19:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:19:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.776489, avg_loss=0.695368, seen=480, correct=245, accuracy=0.510417
2025-10-09 18:19:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:19:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:19:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:19:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2296MB allocated=2116MB
2025-10-09 18:19:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.62484967708588, 'train_avg_loss': 0.6968737473090489, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 18:19:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.7764892578125, 'train_avg_loss': 0.6953676859537761, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 18:19:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 333.7764892578125, 'train_avg_loss': 0.6953676859537761, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 18:19:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:19:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:19:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-09 18:19:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:19:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:19:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:19:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:19:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:19:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:20:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:20:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.328339, avg_loss=0.669434, seen=480, correct=284, accuracy=0.591667
2025-10-09 18:20:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:20:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:20:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:20:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2302MB allocated=2116MB
2025-10-09 18:20:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.55926895141602, 'train_avg_loss': 0.6713272412618001, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 18:20:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3283386230469, 'train_avg_loss': 0.6694340387980143, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:20:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 321.3283386230469, 'train_avg_loss': 0.6694340387980143, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:20:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:20:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:20:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-09 18:20:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:20:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:20:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:20:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:20:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:20:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:20:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:20:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.241638, avg_loss=0.677587, seen=480, correct=271, accuracy=0.564583
2025-10-09 18:20:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:20:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:20:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:21:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2296MB allocated=2116MB
2025-10-09 18:21:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.85400712490082, 'train_avg_loss': 0.6737833927075069, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:21:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.24163818359375, 'train_avg_loss': 0.6775867462158203, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 18:21:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 325.24163818359375, 'train_avg_loss': 0.6775867462158203, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 18:21:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:21:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:21:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:21:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:21:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.778168, avg_loss=0.668288, seen=480, correct=277, accuracy=0.577083
2025-10-09 18:21:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:21:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:21:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:21:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2296MB allocated=2116MB
2025-10-09 18:21:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.39455831050873, 'train_avg_loss': 0.6699546525875727, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 18:21:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.7781677246094, 'train_avg_loss': 0.6682878494262695, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 18:21:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 320.7781677246094, 'train_avg_loss': 0.6682878494262695, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 18:21:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:21:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:21:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:22:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:22:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.594543, avg_loss=0.672072, seen=480, correct=284, accuracy=0.591667
2025-10-09 18:22:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:22:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:22:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:22:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2296MB allocated=2116MB
2025-10-09 18:22:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.9153504371643, 'train_avg_loss': 0.6492945869763692, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 18:22:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.59454345703125, 'train_avg_loss': 0.6720719655354818, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:22:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 322.59454345703125, 'train_avg_loss': 0.6720719655354818, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 18:22:31 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #191) -------------
2025-10-09 18:22:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=191 aidx=7 | s=5 (candidates=6)
2025-10-09 18:22:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 26, 29, 45, 47] (from 6)
2025-10-09 18:22:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:22:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:22:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:23:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:23:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.564514, avg_loss=0.678259, seen=480, correct=267, accuracy=0.556250
2025-10-09 18:23:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:23:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:23:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:23:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2296MB allocated=2116MB
2025-10-09 18:23:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.87327778339386, 'train_avg_loss': 0.6739439815282822, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 18:23:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.56451416015625, 'train_avg_loss': 0.6782594045003255, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 18:23:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 325.56451416015625, 'train_avg_loss': 0.6782594045003255, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 18:23:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:23:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:23:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-09 18:23:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:23:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:23:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:23:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:23:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:23:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:24:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:24:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.937256, avg_loss=0.662369, seen=480, correct=297, accuracy=0.618750
2025-10-09 18:24:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:24:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:24:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:24:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2296MB allocated=2116MB
2025-10-09 18:24:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.28913760185242, 'train_avg_loss': 0.6357428133487701, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 18:24:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.937255859375, 'train_avg_loss': 0.6623692830403646, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 18:24:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 317.937255859375, 'train_avg_loss': 0.6623692830403646, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 18:24:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:24:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:24:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-09 18:24:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:24:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:24:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:24:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:24:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:24:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:24:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:24:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.649597, avg_loss=0.665937, seen=480, correct=280, accuracy=0.583333
2025-10-09 18:24:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:24:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:24:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:24:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2304MB allocated=2116MB
2025-10-09 18:24:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.14775866270065, 'train_avg_loss': 0.6678979888558387, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 18:24:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.64959716796875, 'train_avg_loss': 0.6659366607666015, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 18:24:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 319.64959716796875, 'train_avg_loss': 0.6659366607666015, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 18:24:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:24:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:24:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:25:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:25:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.896576, avg_loss=0.666451, seen=480, correct=273, accuracy=0.568750
2025-10-09 18:25:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:25:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:25:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:25:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2296MB allocated=2116MB
2025-10-09 18:25:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.6668359041214, 'train_avg_loss': 0.6638902992010116, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 18:25:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.8965759277344, 'train_avg_loss': 0.6664511998494466, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 18:25:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 319.8965759277344, 'train_avg_loss': 0.6664511998494466, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 18:25:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:25:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:25:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-09 18:25:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:25:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:25:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:25:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:25:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:25:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:26:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:26:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.803528, avg_loss=0.664174, seen=480, correct=290, accuracy=0.604167
2025-10-09 18:26:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:26:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:26:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:26:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2296MB allocated=2116MB
2025-10-09 18:26:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.13346672058105, 'train_avg_loss': 0.6677788893381754, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 18:26:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.80352783203125, 'train_avg_loss': 0.6641740163167318, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 18:26:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 318.80352783203125, 'train_avg_loss': 0.6641740163167318, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 18:26:18 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #192) -------------
2025-10-09 18:26:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=192 aidx=7 | s=5 (candidates=6)
2025-10-09 18:26:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 1, 29, 26, 47] (from 6)
2025-10-09 18:26:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:26:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:26:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:27:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:27:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.298706, avg_loss=0.665206, seen=480, correct=280, accuracy=0.583333
2025-10-09 18:27:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:27:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:27:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:27:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2296MB allocated=2116MB
2025-10-09 18:27:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.71929633617401, 'train_avg_loss': 0.6643274694681167, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:27:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.2987060546875, 'train_avg_loss': 0.6652056376139323, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 18:27:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 319.2987060546875, 'train_avg_loss': 0.6652056376139323, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 18:27:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:27:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:27:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:27:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:27:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.863892, avg_loss=0.676800, seen=480, correct=269, accuracy=0.560417
2025-10-09 18:27:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:27:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:27:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:27:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2296MB allocated=2116MB
2025-10-09 18:27:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.64391934871674, 'train_avg_loss': 0.6720326612393062, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 18:27:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.8638916015625, 'train_avg_loss': 0.6767997741699219, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 18:27:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 324.8638916015625, 'train_avg_loss': 0.6767997741699219, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 18:27:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:27:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:27:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-09 18:27:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:27:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:27:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:27:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:27:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:27:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:28:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:28:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.986572, avg_loss=0.666639, seen=480, correct=295, accuracy=0.614583
2025-10-09 18:28:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:28:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:28:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:28:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2302MB allocated=2116MB
2025-10-09 18:28:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.66834324598312, 'train_avg_loss': 0.6639028603831927, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 18:28:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.986572265625, 'train_avg_loss': 0.6666386922200521, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 18:28:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 319.986572265625, 'train_avg_loss': 0.6666386922200521, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 18:28:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:28:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:28:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-09 18:28:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:28:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:28:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:28:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:28:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:28:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:29:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:29:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.782837, avg_loss=0.662048, seen=480, correct=292, accuracy=0.608333
2025-10-09 18:29:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:29:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:29:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:29:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2296MB allocated=2116MB
2025-10-09 18:29:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.43577748537064, 'train_avg_loss': 0.645298145711422, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 18:29:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.7828369140625, 'train_avg_loss': 0.6620475769042968, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 18:29:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 317.7828369140625, 'train_avg_loss': 0.6620475769042968, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 18:29:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:29:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:29:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:30:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:30:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.219482, avg_loss=0.650457, seen=480, correct=297, accuracy=0.618750
2025-10-09 18:30:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:30:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:30:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:30:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2296MB allocated=2116MB
2025-10-09 18:30:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.33675420284271, 'train_avg_loss': 0.6611396183570226, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 18:30:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.219482421875, 'train_avg_loss': 0.650457255045573, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 18:30:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 312.219482421875, 'train_avg_loss': 0.650457255045573, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 18:30:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #193) -------------
2025-10-09 18:30:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=193 aidx=7 | s=5 (candidates=6)
2025-10-09 18:30:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 47, 26, 29, 45] (from 6)
2025-10-09 18:30:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:30:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:30:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-09 18:30:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:30:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:30:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:30:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:30:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:30:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:30:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:30:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.758362, avg_loss=0.697413, seen=480, correct=253, accuracy=0.527083
2025-10-09 18:30:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:30:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:30:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:30:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2296MB allocated=2116MB
2025-10-09 18:30:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.52428418397903, 'train_avg_loss': 0.7127023681998252, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 18:30:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.75836181640625, 'train_avg_loss': 0.6974132537841797, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 18:30:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 334.75836181640625, 'train_avg_loss': 0.6974132537841797, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 18:30:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:30:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:30:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-09 18:30:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:30:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:30:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:30:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:30:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:30:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:31:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:31:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.383667, avg_loss=0.638299, seen=480, correct=309, accuracy=0.643750
2025-10-09 18:31:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:31:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:31:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:31:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2296MB allocated=2116MB
2025-10-09 18:31:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.63528251647949, 'train_avg_loss': 0.6469606876373291, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 18:31:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.3836669921875, 'train_avg_loss': 0.638299306233724, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 18:31:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 306.3836669921875, 'train_avg_loss': 0.638299306233724, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 18:31:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:31:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:31:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:32:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:32:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.579773, avg_loss=0.659541, seen=480, correct=287, accuracy=0.597917
2025-10-09 18:32:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:32:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:32:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:32:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2296MB allocated=2116MB
2025-10-09 18:32:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.80743843317032, 'train_avg_loss': 0.640061986943086, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 18:32:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.57977294921875, 'train_avg_loss': 0.6595411936442057, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 18:32:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 316.57977294921875, 'train_avg_loss': 0.6595411936442057, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 18:32:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:32:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:32:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-09 18:32:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-09 18:32:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:32:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:32:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:32:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:32:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:32:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:32:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.951233, avg_loss=0.666565, seen=480, correct=289, accuracy=0.602083
2025-10-09 18:32:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:32:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:33:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:33:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2302MB allocated=2116MB
2025-10-09 18:33:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.46179276704788, 'train_avg_loss': 0.6621816063920657, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 18:33:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.95123291015625, 'train_avg_loss': 0.6665650685628255, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 18:33:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 319.95123291015625, 'train_avg_loss': 0.6665650685628255, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 18:33:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:33:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:33:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:33:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:33:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.029022, avg_loss=0.664644, seen=480, correct=283, accuracy=0.589583
2025-10-09 18:33:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:33:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:33:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:33:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2296MB allocated=2116MB
2025-10-09 18:33:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.30703330039978, 'train_avg_loss': 0.6692252775033315, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 18:33:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0290222167969, 'train_avg_loss': 0.6646437962849935, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 18:33:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 319.0290222167969, 'train_avg_loss': 0.6646437962849935, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 18:33:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #194) -------------
2025-10-09 18:33:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=194 aidx=7 | s=5 (candidates=6)
2025-10-09 18:33:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 45, 26, 47, 1] (from 6)
2025-10-09 18:33:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-09 18:33:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:33:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:34:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:34:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.144989, avg_loss=0.698219, seen=480, correct=254, accuracy=0.529167
2025-10-09 18:34:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:34:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:34:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:34:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2296MB allocated=2116MB
2025-10-09 18:34:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.30005759000778, 'train_avg_loss': 0.7108338132500649, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 18:34:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.1449890136719, 'train_avg_loss': 0.6982187271118164, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:34:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 335.1449890136719, 'train_avg_loss': 0.6982187271118164, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:34:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-09 18:34:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:34:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:35:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:35:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.446899, avg_loss=0.650931, seen=480, correct=299, accuracy=0.622917
2025-10-09 18:35:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:35:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:35:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:35:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2296MB allocated=2116MB
2025-10-09 18:35:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.25779777765274, 'train_avg_loss': 0.6521483148137729, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 18:35:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.4468994140625, 'train_avg_loss': 0.6509310404459635, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 18:35:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 312.4468994140625, 'train_avg_loss': 0.6509310404459635, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 18:35:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-09 18:35:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:35:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:35:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:35:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.578003, avg_loss=0.661621, seen=480, correct=276, accuracy=0.575000
2025-10-09 18:35:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:35:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:36:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:36:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2296MB allocated=2116MB
2025-10-09 18:36:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.76499372720718, 'train_avg_loss': 0.6397082810600598, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 18:36:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.5780029296875, 'train_avg_loss': 0.6616208394368489, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 18:36:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 317.5780029296875, 'train_avg_loss': 0.6616208394368489, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 18:36:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-09 18:36:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:36:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:36:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:36:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.409912, avg_loss=0.640437, seen=480, correct=308, accuracy=0.641667
2025-10-09 18:36:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:36:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:36:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:36:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2296MB allocated=2116MB
2025-10-09 18:36:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.89156997203827, 'train_avg_loss': 0.6490964164336522, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 18:36:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.409912109375, 'train_avg_loss': 0.6404373168945312, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 18:36:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 307.409912109375, 'train_avg_loss': 0.6404373168945312, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 18:36:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:36:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:36:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-09 18:36:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-09 18:36:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:36:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:36:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:36:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:36:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:37:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:37:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.497345, avg_loss=0.676036, seen=480, correct=274, accuracy=0.570833
2025-10-09 18:37:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:37:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:37:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:37:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2296MB allocated=2116MB
2025-10-09 18:37:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.25735461711884, 'train_avg_loss': 0.6688112884759903, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 18:37:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.4973449707031, 'train_avg_loss': 0.6760361353556316, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 18:37:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 324.4973449707031, 'train_avg_loss': 0.6760361353556316, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 18:37:31 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #195) -------------
2025-10-09 18:37:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=195 aidx=8 | s=5 (candidates=12)
2025-10-09 18:37:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 14, 49, 10, 39] (from 12)
2025-10-09 18:37:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:37:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:37:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-09 18:37:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 18:37:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:37:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:37:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:37:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:37:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:38:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:38:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.996002, avg_loss=0.712492, seen=480, correct=254, accuracy=0.529167
2025-10-09 18:38:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:38:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:38:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:38:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2330MB allocated=2200MB
2025-10-09 18:38:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.74345803260803, 'train_avg_loss': 0.7228621502717336, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 18:38:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.9960021972656, 'train_avg_loss': 0.7124916712443033, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:38:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 341.9960021972656, 'train_avg_loss': 0.7124916712443033, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 18:38:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:38:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:38:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-09 18:38:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 18:38:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:38:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:38:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:38:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:38:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:38:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:38:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.044586, avg_loss=0.727176, seen=480, correct=250, accuracy=0.520833
2025-10-09 18:38:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:38:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:39:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:39:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2342MB allocated=2208MB
2025-10-09 18:39:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.87191092967987, 'train_avg_loss': 0.7155992577473322, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 18:39:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.0445861816406, 'train_avg_loss': 0.7271762212117513, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 18:39:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 349.0445861816406, 'train_avg_loss': 0.7271762212117513, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 18:39:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:39:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:39:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-09 18:39:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 18:39:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:39:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:39:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:39:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:39:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:39:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:39:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=351.425049, avg_loss=0.732136, seen=480, correct=237, accuracy=0.493750
2025-10-09 18:39:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:39:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:39:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:39:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2392MB allocated=2217MB
2025-10-09 18:39:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 91.7297711968422, 'train_avg_loss': 0.7644147599736849, 'train_seen': 120, 'train_correct': 49, 'train_acc': 0.4083333333333333}}
2025-10-09 18:39:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 351.425048828125, 'train_avg_loss': 0.732135518391927, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 18:39:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 351.425048828125, 'train_avg_loss': 0.732135518391927, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 18:39:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:39:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:39:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-09 18:39:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 18:39:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:39:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:39:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:39:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:39:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:40:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:40:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.807892, avg_loss=0.710016, seen=480, correct=244, accuracy=0.508333
2025-10-09 18:40:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:40:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:40:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:40:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2396MB allocated=2225MB
2025-10-09 18:40:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.63541465997696, 'train_avg_loss': 0.6969617888331413, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:40:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.8078918457031, 'train_avg_loss': 0.7100164413452148, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 18:40:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 340.8078918457031, 'train_avg_loss': 0.7100164413452148, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 18:40:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:40:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:40:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-09 18:40:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 18:40:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:40:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:40:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:40:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:40:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:41:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:41:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=350.074738, avg_loss=0.729322, seen=480, correct=239, accuracy=0.497917
2025-10-09 18:41:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:41:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:41:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:41:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2362MB allocated=2234MB
2025-10-09 18:41:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.80249786376953, 'train_avg_loss': 0.7233541488647461, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 18:41:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 350.0747375488281, 'train_avg_loss': 0.7293223698933919, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 18:41:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 350.0747375488281, 'train_avg_loss': 0.7293223698933919, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 18:41:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #196) -------------
2025-10-09 18:41:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=196 aidx=8 | s=5 (candidates=12)
2025-10-09 18:41:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 46, 38, 18, 52] (from 12)
2025-10-09 18:41:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:41:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:41:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-09 18:41:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 18:41:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:41:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:41:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:41:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:41:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:42:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:42:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.180145, avg_loss=0.708709, seen=480, correct=247, accuracy=0.514583
2025-10-09 18:42:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:42:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:42:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:42:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2456MB allocated=2318MB
2025-10-09 18:42:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.16008877754211, 'train_avg_loss': 0.7096674064795176, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 18:42:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.1801452636719, 'train_avg_loss': 0.7087086359659831, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 18:42:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 340.1801452636719, 'train_avg_loss': 0.7087086359659831, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 18:42:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:42:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:42:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-09 18:42:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 18:42:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:42:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:42:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:42:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:42:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:42:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:42:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.419067, avg_loss=0.700873, seen=480, correct=253, accuracy=0.527083
2025-10-09 18:42:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:42:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:42:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:42:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2504MB allocated=2326MB
2025-10-09 18:42:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.73445457220078, 'train_avg_loss': 0.7227871214350065, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 18:42:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4190673828125, 'train_avg_loss': 0.700873057047526, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 18:42:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 336.4190673828125, 'train_avg_loss': 0.700873057047526, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 18:42:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:42:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:42:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-09 18:42:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 18:42:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:42:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:42:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:42:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:42:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:43:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:43:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.351257, avg_loss=0.692398, seen=480, correct=267, accuracy=0.556250
2025-10-09 18:43:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:43:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:43:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:43:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2506MB allocated=2335MB
2025-10-09 18:43:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.41954416036606, 'train_avg_loss': 0.6868295346697172, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 18:43:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.35125732421875, 'train_avg_loss': 0.6923984527587891, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 18:43:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 332.35125732421875, 'train_avg_loss': 0.6923984527587891, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 18:43:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:43:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:43:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-09 18:43:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 18:43:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:43:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:43:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:43:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:43:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:44:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:44:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.000824, avg_loss=0.706252, seen=480, correct=252, accuracy=0.525000
2025-10-09 18:44:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:44:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:44:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:44:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2522MB allocated=2343MB
2025-10-09 18:44:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.32803773880005, 'train_avg_loss': 0.7110669811566671, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:44:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.0008239746094, 'train_avg_loss': 0.7062517166137695, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:44:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 339.0008239746094, 'train_avg_loss': 0.7062517166137695, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:44:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:44:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:44:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-09 18:44:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 18:44:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:44:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:44:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:44:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:44:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:45:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:45:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.056213, avg_loss=0.702200, seen=480, correct=248, accuracy=0.516667
2025-10-09 18:45:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:45:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:45:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:45:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2502MB allocated=2351MB
2025-10-09 18:45:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.17141938209534, 'train_avg_loss': 0.6847618281841278, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 18:45:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.05621337890625, 'train_avg_loss': 0.702200444539388, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 18:45:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 337.05621337890625, 'train_avg_loss': 0.702200444539388, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 18:45:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #197) -------------
2025-10-09 18:45:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=197 aidx=8 | s=5 (candidates=12)
2025-10-09 18:45:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 49, 18, 52, 39] (from 12)
2025-10-09 18:45:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:45:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:45:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-09 18:45:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 18:45:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:45:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:45:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:45:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:45:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:45:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:45:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.966553, avg_loss=0.697847, seen=480, correct=246, accuracy=0.512500
2025-10-09 18:45:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:45:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:46:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:46:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2486MB allocated=2276MB
2025-10-09 18:46:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.69008958339691, 'train_avg_loss': 0.6890840798616409, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:46:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.966552734375, 'train_avg_loss': 0.6978469848632812, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 18:46:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 334.966552734375, 'train_avg_loss': 0.6978469848632812, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 18:46:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:46:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:46:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-09 18:46:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 18:46:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:46:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:46:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:46:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:46:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:46:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:46:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.978485, avg_loss=0.708289, seen=480, correct=227, accuracy=0.472917
2025-10-09 18:46:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:46:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:46:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:46:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2484MB allocated=2276MB
2025-10-09 18:46:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.33315360546112, 'train_avg_loss': 0.719442946712176, 'train_seen': 120, 'train_correct': 51, 'train_acc': 0.425}}
2025-10-09 18:46:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.9784851074219, 'train_avg_loss': 0.7082885106404623, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-09 18:46:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 339.9784851074219, 'train_avg_loss': 0.7082885106404623, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-09 18:46:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:46:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:46:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-09 18:46:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 18:46:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:46:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:46:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:46:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:46:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:47:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:47:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.253479, avg_loss=0.702611, seen=480, correct=241, accuracy=0.502083
2025-10-09 18:47:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:47:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:47:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:47:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2498MB allocated=2276MB
2025-10-09 18:47:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.35111176967621, 'train_avg_loss': 0.7112592647473017, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 18:47:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.25347900390625, 'train_avg_loss': 0.7026114145914714, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 18:47:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 337.25347900390625, 'train_avg_loss': 0.7026114145914714, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 18:47:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:47:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:47:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-09 18:47:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 18:47:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:47:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:47:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:47:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:47:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:48:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:48:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.042786, avg_loss=0.695922, seen=480, correct=255, accuracy=0.531250
2025-10-09 18:48:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:48:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:48:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:48:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2472MB allocated=2276MB
2025-10-09 18:48:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.55876398086548, 'train_avg_loss': 0.6796563665072123, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 18:48:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.04278564453125, 'train_avg_loss': 0.6959224700927734, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 18:48:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 334.04278564453125, 'train_avg_loss': 0.6959224700927734, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 18:48:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 18:48:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:48:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:48:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:48:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.146118, avg_loss=0.702388, seen=480, correct=250, accuracy=0.520833
2025-10-09 18:48:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:48:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:49:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:49:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2472MB allocated=2276MB
2025-10-09 18:49:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.85625886917114, 'train_avg_loss': 0.7071354905764262, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 18:49:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.1461181640625, 'train_avg_loss': 0.7023877461751302, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 18:49:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 337.1461181640625, 'train_avg_loss': 0.7023877461751302, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 18:49:04 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #198) -------------
2025-10-09 18:49:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=198 aidx=8 | s=5 (candidates=12)
2025-10-09 18:49:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 10, 13, 53, 18] (from 12)
2025-10-09 18:49:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:49:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:49:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-09 18:49:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 18:49:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:49:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:49:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:49:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:49:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:49:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:49:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.905426, avg_loss=0.691470, seen=480, correct=258, accuracy=0.537500
2025-10-09 18:49:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:49:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:49:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:49:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2400MB allocated=2200MB
2025-10-09 18:49:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.76300781965256, 'train_avg_loss': 0.689691731830438, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 18:49:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.9054260253906, 'train_avg_loss': 0.6914696375528971, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 18:49:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 331.9054260253906, 'train_avg_loss': 0.6914696375528971, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 18:49:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:49:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:49:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-09 18:49:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 18:49:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:49:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:49:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:49:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:49:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:50:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:50:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.612183, avg_loss=0.692942, seen=480, correct=252, accuracy=0.525000
2025-10-09 18:50:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:50:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:50:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:50:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2412MB allocated=2200MB
2025-10-09 18:50:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.42323446273804, 'train_avg_loss': 0.6868602871894837, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 18:50:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.6121826171875, 'train_avg_loss': 0.6929420471191406, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:50:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 332.6121826171875, 'train_avg_loss': 0.6929420471191406, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:50:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:50:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:50:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-09 18:50:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 18:50:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:50:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:50:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:50:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:50:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:51:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:51:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.186798, avg_loss=0.694139, seen=480, correct=245, accuracy=0.510417
2025-10-09 18:51:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:51:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:51:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:51:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2424MB allocated=2284MB
2025-10-09 18:51:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.92011046409607, 'train_avg_loss': 0.6910009205341339, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:51:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.1867980957031, 'train_avg_loss': 0.6941391626993815, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 18:51:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 333.1867980957031, 'train_avg_loss': 0.6941391626993815, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 18:51:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:51:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:51:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-09 18:51:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 18:51:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:51:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:51:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:51:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:51:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:52:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:52:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.776459, avg_loss=0.699534, seen=480, correct=251, accuracy=0.522917
2025-10-09 18:52:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:52:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:52:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:52:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2396MB allocated=2209MB
2025-10-09 18:52:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.94677937030792, 'train_avg_loss': 0.699556494752566, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 18:52:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.7764587402344, 'train_avg_loss': 0.699534289042155, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 18:52:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 335.7764587402344, 'train_avg_loss': 0.699534289042155, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 18:52:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 18:52:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:52:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:52:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:52:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.002289, avg_loss=0.700005, seen=480, correct=240, accuracy=0.500000
2025-10-09 18:52:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:52:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:52:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:52:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2418MB allocated=2209MB
2025-10-09 18:52:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.906669318676, 'train_avg_loss': 0.7075555776556333, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 18:52:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.0022888183594, 'train_avg_loss': 0.700004768371582, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 18:52:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 336.0022888183594, 'train_avg_loss': 0.700004768371582, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-09 18:52:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #199) -------------
2025-10-09 18:52:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=199 aidx=8 | s=5 (candidates=12)
2025-10-09 18:52:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[19, 53, 14, 38, 52] (from 12)
2025-10-09 18:52:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:52:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:52:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-09 18:52:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 18:52:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:52:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:52:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:52:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:52:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:53:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:53:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.570038, avg_loss=0.694938, seen=480, correct=252, accuracy=0.525000
2025-10-09 18:53:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:53:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:53:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:53:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2518MB allocated=2293MB
2025-10-09 18:53:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.72805523872375, 'train_avg_loss': 0.6810671269893647, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 18:53:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5700378417969, 'train_avg_loss': 0.6949375788370769, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:53:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 333.5700378417969, 'train_avg_loss': 0.6949375788370769, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:53:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 18:53:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:53:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:54:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:54:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.766937, avg_loss=0.699514, seen=480, correct=242, accuracy=0.504167
2025-10-09 18:54:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:54:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:54:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:54:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2416MB allocated=2217MB
2025-10-09 18:54:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.86827600002289, 'train_avg_loss': 0.6989023000001907, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:54:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.7669372558594, 'train_avg_loss': 0.6995144526163737, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 18:54:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 335.7669372558594, 'train_avg_loss': 0.6995144526163737, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 18:54:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 18:54:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:54:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:55:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:55:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.344299, avg_loss=0.704884, seen=480, correct=253, accuracy=0.527083
2025-10-09 18:55:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:55:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:55:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:55:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2416MB allocated=2217MB
2025-10-09 18:55:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.07125353813171, 'train_avg_loss': 0.6839271128177643, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 18:55:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.34429931640625, 'train_avg_loss': 0.7048839569091797, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 18:55:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 338.34429931640625, 'train_avg_loss': 0.7048839569091797, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 18:55:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 18:55:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:55:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:55:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:55:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.074982, avg_loss=0.693906, seen=480, correct=260, accuracy=0.541667
2025-10-09 18:55:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:55:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:55:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:55:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2418MB allocated=2217MB
2025-10-09 18:55:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.97531461715698, 'train_avg_loss': 0.6914609551429749, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 18:55:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0749816894531, 'train_avg_loss': 0.6939062118530274, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 18:55:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 333.0749816894531, 'train_avg_loss': 0.6939062118530274, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 18:55:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 18:55:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:55:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:56:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:56:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.341156, avg_loss=0.690294, seen=480, correct=262, accuracy=0.545833
2025-10-09 18:56:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:56:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:56:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:56:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2416MB allocated=2217MB
2025-10-09 18:56:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.90442419052124, 'train_avg_loss': 0.6742035349210104, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 18:56:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3411560058594, 'train_avg_loss': 0.6902940750122071, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 18:56:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 331.3411560058594, 'train_avg_loss': 0.6902940750122071, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 18:56:34 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #200) -------------
2025-10-09 18:56:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=200 aidx=8 | s=5 (candidates=12)
2025-10-09 18:56:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 38, 46, 52, 19] (from 12)
2025-10-09 18:56:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 18:56:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:56:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:57:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:57:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.490479, avg_loss=0.696855, seen=480, correct=249, accuracy=0.518750
2025-10-09 18:57:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:57:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:57:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:57:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2416MB allocated=2217MB
2025-10-09 18:57:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.85885012149811, 'train_avg_loss': 0.6904904176791509, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 18:57:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.490478515625, 'train_avg_loss': 0.6968551635742187, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 18:57:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 334.490478515625, 'train_avg_loss': 0.6968551635742187, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 18:57:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:57:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:57:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-09 18:57:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 18:57:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:57:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:57:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:57:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:57:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:58:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:58:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.450134, avg_loss=0.688438, seen=480, correct=252, accuracy=0.525000
2025-10-09 18:58:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:58:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:58:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:58:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2418MB allocated=2217MB
2025-10-09 18:58:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.88675904273987, 'train_avg_loss': 0.6823896586894989, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 18:58:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.45013427734375, 'train_avg_loss': 0.6884377797444662, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:58:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 330.45013427734375, 'train_avg_loss': 0.6884377797444662, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 18:58:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:58:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:58:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-09 18:58:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 18:58:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:58:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:58:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:58:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:58:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:58:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:58:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.495728, avg_loss=0.696866, seen=480, correct=250, accuracy=0.520833
2025-10-09 18:58:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:58:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:58:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:58:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2428MB allocated=2217MB
2025-10-09 18:58:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.9830961227417, 'train_avg_loss': 0.7248591343561809, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-09 18:58:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.4957275390625, 'train_avg_loss': 0.6968660990397135, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 18:58:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 334.4957275390625, 'train_avg_loss': 0.6968660990397135, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-09 18:58:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:58:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:58:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-09 18:58:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 18:58:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:58:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:58:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:58:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:58:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 18:59:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 18:59:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.475800, avg_loss=0.684325, seen=480, correct=274, accuracy=0.570833
2025-10-09 18:59:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 18:59:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:59:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 18:59:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2416MB allocated=2217MB
2025-10-09 18:59:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.40731751918793, 'train_avg_loss': 0.670060979326566, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 18:59:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4757995605469, 'train_avg_loss': 0.684324582417806, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 18:59:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 328.4757995605469, 'train_avg_loss': 0.684324582417806, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 18:59:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 18:59:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 18:59:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-09 18:59:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 18:59:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 18:59:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 18:59:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 18:59:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 18:59:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:00:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:00:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.181763, avg_loss=0.694129, seen=480, correct=248, accuracy=0.516667
2025-10-09 19:00:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:00:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:00:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:00:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2472MB allocated=2217MB
2025-10-09 19:00:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73514688014984, 'train_avg_loss': 0.6977928906679154, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 19:00:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.1817626953125, 'train_avg_loss': 0.694128672281901, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 19:00:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 333.1817626953125, 'train_avg_loss': 0.694128672281901, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 19:00:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #201) -------------
2025-10-09 19:00:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=201 aidx=8 | s=5 (candidates=12)
2025-10-09 19:00:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 19, 14, 52, 39] (from 12)
2025-10-09 19:00:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:00:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:00:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-09 19:00:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 19:00:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:00:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:00:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:00:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:00:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:01:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:01:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.906494, avg_loss=0.685222, seen=480, correct=265, accuracy=0.552083
2025-10-09 19:01:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:01:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:01:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:01:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2426MB allocated=2217MB
2025-10-09 19:01:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.6681045293808, 'train_avg_loss': 0.6722342044115066, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:01:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.906494140625, 'train_avg_loss': 0.6852218627929687, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 19:01:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 328.906494140625, 'train_avg_loss': 0.6852218627929687, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 19:01:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 19:01:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:01:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:01:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:01:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.338959, avg_loss=0.688206, seen=480, correct=253, accuracy=0.527083
2025-10-09 19:01:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:01:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:01:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:01:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2472MB allocated=2217MB
2025-10-09 19:01:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.42745673656464, 'train_avg_loss': 0.6868954728047053, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 19:01:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3389587402344, 'train_avg_loss': 0.688206164042155, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 19:01:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 330.3389587402344, 'train_avg_loss': 0.688206164042155, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 19:01:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:01:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:01:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-09 19:01:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:01:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:01:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:01:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:01:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:01:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:02:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:02:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.265320, avg_loss=0.704719, seen=480, correct=251, accuracy=0.522917
2025-10-09 19:02:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:02:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:02:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:02:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2416MB allocated=2217MB
2025-10-09 19:02:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49649977684021, 'train_avg_loss': 0.6958041648070018, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 19:02:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.26531982421875, 'train_avg_loss': 0.7047194163004558, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 19:02:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 338.26531982421875, 'train_avg_loss': 0.7047194163004558, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 19:02:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:02:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:02:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:03:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:03:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.502136, avg_loss=0.682296, seen=480, correct=276, accuracy=0.575000
2025-10-09 19:03:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:03:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:03:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:03:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2416MB allocated=2217MB
2025-10-09 19:03:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.67414712905884, 'train_avg_loss': 0.6639512260754903, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 19:03:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.50213623046875, 'train_avg_loss': 0.6822961171468099, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 19:03:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 327.50213623046875, 'train_avg_loss': 0.6822961171468099, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 19:03:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:03:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:03:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:04:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:04:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.522644, avg_loss=0.690672, seen=480, correct=266, accuracy=0.554167
2025-10-09 19:04:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:04:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:04:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:04:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2416MB allocated=2217MB
2025-10-09 19:04:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.95506185293198, 'train_avg_loss': 0.6912921821077664, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 19:04:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.52264404296875, 'train_avg_loss': 0.6906721750895183, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 19:04:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 331.52264404296875, 'train_avg_loss': 0.6906721750895183, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 19:04:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #202) -------------
2025-10-09 19:04:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=202 aidx=8 | s=5 (candidates=12)
2025-10-09 19:04:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[10, 52, 49, 14, 39] (from 12)
2025-10-09 19:04:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:04:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:04:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-09 19:04:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 19:04:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:04:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:04:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:04:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:04:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:04:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:04:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.299042, avg_loss=0.681873, seen=480, correct=261, accuracy=0.543750
2025-10-09 19:04:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:04:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:04:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:04:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2426MB allocated=2217MB
2025-10-09 19:04:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.79320526123047, 'train_avg_loss': 0.673276710510254, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 19:04:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.2990417480469, 'train_avg_loss': 0.6818730036417643, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:04:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 327.2990417480469, 'train_avg_loss': 0.6818730036417643, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:04:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:04:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:04:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:05:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:05:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.200867, avg_loss=0.681668, seen=480, correct=273, accuracy=0.568750
2025-10-09 19:05:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:05:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:05:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:05:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2416MB allocated=2217MB
2025-10-09 19:05:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.15544497966766, 'train_avg_loss': 0.6596287081638972, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 19:05:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.20086669921875, 'train_avg_loss': 0.681668472290039, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 19:05:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 327.20086669921875, 'train_avg_loss': 0.681668472290039, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 19:05:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:05:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:05:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:06:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:06:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.194122, avg_loss=0.698321, seen=480, correct=248, accuracy=0.516667
2025-10-09 19:06:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:06:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:06:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:06:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2420MB allocated=2217MB
2025-10-09 19:06:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.16987717151642, 'train_avg_loss': 0.7180823097626369, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 19:06:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.1941223144531, 'train_avg_loss': 0.6983210881551106, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 19:06:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 335.1941223144531, 'train_avg_loss': 0.6983210881551106, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 19:06:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:06:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:06:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:07:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:07:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.725159, avg_loss=0.699427, seen=480, correct=258, accuracy=0.537500
2025-10-09 19:07:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:07:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:07:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:07:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2416MB allocated=2217MB
2025-10-09 19:07:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63577950000763, 'train_avg_loss': 0.6802981625000636, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 19:07:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.72515869140625, 'train_avg_loss': 0.6994274139404297, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 19:07:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 335.72515869140625, 'train_avg_loss': 0.6994274139404297, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 19:07:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:07:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:07:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-09 19:07:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:07:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:07:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:07:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:07:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:07:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:07:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:07:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.490021, avg_loss=0.680188, seen=480, correct=282, accuracy=0.587500
2025-10-09 19:07:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:07:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:07:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:07:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2416MB allocated=2217MB
2025-10-09 19:07:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62601512670517, 'train_avg_loss': 0.6802167927225431, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 19:07:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.4900207519531, 'train_avg_loss': 0.6801875432332357, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 19:07:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 326.4900207519531, 'train_avg_loss': 0.6801875432332357, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 19:07:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #203) -------------
2025-10-09 19:07:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=203 aidx=8 | s=5 (candidates=12)
2025-10-09 19:07:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 46, 49, 14, 13] (from 12)
2025-10-09 19:07:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:07:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:07:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:08:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:08:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.567383, avg_loss=0.680349, seen=480, correct=272, accuracy=0.566667
2025-10-09 19:08:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:08:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:08:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:08:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2416MB allocated=2217MB
2025-10-09 19:08:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.11025512218475, 'train_avg_loss': 0.6592521260182063, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 19:08:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.5673828125, 'train_avg_loss': 0.6803487141927084, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 19:08:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 326.5673828125, 'train_avg_loss': 0.6803487141927084, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 19:08:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:08:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:08:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:09:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:09:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.980927, avg_loss=0.695794, seen=480, correct=253, accuracy=0.527083
2025-10-09 19:09:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:09:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:09:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:09:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2428MB allocated=2217MB
2025-10-09 19:09:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.03471839427948, 'train_avg_loss': 0.7169559866189956, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 19:09:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9809265136719, 'train_avg_loss': 0.6957935969034831, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 19:09:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 333.9809265136719, 'train_avg_loss': 0.6957935969034831, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 19:09:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:09:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:09:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-09 19:09:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:09:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:09:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:09:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:09:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:09:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:10:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:10:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.560486, avg_loss=0.697001, seen=480, correct=255, accuracy=0.531250
2025-10-09 19:10:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:10:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:10:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:10:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2420MB allocated=2217MB
2025-10-09 19:10:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.63917207717896, 'train_avg_loss': 0.7136597673098246, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 19:10:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.56048583984375, 'train_avg_loss': 0.6970010121663411, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 19:10:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 334.56048583984375, 'train_avg_loss': 0.6970010121663411, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 19:10:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:10:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:10:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:10:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:10:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.331238, avg_loss=0.696523, seen=480, correct=260, accuracy=0.541667
2025-10-09 19:10:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:10:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:10:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:10:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2416MB allocated=2217MB
2025-10-09 19:10:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.98894375562668, 'train_avg_loss': 0.6749078646302223, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 19:10:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.33123779296875, 'train_avg_loss': 0.6965234120686848, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 19:10:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 334.33123779296875, 'train_avg_loss': 0.6965234120686848, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 19:10:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:10:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:10:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-09 19:10:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:10:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:10:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:10:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:10:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:10:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:11:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:11:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.424347, avg_loss=0.686301, seen=480, correct=267, accuracy=0.556250
2025-10-09 19:11:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:11:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:11:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:11:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2416MB allocated=2217MB
2025-10-09 19:11:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.75452476739883, 'train_avg_loss': 0.6896210397283237, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 19:11:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4243469238281, 'train_avg_loss': 0.6863007227579753, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 19:11:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 329.4243469238281, 'train_avg_loss': 0.6863007227579753, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 19:11:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #204) -------------
2025-10-09 19:11:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=204 aidx=8 | s=5 (candidates=12)
2025-10-09 19:11:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 53, 39, 13, 38] (from 12)
2025-10-09 19:11:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:11:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:11:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:12:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:12:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.290070, avg_loss=0.679771, seen=480, correct=264, accuracy=0.550000
2025-10-09 19:12:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:12:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:12:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:12:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2416MB allocated=2217MB
2025-10-09 19:12:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.54942262172699, 'train_avg_loss': 0.6629118551810582, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 19:12:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.2900695800781, 'train_avg_loss': 0.6797709782918294, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:12:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 326.2900695800781, 'train_avg_loss': 0.6797709782918294, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:12:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:12:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:12:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-09 19:12:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:12:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:12:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:12:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:12:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:12:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:13:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:13:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.418671, avg_loss=0.694622, seen=480, correct=267, accuracy=0.556250
2025-10-09 19:13:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:13:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:13:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:13:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2416MB allocated=2217MB
2025-10-09 19:13:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.38052904605865, 'train_avg_loss': 0.6781710753838222, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 19:13:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.4186706542969, 'train_avg_loss': 0.6946222305297851, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 19:13:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 333.4186706542969, 'train_avg_loss': 0.6946222305297851, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 19:13:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:13:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:13:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:13:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:13:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.425049, avg_loss=0.673802, seen=480, correct=272, accuracy=0.566667
2025-10-09 19:13:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:13:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:13:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:13:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2416MB allocated=2217MB
2025-10-09 19:13:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.98216342926025, 'train_avg_loss': 0.6748513619105021, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 19:13:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.425048828125, 'train_avg_loss': 0.6738021850585938, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 19:13:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 323.425048828125, 'train_avg_loss': 0.6738021850585938, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 19:13:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:13:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:13:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-09 19:13:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:13:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:13:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:13:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:13:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:13:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:14:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:14:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.624634, avg_loss=0.682551, seen=480, correct=264, accuracy=0.550000
2025-10-09 19:14:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:14:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:14:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:14:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2416MB allocated=2217MB
2025-10-09 19:14:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.07175827026367, 'train_avg_loss': 0.6839313189188639, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 19:14:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6246337890625, 'train_avg_loss': 0.6825513203938802, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:14:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 327.6246337890625, 'train_avg_loss': 0.6825513203938802, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:14:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 19:14:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:14:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:15:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:15:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.810333, avg_loss=0.687105, seen=480, correct=268, accuracy=0.558333
2025-10-09 19:15:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:15:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:15:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:15:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2418MB allocated=2217MB
2025-10-09 19:15:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.84931081533432, 'train_avg_loss': 0.682077590127786, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 19:15:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8103332519531, 'train_avg_loss': 0.687104860941569, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 19:15:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 329.8103332519531, 'train_avg_loss': 0.687104860941569, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 19:15:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #205) -------------
2025-10-09 19:15:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=205 aidx=8 | s=5 (candidates=12)
2025-10-09 19:15:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 10, 49, 14, 38] (from 12)
2025-10-09 19:15:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:15:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:15:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:16:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:16:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.708435, avg_loss=0.674393, seen=480, correct=288, accuracy=0.600000
2025-10-09 19:16:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:16:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:16:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:16:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2416MB allocated=2217MB
2025-10-09 19:16:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.87462383508682, 'train_avg_loss': 0.6739551986257235, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:16:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.70843505859375, 'train_avg_loss': 0.674392573038737, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 19:16:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 323.70843505859375, 'train_avg_loss': 0.674392573038737, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 19:16:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 19:16:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:16:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:16:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:16:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.739227, avg_loss=0.674457, seen=480, correct=272, accuracy=0.566667
2025-10-09 19:16:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:16:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:16:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:16:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2426MB allocated=2217MB
2025-10-09 19:16:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.21072053909302, 'train_avg_loss': 0.6684226711591085, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 19:16:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.7392272949219, 'train_avg_loss': 0.6744567235310872, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 19:16:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 323.7392272949219, 'train_avg_loss': 0.6744567235310872, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 19:16:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:16:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:16:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:17:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:17:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.527222, avg_loss=0.694848, seen=480, correct=254, accuracy=0.529167
2025-10-09 19:17:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:17:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:17:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:17:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2420MB allocated=2217MB
2025-10-09 19:17:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.19926589727402, 'train_avg_loss': 0.7099938824772835, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-09 19:17:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5272216796875, 'train_avg_loss': 0.694848378499349, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 19:17:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 333.5272216796875, 'train_avg_loss': 0.694848378499349, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 19:17:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:17:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:17:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:18:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:18:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.870605, avg_loss=0.695564, seen=480, correct=263, accuracy=0.547917
2025-10-09 19:18:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:18:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:18:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:18:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2416MB allocated=2217MB
2025-10-09 19:18:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.44663614034653, 'train_avg_loss': 0.6703886345028878, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:18:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.87060546875, 'train_avg_loss': 0.6955637613932292, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 19:18:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 333.87060546875, 'train_avg_loss': 0.6955637613932292, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 19:18:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 19:18:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:18:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:19:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:19:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.189240, avg_loss=0.675394, seen=480, correct=276, accuracy=0.575000
2025-10-09 19:19:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:19:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:19:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:19:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2418MB allocated=2217MB
2025-10-09 19:19:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.50052893161774, 'train_avg_loss': 0.6708377410968145, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 19:19:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.1892395019531, 'train_avg_loss': 0.6753942489624023, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 19:19:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 324.1892395019531, 'train_avg_loss': 0.6753942489624023, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 19:19:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #206) -------------
2025-10-09 19:19:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=206 aidx=8 | s=5 (candidates=12)
2025-10-09 19:19:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 18, 38, 23, 46] (from 12)
2025-10-09 19:19:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:19:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:19:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-09 19:19:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:19:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:19:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:19:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:19:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:19:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:20:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:20:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.457581, avg_loss=0.692620, seen=480, correct=261, accuracy=0.543750
2025-10-09 19:20:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:20:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:20:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:20:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2416MB allocated=2217MB
2025-10-09 19:20:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.3692016005516, 'train_avg_loss': 0.66141001333793, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 19:20:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.45758056640625, 'train_avg_loss': 0.6926199595133463, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:20:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 332.45758056640625, 'train_avg_loss': 0.6926199595133463, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:20:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 19:20:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:20:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:20:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:20:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.120697, avg_loss=0.689835, seen=480, correct=254, accuracy=0.529167
2025-10-09 19:20:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:20:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:20:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:20:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2436MB allocated=2217MB
2025-10-09 19:20:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.0096343755722, 'train_avg_loss': 0.7000802864631017, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 19:20:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1206970214844, 'train_avg_loss': 0.6898347854614257, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 19:20:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 331.1206970214844, 'train_avg_loss': 0.6898347854614257, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 19:20:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 19:20:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:20:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:21:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:21:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.201477, avg_loss=0.667086, seen=480, correct=289, accuracy=0.602083
2025-10-09 19:21:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:21:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:21:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:21:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2418MB allocated=2217MB
2025-10-09 19:21:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.70102280378342, 'train_avg_loss': 0.6641751900315285, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 19:21:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.20147705078125, 'train_avg_loss': 0.667086410522461, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 19:21:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 320.20147705078125, 'train_avg_loss': 0.667086410522461, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 19:21:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:21:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:21:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-09 19:21:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 19:21:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:21:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:21:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:21:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:21:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:22:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:22:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.900452, avg_loss=0.695626, seen=480, correct=270, accuracy=0.562500
2025-10-09 19:22:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:22:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:22:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:22:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2416MB allocated=2217MB
2025-10-09 19:22:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.0766926407814, 'train_avg_loss': 0.700639105339845, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:22:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.90045166015625, 'train_avg_loss': 0.6956259409586588, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 19:22:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 333.90045166015625, 'train_avg_loss': 0.6956259409586588, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 19:22:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:22:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:22:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-09 19:22:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:22:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:22:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:22:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:22:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:22:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:23:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:23:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.265625, avg_loss=0.696387, seen=480, correct=249, accuracy=0.518750
2025-10-09 19:23:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:23:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:23:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:23:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2432MB allocated=2217MB
2025-10-09 19:23:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.77898961305618, 'train_avg_loss': 0.7148249134421348, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 19:23:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.265625, 'train_avg_loss': 0.69638671875, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 19:23:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 334.265625, 'train_avg_loss': 0.69638671875, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 19:23:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #207) -------------
2025-10-09 19:23:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=207 aidx=8 | s=5 (candidates=12)
2025-10-09 19:23:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 23, 13, 46, 53] (from 12)
2025-10-09 19:23:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:23:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:23:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-09 19:23:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:23:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:23:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:23:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:23:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:23:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:23:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:23:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.621185, avg_loss=0.672127, seen=480, correct=277, accuracy=0.577083
2025-10-09 19:23:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:23:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:23:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:24:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2416MB allocated=2217MB
2025-10-09 19:24:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.71089279651642, 'train_avg_loss': 0.6559241066376368, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 19:24:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6211853027344, 'train_avg_loss': 0.6721274693806966, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 19:24:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 322.6211853027344, 'train_avg_loss': 0.6721274693806966, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 19:24:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 19:24:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:24:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:24:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:24:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.543854, avg_loss=0.694883, seen=480, correct=262, accuracy=0.545833
2025-10-09 19:24:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:24:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:24:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:24:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2416MB allocated=2217MB
2025-10-09 19:24:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.84856879711151, 'train_avg_loss': 0.6987380733092626, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 19:24:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5438537597656, 'train_avg_loss': 0.6948830286661783, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:24:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 333.5438537597656, 'train_avg_loss': 0.6948830286661783, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:24:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:24:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:24:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:25:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:25:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.989197, avg_loss=0.672894, seen=480, correct=280, accuracy=0.583333
2025-10-09 19:25:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:25:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:25:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:25:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2416MB allocated=2217MB
2025-10-09 19:25:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.71204912662506, 'train_avg_loss': 0.6726004093885422, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:25:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.98919677734375, 'train_avg_loss': 0.6728941599527994, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 19:25:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 322.98919677734375, 'train_avg_loss': 0.6728941599527994, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 19:25:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:25:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:25:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-09 19:25:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:25:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:25:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:25:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:25:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:25:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:26:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:26:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.602173, avg_loss=0.690838, seen=480, correct=260, accuracy=0.541667
2025-10-09 19:26:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:26:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:26:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:26:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2432MB allocated=2217MB
2025-10-09 19:26:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.86199617385864, 'train_avg_loss': 0.707183301448822, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 19:26:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6021728515625, 'train_avg_loss': 0.6908378601074219, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 19:26:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 331.6021728515625, 'train_avg_loss': 0.6908378601074219, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 19:26:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:26:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:26:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-09 19:26:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:26:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:26:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:26:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:26:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:26:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:26:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:26:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.077881, avg_loss=0.693912, seen=480, correct=264, accuracy=0.550000
2025-10-09 19:26:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:26:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:26:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:27:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2416MB allocated=2217MB
2025-10-09 19:27:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.83463263511658, 'train_avg_loss': 0.6819552719593048, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:27:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.077880859375, 'train_avg_loss': 0.6939122517903645, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:27:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 333.077880859375, 'train_avg_loss': 0.6939122517903645, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:27:01 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #208) -------------
2025-10-09 19:27:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=208 aidx=8 | s=5 (candidates=12)
2025-10-09 19:27:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 39, 13, 53, 46] (from 12)
2025-10-09 19:27:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:27:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:27:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:27:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:27:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.309753, avg_loss=0.692312, seen=480, correct=268, accuracy=0.558333
2025-10-09 19:27:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:27:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:27:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:27:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2416MB allocated=2217MB
2025-10-09 19:27:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.80672562122345, 'train_avg_loss': 0.6650560468435287, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 19:27:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.30975341796875, 'train_avg_loss': 0.6923119862874348, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 19:27:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 332.30975341796875, 'train_avg_loss': 0.6923119862874348, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 19:27:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:27:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:27:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:28:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:28:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.506439, avg_loss=0.673972, seen=480, correct=284, accuracy=0.591667
2025-10-09 19:28:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:28:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:28:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:28:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2416MB allocated=2217MB
2025-10-09 19:28:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.58033168315887, 'train_avg_loss': 0.6715027640263239, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 19:28:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.5064392089844, 'train_avg_loss': 0.6739717483520508, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 19:28:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 323.5064392089844, 'train_avg_loss': 0.6739717483520508, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 19:28:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:28:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:28:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:29:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:29:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.025513, avg_loss=0.672970, seen=480, correct=281, accuracy=0.585417
2025-10-09 19:29:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:29:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:29:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:29:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2416MB allocated=2217MB
2025-10-09 19:29:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.88591313362122, 'train_avg_loss': 0.6740492761135102, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:29:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0255126953125, 'train_avg_loss': 0.6729698181152344, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 19:29:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 323.0255126953125, 'train_avg_loss': 0.6729698181152344, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 19:29:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:29:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:29:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:29:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:29:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.059265, avg_loss=0.685540, seen=480, correct=270, accuracy=0.562500
2025-10-09 19:29:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:29:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:29:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:30:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2416MB allocated=2217MB
2025-10-09 19:30:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.55424791574478, 'train_avg_loss': 0.6796187326312065, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 19:30:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.05926513671875, 'train_avg_loss': 0.6855401357014974, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 19:30:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 329.05926513671875, 'train_avg_loss': 0.6855401357014974, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 19:30:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:30:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:30:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-09 19:30:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:30:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:30:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:30:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:30:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:30:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:30:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:30:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.987000, avg_loss=0.689556, seen=480, correct=262, accuracy=0.545833
2025-10-09 19:30:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:30:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:30:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:30:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2432MB allocated=2217MB
2025-10-09 19:30:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.5356450676918, 'train_avg_loss': 0.7044637088974317, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 19:30:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.98699951171875, 'train_avg_loss': 0.6895562489827474, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:30:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 330.98699951171875, 'train_avg_loss': 0.6895562489827474, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:30:47 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #209) -------------
2025-10-09 19:30:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=209 aidx=8 | s=5 (candidates=12)
2025-10-09 19:30:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 46, 49, 13, 53] (from 12)
2025-10-09 19:30:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:30:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:30:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-09 19:30:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 19:30:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:30:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:30:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:30:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:30:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:31:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:31:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.823639, avg_loss=0.691299, seen=480, correct=263, accuracy=0.547917
2025-10-09 19:31:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:31:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:31:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:31:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2416MB allocated=2217MB
2025-10-09 19:31:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.83852481842041, 'train_avg_loss': 0.6903210401535034, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 19:31:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8236389160156, 'train_avg_loss': 0.6912992477416993, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 19:31:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 331.8236389160156, 'train_avg_loss': 0.6912992477416993, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 19:31:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:31:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:31:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:32:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:32:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.238861, avg_loss=0.683831, seen=480, correct=266, accuracy=0.554167
2025-10-09 19:32:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:32:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:32:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:32:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2432MB allocated=2217MB
2025-10-09 19:32:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.06159353256226, 'train_avg_loss': 0.7005132794380188, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 19:32:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2388610839844, 'train_avg_loss': 0.6838309605916341, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 19:32:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 328.2388610839844, 'train_avg_loss': 0.6838309605916341, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 19:32:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:32:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:32:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:33:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:33:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.857422, avg_loss=0.691370, seen=480, correct=255, accuracy=0.531250
2025-10-09 19:33:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:33:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:33:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:33:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2420MB allocated=2217MB
2025-10-09 19:33:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.13762974739075, 'train_avg_loss': 0.7094802478949229, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 19:33:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.857421875, 'train_avg_loss': 0.69136962890625, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 19:33:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 331.857421875, 'train_avg_loss': 0.69136962890625, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 19:33:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:33:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:33:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-09 19:33:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:33:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:33:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:33:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:33:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:33:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:33:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:33:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.930908, avg_loss=0.672773, seen=480, correct=285, accuracy=0.593750
2025-10-09 19:33:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:33:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:33:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:33:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2416MB allocated=2217MB
2025-10-09 19:33:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.51163983345032, 'train_avg_loss': 0.6709303319454193, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 19:33:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.930908203125, 'train_avg_loss': 0.6727727254231771, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 19:33:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 322.930908203125, 'train_avg_loss': 0.6727727254231771, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 19:33:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:33:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:33:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:34:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:34:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.402252, avg_loss=0.684171, seen=480, correct=261, accuracy=0.543750
2025-10-09 19:34:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:34:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:34:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:34:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2416MB allocated=2217MB
2025-10-09 19:34:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.21479964256287, 'train_avg_loss': 0.6767899970213572, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 19:34:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4022521972656, 'train_avg_loss': 0.6841713587443033, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:34:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 328.4022521972656, 'train_avg_loss': 0.6841713587443033, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:34:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #210) -------------
2025-10-09 19:34:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=210 aidx=8 | s=5 (candidates=12)
2025-10-09 19:34:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 53, 13, 10, 38] (from 12)
2025-10-09 19:34:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:34:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:34:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:35:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:35:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.574188, avg_loss=0.686613, seen=480, correct=265, accuracy=0.552083
2025-10-09 19:35:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:35:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:35:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:35:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2432MB allocated=2217MB
2025-10-09 19:35:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.45959120988846, 'train_avg_loss': 0.6954965934157371, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 19:35:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5741882324219, 'train_avg_loss': 0.686612892150879, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 19:35:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 329.5741882324219, 'train_avg_loss': 0.686612892150879, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 19:35:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:35:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:35:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:36:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:36:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.959412, avg_loss=0.679082, seen=480, correct=273, accuracy=0.568750
2025-10-09 19:36:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:36:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:36:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:36:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2416MB allocated=2217MB
2025-10-09 19:36:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.64357459545135, 'train_avg_loss': 0.6720297882954279, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 19:36:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.95941162109375, 'train_avg_loss': 0.6790821075439453, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 19:36:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 325.95941162109375, 'train_avg_loss': 0.6790821075439453, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 19:36:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:36:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:36:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-09 19:36:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:36:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:36:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:36:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:36:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:36:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:36:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:36:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.360413, avg_loss=0.673668, seen=480, correct=286, accuracy=0.595833
2025-10-09 19:36:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:36:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:36:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:36:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2416MB allocated=2217MB
2025-10-09 19:36:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.22108709812164, 'train_avg_loss': 0.6768423924843471, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 19:36:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.36041259765625, 'train_avg_loss': 0.6736675262451172, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 19:36:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 323.36041259765625, 'train_avg_loss': 0.6736675262451172, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 19:36:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 19:36:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:36:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:37:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:37:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.629517, avg_loss=0.672145, seen=480, correct=279, accuracy=0.581250
2025-10-09 19:37:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:37:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:37:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:37:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2426MB allocated=2217MB
2025-10-09 19:37:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.74805331230164, 'train_avg_loss': 0.664567110935847, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:37:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6295166015625, 'train_avg_loss': 0.6721448262532552, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 19:37:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 322.6295166015625, 'train_avg_loss': 0.6721448262532552, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 19:37:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:37:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:37:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-09 19:37:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 19:37:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:37:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:37:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:37:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:37:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:38:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:38:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.769958, avg_loss=0.672437, seen=480, correct=277, accuracy=0.577083
2025-10-09 19:38:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:38:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:38:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:38:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2418MB allocated=2217MB
2025-10-09 19:38:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.24609756469727, 'train_avg_loss': 0.6687174797058105, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 19:38:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.76995849609375, 'train_avg_loss': 0.6724374135335286, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 19:38:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 322.76995849609375, 'train_avg_loss': 0.6724374135335286, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 19:38:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #211) -------------
2025-10-09 19:38:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=211 aidx=8 | s=5 (candidates=12)
2025-10-09 19:38:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 49, 52, 23, 10] (from 12)
2025-10-09 19:38:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:38:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:38:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #211, planning to set LR to 1.00e-05
2025-10-09 19:38:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 19:38:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:38:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:38:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:38:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:38:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:39:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:39:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.097961, avg_loss=0.685621, seen=480, correct=251, accuracy=0.522917
2025-10-09 19:39:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:39:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:39:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:39:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=211 reserved=2436MB allocated=2217MB
2025-10-09 19:39:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 211, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.07886725664139, 'train_avg_loss': 0.6923238938053449, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 19:39:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 211, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.09796142578125, 'train_avg_loss': 0.6856207529703776, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 19:39:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 211, 'Results_raw': {'train_total': 480, 'train_loss': 329.09796142578125, 'train_avg_loss': 0.6856207529703776, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 19:39:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #211, planning to set LR to 1.00e-05
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:39:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:39:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:39:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:39:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.958130, avg_loss=0.691579, seen=480, correct=254, accuracy=0.529167
2025-10-09 19:39:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:39:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:40:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:40:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=211 reserved=2420MB allocated=2217MB
2025-10-09 19:40:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 211, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.13084506988525, 'train_avg_loss': 0.7094237089157105, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-09 19:40:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 211, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.9581298828125, 'train_avg_loss': 0.6915794372558594, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 19:40:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 211, 'Results_raw': {'train_total': 480, 'train_loss': 331.9581298828125, 'train_avg_loss': 0.6915794372558594, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 19:40:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #211, planning to set LR to 1.00e-05
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:40:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:40:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:40:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:40:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.515137, avg_loss=0.667740, seen=480, correct=288, accuracy=0.600000
2025-10-09 19:40:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:40:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:40:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:40:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=211 reserved=2416MB allocated=2217MB
2025-10-09 19:40:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 211, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.6533967256546, 'train_avg_loss': 0.647111639380455, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 19:40:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 211, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.51513671875, 'train_avg_loss': 0.6677398681640625, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 19:40:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 211, 'Results_raw': {'train_total': 480, 'train_loss': 320.51513671875, 'train_avg_loss': 0.6677398681640625, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 19:40:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #211, planning to set LR to 1.00e-05
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 19:40:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:40:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:41:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:41:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.313385, avg_loss=0.690236, seen=480, correct=270, accuracy=0.562500
2025-10-09 19:41:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:41:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:41:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:41:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=211 reserved=2416MB allocated=2217MB
2025-10-09 19:41:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 211, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3170879483223, 'train_avg_loss': 0.6943090662360192, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:41:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 211, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3133850097656, 'train_avg_loss': 0.690236218770345, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 19:41:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 211, 'Results_raw': {'train_total': 480, 'train_loss': 331.3133850097656, 'train_avg_loss': 0.690236218770345, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 19:41:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:41:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:41:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #211, planning to set LR to 1.00e-05
2025-10-09 19:41:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 19:41:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:41:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:41:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:41:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:41:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:42:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:42:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.399506, avg_loss=0.667499, seen=480, correct=286, accuracy=0.595833
2025-10-09 19:42:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:42:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:42:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:42:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=211 reserved=2426MB allocated=2217MB
2025-10-09 19:42:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 211, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.67960941791534, 'train_avg_loss': 0.6639967451492945, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 19:42:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 211, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.3995056152344, 'train_avg_loss': 0.6674989700317383, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 19:42:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 211, 'Results_raw': {'train_total': 480, 'train_loss': 320.3995056152344, 'train_avg_loss': 0.6674989700317383, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 19:42:20 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #212) -------------
2025-10-09 19:42:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=212 aidx=8 | s=5 (candidates=12)
2025-10-09 19:42:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 18, 39, 23, 53] (from 12)
2025-10-09 19:42:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #212, planning to set LR to 1.00e-05
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:42:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:42:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:43:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:43:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.854919, avg_loss=0.666364, seen=480, correct=283, accuracy=0.589583
2025-10-09 19:43:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:43:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:43:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:43:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=212 reserved=2416MB allocated=2217MB
2025-10-09 19:43:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 212, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.70970296859741, 'train_avg_loss': 0.6475808580716451, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:43:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 212, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.85491943359375, 'train_avg_loss': 0.6663644154866536, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 19:43:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 212, 'Results_raw': {'train_total': 480, 'train_loss': 319.85491943359375, 'train_avg_loss': 0.6663644154866536, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 19:43:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:43:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:43:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #212, planning to set LR to 1.00e-05
2025-10-09 19:43:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 19:43:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:43:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:43:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:43:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:43:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:43:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:43:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.995026, avg_loss=0.683323, seen=480, correct=262, accuracy=0.545833
2025-10-09 19:43:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:43:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:43:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:43:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=212 reserved=2436MB allocated=2217MB
2025-10-09 19:43:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 212, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.32692438364029, 'train_avg_loss': 0.6943910365303357, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 19:43:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 212, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.9950256347656, 'train_avg_loss': 0.6833229700724284, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:43:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 212, 'Results_raw': {'train_total': 480, 'train_loss': 327.9950256347656, 'train_avg_loss': 0.6833229700724284, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:43:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:43:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:43:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #212, planning to set LR to 1.00e-05
2025-10-09 19:43:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:43:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:43:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:43:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:43:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:43:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:44:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:44:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.374634, avg_loss=0.669530, seen=480, correct=293, accuracy=0.610417
2025-10-09 19:44:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:44:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:44:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:44:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=212 reserved=2416MB allocated=2217MB
2025-10-09 19:44:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 212, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.12910306453705, 'train_avg_loss': 0.6677425255378088, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 19:44:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 212, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3746337890625, 'train_avg_loss': 0.6695304870605469, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 19:44:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 212, 'Results_raw': {'train_total': 480, 'train_loss': 321.3746337890625, 'train_avg_loss': 0.6695304870605469, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 19:44:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #212, planning to set LR to 1.00e-05
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 19:44:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:44:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:45:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:45:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.811920, avg_loss=0.691275, seen=480, correct=261, accuracy=0.543750
2025-10-09 19:45:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:45:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:45:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:45:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=212 reserved=2416MB allocated=2217MB
2025-10-09 19:45:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 212, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.58917272090912, 'train_avg_loss': 0.6965764393409093, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 19:45:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 212, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8119201660156, 'train_avg_loss': 0.6912748336791992, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:45:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 212, 'Results_raw': {'train_total': 480, 'train_loss': 331.8119201660156, 'train_avg_loss': 0.6912748336791992, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 19:45:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:45:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:45:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #212, planning to set LR to 1.00e-05
2025-10-09 19:45:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:45:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:45:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:45:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:45:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:45:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:46:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:46:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.986450, avg_loss=0.679138, seen=480, correct=271, accuracy=0.564583
2025-10-09 19:46:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:46:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:46:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:46:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=212 reserved=2416MB allocated=2217MB
2025-10-09 19:46:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 212, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.04439389705658, 'train_avg_loss': 0.6670366158088048, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 19:46:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 212, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.9864501953125, 'train_avg_loss': 0.6791384379069011, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 19:46:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 212, 'Results_raw': {'train_total': 480, 'train_loss': 325.9864501953125, 'train_avg_loss': 0.6791384379069011, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 19:46:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #213) -------------
2025-10-09 19:46:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=213 aidx=8 | s=5 (candidates=12)
2025-10-09 19:46:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 53, 46, 13, 18] (from 12)
2025-10-09 19:46:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #213, planning to set LR to 1.00e-05
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:46:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:46:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:46:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:46:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.388275, avg_loss=0.669559, seen=480, correct=288, accuracy=0.600000
2025-10-09 19:46:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:46:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:46:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:46:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=213 reserved=2416MB allocated=2217MB
2025-10-09 19:46:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 213, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.06098359823227, 'train_avg_loss': 0.6671748633186022, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 19:46:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 213, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.3882751464844, 'train_avg_loss': 0.6695589065551758, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 19:46:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 213, 'Results_raw': {'train_total': 480, 'train_loss': 321.3882751464844, 'train_avg_loss': 0.6695589065551758, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 19:46:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:46:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:46:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #213, planning to set LR to 1.00e-05
2025-10-09 19:46:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:46:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:46:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:46:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:46:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:46:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:47:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:47:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.007751, avg_loss=0.670849, seen=480, correct=279, accuracy=0.581250
2025-10-09 19:47:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:47:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:47:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:47:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=213 reserved=2416MB allocated=2217MB
2025-10-09 19:47:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 213, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.7139652967453, 'train_avg_loss': 0.6559497108062108, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 19:47:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 213, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.00775146484375, 'train_avg_loss': 0.6708494822184244, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 19:47:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 213, 'Results_raw': {'train_total': 480, 'train_loss': 322.00775146484375, 'train_avg_loss': 0.6708494822184244, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 19:47:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:47:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:47:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #213, planning to set LR to 1.00e-05
2025-10-09 19:47:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:47:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:47:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:47:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:47:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:47:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:48:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:48:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.838867, avg_loss=0.685081, seen=480, correct=265, accuracy=0.552083
2025-10-09 19:48:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:48:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:48:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:48:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=213 reserved=2432MB allocated=2217MB
2025-10-09 19:48:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 213, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.39655411243439, 'train_avg_loss': 0.6949712842702865, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:48:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 213, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.8388671875, 'train_avg_loss': 0.6850809733072917, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 19:48:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 213, 'Results_raw': {'train_total': 480, 'train_loss': 328.8388671875, 'train_avg_loss': 0.6850809733072917, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 19:48:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #213, planning to set LR to 1.00e-05
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 19:48:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:48:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:49:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:49:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.875793, avg_loss=0.664325, seen=480, correct=289, accuracy=0.602083
2025-10-09 19:49:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:49:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:49:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:49:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=213 reserved=2416MB allocated=2217MB
2025-10-09 19:49:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 213, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.12799042463303, 'train_avg_loss': 0.6677332535386086, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:49:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 213, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.87579345703125, 'train_avg_loss': 0.6643245697021485, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 19:49:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 213, 'Results_raw': {'train_total': 480, 'train_loss': 318.87579345703125, 'train_avg_loss': 0.6643245697021485, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 19:49:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #213, planning to set LR to 1.00e-05
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 19:49:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:49:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:49:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:49:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.150452, avg_loss=0.681563, seen=480, correct=264, accuracy=0.550000
2025-10-09 19:49:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:49:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:49:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:49:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=213 reserved=2436MB allocated=2217MB
2025-10-09 19:49:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 213, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.30450612306595, 'train_avg_loss': 0.6942042176922162, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 19:49:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 213, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.15045166015625, 'train_avg_loss': 0.6815634409586588, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:49:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 213, 'Results_raw': {'train_total': 480, 'train_loss': 327.15045166015625, 'train_avg_loss': 0.6815634409586588, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 19:49:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #214) -------------
2025-10-09 19:49:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=214 aidx=8 | s=5 (candidates=12)
2025-10-09 19:49:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 46, 49, 14, 39] (from 12)
2025-10-09 19:49:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:49:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:49:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #214, planning to set LR to 1.00e-05
2025-10-09 19:49:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:49:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:49:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:49:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:49:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:49:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:50:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:50:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.948853, avg_loss=0.664477, seen=480, correct=281, accuracy=0.585417
2025-10-09 19:50:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:50:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:50:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:50:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=214 reserved=2416MB allocated=2217MB
2025-10-09 19:50:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 214, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.7977197766304, 'train_avg_loss': 0.6399809981385867, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 19:50:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 214, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.9488525390625, 'train_avg_loss': 0.6644767761230469, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 19:50:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 214, 'Results_raw': {'train_total': 480, 'train_loss': 318.9488525390625, 'train_avg_loss': 0.6644767761230469, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 19:50:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:50:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:50:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #214, planning to set LR to 1.00e-05
2025-10-09 19:50:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 19:50:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:50:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:50:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:50:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:50:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:51:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:51:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.509033, avg_loss=0.686477, seen=480, correct=269, accuracy=0.560417
2025-10-09 19:51:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:51:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:51:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:51:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=214 reserved=2432MB allocated=2217MB
2025-10-09 19:51:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 214, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.49909871816635, 'train_avg_loss': 0.687492489318053, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:51:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 214, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.509033203125, 'train_avg_loss': 0.6864771525065104, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 19:51:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 214, 'Results_raw': {'train_total': 480, 'train_loss': 329.509033203125, 'train_avg_loss': 0.6864771525065104, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 19:51:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #214, planning to set LR to 1.00e-05
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:51:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:51:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:52:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:52:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.921143, avg_loss=0.687336, seen=480, correct=258, accuracy=0.537500
2025-10-09 19:52:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:52:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:52:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:52:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=214 reserved=2420MB allocated=2217MB
2025-10-09 19:52:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 214, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.17500537633896, 'train_avg_loss': 0.7181250448028247, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-09 19:52:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 214, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.921142578125, 'train_avg_loss': 0.687335713704427, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 19:52:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 214, 'Results_raw': {'train_total': 480, 'train_loss': 329.921142578125, 'train_avg_loss': 0.687335713704427, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-09 19:52:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #214, planning to set LR to 1.00e-05
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:52:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:52:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:52:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:52:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.576355, avg_loss=0.678284, seen=480, correct=277, accuracy=0.577083
2025-10-09 19:52:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:52:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:52:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:52:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=214 reserved=2416MB allocated=2217MB
2025-10-09 19:52:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 214, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.2692089676857, 'train_avg_loss': 0.6355767413973809, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 19:52:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 214, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.57635498046875, 'train_avg_loss': 0.6782840728759766, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 19:52:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 214, 'Results_raw': {'train_total': 480, 'train_loss': 325.57635498046875, 'train_avg_loss': 0.6782840728759766, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 19:52:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #214, planning to set LR to 1.00e-05
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 19:53:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:53:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:53:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:53:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.952087, avg_loss=0.670734, seen=480, correct=292, accuracy=0.608333
2025-10-09 19:53:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:53:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:53:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:53:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=214 reserved=2416MB allocated=2217MB
2025-10-09 19:53:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 214, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.19265115261078, 'train_avg_loss': 0.6682720929384232, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 19:53:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 214, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.95208740234375, 'train_avg_loss': 0.6707335154215495, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 19:53:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 214, 'Results_raw': {'train_total': 480, 'train_loss': 321.95208740234375, 'train_avg_loss': 0.6707335154215495, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 19:53:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #215) -------------
2025-10-09 19:53:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=215 aidx=8 | s=5 (candidates=12)
2025-10-09 19:53:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 49, 23, 52, 38] (from 12)
2025-10-09 19:53:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #215, planning to set LR to 1.00e-05
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:53:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:53:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:54:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:54:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.884308, avg_loss=0.676842, seen=480, correct=274, accuracy=0.570833
2025-10-09 19:54:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:54:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:54:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:54:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=215 reserved=2416MB allocated=2217MB
2025-10-09 19:54:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 215, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.18649071455002, 'train_avg_loss': 0.6348874226212502, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 19:54:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 215, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.8843078613281, 'train_avg_loss': 0.6768423080444336, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 19:54:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 215, 'Results_raw': {'train_total': 480, 'train_loss': 324.8843078613281, 'train_avg_loss': 0.6768423080444336, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 19:54:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #215, planning to set LR to 1.00e-05
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 19:54:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:54:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:55:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:55:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.694397, avg_loss=0.686863, seen=480, correct=262, accuracy=0.545833
2025-10-09 19:55:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:55:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:55:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:55:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=215 reserved=2420MB allocated=2217MB
2025-10-09 19:55:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 215, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.296233355999, 'train_avg_loss': 0.7108019446333249, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 19:55:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 215, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.69439697265625, 'train_avg_loss': 0.6868633270263672, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:55:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 215, 'Results_raw': {'train_total': 480, 'train_loss': 329.69439697265625, 'train_avg_loss': 0.6868633270263672, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 19:55:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:55:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:55:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #215, planning to set LR to 1.00e-05
2025-10-09 19:55:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 19:55:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:55:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:55:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:55:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:55:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:55:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:55:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.552277, avg_loss=0.686567, seen=480, correct=274, accuracy=0.570833
2025-10-09 19:55:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:55:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:56:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:56:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=215 reserved=2416MB allocated=2217MB
2025-10-09 19:56:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 215, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.85312819480896, 'train_avg_loss': 0.6904427349567414, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 19:56:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 215, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5522766113281, 'train_avg_loss': 0.6865672429402669, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 19:56:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 215, 'Results_raw': {'train_total': 480, 'train_loss': 329.5522766113281, 'train_avg_loss': 0.6865672429402669, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 19:56:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:56:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:56:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #215, planning to set LR to 1.00e-05
2025-10-09 19:56:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 19:56:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:56:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:56:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:56:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:56:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:56:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:56:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.670258, avg_loss=0.663896, seen=480, correct=280, accuracy=0.583333
2025-10-09 19:56:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:56:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:56:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:56:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=215 reserved=2416MB allocated=2217MB
2025-10-09 19:56:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 215, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.91588366031647, 'train_avg_loss': 0.6409656971693038, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 19:56:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 215, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.6702575683594, 'train_avg_loss': 0.6638963699340821, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 19:56:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 215, 'Results_raw': {'train_total': 480, 'train_loss': 318.6702575683594, 'train_avg_loss': 0.6638963699340821, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 19:56:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #215, planning to set LR to 1.00e-05
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 19:56:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:56:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:57:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:57:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.763428, avg_loss=0.655757, seen=480, correct=294, accuracy=0.612500
2025-10-09 19:57:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:57:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:57:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:57:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=215 reserved=2418MB allocated=2217MB
2025-10-09 19:57:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 215, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.86206436157227, 'train_avg_loss': 0.6488505363464355, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 19:57:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 215, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.763427734375, 'train_avg_loss': 0.6557571411132812, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 19:57:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 215, 'Results_raw': {'train_total': 480, 'train_loss': 314.763427734375, 'train_avg_loss': 0.6557571411132812, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 19:57:34 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #216) -------------
2025-10-09 19:57:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=216 aidx=8 | s=5 (candidates=12)
2025-10-09 19:57:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 14, 53, 19, 39] (from 12)
2025-10-09 19:57:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:57:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:57:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #216, planning to set LR to 1.00e-05
2025-10-09 19:57:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 19:57:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:57:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:57:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:57:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:57:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:58:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:58:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.851624, avg_loss=0.643441, seen=480, correct=308, accuracy=0.641667
2025-10-09 19:58:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:58:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:58:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:58:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=216 reserved=2418MB allocated=2217MB
2025-10-09 19:58:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 216, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.45210176706314, 'train_avg_loss': 0.6371008480588595, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 19:58:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 216, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.85162353515625, 'train_avg_loss': 0.6434408823649088, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 19:58:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 216, 'Results_raw': {'train_total': 480, 'train_loss': 308.85162353515625, 'train_avg_loss': 0.6434408823649088, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 19:58:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:58:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:58:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #216, planning to set LR to 1.00e-05
2025-10-09 19:58:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 19:58:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:58:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:58:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:58:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:58:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:59:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:59:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.409393, avg_loss=0.673770, seen=480, correct=278, accuracy=0.579167
2025-10-09 19:59:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:59:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:59:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:59:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=216 reserved=2416MB allocated=2217MB
2025-10-09 19:59:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 216, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.30403560400009, 'train_avg_loss': 0.6192002967000008, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 19:59:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 216, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4093933105469, 'train_avg_loss': 0.6737695693969726, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 19:59:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 216, 'Results_raw': {'train_total': 480, 'train_loss': 323.4093933105469, 'train_avg_loss': 0.6737695693969726, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 19:59:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:59:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:59:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #216, planning to set LR to 1.00e-05
2025-10-09 19:59:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 19:59:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:59:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:59:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:59:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:59:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 19:59:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 19:59:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.205566, avg_loss=0.667095, seen=480, correct=283, accuracy=0.589583
2025-10-09 19:59:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 19:59:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:59:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 19:59:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=216 reserved=2416MB allocated=2217MB
2025-10-09 19:59:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 216, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.96428608894348, 'train_avg_loss': 0.649702384074529, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 19:59:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 216, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.20556640625, 'train_avg_loss': 0.6670949300130208, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 19:59:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 216, 'Results_raw': {'train_total': 480, 'train_loss': 320.20556640625, 'train_avg_loss': 0.6670949300130208, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 19:59:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #216, planning to set LR to 1.00e-05
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 19:59:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 19:59:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:00:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:00:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.541718, avg_loss=0.659462, seen=480, correct=297, accuracy=0.618750
2025-10-09 20:00:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:00:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:00:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:00:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=216 reserved=2470MB allocated=2217MB
2025-10-09 20:00:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 216, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.0731310248375, 'train_avg_loss': 0.6422760918736458, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 20:00:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 216, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.5417175292969, 'train_avg_loss': 0.6594619115193685, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 20:00:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 216, 'Results_raw': {'train_total': 480, 'train_loss': 316.5417175292969, 'train_avg_loss': 0.6594619115193685, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 20:00:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:00:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:00:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #216, planning to set LR to 1.00e-05
2025-10-09 20:00:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:00:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:00:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:00:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:00:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:00:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:01:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:01:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.815643, avg_loss=0.657949, seen=480, correct=296, accuracy=0.616667
2025-10-09 20:01:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:01:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:01:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:01:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=216 reserved=2416MB allocated=2217MB
2025-10-09 20:01:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 216, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.93238282203674, 'train_avg_loss': 0.6494365235169729, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 20:01:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 216, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.8156433105469, 'train_avg_loss': 0.6579492568969727, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 20:01:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 216, 'Results_raw': {'train_total': 480, 'train_loss': 315.8156433105469, 'train_avg_loss': 0.6579492568969727, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 20:01:18 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #217) -------------
2025-10-09 20:01:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=217 aidx=8 | s=5 (candidates=12)
2025-10-09 20:01:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 46, 14, 49, 18] (from 12)
2025-10-09 20:01:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #217, planning to set LR to 1.00e-05
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:01:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:01:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:02:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:02:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.082458, avg_loss=0.650172, seen=480, correct=298, accuracy=0.620833
2025-10-09 20:02:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:02:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:02:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:02:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=217 reserved=2416MB allocated=2217MB
2025-10-09 20:02:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 217, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.57493311166763, 'train_avg_loss': 0.6381244425972302, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 20:02:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 217, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.08245849609375, 'train_avg_loss': 0.6501717885335286, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 20:02:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 217, 'Results_raw': {'train_total': 480, 'train_loss': 312.08245849609375, 'train_avg_loss': 0.6501717885335286, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 20:02:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #217, planning to set LR to 1.00e-05
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:02:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:02:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:02:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:02:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.904114, avg_loss=0.689384, seen=480, correct=263, accuracy=0.547917
2025-10-09 20:02:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:02:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:02:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:02:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=217 reserved=2432MB allocated=2217MB
2025-10-09 20:02:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 217, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.19734227657318, 'train_avg_loss': 0.6933111856381099, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 20:02:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 217, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.90411376953125, 'train_avg_loss': 0.6893835703531901, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 20:02:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 217, 'Results_raw': {'train_total': 480, 'train_loss': 330.90411376953125, 'train_avg_loss': 0.6893835703531901, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 20:02:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #217, planning to set LR to 1.00e-05
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 20:02:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:02:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:03:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:03:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.687897, avg_loss=0.672266, seen=480, correct=280, accuracy=0.583333
2025-10-09 20:03:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:03:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:03:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:03:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=217 reserved=2416MB allocated=2217MB
2025-10-09 20:03:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 217, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.51895785331726, 'train_avg_loss': 0.6126579821109772, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 20:03:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 217, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6878967285156, 'train_avg_loss': 0.6722664515177409, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 20:03:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 217, 'Results_raw': {'train_total': 480, 'train_loss': 322.6878967285156, 'train_avg_loss': 0.6722664515177409, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 20:03:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #217, planning to set LR to 1.00e-05
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:03:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:03:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:04:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:04:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.558716, avg_loss=0.686581, seen=480, correct=265, accuracy=0.552083
2025-10-09 20:04:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:04:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:04:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:04:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=217 reserved=2420MB allocated=2217MB
2025-10-09 20:04:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 217, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.35168915987015, 'train_avg_loss': 0.7112640763322512, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 20:04:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 217, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5587158203125, 'train_avg_loss': 0.6865806579589844, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 20:04:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 217, 'Results_raw': {'train_total': 480, 'train_loss': 329.5587158203125, 'train_avg_loss': 0.6865806579589844, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 20:04:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:04:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:04:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #217, planning to set LR to 1.00e-05
2025-10-09 20:04:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:04:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:04:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:04:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:04:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:04:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:05:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:05:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.650787, avg_loss=0.672189, seen=480, correct=284, accuracy=0.591667
2025-10-09 20:05:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:05:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:05:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:05:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=217 reserved=2436MB allocated=2217MB
2025-10-09 20:05:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 217, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.50037586688995, 'train_avg_loss': 0.687503132224083, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 20:05:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 217, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6507873535156, 'train_avg_loss': 0.6721891403198242, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 20:05:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 217, 'Results_raw': {'train_total': 480, 'train_loss': 322.6507873535156, 'train_avg_loss': 0.6721891403198242, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 20:05:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #218) -------------
2025-10-09 20:05:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=218 aidx=8 | s=5 (candidates=12)
2025-10-09 20:05:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 39, 10, 18, 19] (from 12)
2025-10-09 20:05:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #218, planning to set LR to 1.00e-05
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:05:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:05:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:05:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:05:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.334839, avg_loss=0.681948, seen=480, correct=276, accuracy=0.575000
2025-10-09 20:05:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:05:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:05:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:05:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=218 reserved=2416MB allocated=2217MB
2025-10-09 20:05:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 218, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.93657612800598, 'train_avg_loss': 0.6911381344000499, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 20:05:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 218, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.3348388671875, 'train_avg_loss': 0.6819475809733073, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 20:05:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 218, 'Results_raw': {'train_total': 480, 'train_loss': 327.3348388671875, 'train_avg_loss': 0.6819475809733073, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 20:05:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:05:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:05:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #218, planning to set LR to 1.00e-05
2025-10-09 20:05:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:05:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:05:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:05:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:05:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:05:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:06:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:06:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.601074, avg_loss=0.649169, seen=480, correct=299, accuracy=0.622917
2025-10-09 20:06:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:06:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:06:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:06:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=218 reserved=2416MB allocated=2217MB
2025-10-09 20:06:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 218, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.0470717549324, 'train_avg_loss': 0.6420589312911034, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 20:06:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 218, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.60107421875, 'train_avg_loss': 0.6491689046223958, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 20:06:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 218, 'Results_raw': {'train_total': 480, 'train_loss': 311.60107421875, 'train_avg_loss': 0.6491689046223958, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 20:06:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:06:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:06:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #218, planning to set LR to 1.00e-05
2025-10-09 20:06:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:06:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:06:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:06:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:06:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:06:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:07:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:07:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.071960, avg_loss=0.637650, seen=480, correct=305, accuracy=0.635417
2025-10-09 20:07:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:07:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:07:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:07:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=218 reserved=2426MB allocated=2217MB
2025-10-09 20:07:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 218, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.45531892776489, 'train_avg_loss': 0.6371276577313741, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:07:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 218, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.07196044921875, 'train_avg_loss': 0.6376499176025391, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 20:07:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 218, 'Results_raw': {'train_total': 480, 'train_loss': 306.07196044921875, 'train_avg_loss': 0.6376499176025391, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 20:07:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:07:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:07:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #218, planning to set LR to 1.00e-05
2025-10-09 20:07:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:07:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:07:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:07:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:07:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:07:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:08:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:08:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.847015, avg_loss=0.662181, seen=480, correct=289, accuracy=0.602083
2025-10-09 20:08:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:08:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:08:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:08:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=218 reserved=2436MB allocated=2217MB
2025-10-09 20:08:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 218, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63657474517822, 'train_avg_loss': 0.6803047895431519, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 20:08:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 218, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8470153808594, 'train_avg_loss': 0.662181282043457, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 20:08:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 218, 'Results_raw': {'train_total': 480, 'train_loss': 317.8470153808594, 'train_avg_loss': 0.662181282043457, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 20:08:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #218, planning to set LR to 1.00e-05
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 20:08:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:08:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:08:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:08:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.350281, avg_loss=0.659063, seen=480, correct=289, accuracy=0.602083
2025-10-09 20:08:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:08:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:08:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:08:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=218 reserved=2470MB allocated=2217MB
2025-10-09 20:08:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 218, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.32114899158478, 'train_avg_loss': 0.6360095749298732, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 20:08:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 218, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.35028076171875, 'train_avg_loss': 0.6590630849202473, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 20:08:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 218, 'Results_raw': {'train_total': 480, 'train_loss': 316.35028076171875, 'train_avg_loss': 0.6590630849202473, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-09 20:08:54 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #219) -------------
2025-10-09 20:08:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=219 aidx=8 | s=5 (candidates=12)
2025-10-09 20:08:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 13, 23, 49, 46] (from 12)
2025-10-09 20:08:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #219, planning to set LR to 1.00e-05
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 20:08:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:08:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:09:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:09:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.447754, avg_loss=0.671766, seen=480, correct=282, accuracy=0.587500
2025-10-09 20:09:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:09:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:09:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:09:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=219 reserved=2416MB allocated=2217MB
2025-10-09 20:09:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 219, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.14725252985954, 'train_avg_loss': 0.6178937710821628, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 20:09:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 219, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.44775390625, 'train_avg_loss': 0.6717661539713542, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:09:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 219, 'Results_raw': {'train_total': 480, 'train_loss': 322.44775390625, 'train_avg_loss': 0.6717661539713542, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:09:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #219, planning to set LR to 1.00e-05
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 20:09:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:09:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:10:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:10:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.318298, avg_loss=0.642330, seen=480, correct=314, accuracy=0.654167
2025-10-09 20:10:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:10:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:10:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:10:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=219 reserved=2416MB allocated=2217MB
2025-10-09 20:10:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 219, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.0125886797905, 'train_avg_loss': 0.6501049056649209, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 20:10:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 219, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.31829833984375, 'train_avg_loss': 0.6423297882080078, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 20:10:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 219, 'Results_raw': {'train_total': 480, 'train_loss': 308.31829833984375, 'train_avg_loss': 0.6423297882080078, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 20:10:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #219, planning to set LR to 1.00e-05
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:10:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:10:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:11:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:11:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.628754, avg_loss=0.684643, seen=480, correct=272, accuracy=0.566667
2025-10-09 20:11:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:11:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:11:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:11:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=219 reserved=2416MB allocated=2217MB
2025-10-09 20:11:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 219, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.80240392684937, 'train_avg_loss': 0.6900200327237447, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 20:11:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 219, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.6287536621094, 'train_avg_loss': 0.6846432367960612, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 20:11:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 219, 'Results_raw': {'train_total': 480, 'train_loss': 328.6287536621094, 'train_avg_loss': 0.6846432367960612, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-09 20:11:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #219, planning to set LR to 1.00e-05
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:11:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:11:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:11:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:11:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.274017, avg_loss=0.685988, seen=480, correct=264, accuracy=0.550000
2025-10-09 20:11:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:11:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:12:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:12:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=219 reserved=2420MB allocated=2217MB
2025-10-09 20:12:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 219, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.06359112262726, 'train_avg_loss': 0.7088632593552272, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 20:12:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 219, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2740173339844, 'train_avg_loss': 0.6859875361124674, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 20:12:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 219, 'Results_raw': {'train_total': 480, 'train_loss': 329.2740173339844, 'train_avg_loss': 0.6859875361124674, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 20:12:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #219, planning to set LR to 1.00e-05
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:12:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:12:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:12:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:12:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.045746, avg_loss=0.685512, seen=480, correct=268, accuracy=0.558333
2025-10-09 20:12:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:12:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:12:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:12:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=219 reserved=2432MB allocated=2217MB
2025-10-09 20:12:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 219, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.72490763664246, 'train_avg_loss': 0.6893742303053538, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 20:12:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 219, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0457458496094, 'train_avg_loss': 0.6855119705200196, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 20:12:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 219, 'Results_raw': {'train_total': 480, 'train_loss': 329.0457458496094, 'train_avg_loss': 0.6855119705200196, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 20:12:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #220) -------------
2025-10-09 20:12:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=220 aidx=8 | s=5 (candidates=12)
2025-10-09 20:12:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 18, 53, 52, 10] (from 12)
2025-10-09 20:12:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:12:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:12:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #220, planning to set LR to 1.00e-05
2025-10-09 20:12:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:12:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:12:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:12:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:12:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:12:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:13:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:13:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.021454, avg_loss=0.683378, seen=480, correct=269, accuracy=0.560417
2025-10-09 20:13:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:13:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:13:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:13:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=220 reserved=2420MB allocated=2217MB
2025-10-09 20:13:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 220, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.21280509233475, 'train_avg_loss': 0.7101067091027896, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 20:13:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 220, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0214538574219, 'train_avg_loss': 0.683378028869629, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 20:13:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 220, 'Results_raw': {'train_total': 480, 'train_loss': 328.0214538574219, 'train_avg_loss': 0.683378028869629, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 20:13:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:13:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:13:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #220, planning to set LR to 1.00e-05
2025-10-09 20:13:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:13:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:13:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:13:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:13:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:13:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:14:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:14:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.188110, avg_loss=0.658725, seen=480, correct=290, accuracy=0.604167
2025-10-09 20:14:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:14:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:14:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:14:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=220 reserved=2436MB allocated=2217MB
2025-10-09 20:14:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 220, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.74746078252792, 'train_avg_loss': 0.672895506521066, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 20:14:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 220, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.1881103515625, 'train_avg_loss': 0.6587252298990885, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 20:14:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 220, 'Results_raw': {'train_total': 480, 'train_loss': 316.1881103515625, 'train_avg_loss': 0.6587252298990885, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 20:14:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:14:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:14:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #220, planning to set LR to 1.00e-05
2025-10-09 20:14:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 20:14:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:14:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:14:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:14:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:14:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:15:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:15:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.185669, avg_loss=0.664970, seen=480, correct=286, accuracy=0.595833
2025-10-09 20:15:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:15:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:15:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:15:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=220 reserved=2416MB allocated=2217MB
2025-10-09 20:15:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 220, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.02121067047119, 'train_avg_loss': 0.6418434222539265, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 20:15:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 220, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.1856689453125, 'train_avg_loss': 0.6649701436360677, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:15:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 220, 'Results_raw': {'train_total': 480, 'train_loss': 319.1856689453125, 'train_avg_loss': 0.6649701436360677, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:15:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #220, planning to set LR to 1.00e-05
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 20:15:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:15:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:15:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:15:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.878601, avg_loss=0.658080, seen=480, correct=277, accuracy=0.577083
2025-10-09 20:15:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:15:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:15:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:15:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=220 reserved=2416MB allocated=2217MB
2025-10-09 20:15:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 220, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.04786205291748, 'train_avg_loss': 0.6337321837743123, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 20:15:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 220, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.87860107421875, 'train_avg_loss': 0.6580804189046224, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 20:15:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 220, 'Results_raw': {'train_total': 480, 'train_loss': 315.87860107421875, 'train_avg_loss': 0.6580804189046224, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 20:15:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #220, planning to set LR to 1.00e-05
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:15:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:15:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:16:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:16:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.240906, avg_loss=0.640085, seen=480, correct=304, accuracy=0.633333
2025-10-09 20:16:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:16:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:16:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:16:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=220 reserved=2426MB allocated=2217MB
2025-10-09 20:16:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 220, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.76722890138626, 'train_avg_loss': 0.6313935741782188, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:16:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 220, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.24090576171875, 'train_avg_loss': 0.6400852203369141, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:16:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 220, 'Results_raw': {'train_total': 480, 'train_loss': 307.24090576171875, 'train_avg_loss': 0.6400852203369141, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:16:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #221) -------------
2025-10-09 20:16:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=221 aidx=8 | s=5 (candidates=12)
2025-10-09 20:16:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[19, 52, 39, 13, 46] (from 12)
2025-10-09 20:16:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:16:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:16:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #221, planning to set LR to 1.00e-05
2025-10-09 20:16:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 20:16:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:16:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:16:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:16:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:16:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:17:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:17:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.608154, avg_loss=0.645017, seen=480, correct=300, accuracy=0.625000
2025-10-09 20:17:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:17:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:17:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:17:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=221 reserved=2470MB allocated=2217MB
2025-10-09 20:17:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 221, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.73972743749619, 'train_avg_loss': 0.6228310619791348, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:17:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 221, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.608154296875, 'train_avg_loss': 0.6450169881184896, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 20:17:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 221, 'Results_raw': {'train_total': 480, 'train_loss': 309.608154296875, 'train_avg_loss': 0.6450169881184896, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 20:17:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #221, planning to set LR to 1.00e-05
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 20:17:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:17:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:18:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:18:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.902405, avg_loss=0.658130, seen=480, correct=285, accuracy=0.593750
2025-10-09 20:18:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:18:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:18:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:18:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=221 reserved=2416MB allocated=2217MB
2025-10-09 20:18:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 221, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.6543635725975, 'train_avg_loss': 0.6304530297716459, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:18:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 221, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.90240478515625, 'train_avg_loss': 0.6581300099690756, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 20:18:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 221, 'Results_raw': {'train_total': 480, 'train_loss': 315.90240478515625, 'train_avg_loss': 0.6581300099690756, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 20:18:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:18:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:18:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #221, planning to set LR to 1.00e-05
2025-10-09 20:18:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:18:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:18:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:18:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:18:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:18:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:18:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:18:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.450317, avg_loss=0.646771, seen=480, correct=294, accuracy=0.612500
2025-10-09 20:18:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:18:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:18:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:18:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=221 reserved=2416MB allocated=2217MB
2025-10-09 20:18:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 221, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.18446570634842, 'train_avg_loss': 0.6348705475529035, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 20:18:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 221, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.4503173828125, 'train_avg_loss': 0.646771494547526, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 20:18:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 221, 'Results_raw': {'train_total': 480, 'train_loss': 310.4503173828125, 'train_avg_loss': 0.646771494547526, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 20:18:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:18:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:18:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #221, planning to set LR to 1.00e-05
2025-10-09 20:18:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 20:18:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:18:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:18:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:18:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:18:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:19:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:19:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.977966, avg_loss=0.637454, seen=480, correct=319, accuracy=0.664583
2025-10-09 20:19:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:19:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:19:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:19:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=221 reserved=2416MB allocated=2217MB
2025-10-09 20:19:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 221, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.32516664266586, 'train_avg_loss': 0.6443763886888821, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:19:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 221, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.97796630859375, 'train_avg_loss': 0.637454096476237, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 20:19:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 221, 'Results_raw': {'train_total': 480, 'train_loss': 305.97796630859375, 'train_avg_loss': 0.637454096476237, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 20:19:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #221, planning to set LR to 1.00e-05
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:19:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:19:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:20:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:20:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.948792, avg_loss=0.676977, seen=480, correct=270, accuracy=0.562500
2025-10-09 20:20:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:20:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:20:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:20:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=221 reserved=2432MB allocated=2217MB
2025-10-09 20:20:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 221, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.52746218442917, 'train_avg_loss': 0.671062184870243, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 20:20:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 221, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.94879150390625, 'train_avg_loss': 0.6769766489664714, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 20:20:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 221, 'Results_raw': {'train_total': 480, 'train_loss': 324.94879150390625, 'train_avg_loss': 0.6769766489664714, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 20:20:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #222) -------------
2025-10-09 20:20:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=222 aidx=8 | s=5 (candidates=12)
2025-10-09 20:20:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 23, 53, 49, 18] (from 12)
2025-10-09 20:20:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #222, planning to set LR to 1.00e-05
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:20:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:20:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:21:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:21:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.038055, avg_loss=0.666746, seen=480, correct=282, accuracy=0.587500
2025-10-09 20:21:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:21:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:21:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:21:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=222 reserved=2432MB allocated=2217MB
2025-10-09 20:21:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 222, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.1073466539383, 'train_avg_loss': 0.6592278887828191, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 20:21:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 222, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.0380554199219, 'train_avg_loss': 0.666745948791504, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:21:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 222, 'Results_raw': {'train_total': 480, 'train_loss': 320.0380554199219, 'train_avg_loss': 0.666745948791504, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:21:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:21:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:21:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #222, planning to set LR to 1.00e-05
2025-10-09 20:21:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:21:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:21:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:21:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:21:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:21:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:21:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:21:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.897217, avg_loss=0.678953, seen=480, correct=282, accuracy=0.587500
2025-10-09 20:21:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:21:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:21:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:21:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=222 reserved=2416MB allocated=2217MB
2025-10-09 20:21:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 222, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60934883356094, 'train_avg_loss': 0.6884112402796745, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 20:21:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 222, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.897216796875, 'train_avg_loss': 0.6789525349934896, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:21:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 222, 'Results_raw': {'train_total': 480, 'train_loss': 325.897216796875, 'train_avg_loss': 0.6789525349934896, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:21:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #222, planning to set LR to 1.00e-05
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 20:21:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:21:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:22:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:22:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.033325, avg_loss=0.664653, seen=480, correct=288, accuracy=0.600000
2025-10-09 20:22:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:22:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:22:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:22:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=222 reserved=2416MB allocated=2217MB
2025-10-09 20:22:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 222, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.51390552520752, 'train_avg_loss': 0.6459492127100627, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 20:22:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 222, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0333251953125, 'train_avg_loss': 0.6646527608235677, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 20:22:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 222, 'Results_raw': {'train_total': 480, 'train_loss': 319.0333251953125, 'train_avg_loss': 0.6646527608235677, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 20:22:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #222, planning to set LR to 1.00e-05
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:22:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:22:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:23:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:23:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.721497, avg_loss=0.680670, seen=480, correct=269, accuracy=0.560417
2025-10-09 20:23:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:23:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:23:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:23:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=222 reserved=2420MB allocated=2217MB
2025-10-09 20:23:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 222, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.02827650308609, 'train_avg_loss': 0.7085689708590508, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 20:23:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 222, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.72149658203125, 'train_avg_loss': 0.6806697845458984, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 20:23:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 222, 'Results_raw': {'train_total': 480, 'train_loss': 326.72149658203125, 'train_avg_loss': 0.6806697845458984, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 20:23:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:23:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:23:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #222, planning to set LR to 1.00e-05
2025-10-09 20:23:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:23:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:23:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:23:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:23:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:23:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:24:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:24:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.923157, avg_loss=0.658173, seen=480, correct=288, accuracy=0.600000
2025-10-09 20:24:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:24:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:24:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:24:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=222 reserved=2436MB allocated=2217MB
2025-10-09 20:24:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 222, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.05585277080536, 'train_avg_loss': 0.6754654397567114, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 20:24:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 222, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.92315673828125, 'train_avg_loss': 0.6581732432047526, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 20:24:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 222, 'Results_raw': {'train_total': 480, 'train_loss': 315.92315673828125, 'train_avg_loss': 0.6581732432047526, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 20:24:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #223) -------------
2025-10-09 20:24:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=223 aidx=8 | s=5 (candidates=12)
2025-10-09 20:24:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 53, 13, 10, 19] (from 12)
2025-10-09 20:24:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #223, planning to set LR to 1.00e-05
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:24:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:24:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:24:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:24:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.525452, avg_loss=0.646928, seen=480, correct=303, accuracy=0.631250
2025-10-09 20:24:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:24:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:24:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:24:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=223 reserved=2416MB allocated=2217MB
2025-10-09 20:24:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 223, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.88528043031693, 'train_avg_loss': 0.6407106702526411, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:24:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 223, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.52545166015625, 'train_avg_loss': 0.6469280242919921, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 20:24:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 223, 'Results_raw': {'train_total': 480, 'train_loss': 310.52545166015625, 'train_avg_loss': 0.6469280242919921, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 20:24:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:24:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:24:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #223, planning to set LR to 1.00e-05
2025-10-09 20:24:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 20:24:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:24:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:24:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:24:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:24:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:25:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:25:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.557678, avg_loss=0.665745, seen=480, correct=280, accuracy=0.583333
2025-10-09 20:25:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:25:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:25:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:25:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=223 reserved=2416MB allocated=2217MB
2025-10-09 20:25:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 223, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.08687472343445, 'train_avg_loss': 0.642390622695287, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:25:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 223, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.55767822265625, 'train_avg_loss': 0.6657451629638672, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 20:25:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 223, 'Results_raw': {'train_total': 480, 'train_loss': 319.55767822265625, 'train_avg_loss': 0.6657451629638672, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 20:25:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #223, planning to set LR to 1.00e-05
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 20:25:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:25:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:26:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:26:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.140503, avg_loss=0.639876, seen=480, correct=312, accuracy=0.650000
2025-10-09 20:26:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:26:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:26:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:26:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=223 reserved=2416MB allocated=2217MB
2025-10-09 20:26:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 223, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.02281266450882, 'train_avg_loss': 0.6501901055375735, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 20:26:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 223, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.1405029296875, 'train_avg_loss': 0.6398760477701823, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 20:26:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 223, 'Results_raw': {'train_total': 480, 'train_loss': 307.1405029296875, 'train_avg_loss': 0.6398760477701823, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 20:26:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #223, planning to set LR to 1.00e-05
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:26:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:26:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:27:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:27:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.299194, avg_loss=0.623540, seen=480, correct=312, accuracy=0.650000
2025-10-09 20:27:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:27:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:27:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:27:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=223 reserved=2426MB allocated=2217MB
2025-10-09 20:27:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 223, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.36209958791733, 'train_avg_loss': 0.6196841632326444, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 20:27:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 223, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.2991943359375, 'train_avg_loss': 0.6235399881998698, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 20:27:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 223, 'Results_raw': {'train_total': 480, 'train_loss': 299.2991943359375, 'train_avg_loss': 0.6235399881998698, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 20:27:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:27:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:27:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #223, planning to set LR to 1.00e-05
2025-10-09 20:27:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 20:27:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:27:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:27:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:27:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:27:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:27:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:27:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.368927, avg_loss=0.642435, seen=480, correct=301, accuracy=0.627083
2025-10-09 20:27:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:27:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:27:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:27:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=223 reserved=2470MB allocated=2217MB
2025-10-09 20:27:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 223, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.63973450660706, 'train_avg_loss': 0.6136644542217254, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 20:27:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 223, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.3689270019531, 'train_avg_loss': 0.6424352645874023, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 20:27:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 223, 'Results_raw': {'train_total': 480, 'train_loss': 308.3689270019531, 'train_avg_loss': 0.6424352645874023, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 20:27:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #224) -------------
2025-10-09 20:27:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=224 aidx=8 | s=5 (candidates=12)
2025-10-09 20:27:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 14, 49, 10, 19] (from 12)
2025-10-09 20:27:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #224, planning to set LR to 1.00e-05
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:27:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:27:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:28:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:28:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.453278, avg_loss=0.667611, seen=480, correct=277, accuracy=0.577083
2025-10-09 20:28:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:28:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:28:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:28:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=224 reserved=2432MB allocated=2217MB
2025-10-09 20:28:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 224, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.14606773853302, 'train_avg_loss': 0.6595505644877752, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:28:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 224, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.4532775878906, 'train_avg_loss': 0.6676109949747722, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 20:28:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 224, 'Results_raw': {'train_total': 480, 'train_loss': 320.4532775878906, 'train_avg_loss': 0.6676109949747722, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 20:28:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:28:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:28:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #224, planning to set LR to 1.00e-05
2025-10-09 20:28:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 20:28:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:28:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:28:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:28:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:28:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:29:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:29:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.253967, avg_loss=0.663029, seen=480, correct=286, accuracy=0.595833
2025-10-09 20:29:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:29:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:29:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:29:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=224 reserved=2416MB allocated=2217MB
2025-10-09 20:29:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 224, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.51246738433838, 'train_avg_loss': 0.6042705615361531, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 20:29:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 224, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.25396728515625, 'train_avg_loss': 0.6630290985107422, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:29:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 224, 'Results_raw': {'train_total': 480, 'train_loss': 318.25396728515625, 'train_avg_loss': 0.6630290985107422, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #224, planning to set LR to 1.00e-05
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:29:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:29:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:30:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:30:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.661926, avg_loss=0.680546, seen=480, correct=278, accuracy=0.579167
2025-10-09 20:30:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:30:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:30:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:30:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=224 reserved=2420MB allocated=2217MB
2025-10-09 20:30:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 224, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.84267929196358, 'train_avg_loss': 0.7070223274330298, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 20:30:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 224, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.66192626953125, 'train_avg_loss': 0.6805456797281901, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 20:30:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 224, 'Results_raw': {'train_total': 480, 'train_loss': 326.66192626953125, 'train_avg_loss': 0.6805456797281901, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 20:30:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #224, planning to set LR to 1.00e-05
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:30:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:30:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:30:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:30:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.921112, avg_loss=0.618586, seen=480, correct=321, accuracy=0.668750
2025-10-09 20:30:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:30:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:30:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:30:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=224 reserved=2426MB allocated=2217MB
2025-10-09 20:30:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 224, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.68868732452393, 'train_avg_loss': 0.6140723943710327, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 20:30:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 224, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.9211120605469, 'train_avg_loss': 0.6185856501261393, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 20:30:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 224, 'Results_raw': {'train_total': 480, 'train_loss': 296.9211120605469, 'train_avg_loss': 0.6185856501261393, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 20:30:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:30:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:30:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #224, planning to set LR to 1.00e-05
2025-10-09 20:30:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 20:30:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:30:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:30:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:30:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:30:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:31:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:31:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.964325, avg_loss=0.624926, seen=480, correct=311, accuracy=0.647917
2025-10-09 20:31:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:31:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:31:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:31:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=224 reserved=2470MB allocated=2217MB
2025-10-09 20:31:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 224, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.62883394956589, 'train_avg_loss': 0.6052402829130491, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:31:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 224, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.9643249511719, 'train_avg_loss': 0.6249256769816081, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 20:31:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 224, 'Results_raw': {'train_total': 480, 'train_loss': 299.9643249511719, 'train_avg_loss': 0.6249256769816081, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 20:31:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #225) -------------
2025-10-09 20:31:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=225 aidx=8 | s=5 (candidates=12)
2025-10-09 20:31:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 18, 49, 39, 19] (from 12)
2025-10-09 20:31:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #225, planning to set LR to 1.00e-05
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:31:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:31:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:32:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:32:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.942566, avg_loss=0.679047, seen=480, correct=286, accuracy=0.595833
2025-10-09 20:32:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:32:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:32:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:32:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=225 reserved=2416MB allocated=2217MB
2025-10-09 20:32:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 225, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.93529558181763, 'train_avg_loss': 0.6911274631818135, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 20:32:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 225, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.94256591796875, 'train_avg_loss': 0.6790470123291016, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:32:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 225, 'Results_raw': {'train_total': 480, 'train_loss': 325.94256591796875, 'train_avg_loss': 0.6790470123291016, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:32:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #225, planning to set LR to 1.00e-05
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:32:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:32:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:33:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:33:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.794800, avg_loss=0.641239, seen=480, correct=304, accuracy=0.633333
2025-10-09 20:33:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:33:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:33:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:33:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=225 reserved=2436MB allocated=2217MB
2025-10-09 20:33:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 225, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.9949762225151, 'train_avg_loss': 0.6582914685209592, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:33:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 225, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.7947998046875, 'train_avg_loss': 0.6412391662597656, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:33:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 225, 'Results_raw': {'train_total': 480, 'train_loss': 307.7947998046875, 'train_avg_loss': 0.6412391662597656, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:33:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #225, planning to set LR to 1.00e-05
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:33:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:33:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:33:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:33:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.992584, avg_loss=0.681235, seen=480, correct=280, accuracy=0.583333
2025-10-09 20:33:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:33:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:33:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:33:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=225 reserved=2420MB allocated=2217MB
2025-10-09 20:33:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 225, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.92092901468277, 'train_avg_loss': 0.7076744084556897, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 20:33:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 225, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.9925842285156, 'train_avg_loss': 0.6812345504760742, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 20:33:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 225, 'Results_raw': {'train_total': 480, 'train_loss': 326.9925842285156, 'train_avg_loss': 0.6812345504760742, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 20:33:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #225, planning to set LR to 1.00e-05
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:34:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:34:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:34:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:34:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.227295, avg_loss=0.650474, seen=480, correct=304, accuracy=0.633333
2025-10-09 20:34:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:34:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:34:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:34:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=225 reserved=2416MB allocated=2217MB
2025-10-09 20:34:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 225, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.94852596521378, 'train_avg_loss': 0.6412377163767815, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:34:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 225, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.227294921875, 'train_avg_loss': 0.6504735310872396, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:34:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 225, 'Results_raw': {'train_total': 480, 'train_loss': 312.227294921875, 'train_avg_loss': 0.6504735310872396, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:34:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:34:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:34:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #225, planning to set LR to 1.00e-05
2025-10-09 20:34:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 20:34:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:34:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:34:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:34:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:34:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:35:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:35:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.149841, avg_loss=0.614896, seen=480, correct=318, accuracy=0.662500
2025-10-09 20:35:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:35:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:35:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:35:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=225 reserved=2468MB allocated=2217MB
2025-10-09 20:35:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 225, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.43043214082718, 'train_avg_loss': 0.5952536011735599, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 20:35:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 225, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.14984130859375, 'train_avg_loss': 0.6148955027262369, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 20:35:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 225, 'Results_raw': {'train_total': 480, 'train_loss': 295.14984130859375, 'train_avg_loss': 0.6148955027262369, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 20:35:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #226) -------------
2025-10-09 20:35:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=226 aidx=8 | s=5 (candidates=12)
2025-10-09 20:35:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 23, 10, 38, 13] (from 12)
2025-10-09 20:35:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:35:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:35:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #226, planning to set LR to 1.00e-05
2025-10-09 20:35:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:35:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:35:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:35:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:35:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:35:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:36:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:36:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.408752, avg_loss=0.673768, seen=480, correct=277, accuracy=0.577083
2025-10-09 20:36:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:36:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:36:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:36:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=226 reserved=2432MB allocated=2217MB
2025-10-09 20:36:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 226, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.0449989438057, 'train_avg_loss': 0.6587083245317141, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:36:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 226, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.40875244140625, 'train_avg_loss': 0.6737682342529296, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 20:36:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 226, 'Results_raw': {'train_total': 480, 'train_loss': 323.40875244140625, 'train_avg_loss': 0.6737682342529296, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 20:36:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #226, planning to set LR to 1.00e-05
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:36:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:36:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:36:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:36:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.014679, avg_loss=0.683364, seen=480, correct=282, accuracy=0.587500
2025-10-09 20:36:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:36:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:36:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=226 reserved=2416MB allocated=2217MB
2025-10-09 20:36:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 226, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.92891249060631, 'train_avg_loss': 0.6994076040883859, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 20:36:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 226, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0146789550781, 'train_avg_loss': 0.6833639144897461, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:36:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 226, 'Results_raw': {'train_total': 480, 'train_loss': 328.0146789550781, 'train_avg_loss': 0.6833639144897461, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-09 20:36:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:36:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:36:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #226, planning to set LR to 1.00e-05
2025-10-09 20:36:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:36:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:36:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:36:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:36:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:36:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:37:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:37:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.024658, avg_loss=0.612551, seen=480, correct=321, accuracy=0.668750
2025-10-09 20:37:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:37:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:37:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:37:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=226 reserved=2426MB allocated=2217MB
2025-10-09 20:37:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 226, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.13997620344162, 'train_avg_loss': 0.6011664683620135, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 20:37:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 226, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.024658203125, 'train_avg_loss': 0.6125513712565104, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 20:37:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 226, 'Results_raw': {'train_total': 480, 'train_loss': 294.024658203125, 'train_avg_loss': 0.6125513712565104, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 20:37:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #226, planning to set LR to 1.00e-05
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 20:37:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:37:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:38:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:38:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.831421, avg_loss=0.641315, seen=480, correct=296, accuracy=0.616667
2025-10-09 20:38:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:38:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:38:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:38:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=226 reserved=2418MB allocated=2217MB
2025-10-09 20:38:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 226, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.1965623497963, 'train_avg_loss': 0.6183046862483025, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 20:38:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 226, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.8314208984375, 'train_avg_loss': 0.6413154602050781, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 20:38:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 226, 'Results_raw': {'train_total': 480, 'train_loss': 307.8314208984375, 'train_avg_loss': 0.6413154602050781, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 20:38:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:38:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:38:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #226, planning to set LR to 1.00e-05
2025-10-09 20:38:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 20:38:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:38:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:38:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:38:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:38:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:39:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:39:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.126740, avg_loss=0.629431, seen=480, correct=321, accuracy=0.668750
2025-10-09 20:39:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:39:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:39:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:39:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=226 reserved=2416MB allocated=2217MB
2025-10-09 20:39:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 226, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.21431857347488, 'train_avg_loss': 0.6434526547789574, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 20:39:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 226, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.1267395019531, 'train_avg_loss': 0.6294307072957357, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 20:39:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 226, 'Results_raw': {'train_total': 480, 'train_loss': 302.1267395019531, 'train_avg_loss': 0.6294307072957357, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-09 20:39:10 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #227) -------------
2025-10-09 20:39:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=227 aidx=8 | s=5 (candidates=12)
2025-10-09 20:39:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 39, 52, 46, 23] (from 12)
2025-10-09 20:39:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #227, planning to set LR to 1.00e-05
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:39:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:39:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:39:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:39:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.519501, avg_loss=0.638582, seen=480, correct=304, accuracy=0.633333
2025-10-09 20:39:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:39:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:39:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:39:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=227 reserved=2436MB allocated=2217MB
2025-10-09 20:39:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 227, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.76545894145966, 'train_avg_loss': 0.6480454911788305, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:39:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 227, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.5195007324219, 'train_avg_loss': 0.6385822931925456, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:39:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 227, 'Results_raw': {'train_total': 480, 'train_loss': 306.5195007324219, 'train_avg_loss': 0.6385822931925456, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:39:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #227, planning to set LR to 1.00e-05
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:39:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:39:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:40:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:40:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.385864, avg_loss=0.648721, seen=480, correct=311, accuracy=0.647917
2025-10-09 20:40:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:40:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:40:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:40:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=227 reserved=2416MB allocated=2217MB
2025-10-09 20:40:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 227, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.51411175727844, 'train_avg_loss': 0.6376175979773203, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:40:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 227, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.3858642578125, 'train_avg_loss': 0.6487205505371094, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 20:40:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 227, 'Results_raw': {'train_total': 480, 'train_loss': 311.3858642578125, 'train_avg_loss': 0.6487205505371094, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 20:40:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:40:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:40:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #227, planning to set LR to 1.00e-05
2025-10-09 20:40:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 20:40:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:40:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:40:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:40:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:40:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:41:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:41:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.379486, avg_loss=0.654957, seen=480, correct=292, accuracy=0.608333
2025-10-09 20:41:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:41:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:41:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:41:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=227 reserved=2416MB allocated=2217MB
2025-10-09 20:41:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 227, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.06925475597382, 'train_avg_loss': 0.6255771229664485, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 20:41:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 227, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.3794860839844, 'train_avg_loss': 0.6549572626749675, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 20:41:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 227, 'Results_raw': {'train_total': 480, 'train_loss': 314.3794860839844, 'train_avg_loss': 0.6549572626749675, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 20:41:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #227, planning to set LR to 1.00e-05
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:41:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:41:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:42:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:42:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.443237, avg_loss=0.669673, seen=480, correct=275, accuracy=0.572917
2025-10-09 20:42:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:42:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:42:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:42:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=227 reserved=2432MB allocated=2217MB
2025-10-09 20:42:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 227, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.43172037601471, 'train_avg_loss': 0.6619310031334559, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 20:42:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 227, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.4432373046875, 'train_avg_loss': 0.6696734110514323, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 20:42:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 227, 'Results_raw': {'train_total': 480, 'train_loss': 321.4432373046875, 'train_avg_loss': 0.6696734110514323, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 20:42:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #227, planning to set LR to 1.00e-05
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:42:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:42:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:43:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:43:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.729187, avg_loss=0.689019, seen=480, correct=275, accuracy=0.572917
2025-10-09 20:43:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:43:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:43:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:43:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=227 reserved=2416MB allocated=2217MB
2025-10-09 20:43:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 227, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.54454666376114, 'train_avg_loss': 0.7045378888646762, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 20:43:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 227, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.72918701171875, 'train_avg_loss': 0.6890191396077474, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 20:43:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 227, 'Results_raw': {'train_total': 480, 'train_loss': 330.72918701171875, 'train_avg_loss': 0.6890191396077474, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 20:43:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #228) -------------
2025-10-09 20:43:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=228 aidx=8 | s=5 (candidates=12)
2025-10-09 20:43:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 10, 53, 46, 14] (from 12)
2025-10-09 20:43:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:43:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:43:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #228, planning to set LR to 1.00e-05
2025-10-09 20:43:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:43:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:43:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:43:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:43:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:43:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:43:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:43:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.697510, avg_loss=0.680620, seen=480, correct=279, accuracy=0.581250
2025-10-09 20:43:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:43:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:43:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:43:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=228 reserved=2420MB allocated=2217MB
2025-10-09 20:43:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 228, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.8706790804863, 'train_avg_loss': 0.7072556590040525, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 20:43:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 228, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.697509765625, 'train_avg_loss': 0.6806198120117187, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 20:43:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 228, 'Results_raw': {'train_total': 480, 'train_loss': 326.697509765625, 'train_avg_loss': 0.6806198120117187, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 20:43:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:43:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:43:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #228, planning to set LR to 1.00e-05
2025-10-09 20:43:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:43:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:43:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:43:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:43:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:43:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:44:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:44:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.873047, avg_loss=0.616402, seen=480, correct=315, accuracy=0.656250
2025-10-09 20:44:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:44:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:44:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:44:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=228 reserved=2426MB allocated=2217MB
2025-10-09 20:44:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 228, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.94776940345764, 'train_avg_loss': 0.607898078362147, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:44:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 228, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.873046875, 'train_avg_loss': 0.6164021809895833, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 20:44:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 228, 'Results_raw': {'train_total': 480, 'train_loss': 295.873046875, 'train_avg_loss': 0.6164021809895833, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 20:44:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #228, planning to set LR to 1.00e-05
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 20:44:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:44:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:45:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:45:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.368164, avg_loss=0.663267, seen=480, correct=297, accuracy=0.618750
2025-10-09 20:45:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:45:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:45:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:45:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=228 reserved=2416MB allocated=2217MB
2025-10-09 20:45:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 228, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.96128502488136, 'train_avg_loss': 0.633010708540678, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:45:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 228, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.3681640625, 'train_avg_loss': 0.6632670084635417, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 20:45:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 228, 'Results_raw': {'train_total': 480, 'train_loss': 318.3681640625, 'train_avg_loss': 0.6632670084635417, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 20:45:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:45:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:45:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #228, planning to set LR to 1.00e-05
2025-10-09 20:45:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:45:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:45:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:45:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:45:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:45:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:46:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:46:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.477844, avg_loss=0.665579, seen=480, correct=274, accuracy=0.570833
2025-10-09 20:46:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:46:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:46:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:46:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=228 reserved=2432MB allocated=2217MB
2025-10-09 20:46:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 228, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.16859632730484, 'train_avg_loss': 0.6597383027275403, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:46:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 228, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.47784423828125, 'train_avg_loss': 0.6655788421630859, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 20:46:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 228, 'Results_raw': {'train_total': 480, 'train_loss': 319.47784423828125, 'train_avg_loss': 0.6655788421630859, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 20:46:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:46:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:46:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #228, planning to set LR to 1.00e-05
2025-10-09 20:46:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 20:46:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:46:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:46:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:46:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:46:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:46:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:46:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.176147, avg_loss=0.658700, seen=480, correct=288, accuracy=0.600000
2025-10-09 20:46:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:46:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:46:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:46:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=228 reserved=2416MB allocated=2217MB
2025-10-09 20:46:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 228, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.91930902004242, 'train_avg_loss': 0.5993275751670202, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 20:46:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 228, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.1761474609375, 'train_avg_loss': 0.6587003072102865, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 20:46:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 228, 'Results_raw': {'train_total': 480, 'train_loss': 316.1761474609375, 'train_avg_loss': 0.6587003072102865, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 20:46:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #229) -------------
2025-10-09 20:46:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=229 aidx=8 | s=5 (candidates=12)
2025-10-09 20:46:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 46, 19, 23, 38] (from 12)
2025-10-09 20:46:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #229, planning to set LR to 1.00e-05
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 20:46:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:46:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:47:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:47:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.692017, avg_loss=0.682692, seen=480, correct=270, accuracy=0.562500
2025-10-09 20:47:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:47:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:47:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:47:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=229 reserved=2420MB allocated=2217MB
2025-10-09 20:47:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 229, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.00184261798859, 'train_avg_loss': 0.6666820218165715, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 20:47:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 229, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6920166015625, 'train_avg_loss': 0.6826917012532552, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 20:47:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 229, 'Results_raw': {'train_total': 480, 'train_loss': 327.6920166015625, 'train_avg_loss': 0.6826917012532552, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 20:47:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #229, planning to set LR to 1.00e-05
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:47:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:47:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:48:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:48:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.913147, avg_loss=0.674819, seen=480, correct=290, accuracy=0.604167
2025-10-09 20:48:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:48:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:48:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:48:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=229 reserved=2432MB allocated=2217MB
2025-10-09 20:48:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 229, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.37989163398743, 'train_avg_loss': 0.6864990969498952, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 20:48:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 229, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.91314697265625, 'train_avg_loss': 0.6748190561930338, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 20:48:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 229, 'Results_raw': {'train_total': 480, 'train_loss': 323.91314697265625, 'train_avg_loss': 0.6748190561930338, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 20:48:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:48:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:48:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #229, planning to set LR to 1.00e-05
2025-10-09 20:48:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 20:48:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:48:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:48:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:48:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:48:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:49:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:49:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.901978, avg_loss=0.626879, seen=480, correct=301, accuracy=0.627083
2025-10-09 20:49:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:49:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:49:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:49:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=229 reserved=2470MB allocated=2217MB
2025-10-09 20:49:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 229, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.72206300497055, 'train_avg_loss': 0.6310171917080879, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 20:49:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 229, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.9019775390625, 'train_avg_loss': 0.6268791198730469, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 20:49:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 229, 'Results_raw': {'train_total': 480, 'train_loss': 300.9019775390625, 'train_avg_loss': 0.6268791198730469, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 20:49:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:49:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:49:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #229, planning to set LR to 1.00e-05
2025-10-09 20:49:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:49:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:49:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:49:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:49:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:49:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:49:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:49:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.888580, avg_loss=0.674768, seen=480, correct=279, accuracy=0.581250
2025-10-09 20:49:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:49:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:49:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:49:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=229 reserved=2416MB allocated=2217MB
2025-10-09 20:49:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 229, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.35526525974274, 'train_avg_loss': 0.6862938771645228, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 20:49:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 229, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.8885803222656, 'train_avg_loss': 0.6747678756713867, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 20:49:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 229, 'Results_raw': {'train_total': 480, 'train_loss': 323.8885803222656, 'train_avg_loss': 0.6747678756713867, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 20:49:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #229, planning to set LR to 1.00e-05
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 20:49:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:49:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:50:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:50:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.641663, avg_loss=0.647170, seen=480, correct=308, accuracy=0.641667
2025-10-09 20:50:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:50:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:50:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:50:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=229 reserved=2418MB allocated=2217MB
2025-10-09 20:50:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 229, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.96940815448761, 'train_avg_loss': 0.6330784012873968, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 20:50:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 229, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.64166259765625, 'train_avg_loss': 0.6471701304117838, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 20:50:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 229, 'Results_raw': {'train_total': 480, 'train_loss': 310.64166259765625, 'train_avg_loss': 0.6471701304117838, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 20:50:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #230) -------------
2025-10-09 20:50:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=230 aidx=8 | s=5 (candidates=12)
2025-10-09 20:50:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 10, 38, 39, 23] (from 12)
2025-10-09 20:50:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #230, planning to set LR to 1.00e-05
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 20:50:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:50:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:51:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:51:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.068542, avg_loss=0.662643, seen=480, correct=295, accuracy=0.614583
2025-10-09 20:51:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:51:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:51:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:51:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=230 reserved=2416MB allocated=2217MB
2025-10-09 20:51:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 230, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.30554237961769, 'train_avg_loss': 0.6358795198301475, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:51:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 230, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.06854248046875, 'train_avg_loss': 0.6626427968343099, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 20:51:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 230, 'Results_raw': {'train_total': 480, 'train_loss': 318.06854248046875, 'train_avg_loss': 0.6626427968343099, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 20:51:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #230, planning to set LR to 1.00e-05
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 20:51:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:51:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:52:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:52:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.201141, avg_loss=0.615002, seen=480, correct=319, accuracy=0.664583
2025-10-09 20:52:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:52:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:52:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:52:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=230 reserved=2426MB allocated=2217MB
2025-10-09 20:52:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 230, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.16576996445656, 'train_avg_loss': 0.6097147497038047, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:52:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 230, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.2011413574219, 'train_avg_loss': 0.6150023778279622, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 20:52:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 230, 'Results_raw': {'train_total': 480, 'train_loss': 295.2011413574219, 'train_avg_loss': 0.6150023778279622, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 20:52:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:52:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:52:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #230, planning to set LR to 1.00e-05
2025-10-09 20:52:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 20:52:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:52:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:52:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:52:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:52:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:52:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:52:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.089722, avg_loss=0.627270, seen=480, correct=304, accuracy=0.633333
2025-10-09 20:52:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:52:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:52:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:53:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=230 reserved=2418MB allocated=2217MB
2025-10-09 20:53:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 230, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.67590594291687, 'train_avg_loss': 0.6139658828576405, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:53:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 230, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.0897216796875, 'train_avg_loss': 0.627270253499349, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:53:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 230, 'Results_raw': {'train_total': 480, 'train_loss': 301.0897216796875, 'train_avg_loss': 0.627270253499349, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 20:53:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #230, planning to set LR to 1.00e-05
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:53:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:53:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:53:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:53:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.682739, avg_loss=0.647256, seen=480, correct=303, accuracy=0.631250
2025-10-09 20:53:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:53:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:53:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:53:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=230 reserved=2416MB allocated=2217MB
2025-10-09 20:53:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 230, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.11930668354034, 'train_avg_loss': 0.6343275556961695, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 20:53:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 230, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.6827392578125, 'train_avg_loss': 0.6472557067871094, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 20:53:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 230, 'Results_raw': {'train_total': 480, 'train_loss': 310.6827392578125, 'train_avg_loss': 0.6472557067871094, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 20:53:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #230, planning to set LR to 1.00e-05
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 20:53:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:53:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:54:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:54:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.844208, avg_loss=0.660092, seen=480, correct=293, accuracy=0.610417
2025-10-09 20:54:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:54:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:54:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:54:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=230 reserved=2416MB allocated=2217MB
2025-10-09 20:54:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 230, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.34615898132324, 'train_avg_loss': 0.6778846581776937, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 20:54:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 230, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.8442077636719, 'train_avg_loss': 0.6600920995076497, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 20:54:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 230, 'Results_raw': {'train_total': 480, 'train_loss': 316.8442077636719, 'train_avg_loss': 0.6600920995076497, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 20:54:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #231) -------------
2025-10-09 20:54:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=231 aidx=8 | s=5 (candidates=12)
2025-10-09 20:54:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 13, 14, 46, 39] (from 12)
2025-10-09 20:54:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #231, planning to set LR to 1.00e-05
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 20:54:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:54:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:55:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:55:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.705383, avg_loss=0.649386, seen=480, correct=291, accuracy=0.606250
2025-10-09 20:55:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:55:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:55:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:55:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=231 reserved=2416MB allocated=2217MB
2025-10-09 20:55:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 231, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.42621207237244, 'train_avg_loss': 0.6285517672697704, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 20:55:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 231, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.70538330078125, 'train_avg_loss': 0.649386215209961, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 20:55:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 231, 'Results_raw': {'train_total': 480, 'train_loss': 311.70538330078125, 'train_avg_loss': 0.649386215209961, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 20:55:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:55:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:55:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #231, planning to set LR to 1.00e-05
2025-10-09 20:55:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 20:55:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:55:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:55:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:55:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:55:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:56:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:56:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.653625, avg_loss=0.618028, seen=480, correct=318, accuracy=0.662500
2025-10-09 20:56:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:56:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:56:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:56:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=231 reserved=2416MB allocated=2217MB
2025-10-09 20:56:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 231, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.19182652235031, 'train_avg_loss': 0.6265985543529192, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:56:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 231, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.65362548828125, 'train_avg_loss': 0.6180283864339192, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 20:56:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 231, 'Results_raw': {'train_total': 480, 'train_loss': 296.65362548828125, 'train_avg_loss': 0.6180283864339192, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 20:56:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #231, planning to set LR to 1.00e-05
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 20:56:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:56:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:56:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:56:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.137238, avg_loss=0.637786, seen=480, correct=294, accuracy=0.612500
2025-10-09 20:56:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:56:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:56:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:56:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=231 reserved=2416MB allocated=2217MB
2025-10-09 20:56:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 231, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.10582935810089, 'train_avg_loss': 0.5842152446508407, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 20:56:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 231, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.1372375488281, 'train_avg_loss': 0.6377859115600586, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 20:56:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 231, 'Results_raw': {'train_total': 480, 'train_loss': 306.1372375488281, 'train_avg_loss': 0.6377859115600586, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 20:56:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #231, planning to set LR to 1.00e-05
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 20:56:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:56:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:57:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:57:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.655334, avg_loss=0.663865, seen=480, correct=286, accuracy=0.595833
2025-10-09 20:57:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:57:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:57:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:57:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=231 reserved=2432MB allocated=2217MB
2025-10-09 20:57:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 231, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.31651473045349, 'train_avg_loss': 0.6526376227537791, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 20:57:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 231, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.65533447265625, 'train_avg_loss': 0.6638652801513671, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:57:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 231, 'Results_raw': {'train_total': 480, 'train_loss': 318.65533447265625, 'train_avg_loss': 0.6638652801513671, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-09 20:57:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #231, planning to set LR to 1.00e-05
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 20:57:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:57:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:58:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:58:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.495453, avg_loss=0.646866, seen=480, correct=306, accuracy=0.637500
2025-10-09 20:58:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:58:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:58:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:58:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=231 reserved=2416MB allocated=2217MB
2025-10-09 20:58:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 231, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.32750183343887, 'train_avg_loss': 0.6360625152786573, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 20:58:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 231, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.4954528808594, 'train_avg_loss': 0.6468655268351237, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 20:58:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 231, 'Results_raw': {'train_total': 480, 'train_loss': 310.4954528808594, 'train_avg_loss': 0.6468655268351237, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 20:58:20 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #232) -------------
2025-10-09 20:58:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=232 aidx=8 | s=5 (candidates=12)
2025-10-09 20:58:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 52, 18, 38, 49] (from 12)
2025-10-09 20:58:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #232, planning to set LR to 1.00e-05
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 20:58:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:58:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:59:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:59:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.793945, avg_loss=0.614154, seen=480, correct=318, accuracy=0.662500
2025-10-09 20:59:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:59:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:59:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:59:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=232 reserved=2416MB allocated=2217MB
2025-10-09 20:59:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 232, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.4231790304184, 'train_avg_loss': 0.6285264919201533, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 20:59:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 232, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.7939453125, 'train_avg_loss': 0.614154052734375, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 20:59:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 232, 'Results_raw': {'train_total': 480, 'train_loss': 294.7939453125, 'train_avg_loss': 0.614154052734375, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 20:59:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:59:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:59:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #232, planning to set LR to 1.00e-05
2025-10-09 20:59:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 20:59:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:59:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:59:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:59:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:59:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 20:59:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 20:59:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.890472, avg_loss=0.649772, seen=480, correct=291, accuracy=0.606250
2025-10-09 20:59:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 20:59:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:59:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 20:59:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=232 reserved=2416MB allocated=2217MB
2025-10-09 20:59:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 232, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.325041949749, 'train_avg_loss': 0.6277086829145749, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 20:59:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 232, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.8904724121094, 'train_avg_loss': 0.6497718175252278, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 20:59:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 232, 'Results_raw': {'train_total': 480, 'train_loss': 311.8904724121094, 'train_avg_loss': 0.6497718175252278, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 20:59:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 20:59:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 20:59:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #232, planning to set LR to 1.00e-05
2025-10-09 20:59:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 20:59:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 20:59:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 20:59:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 20:59:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 20:59:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:00:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:00:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.750244, avg_loss=0.641146, seen=480, correct=308, accuracy=0.641667
2025-10-09 21:00:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:00:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:00:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:00:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=232 reserved=2436MB allocated=2217MB
2025-10-09 21:00:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 232, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.1622707247734, 'train_avg_loss': 0.668018922706445, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 21:00:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 232, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.750244140625, 'train_avg_loss': 0.6411463419596354, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 21:00:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 232, 'Results_raw': {'train_total': 480, 'train_loss': 307.750244140625, 'train_avg_loss': 0.6411463419596354, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 21:00:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:00:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:00:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #232, planning to set LR to 1.00e-05
2025-10-09 21:00:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 21:00:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:00:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:00:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:00:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:00:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:01:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:01:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.138519, avg_loss=0.627372, seen=480, correct=308, accuracy=0.641667
2025-10-09 21:01:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:01:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:01:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:01:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=232 reserved=2418MB allocated=2217MB
2025-10-09 21:01:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 232, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.52379947900772, 'train_avg_loss': 0.612698328991731, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 21:01:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 232, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.1385192871094, 'train_avg_loss': 0.6273719151814778, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 21:01:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 232, 'Results_raw': {'train_total': 480, 'train_loss': 301.1385192871094, 'train_avg_loss': 0.6273719151814778, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 21:01:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #232, planning to set LR to 1.00e-05
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 21:01:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:01:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:01:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:01:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.574890, avg_loss=0.672031, seen=480, correct=287, accuracy=0.597917
2025-10-09 21:01:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:01:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:01:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:01:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=232 reserved=2420MB allocated=2217MB
2025-10-09 21:01:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 232, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.14415043592453, 'train_avg_loss': 0.692867920299371, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 21:01:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 232, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.57489013671875, 'train_avg_loss': 0.672031021118164, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 21:01:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 232, 'Results_raw': {'train_total': 480, 'train_loss': 322.57489013671875, 'train_avg_loss': 0.672031021118164, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 21:01:52 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #233) -------------
2025-10-09 21:01:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=233 aidx=8 | s=5 (candidates=12)
2025-10-09 21:01:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 13, 46, 39, 23] (from 12)
2025-10-09 21:01:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #233, planning to set LR to 1.00e-05
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 21:01:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:01:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:02:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:02:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.337402, avg_loss=0.640286, seen=480, correct=306, accuracy=0.637500
2025-10-09 21:02:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:02:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:02:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:02:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=233 reserved=2436MB allocated=2217MB
2025-10-09 21:02:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 233, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.01863276958466, 'train_avg_loss': 0.6584886064132055, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 21:02:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 233, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.33740234375, 'train_avg_loss': 0.6402862548828125, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:02:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 233, 'Results_raw': {'train_total': 480, 'train_loss': 307.33740234375, 'train_avg_loss': 0.6402862548828125, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:02:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #233, planning to set LR to 1.00e-05
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 21:02:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:02:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:03:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:03:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.514008, avg_loss=0.617738, seen=480, correct=315, accuracy=0.656250
2025-10-09 21:03:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:03:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:03:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:03:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=233 reserved=2416MB allocated=2217MB
2025-10-09 21:03:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 233, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.11805814504623, 'train_avg_loss': 0.6259838178753853, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 21:03:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 233, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.5140075683594, 'train_avg_loss': 0.6177375157674153, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:03:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 233, 'Results_raw': {'train_total': 480, 'train_loss': 296.5140075683594, 'train_avg_loss': 0.6177375157674153, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:03:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #233, planning to set LR to 1.00e-05
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 21:03:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:03:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:03:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:03:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.716705, avg_loss=0.663993, seen=480, correct=288, accuracy=0.600000
2025-10-09 21:03:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:03:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:03:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:03:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=233 reserved=2432MB allocated=2217MB
2025-10-09 21:03:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 233, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.51051932573318, 'train_avg_loss': 0.6459209943811098, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 21:03:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 233, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.7167053222656, 'train_avg_loss': 0.6639931360880534, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 21:03:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 233, 'Results_raw': {'train_total': 480, 'train_loss': 318.7167053222656, 'train_avg_loss': 0.6639931360880534, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 21:03:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #233, planning to set LR to 1.00e-05
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 21:04:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:04:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:04:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:04:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.939209, avg_loss=0.635290, seen=480, correct=316, accuracy=0.658333
2025-10-09 21:04:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:04:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:04:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:04:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=233 reserved=2416MB allocated=2217MB
2025-10-09 21:04:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 233, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.8894305229187, 'train_avg_loss': 0.6240785876909892, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 21:04:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 233, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.939208984375, 'train_avg_loss': 0.635290018717448, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 21:04:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 233, 'Results_raw': {'train_total': 480, 'train_loss': 304.939208984375, 'train_avg_loss': 0.635290018717448, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 21:04:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #233, planning to set LR to 1.00e-05
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 21:04:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:04:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:05:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:05:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.880249, avg_loss=0.643501, seen=480, correct=302, accuracy=0.629167
2025-10-09 21:05:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:05:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:05:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:05:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=233 reserved=2416MB allocated=2217MB
2025-10-09 21:05:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 233, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.02843987941742, 'train_avg_loss': 0.6669036656618118, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 21:05:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 233, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.8802490234375, 'train_avg_loss': 0.6435005187988281, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 21:05:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 233, 'Results_raw': {'train_total': 480, 'train_loss': 308.8802490234375, 'train_avg_loss': 0.6435005187988281, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 21:05:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #234) -------------
2025-10-09 21:05:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=234 aidx=8 | s=5 (candidates=12)
2025-10-09 21:05:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 10, 19, 49, 13] (from 12)
2025-10-09 21:05:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:05:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:05:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #234, planning to set LR to 1.00e-05
2025-10-09 21:05:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 21:05:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:05:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:05:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:05:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:05:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:06:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:06:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.380035, avg_loss=0.627875, seen=480, correct=306, accuracy=0.637500
2025-10-09 21:06:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:06:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:06:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:06:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=234 reserved=2418MB allocated=2217MB
2025-10-09 21:06:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 234, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.4914536178112, 'train_avg_loss': 0.62076211348176, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 21:06:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 234, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.3800354003906, 'train_avg_loss': 0.6278750737508138, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:06:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 234, 'Results_raw': {'train_total': 480, 'train_loss': 301.3800354003906, 'train_avg_loss': 0.6278750737508138, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:06:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:06:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:06:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #234, planning to set LR to 1.00e-05
2025-10-09 21:06:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 21:06:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:06:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:06:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:06:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:06:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:06:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:06:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.154907, avg_loss=0.610739, seen=480, correct=319, accuracy=0.664583
2025-10-09 21:06:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:06:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:06:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:06:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=234 reserved=2426MB allocated=2217MB
2025-10-09 21:06:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 234, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.50253087282181, 'train_avg_loss': 0.604187757273515, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 21:06:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 234, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.1549072265625, 'train_avg_loss': 0.6107393900553385, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 21:06:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 234, 'Results_raw': {'train_total': 480, 'train_loss': 293.1549072265625, 'train_avg_loss': 0.6107393900553385, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 21:06:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:06:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:06:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #234, planning to set LR to 1.00e-05
2025-10-09 21:06:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 21:06:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:06:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:06:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:06:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:06:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:07:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:07:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=289.834930, avg_loss=0.603823, seen=480, correct=326, accuracy=0.679167
2025-10-09 21:07:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:07:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:07:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:07:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=234 reserved=2468MB allocated=2217MB
2025-10-09 21:07:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 234, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.42348504066467, 'train_avg_loss': 0.5868623753388723, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 21:07:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 234, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 289.8349304199219, 'train_avg_loss': 0.6038227717081706, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 21:07:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 234, 'Results_raw': {'train_total': 480, 'train_loss': 289.8349304199219, 'train_avg_loss': 0.6038227717081706, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 21:07:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:07:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:07:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #234, planning to set LR to 1.00e-05
2025-10-09 21:07:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 21:07:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:07:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:07:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:07:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:07:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:08:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:08:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.625793, avg_loss=0.661720, seen=480, correct=297, accuracy=0.618750
2025-10-09 21:08:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:08:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:08:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:08:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=234 reserved=2420MB allocated=2217MB
2025-10-09 21:08:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 234, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3161470592022, 'train_avg_loss': 0.677634558826685, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 21:08:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 234, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.62579345703125, 'train_avg_loss': 0.6617204030354817, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 21:08:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 234, 'Results_raw': {'train_total': 480, 'train_loss': 317.62579345703125, 'train_avg_loss': 0.6617204030354817, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 21:08:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:08:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:08:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #234, planning to set LR to 1.00e-05
2025-10-09 21:08:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 21:08:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:08:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:08:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:08:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:08:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:08:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:08:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.207947, avg_loss=0.615017, seen=480, correct=319, accuracy=0.664583
2025-10-09 21:08:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:08:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:08:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:08:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=234 reserved=2416MB allocated=2217MB
2025-10-09 21:08:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 234, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.54237747192383, 'train_avg_loss': 0.6295198122660319, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 21:08:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 234, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.20794677734375, 'train_avg_loss': 0.6150165557861328, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 21:08:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 234, 'Results_raw': {'train_total': 480, 'train_loss': 295.20794677734375, 'train_avg_loss': 0.6150165557861328, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-09 21:08:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #235) -------------
2025-10-09 21:08:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=235 aidx=8 | s=5 (candidates=12)
2025-10-09 21:08:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 18, 38, 10, 19] (from 12)
2025-10-09 21:08:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #235, planning to set LR to 1.00e-05
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 21:08:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:08:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:09:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:09:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.302277, avg_loss=0.646463, seen=480, correct=299, accuracy=0.622917
2025-10-09 21:09:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:09:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:09:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:09:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=235 reserved=2416MB allocated=2217MB
2025-10-09 21:09:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 235, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.52724176645279, 'train_avg_loss': 0.6210603480537732, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 21:09:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 235, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.3022766113281, 'train_avg_loss': 0.6464630762736002, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 21:09:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 235, 'Results_raw': {'train_total': 480, 'train_loss': 310.3022766113281, 'train_avg_loss': 0.6464630762736002, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 21:09:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #235, planning to set LR to 1.00e-05
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-09 21:09:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:09:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:10:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:10:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.970337, avg_loss=0.635355, seen=480, correct=309, accuracy=0.643750
2025-10-09 21:10:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:10:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:10:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:10:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=235 reserved=2436MB allocated=2217MB
2025-10-09 21:10:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 235, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.72340625524521, 'train_avg_loss': 0.6560283854603768, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 21:10:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 235, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.9703369140625, 'train_avg_loss': 0.6353548685709636, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 21:10:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 235, 'Results_raw': {'train_total': 480, 'train_loss': 304.9703369140625, 'train_avg_loss': 0.6353548685709636, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 21:10:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:10:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:10:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #235, planning to set LR to 1.00e-05
2025-10-09 21:10:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 21:10:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:10:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:10:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:10:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:10:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:10:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:10:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.514130, avg_loss=0.628154, seen=480, correct=316, accuracy=0.658333
2025-10-09 21:10:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:10:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:10:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:10:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=235 reserved=2418MB allocated=2217MB
2025-10-09 21:10:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 235, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.31673741340637, 'train_avg_loss': 0.6109728117783865, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 21:10:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 235, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.5141296386719, 'train_avg_loss': 0.628154436747233, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 21:10:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 235, 'Results_raw': {'train_total': 480, 'train_loss': 301.5141296386719, 'train_avg_loss': 0.628154436747233, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 21:10:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:10:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:10:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #235, planning to set LR to 1.00e-05
2025-10-09 21:10:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 21:10:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:10:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:10:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:10:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:10:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:11:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:11:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.867767, avg_loss=0.612225, seen=480, correct=315, accuracy=0.656250
2025-10-09 21:11:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:11:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:11:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:11:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=235 reserved=2426MB allocated=2217MB
2025-10-09 21:11:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 235, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.42849680781364, 'train_avg_loss': 0.6035708067317803, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 21:11:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 235, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.8677673339844, 'train_avg_loss': 0.6122245152791341, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:11:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 235, 'Results_raw': {'train_total': 480, 'train_loss': 293.8677673339844, 'train_avg_loss': 0.6122245152791341, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:11:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:11:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:11:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #235, planning to set LR to 1.00e-05
2025-10-09 21:11:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 21:11:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:11:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:11:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:11:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:11:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:12:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:12:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.857574, avg_loss=0.608037, seen=480, correct=324, accuracy=0.675000
2025-10-09 21:12:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:12:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:12:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:12:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=235 reserved=2470MB allocated=2217MB
2025-10-09 21:12:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 235, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.7599231004715, 'train_avg_loss': 0.5979993591705958, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 21:12:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 235, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.8575744628906, 'train_avg_loss': 0.6080366134643554, 'train_seen': 480, 'train_correct': 324, 'train_acc': 0.675}}
2025-10-09 21:12:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 235, 'Results_raw': {'train_total': 480, 'train_loss': 291.8575744628906, 'train_avg_loss': 0.6080366134643554, 'train_seen': 480, 'train_correct': 324, 'train_acc': 0.675}}
2025-10-09 21:12:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #236) -------------
2025-10-09 21:12:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=236 aidx=8 | s=5 (candidates=12)
2025-10-09 21:12:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 49, 19, 52, 39] (from 12)
2025-10-09 21:12:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #236, planning to set LR to 1.00e-05
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 21:12:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:12:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:12:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:12:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.097107, avg_loss=0.666869, seen=480, correct=301, accuracy=0.627083
2025-10-09 21:12:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:12:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:12:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:12:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=236 reserved=2416MB allocated=2217MB
2025-10-09 21:13:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 236, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.18646717071533, 'train_avg_loss': 0.6265538930892944, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 21:13:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 236, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.09710693359375, 'train_avg_loss': 0.6668689727783204, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 21:13:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 236, 'Results_raw': {'train_total': 480, 'train_loss': 320.09710693359375, 'train_avg_loss': 0.6668689727783204, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 21:13:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #236, planning to set LR to 1.00e-05
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 21:13:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:13:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:13:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:13:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.446594, avg_loss=0.667597, seen=480, correct=300, accuracy=0.625000
2025-10-09 21:13:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:13:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:13:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:13:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=236 reserved=2420MB allocated=2217MB
2025-10-09 21:13:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 236, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.19083192944527, 'train_avg_loss': 0.6849235994120438, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 21:13:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 236, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.44659423828125, 'train_avg_loss': 0.6675970713297527, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:13:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 236, 'Results_raw': {'train_total': 480, 'train_loss': 320.44659423828125, 'train_avg_loss': 0.6675970713297527, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:13:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #236, planning to set LR to 1.00e-05
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 21:13:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:13:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:14:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:14:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=282.084015, avg_loss=0.587675, seen=480, correct=337, accuracy=0.702083
2025-10-09 21:14:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:14:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:14:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:14:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=236 reserved=2470MB allocated=2217MB
2025-10-09 21:14:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 236, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.15930187702179, 'train_avg_loss': 0.567994182308515, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-09 21:14:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 236, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 282.0840148925781, 'train_avg_loss': 0.5876750310262044, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-09 21:14:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 236, 'Results_raw': {'train_total': 480, 'train_loss': 282.0840148925781, 'train_avg_loss': 0.5876750310262044, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-09 21:14:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #236, planning to set LR to 1.00e-05
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 21:14:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:14:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:15:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:15:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.847046, avg_loss=0.647598, seen=480, correct=299, accuracy=0.622917
2025-10-09 21:15:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:15:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:15:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:15:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=236 reserved=2416MB allocated=2217MB
2025-10-09 21:15:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 236, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.73200857639313, 'train_avg_loss': 0.6227667381366094, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 21:15:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 236, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8470458984375, 'train_avg_loss': 0.6475980122884114, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 21:15:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 236, 'Results_raw': {'train_total': 480, 'train_loss': 310.8470458984375, 'train_avg_loss': 0.6475980122884114, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 21:15:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #236, planning to set LR to 1.00e-05
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 21:15:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:15:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:15:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:15:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.689331, avg_loss=0.636853, seen=480, correct=310, accuracy=0.645833
2025-10-09 21:15:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:15:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:15:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:15:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=236 reserved=2416MB allocated=2217MB
2025-10-09 21:15:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 236, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.14931458234787, 'train_avg_loss': 0.6262442881862322, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 21:15:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 236, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.6893310546875, 'train_avg_loss': 0.636852773030599, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 21:15:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 236, 'Results_raw': {'train_total': 480, 'train_loss': 305.6893310546875, 'train_avg_loss': 0.636852773030599, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 21:15:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #237) -------------
2025-10-09 21:15:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=237 aidx=8 | s=5 (candidates=12)
2025-10-09 21:15:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 38, 10, 14, 23] (from 12)
2025-10-09 21:15:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #237, planning to set LR to 1.00e-05
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 21:15:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:15:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:16:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:16:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.112823, avg_loss=0.668985, seen=480, correct=297, accuracy=0.618750
2025-10-09 21:16:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:16:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:16:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:16:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=237 reserved=2416MB allocated=2217MB
2025-10-09 21:16:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 237, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.09175530076027, 'train_avg_loss': 0.6257646275063355, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 21:16:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 237, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.1128234863281, 'train_avg_loss': 0.6689850489298502, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 21:16:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 237, 'Results_raw': {'train_total': 480, 'train_loss': 321.1128234863281, 'train_avg_loss': 0.6689850489298502, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 21:16:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #237, planning to set LR to 1.00e-05
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 21:16:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:16:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:17:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:17:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.553223, avg_loss=0.624069, seen=480, correct=312, accuracy=0.650000
2025-10-09 21:17:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:17:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:17:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:17:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=237 reserved=2418MB allocated=2217MB
2025-10-09 21:17:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 237, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.26414030790329, 'train_avg_loss': 0.6022011692325274, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 21:17:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 237, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.55322265625, 'train_avg_loss': 0.6240692138671875, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 21:17:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 237, 'Results_raw': {'train_total': 480, 'train_loss': 299.55322265625, 'train_avg_loss': 0.6240692138671875, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 21:17:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #237, planning to set LR to 1.00e-05
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-09 21:17:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:17:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:17:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:17:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.662170, avg_loss=0.607630, seen=480, correct=316, accuracy=0.658333
2025-10-09 21:17:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:17:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:17:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:17:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=237 reserved=2426MB allocated=2217MB
2025-10-09 21:17:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 237, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.16774132847786, 'train_avg_loss': 0.6013978444039821, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 21:17:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 237, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.66217041015625, 'train_avg_loss': 0.6076295216878255, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 21:17:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 237, 'Results_raw': {'train_total': 480, 'train_loss': 291.66217041015625, 'train_avg_loss': 0.6076295216878255, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 21:17:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:17:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:17:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #237, planning to set LR to 1.00e-05
2025-10-09 21:17:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-09 21:17:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:17:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:17:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:17:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:17:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:18:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:18:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.255280, avg_loss=0.623448, seen=480, correct=314, accuracy=0.654167
2025-10-09 21:18:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:18:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:18:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:18:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=237 reserved=2416MB allocated=2217MB
2025-10-09 21:18:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 237, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 66.51876905560493, 'train_avg_loss': 0.5543230754633744, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 21:18:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 237, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.2552795410156, 'train_avg_loss': 0.6234484990437825, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 21:18:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 237, 'Results_raw': {'train_total': 480, 'train_loss': 299.2552795410156, 'train_avg_loss': 0.6234484990437825, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-09 21:18:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:18:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:18:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #237, planning to set LR to 1.00e-05
2025-10-09 21:18:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 21:18:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:18:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:18:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:18:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:18:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:19:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:19:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.309998, avg_loss=0.625646, seen=480, correct=308, accuracy=0.641667
2025-10-09 21:19:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:19:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:19:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:19:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=237 reserved=2416MB allocated=2217MB
2025-10-09 21:19:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 237, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.94713377952576, 'train_avg_loss': 0.657892781496048, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 21:19:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 237, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.30999755859375, 'train_avg_loss': 0.6256458282470703, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 21:19:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 237, 'Results_raw': {'train_total': 480, 'train_loss': 300.30999755859375, 'train_avg_loss': 0.6256458282470703, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 21:19:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #238) -------------
2025-10-09 21:19:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=238 aidx=8 | s=5 (candidates=12)
2025-10-09 21:19:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 23, 39, 49, 53] (from 12)
2025-10-09 21:19:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #238, planning to set LR to 1.00e-05
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 21:19:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:19:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:19:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:19:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.312744, avg_loss=0.629818, seen=480, correct=312, accuracy=0.650000
2025-10-09 21:19:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:19:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:19:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:19:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=238 reserved=2418MB allocated=2217MB
2025-10-09 21:19:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 238, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.53827148675919, 'train_avg_loss': 0.6128189290563265, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 21:19:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 238, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.312744140625, 'train_avg_loss': 0.6298182169596355, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 21:19:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 238, 'Results_raw': {'train_total': 480, 'train_loss': 302.312744140625, 'train_avg_loss': 0.6298182169596355, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 21:19:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #238, planning to set LR to 1.00e-05
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 21:19:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:19:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:20:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:20:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.210754, avg_loss=0.608772, seen=480, correct=315, accuracy=0.656250
2025-10-09 21:20:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:20:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:20:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:20:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=238 reserved=2416MB allocated=2217MB
2025-10-09 21:20:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 238, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.84335434436798, 'train_avg_loss': 0.6486946195363998, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 21:20:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 238, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.21075439453125, 'train_avg_loss': 0.6087724049886067, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:20:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 238, 'Results_raw': {'train_total': 480, 'train_loss': 292.21075439453125, 'train_avg_loss': 0.6087724049886067, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:20:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #238, planning to set LR to 1.00e-05
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 21:20:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:20:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:21:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:21:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.180725, avg_loss=0.625377, seen=480, correct=325, accuracy=0.677083
2025-10-09 21:21:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:21:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:21:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:21:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=238 reserved=2416MB allocated=2217MB
2025-10-09 21:21:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 238, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.33808931708336, 'train_avg_loss': 0.6111507443090279, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-09 21:21:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 238, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.18072509765625, 'train_avg_loss': 0.6253765106201172, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-09 21:21:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 238, 'Results_raw': {'train_total': 480, 'train_loss': 300.18072509765625, 'train_avg_loss': 0.6253765106201172, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-09 21:21:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #238, planning to set LR to 1.00e-05
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 21:21:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:21:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:21:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:21:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.085663, avg_loss=0.664762, seen=480, correct=302, accuracy=0.629167
2025-10-09 21:21:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:21:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:21:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:21:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=238 reserved=2420MB allocated=2217MB
2025-10-09 21:21:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 238, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.2074782550335, 'train_avg_loss': 0.6767289854586125, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 21:21:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 238, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0856628417969, 'train_avg_loss': 0.6647617975870769, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 21:21:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 238, 'Results_raw': {'train_total': 480, 'train_loss': 319.0856628417969, 'train_avg_loss': 0.6647617975870769, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 21:21:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #238, planning to set LR to 1.00e-05
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 21:21:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:21:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:22:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:22:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.151855, avg_loss=0.666983, seen=480, correct=300, accuracy=0.625000
2025-10-09 21:22:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:22:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:22:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:22:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=238 reserved=2416MB allocated=2217MB
2025-10-09 21:22:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 238, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.6217423081398, 'train_avg_loss': 0.630181185901165, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 21:22:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 238, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.15185546875, 'train_avg_loss': 0.6669830322265625, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:22:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 238, 'Results_raw': {'train_total': 480, 'train_loss': 320.15185546875, 'train_avg_loss': 0.6669830322265625, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:22:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #239) -------------
2025-10-09 21:22:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=239 aidx=8 | s=5 (candidates=12)
2025-10-09 21:22:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 38, 13, 39, 46] (from 12)
2025-10-09 21:22:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #239, planning to set LR to 1.00e-05
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-09 21:22:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:22:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:23:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:23:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.965210, avg_loss=0.662428, seen=480, correct=291, accuracy=0.606250
2025-10-09 21:23:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:23:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:23:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:23:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=239 reserved=2420MB allocated=2217MB
2025-10-09 21:23:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 239, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45381736755371, 'train_avg_loss': 0.6787818113962809, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 21:23:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 239, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.9652099609375, 'train_avg_loss': 0.6624275207519531, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 21:23:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 239, 'Results_raw': {'train_total': 480, 'train_loss': 317.9652099609375, 'train_avg_loss': 0.6624275207519531, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 21:23:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:23:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:23:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #239, planning to set LR to 1.00e-05
2025-10-09 21:23:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-09 21:23:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:23:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:23:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:23:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:23:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:23:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:23:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.435211, avg_loss=0.623823, seen=480, correct=311, accuracy=0.647917
2025-10-09 21:23:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:23:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:23:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:23:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=239 reserved=2418MB allocated=2217MB
2025-10-09 21:23:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 239, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.5461677312851, 'train_avg_loss': 0.6128847310940425, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-09 21:23:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 239, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.4352111816406, 'train_avg_loss': 0.6238233566284179, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 21:23:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 239, 'Results_raw': {'train_total': 480, 'train_loss': 299.4352111816406, 'train_avg_loss': 0.6238233566284179, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 21:23:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #239, planning to set LR to 1.00e-05
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-09 21:23:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:23:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:24:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:24:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.845154, avg_loss=0.608011, seen=480, correct=328, accuracy=0.683333
2025-10-09 21:24:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:24:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:24:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:24:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=239 reserved=2416MB allocated=2217MB
2025-10-09 21:24:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 239, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.12054318189621, 'train_avg_loss': 0.6176711931824684, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 21:24:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 239, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.84515380859375, 'train_avg_loss': 0.608010737101237, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-09 21:24:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 239, 'Results_raw': {'train_total': 480, 'train_loss': 291.84515380859375, 'train_avg_loss': 0.608010737101237, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-09 21:24:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:24:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:24:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #239, planning to set LR to 1.00e-05
2025-10-09 21:24:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-09 21:24:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:24:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:24:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:24:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:24:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:25:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:25:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.055054, avg_loss=0.627198, seen=480, correct=318, accuracy=0.662500
2025-10-09 21:25:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:25:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:25:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:25:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=239 reserved=2416MB allocated=2217MB
2025-10-09 21:25:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 239, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.6745679974556, 'train_avg_loss': 0.6222880666454633, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-09 21:25:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 239, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.0550537109375, 'train_avg_loss': 0.6271980285644532, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 21:25:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 239, 'Results_raw': {'train_total': 480, 'train_loss': 301.0550537109375, 'train_avg_loss': 0.6271980285644532, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 21:25:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:25:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:25:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #239, planning to set LR to 1.00e-05
2025-10-09 21:25:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 21:25:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:25:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:25:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:25:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:25:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:25:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:25:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.547577, avg_loss=0.663641, seen=480, correct=283, accuracy=0.589583
2025-10-09 21:25:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:25:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:25:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:25:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=239 reserved=2432MB allocated=2217MB
2025-10-09 21:25:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 239, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.7303232550621, 'train_avg_loss': 0.6560860271255176, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 21:25:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 239, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.5475769042969, 'train_avg_loss': 0.6636407852172852, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 21:25:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 239, 'Results_raw': {'train_total': 480, 'train_loss': 318.5475769042969, 'train_avg_loss': 0.6636407852172852, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 21:25:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #240) -------------
2025-10-09 21:25:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=240 aidx=8 | s=5 (candidates=12)
2025-10-09 21:25:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 19, 52, 23, 46] (from 12)
2025-10-09 21:25:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:25:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:25:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #240, planning to set LR to 1.00e-05
2025-10-09 21:25:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-09 21:25:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:25:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:25:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:25:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:25:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:26:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:26:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.643463, avg_loss=0.647174, seen=480, correct=306, accuracy=0.637500
2025-10-09 21:26:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:26:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:26:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:26:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=240 reserved=2416MB allocated=2217MB
2025-10-09 21:26:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 240, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.7560638487339, 'train_avg_loss': 0.6229671987394492, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 21:26:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 240, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.6434631347656, 'train_avg_loss': 0.6471738815307617, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:26:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 240, 'Results_raw': {'train_total': 480, 'train_loss': 310.6434631347656, 'train_avg_loss': 0.6471738815307617, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:26:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:26:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:26:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #240, planning to set LR to 1.00e-05
2025-10-09 21:26:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-09 21:26:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:26:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:26:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:26:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:26:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:27:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:27:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=282.355804, avg_loss=0.588241, seen=480, correct=340, accuracy=0.708333
2025-10-09 21:27:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:27:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:27:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:27:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=240 reserved=2468MB allocated=2217MB
2025-10-09 21:27:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 240, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.47909939289093, 'train_avg_loss': 0.562325828274091, 'train_seen': 120, 'train_correct': 90, 'train_acc': 0.75}}
2025-10-09 21:27:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 240, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 282.3558044433594, 'train_avg_loss': 0.5882412592569987, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-09 21:27:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 240, 'Results_raw': {'train_total': 480, 'train_loss': 282.3558044433594, 'train_avg_loss': 0.5882412592569987, 'train_seen': 480, 'train_correct': 340, 'train_acc': 0.7083333333333334}}
2025-10-09 21:27:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:27:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:27:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #240, planning to set LR to 1.00e-05
2025-10-09 21:27:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-09 21:27:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:27:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:27:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:27:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:27:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:27:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:27:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.446289, avg_loss=0.646763, seen=480, correct=301, accuracy=0.627083
2025-10-09 21:27:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:27:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:27:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:27:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=240 reserved=2416MB allocated=2217MB
2025-10-09 21:27:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 240, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.84279841184616, 'train_avg_loss': 0.6236899867653847, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 21:27:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 240, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.4462890625, 'train_avg_loss': 0.6467631022135417, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 21:27:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 240, 'Results_raw': {'train_total': 480, 'train_loss': 310.4462890625, 'train_avg_loss': 0.6467631022135417, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-09 21:27:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #240, planning to set LR to 1.00e-05
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-09 21:27:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:27:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:28:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:28:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.335327, avg_loss=0.613199, seen=480, correct=326, accuracy=0.679167
2025-10-09 21:28:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:28:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:28:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:28:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=240 reserved=2416MB allocated=2217MB
2025-10-09 21:28:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 240, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.66525131464005, 'train_avg_loss': 0.6472104276220004, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 21:28:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 240, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.3353271484375, 'train_avg_loss': 0.6131985982259115, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 21:28:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 240, 'Results_raw': {'train_total': 480, 'train_loss': 294.3353271484375, 'train_avg_loss': 0.6131985982259115, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 21:28:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:28:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:28:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #240, planning to set LR to 1.00e-05
2025-10-09 21:28:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-09 21:28:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:28:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:28:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:28:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:28:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:29:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:29:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.208923, avg_loss=0.652519, seen=480, correct=291, accuracy=0.606250
2025-10-09 21:29:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:29:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=140152366170112 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:29:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:29:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=240 reserved=2432MB allocated=2217MB
2025-10-09 21:29:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 240, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.37620359659195, 'train_avg_loss': 0.636468363304933, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 21:29:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 240, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.20892333984375, 'train_avg_loss': 0.6525185902913412, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 21:29:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 240, 'Results_raw': {'train_total': 480, 'train_loss': 313.20892333984375, 'train_avg_loss': 0.6525185902913412, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 21:29:23 (federatedscope.core.workers.server:488) INFO: Server: Training is finished! (skip final evaluation)
2025-10-09 21:29:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 759.57869375, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 154976, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:23 (federatedscope.core.workers.client:842) INFO: ================= client 1 received finish message =================
2025-10-09 21:29:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 759.5828106, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25652288, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:23 (federatedscope.core.workers.client:842) INFO: ================= client 2 received finish message =================
2025-10-09 21:29:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #2, the system-related metrics are: {'id': 2, 'fl_end_time_minutes': 759.5090580833333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209208, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:23 (federatedscope.core.workers.client:842) INFO: ================= client 3 received finish message =================
2025-10-09 21:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #3, the system-related metrics are: {'id': 3, 'fl_end_time_minutes': 759.4649414166666, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:24 (federatedscope.core.workers.client:842) INFO: ================= client 4 received finish message =================
2025-10-09 21:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #4, the system-related metrics are: {'id': 4, 'fl_end_time_minutes': 759.4217088666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:24 (federatedscope.core.workers.client:842) INFO: ================= client 5 received finish message =================
2025-10-09 21:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #5, the system-related metrics are: {'id': 5, 'fl_end_time_minutes': 759.3729005833334, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:24 (federatedscope.core.workers.client:842) INFO: ================= client 6 received finish message =================
2025-10-09 21:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #6, the system-related metrics are: {'id': 6, 'fl_end_time_minutes': 759.3288213333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:24 (federatedscope.core.workers.client:842) INFO: ================= client 7 received finish message =================
2025-10-09 21:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #7, the system-related metrics are: {'id': 7, 'fl_end_time_minutes': 759.2797329, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:24 (federatedscope.core.workers.client:842) INFO: ================= client 8 received finish message =================
2025-10-09 21:29:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #8, the system-related metrics are: {'id': 8, 'fl_end_time_minutes': 759.2349481, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209208, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:24 (federatedscope.core.workers.client:842) INFO: ================= client 9 received finish message =================
2025-10-09 21:29:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #9, the system-related metrics are: {'id': 9, 'fl_end_time_minutes': 759.1915915000001, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:25 (federatedscope.core.workers.client:842) INFO: ================= client 10 received finish message =================
2025-10-09 21:29:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #10, the system-related metrics are: {'id': 10, 'fl_end_time_minutes': 759.1245474166666, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:25 (federatedscope.core.workers.client:842) INFO: ================= client 11 received finish message =================
2025-10-09 21:29:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #11, the system-related metrics are: {'id': 11, 'fl_end_time_minutes': 759.0797528500001, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209208, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:25 (federatedscope.core.workers.client:842) INFO: ================= client 12 received finish message =================
2025-10-09 21:29:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #12, the system-related metrics are: {'id': 12, 'fl_end_time_minutes': 759.03634125, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20766144, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:25 (federatedscope.core.workers.client:842) INFO: ================= client 13 received finish message =================
2025-10-09 21:29:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #13, the system-related metrics are: {'id': 13, 'fl_end_time_minutes': 758.9872460833334, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20766144, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:25 (federatedscope.core.workers.client:842) INFO: ================= client 14 received finish message =================
2025-10-09 21:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #14, the system-related metrics are: {'id': 14, 'fl_end_time_minutes': 758.9442207666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20766144, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:26 (federatedscope.core.workers.client:842) INFO: ================= client 15 received finish message =================
2025-10-09 21:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #15, the system-related metrics are: {'id': 15, 'fl_end_time_minutes': 758.9009288833333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:26 (federatedscope.core.workers.client:842) INFO: ================= client 16 received finish message =================
2025-10-09 21:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #16, the system-related metrics are: {'id': 16, 'fl_end_time_minutes': 758.8577872999999, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25652288, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:26 (federatedscope.core.workers.client:842) INFO: ================= client 17 received finish message =================
2025-10-09 21:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #17, the system-related metrics are: {'id': 17, 'fl_end_time_minutes': 758.8146335666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25652288, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:26 (federatedscope.core.workers.client:842) INFO: ================= client 18 received finish message =================
2025-10-09 21:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #18, the system-related metrics are: {'id': 18, 'fl_end_time_minutes': 758.7506621166667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19544608, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:26 (federatedscope.core.workers.client:842) INFO: ================= client 19 received finish message =================
2025-10-09 21:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #19, the system-related metrics are: {'id': 19, 'fl_end_time_minutes': 758.7068584499999, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17101536, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:26 (federatedscope.core.workers.client:842) INFO: ================= client 20 received finish message =================
2025-10-09 21:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #20, the system-related metrics are: {'id': 20, 'fl_end_time_minutes': 758.6623655666666, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13436928, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:27 (federatedscope.core.workers.client:842) INFO: ================= client 21 received finish message =================
2025-10-09 21:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #21, the system-related metrics are: {'id': 21, 'fl_end_time_minutes': 758.6186651666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20766144, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:27 (federatedscope.core.workers.client:842) INFO: ================= client 22 received finish message =================
2025-10-09 21:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #22, the system-related metrics are: {'id': 22, 'fl_end_time_minutes': 758.5753818166667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 26873824, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:27 (federatedscope.core.workers.client:842) INFO: ================= client 23 received finish message =================
2025-10-09 21:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #23, the system-related metrics are: {'id': 23, 'fl_end_time_minutes': 758.5321841, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:27 (federatedscope.core.workers.client:842) INFO: ================= client 24 received finish message =================
2025-10-09 21:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #24, the system-related metrics are: {'id': 24, 'fl_end_time_minutes': 758.483846, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:27 (federatedscope.core.workers.client:842) INFO: ================= client 25 received finish message =================
2025-10-09 21:29:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:28 (federatedscope.core.monitors.monitor:268) INFO: In worker #25, the system-related metrics are: {'id': 25, 'fl_end_time_minutes': 758.440341, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:28 (federatedscope.core.workers.client:842) INFO: ================= client 26 received finish message =================
2025-10-09 21:29:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:28 (federatedscope.core.monitors.monitor:268) INFO: In worker #26, the system-related metrics are: {'id': 26, 'fl_end_time_minutes': 758.3965317333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:28 (federatedscope.core.workers.client:842) INFO: ================= client 27 received finish message =================
2025-10-09 21:29:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:28 (federatedscope.core.monitors.monitor:268) INFO: In worker #27, the system-related metrics are: {'id': 27, 'fl_end_time_minutes': 758.3362177500001, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:28 (federatedscope.core.workers.client:842) INFO: ================= client 28 received finish message =================
2025-10-09 21:29:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:28 (federatedscope.core.monitors.monitor:268) INFO: In worker #28, the system-related metrics are: {'id': 28, 'fl_end_time_minutes': 758.2921591333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25652288, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:28 (federatedscope.core.workers.client:842) INFO: ================= client 29 received finish message =================
2025-10-09 21:29:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:28 (federatedscope.core.monitors.monitor:268) INFO: In worker #29, the system-related metrics are: {'id': 29, 'fl_end_time_minutes': 758.2486087666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:28 (federatedscope.core.workers.client:842) INFO: ================= client 30 received finish message =================
2025-10-09 21:29:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:28 (federatedscope.core.monitors.monitor:268) INFO: In worker #30, the system-related metrics are: {'id': 30, 'fl_end_time_minutes': 758.2051809166667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:28 (federatedscope.core.workers.client:842) INFO: ================= client 31 received finish message =================
2025-10-09 21:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:29 (federatedscope.core.monitors.monitor:268) INFO: In worker #31, the system-related metrics are: {'id': 31, 'fl_end_time_minutes': 758.1616154333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:29 (federatedscope.core.workers.client:842) INFO: ================= client 32 received finish message =================
2025-10-09 21:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:29 (federatedscope.core.monitors.monitor:268) INFO: In worker #32, the system-related metrics are: {'id': 32, 'fl_end_time_minutes': 758.1169568166666, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 24430752, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:29 (federatedscope.core.workers.client:842) INFO: ================= client 33 received finish message =================
2025-10-09 21:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:29 (federatedscope.core.monitors.monitor:268) INFO: In worker #33, the system-related metrics are: {'id': 33, 'fl_end_time_minutes': 758.0700646, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 26873824, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:29 (federatedscope.core.workers.client:842) INFO: ================= client 34 received finish message =================
2025-10-09 21:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:29 (federatedscope.core.monitors.monitor:268) INFO: In worker #34, the system-related metrics are: {'id': 34, 'fl_end_time_minutes': 758.02630565, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19544608, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:29 (federatedscope.core.workers.client:842) INFO: ================= client 35 received finish message =================
2025-10-09 21:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:29 (federatedscope.core.monitors.monitor:268) INFO: In worker #35, the system-related metrics are: {'id': 35, 'fl_end_time_minutes': 757.9653698333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:29 (federatedscope.core.workers.client:842) INFO: ================= client 36 received finish message =================
2025-10-09 21:29:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:29 (federatedscope.core.monitors.monitor:268) INFO: In worker #36, the system-related metrics are: {'id': 36, 'fl_end_time_minutes': 757.9213941833333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 24430752, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:29 (federatedscope.core.workers.client:842) INFO: ================= client 37 received finish message =================
2025-10-09 21:29:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:30 (federatedscope.core.monitors.monitor:268) INFO: In worker #37, the system-related metrics are: {'id': 37, 'fl_end_time_minutes': 757.8775908833334, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20766144, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:30 (federatedscope.core.workers.client:842) INFO: ================= client 38 received finish message =================
2025-10-09 21:29:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:30 (federatedscope.core.monitors.monitor:268) INFO: In worker #38, the system-related metrics are: {'id': 38, 'fl_end_time_minutes': 757.8338825666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:30 (federatedscope.core.workers.client:842) INFO: ================= client 39 received finish message =================
2025-10-09 21:29:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:30 (federatedscope.core.monitors.monitor:268) INFO: In worker #39, the system-related metrics are: {'id': 39, 'fl_end_time_minutes': 757.7909862333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 28095360, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:30 (federatedscope.core.workers.client:842) INFO: ================= client 40 received finish message =================
2025-10-09 21:29:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:30 (federatedscope.core.monitors.monitor:268) INFO: In worker #40, the system-related metrics are: {'id': 40, 'fl_end_time_minutes': 757.7481314666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:30 (federatedscope.core.workers.client:842) INFO: ================= client 41 received finish message =================
2025-10-09 21:29:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:30 (federatedscope.core.monitors.monitor:268) INFO: In worker #41, the system-related metrics are: {'id': 41, 'fl_end_time_minutes': 757.7016010499999, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 28095360, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:30 (federatedscope.core.workers.client:842) INFO: ================= client 42 received finish message =================
2025-10-09 21:29:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:31 (federatedscope.core.monitors.monitor:268) INFO: In worker #42, the system-related metrics are: {'id': 42, 'fl_end_time_minutes': 757.6565570333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 24430752, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:31 (federatedscope.core.workers.client:842) INFO: ================= client 43 received finish message =================
2025-10-09 21:29:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:31 (federatedscope.core.monitors.monitor:268) INFO: In worker #43, the system-related metrics are: {'id': 43, 'fl_end_time_minutes': 757.6128641333332, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:31 (federatedscope.core.workers.client:842) INFO: ================= client 44 received finish message =================
2025-10-09 21:29:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:31 (federatedscope.core.monitors.monitor:268) INFO: In worker #44, the system-related metrics are: {'id': 44, 'fl_end_time_minutes': 757.5521675833334, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 23209216, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:31 (federatedscope.core.workers.client:842) INFO: ================= client 45 received finish message =================
2025-10-09 21:29:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:31 (federatedscope.core.monitors.monitor:268) INFO: In worker #45, the system-related metrics are: {'id': 45, 'fl_end_time_minutes': 757.5083989833333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 26873824, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:31 (federatedscope.core.workers.client:842) INFO: ================= client 46 received finish message =================
2025-10-09 21:29:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:31 (federatedscope.core.monitors.monitor:268) INFO: In worker #46, the system-related metrics are: {'id': 46, 'fl_end_time_minutes': 757.4646520833334, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 28095360, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:31 (federatedscope.core.workers.client:842) INFO: ================= client 47 received finish message =================
2025-10-09 21:29:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:31 (federatedscope.core.monitors.monitor:268) INFO: In worker #47, the system-related metrics are: {'id': 47, 'fl_end_time_minutes': 757.42203315, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21987680, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:31 (federatedscope.core.workers.client:842) INFO: ================= client 48 received finish message =================
2025-10-09 21:29:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:32 (federatedscope.core.monitors.monitor:268) INFO: In worker #48, the system-related metrics are: {'id': 48, 'fl_end_time_minutes': 757.3806107666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 34203040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:32 (federatedscope.core.workers.client:842) INFO: ================= client 49 received finish message =================
2025-10-09 21:29:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:32 (federatedscope.core.monitors.monitor:268) INFO: In worker #49, the system-related metrics are: {'id': 49, 'fl_end_time_minutes': 757.3392103166666, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 26873824, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:32 (federatedscope.core.workers.client:842) INFO: ================= client 50 received finish message =================
2025-10-09 21:29:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:32 (federatedscope.core.monitors.monitor:268) INFO: In worker #50, the system-related metrics are: {'id': 50, 'fl_end_time_minutes': 757.2934355833333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 24430752, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:32 (federatedscope.core.workers.client:842) INFO: ================= client 51 received finish message =================
2025-10-09 21:29:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:32 (federatedscope.core.monitors.monitor:268) INFO: In worker #51, the system-related metrics are: {'id': 51, 'fl_end_time_minutes': 757.2513637666667, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18323072, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:32 (federatedscope.core.workers.client:842) INFO: ================= client 52 received finish message =================
2025-10-09 21:29:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:32 (federatedscope.core.monitors.monitor:268) INFO: In worker #52, the system-related metrics are: {'id': 52, 'fl_end_time_minutes': 757.1937381833334, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25652288, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:32 (federatedscope.core.workers.client:842) INFO: ================= client 53 received finish message =================
2025-10-09 21:29:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=3360 skipped=0 missing=291 unexpected=0
2025-10-09 21:29:33 (federatedscope.core.monitors.monitor:268) INFO: In worker #53, the system-related metrics are: {'id': 53, 'fl_end_time_minutes': 757.1521623333333, 'total_model_size': 537763968, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25652288, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-09 21:29:33 (federatedscope.core.monitors.monitor:359) INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 758.3703844518519, 'sys_avg/total_model_size': '503.35M', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '0.0', 'sys_avg/total_download_bytes': '21.9M', 'sys_avg/global_convergence_round': 0.0, 'sys_avg/local_convergence_round': 0.0, 'sys_avg/global_convergence_time_minutes': 0.0, 'sys_avg/local_convergence_time_minutes': 0.0})
2025-10-09 21:29:33 (federatedscope.core.monitors.monitor:360) INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.7214542880533896, 'sys_std/total_model_size': '69.14M', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '0.0', 'sys_std/total_download_bytes': '4.19M', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 0.0, 'sys_std/global_convergence_time_minutes': 0.0, 'sys_std/local_convergence_time_minutes': 0.0})
