2025-10-09 21:29:55 (root:426) INFO: [logger] file handler -> exp/tldr/choice_qwen/gfl/fedbis_oracle_u7_1.0/exp_print.log
2025-10-09 21:29:55 (root:51) INFO: [main] outdir=exp/tldr/choice_qwen/gfl/fedbis_oracle_u7_1.0
2025-10-09 21:30:18 (federatedscope.core.data.base_translator:234) INFO: Main process: Completion file found. Skipping generation.
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:264) INFO: [Final Split Summary][loaded][server=0][rank=0/4] Train=92858, Val=33082, Test=50715, Total=176655
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=1][rank=0/4] Train=2793, Val=146, Test=40, Total=2979
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=2][rank=0/4] Train=214, Val=11, Test=40, Total=265
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=3][rank=0/4] Train=691, Val=36, Test=40, Total=767
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=4][rank=0/4] Train=213, Val=11, Test=40, Total=264
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=5][rank=0/4] Train=285, Val=14, Test=40, Total=339
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=6][rank=0/4] Train=2547, Val=134, Test=40, Total=2721
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=7][rank=0/4] Train=1088, Val=57, Test=40, Total=1185
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=8][rank=0/4] Train=1316, Val=69, Test=40, Total=1425
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=9][rank=0/4] Train=3572, Val=188, Test=40, Total=3800
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=10][rank=0/4] Train=1209, Val=63, Test=40, Total=1312
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=11][rank=0/4] Train=621, Val=32, Test=40, Total=693
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=12][rank=0/4] Train=2605, Val=137, Test=40, Total=2782
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=13][rank=0/4] Train=1372, Val=72, Test=40, Total=1484
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=14][rank=0/4] Train=3055, Val=160, Test=40, Total=3255
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=15][rank=0/4] Train=14550, Val=200, Test=40, Total=14790
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=16][rank=0/4] Train=2589, Val=136, Test=40, Total=2765
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=17][rank=0/4] Train=5883, Val=200, Test=40, Total=6123
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=18][rank=0/4] Train=2576, Val=135, Test=40, Total=2751
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=19][rank=0/4] Train=2102, Val=110, Test=40, Total=2252
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=20][rank=0/4] Train=2399, Val=126, Test=40, Total=2565
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=21][rank=0/4] Train=2915, Val=153, Test=40, Total=3108
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=22][rank=0/4] Train=224, Val=11, Test=40, Total=275
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=23][rank=0/4] Train=583, Val=30, Test=40, Total=653
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=24][rank=0/4] Train=4944, Val=200, Test=40, Total=5184
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=25][rank=0/4] Train=4647, Val=200, Test=40, Total=4887
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=26][rank=0/4] Train=3063, Val=161, Test=40, Total=3264
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=27][rank=0/4] Train=2342, Val=123, Test=40, Total=2505
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=28][rank=0/4] Train=1434, Val=75, Test=40, Total=1549
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=29][rank=0/4] Train=6191, Val=200, Test=40, Total=6431
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=30][rank=0/4] Train=3247, Val=170, Test=40, Total=3457
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=31][rank=0/4] Train=3679, Val=193, Test=40, Total=3912
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=32][rank=0/4] Train=2144, Val=112, Test=40, Total=2296
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=33][rank=0/4] Train=1409, Val=74, Test=40, Total=1523
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=34][rank=0/4] Train=4486, Val=200, Test=40, Total=4726
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=35][rank=0/4] Train=4736, Val=200, Test=40, Total=4976
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=36][rank=0/4] Train=1030, Val=54, Test=40, Total=1124
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=37][rank=0/4] Train=4273, Val=200, Test=40, Total=4513
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=38][rank=0/4] Train=6171, Val=200, Test=40, Total=6411
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=39][rank=0/4] Train=1594, Val=83, Test=40, Total=1717
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=40][rank=0/4] Train=4005, Val=200, Test=40, Total=4245
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=41][rank=0/4] Train=2275, Val=119, Test=40, Total=2434
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=42][rank=0/4] Train=5772, Val=200, Test=40, Total=6012
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=43][rank=0/4] Train=1694, Val=89, Test=40, Total=1823
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=44][rank=0/4] Train=7916, Val=200, Test=40, Total=8156
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=45][rank=0/4] Train=1901, Val=100, Test=40, Total=2041
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=46][rank=0/4] Train=2100, Val=110, Test=40, Total=2250
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=47][rank=0/4] Train=2812, Val=147, Test=40, Total=2999
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=48][rank=0/4] Train=880, Val=46, Test=40, Total=966
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=49][rank=0/4] Train=2521, Val=132, Test=40, Total=2693
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=50][rank=0/4] Train=2527, Val=133, Test=40, Total=2700
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=51][rank=0/4] Train=1580, Val=83, Test=40, Total=1703
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=52][rank=0/4] Train=3589, Val=188, Test=40, Total=3817
2025-10-09 21:31:00 (federatedscope.core.data.base_translator:273) INFO: [Final Split Summary][loaded][client=53][rank=0/4] Train=6791, Val=200, Test=40, Total=7031
2025-10-09 21:31:00 (federatedscope.core.configs.config:256) INFO: the used configs are: 
adapter:
  use: False
aggregator:
  BFT_args:
    
  byzantine_node_num: 0
  inside_weight: 1.0
  num_agg_groups: 1
  num_agg_topk: []
  outside_weight: 0.0
  robust_rule: fedavg
asyn:
  use: False
attack:
  alpha_TV: 0.001
  alpha_prop_loss: 0
  attack_method: 
  attacker_id: -1
  classifier_PIA: randomforest
  edge_num: 100
  edge_path: edge_data/
  freq: 10
  info_diff_type: l2
  inject_round: 0
  insert_round: 100000
  label_type: dirty
  max_ite: 400
  mean: [0.9637]
  mia_is_simulate_in: False
  mia_simulate_in_round: 20
  pgd_eps: 2
  pgd_lr: 0.1
  pgd_poisoning: False
  poison_ratio: 0.5
  reconstruct_lr: 0.01
  reconstruct_optim: Adam
  scale_para: 1.0
  scale_poisoning: False
  self_epoch: 6
  self_lr: 0.05
  self_opt: False
  setting: fix
  std: [0.1592]
  target_label_ind: -1
  trigger_path: trigger/
  trigger_type: edge
backend: torch
cfg_file: 
check_completeness: False
criterion:
  type: CrossEntropyLoss
data:
  args: []
  batch_size: 64
  cSBM_phi: [0.5, 0.5, 0.5]
  cache_dir: 
  consistent_label_distribution: True
  drop_last: False
  file_path: 
  hetero_data_name: []
  hetero_synth_batch_size: 32
  hetero_synth_feat_dim: 128
  hetero_synth_prim_weight: 0.5
  is_debug: False
  load_splits: False
  loader: 
  max_query_len: 128
  max_seq_len: 384
  max_tgt_len: 128
  num_contrast: 0
  num_of_client_for_data: []
  num_steps: 30
  num_workers: 0
  pre_transform: []
  quadratic:
    dim: 1
    max_curv: 12.5
    min_curv: 0.02
  root: data/
  save_data: False
  save_splits: False
  server_holds_all: False
  shuffle: True
  sizes: [10, 5]
  splits: [0.9, 0.09, 0.01]
  splits_path: ./final_data_splits
  splitter: meta
  splitter_args: []
  subsample: 1.0
  target_transform: []
  test_pre_transform: []
  test_target_transform: []
  test_transform: []
  transform: []
  trunc_stride: 128
  type: reddit-tldr-comparison-choice@llm
  val_pre_transform: []
  val_target_transform: []
  val_transform: []
  walk_length: 2
dataloader:
  batch_size: 2
  drop_last: False
  num_steps: 30
  num_workers: 0
  pin_memory: False
  shuffle: True
  sizes: [10, 5]
  theta: -1
  type: base
  walk_length: 2
device: 0
distribute:
  use: False
early_stop:
  delta: 0.0
  improve_indicator_mode: best
  patience: 0
eval:
  best_res_update_round_wise_key: test_loss
  count_flops: False
  freq: 500
  metrics: ['loss', 'acc']
  monitoring: []
  report: ['weighted_avg', 'avg', 'fairness', 'raw']
  split: ['val', 'test']
expname: 
expname_tag: 
feat_engr:
  num_bins: 5
  scenario: hfl
  secure:
    dp:
      
    encrypt:
      type: dummy
    key_size: 3072
    type: encrypt
  selec_threshold: 0.05
  selec_woe_binning: quantile
  type: 
federate:
  atc_load_from: 
  atc_vanilla: False
  client_idx_for_local_train: 0
  client_num: 53
  data_weighted_aggr: False
  ignore_weight: True
  join_in_info: []
  make_global_eval: False
  master_addr: 127.0.0.1
  master_port: 29500
  merge_test_data: False
  merge_val_data: False
  method: FedAvg
  mode: standalone
  online_aggr: False
  process_num: 1
  resource_info_file: 
  restore_from: 
  sample_client_num: 5
  sample_client_rate: -1.0
  sampler: cluster
  save_client_model: False
  save_freq: 100
  save_to: checkpoints_1.0_oracle/tldr_choice_qwen_fedbis_oracle_u7.ckpt
  share_local_model: True
  total_round_num: 211
  unseen_clients_rate: 0.0
  use_diff: False
  use_ss: False
fedopt:
  use: False
fedprox:
  use: False
fedsageplus:
  a: 1.0
  b: 1.0
  c: 1.0
  fedgen_epoch: 200
  gen_hidden: 128
  hide_portion: 0.5
  loc_epoch: 1
  num_pred: 5
fedswa:
  use: False
finetune:
  batch_or_epoch: epoch
  before_eval: False
  epoch_linear: 10
  freeze_param: 
  local_param: []
  local_update_steps: 1
  lr_linear: 0.005
  optimizer:
    lr: 0.1
    type: SGD
  scheduler:
    type: 
    warmup_ratio: 0.0
  simple_tuning: False
  weight_decay: 0.0
flitplus:
  factor_ema: 0.8
  lambdavat: 0.5
  tmpFed: 0.5
  weightReg: 1.0
gcflplus:
  EPS_1: 0.05
  EPS_2: 0.1
  seq_length: 5
  standardize: False
grad:
  grad_accum_count: 1
  grad_clip: -1.0
hpo:
  fedex:
    cutoff: 0.0
    diff: False
    eta0: -1.0
    flatten_ss: True
    gamma: 0.0
    pi_lr: 0.01
    psn: False
    sched: auto
    ss: 
    use: False
  fts:
    M: 100
    M_target: 200
    allow_load_existing_info: True
    diff: False
    fed_bo_max_iter: 50
    g_var: 1e-06
    gp_opt_schedule: 1
    local_bo_epochs: 50
    local_bo_max_iter: 50
    ls: 1.0
    obs_noise: 1e-06
    ss: 
    target_clients: []
    use: False
    v_kernel: 1.0
    var: 0.1
  init_cand_num: 16
  larger_better: False
  metric: client_summarized_weighted_avg.val_loss
  num_workers: 0
  pbt:
    max_stage: 5
    perf_threshold: 0.1
  pfedhpo:
    discrete: False
    ss: 
    target_fl_total_round: 1000
    train_anchor: False
    train_fl: False
    use: False
  scheduler: rs
  sha:
    budgets: []
    elim_rate: 3
    iter: 0
  ss: 
  table:
    eps: 0.1
    idx: 0
    num: 27
  trial_index: 0
  working_folder: hpo
llm:
  accelerator:
    config: 
    use: True
  adapter:
    args: [{'adapter_package': 'peft', 'adapter_method': 'lora', 'r': 8, 'lora_alpha': 16, 'lora_dropout': 0.05, 'target_modules': ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']}]
    balance: True
    boundaries: []
    cluster_runtime: {'schedule_file': 'exp/tldr/choice_qwen/gfl/fedbis_oracle_u7_1.0/cluster_schedule/cluster_schedule_u7.json'}
    clusters: [[2, 8, 11], [6, 15, 16, 20, 22, 28, 36, 40, 43, 48, 50, 51], [7, 9, 12, 17, 33, 35, 42], [3, 21, 31, 32, 37, 41], [4, 24, 25, 27, 30, 44], [1, 5, 26, 29, 34, 45, 47], [10, 13, 14, 18, 19, 23, 38, 39, 46, 49, 52, 53]]
    clusters_file: fedbiscuit_script/tldr/clusters_u7_53.json
    count: 7
    grouping:
      round: 50
      use: False
    local_only: False
    mv_to_cpu: False
    per_client_target: 18.867924528301888
    round_budget: 200
    round_ends: [19, 65, 92, 115, 138, 165, 211]
    round_physical: []
    sample_num_per_adapter: [3, 5, 5, 5, 5, 5, 5]
    target_per_round: 5
    use: True
    warmup:
      round: 0
      use: True
  cache:
    model: 
  chat:
    max_history_len: 10
    max_len: 1024
  deepspeed:
    ds_config: 
    use: False
  fedrlhf:
    config_file: 
    frequency: 100
    pretrained: False
    train:
      batch_or_epoch: batch
      local_update_steps: 10
    use: False
  grad_accum_step: 2
  max_new_token: 60
  num_completions: 2
  offsite_tuning:
    emu_align:
      data:
        root: data
        splits: [0.8, 0.1, 0.1]
        type: alpaca@llm
      exit_after_align: False
      init_enable_ground_truth: False
      initial_only: True
      kl_divergence: raw
      layerwise_distill: False
      restore_from: 
      save_to: 
      sim_loss: l2
      train:
        batch_or_epoch: batch
        enable_ground_truth: False
        initial_update_rounds: 50
        kd_loss_weight: 0.9
        lm_loss_weight: 0.1
        local_update_steps: 10
        optimizer:
          lr: 0.01
          type: SGD
      use: False
    emu_l: 1
    emu_r: 10
    eval_type: emu
    kwargs: [{}]
    llm_generated:
      ratio: 0.1
      use: False
    save_full_model: False
    strategy: drop_layer
    use: False
  retry_on_nan_loss: False
  reward_coeff: 0.1
  rlhf: False
  tok_len: 1024
model:
  contrast_temp: 1.0
  contrast_topk: 100
  downstream_tasks: []
  dropout: 0.5
  embed_size: 8
  gamma: 0
  graph_pooling: mean
  hidden: 256
  in_channels: 0
  input_shape: ()
  label_smoothing: 0.1
  lambda_: 0.1
  layer: 2
  length_penalty: 2.0
  llm_kwargs: [{}]
  llm_type: CausalLM
  load_from_local_pretrained_fs_config: 
  load_from_local_pretrained_model_path: 
  max_answer_len: 30
  max_length: 200
  max_tree_depth: 3
  min_length: 1
  model_num_per_trainer: 1
  model_type: google/bert_uncased_L-2_H-128_A-2
  n_best_size: 20
  no_repeat_ngram_size: 3
  null_score_diff_threshold: 0.0
  num_beams: 5
  num_item: 0
  num_labels: 1
  num_of_trees: 10
  num_user: 0
  out_channels: 1
  pretrain_tasks: []
  stage: 
  task: node
  type: Qwen/Qwen2-0.5B@huggingface_llm
  use_bias: True
  use_contrastive_loss: False
nbafl:
  use: False
outdir: exp/tldr/choice_qwen/gfl/fedbis_oracle_u7_1.0
personalization:
  K: 5
  beta: 1.0
  epoch_feature: 1
  epoch_linear: 2
  local_param: []
  local_update_steps: 30
  lr: 1e-05
  lr_feature: 0.1
  lr_linear: 0.1
  regular_weight: 0.1
  share_non_trainable_para: False
  weight_decay: 0.0
print_decimal_digits: 6
quantization:
  method: none
  nbits: 8
regularizer:
  mu: 0.0
  type: 
seed: 0
sgdmf:
  use: False
train:
  batch_or_epoch: batch
  data_para_dids: []
  is_enable_half: True
  local_update_steps: 30
  optimizer:
    betas: (0.9, 0.95)
    lr: 1e-05
    type: AdamW
  scheduler:
    gamma: 1.0
    milestones: [75, 125]
    type: 
    warmup_ratio: 0.0
trainer:
  choices: ['A', 'B']
  disp_freq: 50
  local_entropy:
    alpha: 0.75
    eps: 0.0001
    gamma: 0.03
    inc_factor: 1.0
  sam:
    adaptive: False
    eta: 0.0
    rho: 1.0
  type: llmrewardchoicetrainer
  val_freq: 100000000
use_gpu: True
verbose: 1
vertical:
  use: False
wandb:
  use: False
2025-10-09 21:31:02 (federatedscope.core.auxiliaries.utils:175) INFO: The device information file is not provided
2025-10-09 21:31:02 (federatedscope.core.auxiliaries.model_builder:139) WARNING: The input shape is None. Please specify the `data.input_shape`(a tuple) or give the representative data to `get_model` if necessary
2025-10-09 21:31:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-build][rank=0] tok_len=151643 | base=Qwen2ForCausalLM | in_emb=(Embedding) num=151646 ptr=139799204552768 | out_emb=(Linear) num=151646 ptr=139799204552768 | lora_ptr=None
2025-10-09 21:31:16 (federatedscope.core.fed_runner:211) INFO: Server has been set up ... 
2025-10-09 21:31:17 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:20 (federatedscope.core.fed_runner:275) INFO: Client 1 has been set up ... 
2025-10-09 21:31:20 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:23 (federatedscope.core.fed_runner:275) INFO: Client 2 has been set up ... 
2025-10-09 21:31:23 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:25 (federatedscope.core.fed_runner:275) INFO: Client 3 has been set up ... 
2025-10-09 21:31:25 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:28 (federatedscope.core.fed_runner:275) INFO: Client 4 has been set up ... 
2025-10-09 21:31:28 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:31 (federatedscope.core.fed_runner:275) INFO: Client 5 has been set up ... 
2025-10-09 21:31:31 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:34 (federatedscope.core.fed_runner:275) INFO: Client 6 has been set up ... 
2025-10-09 21:31:34 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:37 (federatedscope.core.fed_runner:275) INFO: Client 7 has been set up ... 
2025-10-09 21:31:37 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:39 (federatedscope.core.fed_runner:275) INFO: Client 8 has been set up ... 
2025-10-09 21:31:39 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:42 (federatedscope.core.fed_runner:275) INFO: Client 9 has been set up ... 
2025-10-09 21:31:42 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:46 (federatedscope.core.fed_runner:275) INFO: Client 10 has been set up ... 
2025-10-09 21:31:46 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:49 (federatedscope.core.fed_runner:275) INFO: Client 11 has been set up ... 
2025-10-09 21:31:49 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:51 (federatedscope.core.fed_runner:275) INFO: Client 12 has been set up ... 
2025-10-09 21:31:52 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:54 (federatedscope.core.fed_runner:275) INFO: Client 13 has been set up ... 
2025-10-09 21:31:54 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:31:57 (federatedscope.core.fed_runner:275) INFO: Client 14 has been set up ... 
2025-10-09 21:31:57 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:00 (federatedscope.core.fed_runner:275) INFO: Client 15 has been set up ... 
2025-10-09 21:32:00 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:02 (federatedscope.core.fed_runner:275) INFO: Client 16 has been set up ... 
2025-10-09 21:32:03 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:05 (federatedscope.core.fed_runner:275) INFO: Client 17 has been set up ... 
2025-10-09 21:32:05 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:08 (federatedscope.core.fed_runner:275) INFO: Client 18 has been set up ... 
2025-10-09 21:32:08 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:10 (federatedscope.core.fed_runner:275) INFO: Client 19 has been set up ... 
2025-10-09 21:32:11 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:14 (federatedscope.core.fed_runner:275) INFO: Client 20 has been set up ... 
2025-10-09 21:32:15 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:17 (federatedscope.core.fed_runner:275) INFO: Client 21 has been set up ... 
2025-10-09 21:32:17 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:20 (federatedscope.core.fed_runner:275) INFO: Client 22 has been set up ... 
2025-10-09 21:32:20 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:23 (federatedscope.core.fed_runner:275) INFO: Client 23 has been set up ... 
2025-10-09 21:32:23 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:25 (federatedscope.core.fed_runner:275) INFO: Client 24 has been set up ... 
2025-10-09 21:32:26 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:28 (federatedscope.core.fed_runner:275) INFO: Client 25 has been set up ... 
2025-10-09 21:32:28 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:31 (federatedscope.core.fed_runner:275) INFO: Client 26 has been set up ... 
2025-10-09 21:32:31 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:34 (federatedscope.core.fed_runner:275) INFO: Client 27 has been set up ... 
2025-10-09 21:32:34 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:36 (federatedscope.core.fed_runner:275) INFO: Client 28 has been set up ... 
2025-10-09 21:32:37 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:39 (federatedscope.core.fed_runner:275) INFO: Client 29 has been set up ... 
2025-10-09 21:32:39 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:43 (federatedscope.core.fed_runner:275) INFO: Client 30 has been set up ... 
2025-10-09 21:32:43 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:46 (federatedscope.core.fed_runner:275) INFO: Client 31 has been set up ... 
2025-10-09 21:32:46 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:48 (federatedscope.core.fed_runner:275) INFO: Client 32 has been set up ... 
2025-10-09 21:32:49 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:51 (federatedscope.core.fed_runner:275) INFO: Client 33 has been set up ... 
2025-10-09 21:32:51 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:54 (federatedscope.core.fed_runner:275) INFO: Client 34 has been set up ... 
2025-10-09 21:32:54 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:57 (federatedscope.core.fed_runner:275) INFO: Client 35 has been set up ... 
2025-10-09 21:32:57 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:32:59 (federatedscope.core.fed_runner:275) INFO: Client 36 has been set up ... 
2025-10-09 21:33:00 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:02 (federatedscope.core.fed_runner:275) INFO: Client 37 has been set up ... 
2025-10-09 21:33:02 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:05 (federatedscope.core.fed_runner:275) INFO: Client 38 has been set up ... 
2025-10-09 21:33:05 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:07 (federatedscope.core.fed_runner:275) INFO: Client 39 has been set up ... 
2025-10-09 21:33:08 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:11 (federatedscope.core.fed_runner:275) INFO: Client 40 has been set up ... 
2025-10-09 21:33:11 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:14 (federatedscope.core.fed_runner:275) INFO: Client 41 has been set up ... 
2025-10-09 21:33:14 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:16 (federatedscope.core.fed_runner:275) INFO: Client 42 has been set up ... 
2025-10-09 21:33:17 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:19 (federatedscope.core.fed_runner:275) INFO: Client 43 has been set up ... 
2025-10-09 21:33:19 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:22 (federatedscope.core.fed_runner:275) INFO: Client 44 has been set up ... 
2025-10-09 21:33:22 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:25 (federatedscope.core.fed_runner:275) INFO: Client 45 has been set up ... 
2025-10-09 21:33:25 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:27 (federatedscope.core.fed_runner:275) INFO: Client 46 has been set up ... 
2025-10-09 21:33:28 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:30 (federatedscope.core.fed_runner:275) INFO: Client 47 has been set up ... 
2025-10-09 21:33:30 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:33 (federatedscope.core.fed_runner:275) INFO: Client 48 has been set up ... 
2025-10-09 21:33:33 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:35 (federatedscope.core.fed_runner:275) INFO: Client 49 has been set up ... 
2025-10-09 21:33:36 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:39 (federatedscope.core.fed_runner:275) INFO: Client 50 has been set up ... 
2025-10-09 21:33:39 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:42 (federatedscope.core.fed_runner:275) INFO: Client 51 has been set up ... 
2025-10-09 21:33:42 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:44 (federatedscope.core.fed_runner:275) INFO: Client 52 has been set up ... 
2025-10-09 21:33:45 (federatedscope.llm.trainer.trainer:181) INFO: Choice token IDs: [362, 425]
2025-10-09 21:33:47 (federatedscope.core.fed_runner:275) INFO: Client 53 has been set up ... 
2025-10-09 21:33:47 (federatedscope.core.trainers.trainer:569) INFO: Model meta-info: <class 'federatedscope.llm.model.adapter_builder.AdapterModel'>.
2025-10-09 21:33:47 (federatedscope.core.trainers.trainer:584) INFO: Num of original para names: 2688.
2025-10-09 21:33:47 (federatedscope.core.trainers.trainer:585) INFO: Num of original trainable para names: 2978.
2025-10-09 21:33:47 (federatedscope.core.trainers.trainer:587) INFO: Num of preserved para names in local update: 2688. 
Preserved para names in local update: {'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.17.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.1.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.10.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.6.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.2.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.0.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.15.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.2.mlp.gate_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.10.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.0.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.5.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.16.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.23.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.9.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.3.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.18.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.5.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.18.self_attn.o_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.23.self_attn.o_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.2.self_attn.o_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.20.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.default.weight', 'base_model.model.model.layers.14.mlp.up_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.o_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.gate_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.4.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.11.mlp.up_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.mlp.up_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.down_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.19.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.12.self_attn.o_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.8.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.16.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.23.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.12.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.mlp.gate_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.13.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.gate_proj.lora_B.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.mlp.up_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.3.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.15.mlp.up_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.7.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.Adapter_0.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.8.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.Adapter_5.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.o_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.21.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.default.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.mlp.down_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.17.mlp.up_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.mlp.up_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.19.mlp.down_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.17.self_attn.o_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.8.mlp.down_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.mlp.down_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.mlp.gate_proj.lora_A.Adapter_2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.Adapter_6.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.Adapter_1.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.14.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.12.mlp.up_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.6.mlp.down_proj.lora_B.Adapter_2.weight', 'base_model.model.model.layers.13.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.16.mlp.down_proj.lora_A.default.weight', 'base_model.model.model.layers.1.mlp.gate_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.19.mlp.gate_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.Adapter_1.weight', 'base_model.model.model.layers.11.mlp.gate_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_B.Adapter_0.weight', 'base_model.model.model.layers.4.self_attn.o_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.6.self_attn.o_proj.lora_B.default.weight', 'base_model.model.model.layers.8.mlp.gate_proj.lora_B.Adapter_5.weight', 'base_model.model.model.layers.9.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.18.mlp.gate_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.2.mlp.down_proj.lora_B.Adapter_6.weight', 'base_model.model.model.layers.21.self_attn.o_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.1.mlp.up_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.Adapter_4.weight', 'base_model.model.model.layers.21.mlp.down_proj.lora_B.Adapter_3.weight', 'base_model.model.model.layers.10.mlp.gate_proj.lora_A.Adapter_3.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.Adapter_4.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.Adapter_1.weight'}.
2025-10-09 21:33:47 (federatedscope.core.trainers.trainer:591) INFO: Num of filtered para names in local update: 0. 
Filtered para names in local update: set().
2025-10-09 21:33:47 (federatedscope.core.trainers.trainer:599) INFO: After register default hooks,
	the hooks_in_train is:
	{
	  "on_fit_start": [
	    "_hook_on_fit_start_numerical_precision",
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init",
	    "_hook_on_fit_start_calculate_model_size"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward",
	    "_hook_on_batch_forward_regularizer",
	    "_hook_on_batch_forward_flop_count"
	  ],
	  "on_batch_backward": [
	    "_hook_on_batch_backward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_on_fit_end_free_space"
	  ]
	};
	the hooks_in_eval is:
            t{
	  "on_fit_start": [
	    "_hook_on_fit_start_numerical_precision",
	    "_hook_on_data_parallel_init",
	    "_hook_on_fit_start_init"
	  ],
	  "on_batch_start": [
	    "_hook_on_batch_start_init"
	  ],
	  "on_batch_forward": [
	    "_hook_on_batch_forward"
	  ],
	  "on_batch_end": [
	    "_hook_on_batch_end"
	  ],
	  "on_fit_end": [
	    "_hook_on_fit_end",
	    "_hook_on_fit_end_free_space"
	  ]
	}
2025-10-09 21:33:47 (federatedscope.llm.llm_local.server:147) INFO: Waited all clients join, start now...
2025-10-09 21:33:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=0 aidx=0 | s=3 (candidates=3)
2025-10-09 21:33:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 21:33:48 (federatedscope.llm.llm_local.server:161) INFO: ----------- Starting training (Round #0) -------------
2025-10-09 21:33:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:33:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:33:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-09 21:33:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:33:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139799204552768 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:33:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:33:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:33:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:33:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:34:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:34:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.507202, avg_loss=0.715640, seen=480, correct=245, accuracy=0.510417
2025-10-09 21:34:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:34:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:34:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:34:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=2196MB allocated=1827MB
2025-10-09 21:34:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.73548412322998, 'train_avg_loss': 0.6894623676935832, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 21:34:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.5072021484375, 'train_avg_loss': 0.7156400044759115, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 21:34:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 343.5072021484375, 'train_avg_loss': 0.7156400044759115, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 21:34:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:34:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:34:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:35:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:35:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.818420, avg_loss=0.728788, seen=480, correct=239, accuracy=0.497917
2025-10-09 21:35:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:35:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:35:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:35:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=2142MB allocated=1835MB
2025-10-09 21:35:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.20781219005585, 'train_avg_loss': 0.7350651015837987, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 21:35:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.81842041015625, 'train_avg_loss': 0.7287883758544922, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 21:35:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 349.81842041015625, 'train_avg_loss': 0.7287883758544922, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-09 21:35:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #0, planning to set LR to 1.00e-05
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:35:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:35:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:35:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:35:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.106598, avg_loss=0.716889, seen=480, correct=247, accuracy=0.514583
2025-10-09 21:35:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:35:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:35:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:35:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=0 reserved=2200MB allocated=1844MB
2025-10-09 21:35:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 0, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.35116511583328, 'train_avg_loss': 0.7112597092986107, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 21:35:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 0, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.1065979003906, 'train_avg_loss': 0.7168887456258138, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 21:35:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 0, 'Results_raw': {'train_total': 480, 'train_loss': 344.1065979003906, 'train_avg_loss': 0.7168887456258138, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-09 21:35:49 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #1) -------------
2025-10-09 21:35:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=1 aidx=0 | s=3 (candidates=3)
2025-10-09 21:35:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-09 21:35:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:35:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:35:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:36:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:36:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.385162, avg_loss=0.700802, seen=480, correct=244, accuracy=0.508333
2025-10-09 21:36:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:36:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:36:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:36:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2170MB allocated=1852MB
2025-10-09 21:36:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.13114798069, 'train_avg_loss': 0.69275956650575, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 21:36:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.3851623535156, 'train_avg_loss': 0.7008024215698242, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 21:36:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 336.3851623535156, 'train_avg_loss': 0.7008024215698242, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-09 21:36:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:36:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:36:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-09 21:36:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:36:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:36:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:36:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:36:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:36:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:37:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:37:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.703796, avg_loss=0.688966, seen=480, correct=267, accuracy=0.556250
2025-10-09 21:37:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:37:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:37:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:37:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2184MB allocated=1852MB
2025-10-09 21:37:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5049124956131, 'train_avg_loss': 0.6708742707967759, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 21:37:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.70379638671875, 'train_avg_loss': 0.6889662424723307, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 21:37:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 330.70379638671875, 'train_avg_loss': 0.6889662424723307, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 21:37:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #1, planning to set LR to 1.00e-05
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:37:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:37:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:37:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:37:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.041077, avg_loss=0.712586, seen=480, correct=220, accuracy=0.458333
2025-10-09 21:37:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:37:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:37:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:37:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=1 reserved=2170MB allocated=1852MB
2025-10-09 21:37:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 1, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.07169830799103, 'train_avg_loss': 0.7339308192332585, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-09 21:37:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 1, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.04107666015625, 'train_avg_loss': 0.7125855763753255, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-09 21:37:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 1, 'Results_raw': {'train_total': 480, 'train_loss': 342.04107666015625, 'train_avg_loss': 0.7125855763753255, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-09 21:37:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #2) -------------
2025-10-09 21:37:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=2 aidx=0 | s=3 (candidates=3)
2025-10-09 21:37:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 21:37:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:37:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:37:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:38:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:38:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.687683, avg_loss=0.688933, seen=480, correct=267, accuracy=0.556250
2025-10-09 21:38:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:38:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:38:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:38:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=2154MB allocated=1794MB
2025-10-09 21:38:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.57040596008301, 'train_avg_loss': 0.6797533830006918, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 21:38:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.68768310546875, 'train_avg_loss': 0.6889326731363933, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 21:38:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 330.68768310546875, 'train_avg_loss': 0.6889326731363933, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 21:38:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:38:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:38:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:38:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:38:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.460876, avg_loss=0.694710, seen=480, correct=248, accuracy=0.516667
2025-10-09 21:38:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:38:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:39:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:39:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=2166MB allocated=1794MB
2025-10-09 21:39:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26306587457657, 'train_avg_loss': 0.6855255489548048, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 21:39:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.46087646484375, 'train_avg_loss': 0.6947101593017578, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 21:39:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 333.46087646484375, 'train_avg_loss': 0.6947101593017578, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 21:39:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #2, planning to set LR to 1.00e-05
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:39:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:39:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:39:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:39:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.472687, avg_loss=0.703068, seen=480, correct=230, accuracy=0.479167
2025-10-09 21:39:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:39:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:39:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:39:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=2 reserved=2102MB allocated=1794MB
2025-10-09 21:39:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 2, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.45049595832825, 'train_avg_loss': 0.7204207996527354, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-09 21:39:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 2, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.4726867675781, 'train_avg_loss': 0.7030680974324545, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 21:39:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 2, 'Results_raw': {'train_total': 480, 'train_loss': 337.4726867675781, 'train_avg_loss': 0.7030680974324545, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-09 21:39:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #3) -------------
2025-10-09 21:39:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=3 aidx=0 | s=3 (candidates=3)
2025-10-09 21:39:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-09 21:39:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:39:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:39:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:40:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:40:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.902496, avg_loss=0.695630, seen=480, correct=251, accuracy=0.522917
2025-10-09 21:40:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:40:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:40:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:40:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=2166MB allocated=1794MB
2025-10-09 21:40:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.23512667417526, 'train_avg_loss': 0.6852927222847939, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 21:40:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9024963378906, 'train_avg_loss': 0.6956302007039388, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 21:40:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 333.9024963378906, 'train_avg_loss': 0.6956302007039388, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 21:40:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:40:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:40:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:40:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:40:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.400818, avg_loss=0.688335, seen=480, correct=261, accuracy=0.543750
2025-10-09 21:40:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:40:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:40:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:40:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=2152MB allocated=1794MB
2025-10-09 21:40:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36512249708176, 'train_avg_loss': 0.6780426874756813, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 21:40:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.40081787109375, 'train_avg_loss': 0.6883350372314453, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 21:40:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 330.40081787109375, 'train_avg_loss': 0.6883350372314453, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 21:40:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #3, planning to set LR to 1.00e-05
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:41:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:41:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:41:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:41:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.227051, avg_loss=0.696306, seen=480, correct=235, accuracy=0.489583
2025-10-09 21:41:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:41:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:41:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:41:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=3 reserved=2102MB allocated=1794MB
2025-10-09 21:41:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 3, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.23240876197815, 'train_avg_loss': 0.7102700730164846, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 21:41:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 3, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.22705078125, 'train_avg_loss': 0.6963063557942708, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 21:41:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 3, 'Results_raw': {'train_total': 480, 'train_loss': 334.22705078125, 'train_avg_loss': 0.6963063557942708, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 21:41:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #4) -------------
2025-10-09 21:41:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=4 aidx=0 | s=3 (candidates=3)
2025-10-09 21:41:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 21:41:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:41:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:41:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:42:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:42:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.066833, avg_loss=0.691806, seen=480, correct=259, accuracy=0.539583
2025-10-09 21:42:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:42:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:42:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:42:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=2128MB allocated=1794MB
2025-10-09 21:42:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.78275382518768, 'train_avg_loss': 0.6815229485432307, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 21:42:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.06683349609375, 'train_avg_loss': 0.691805903116862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 21:42:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 332.06683349609375, 'train_avg_loss': 0.691805903116862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 21:42:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:42:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:42:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:42:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:42:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.110687, avg_loss=0.687731, seen=480, correct=251, accuracy=0.522917
2025-10-09 21:42:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:42:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:42:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:42:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=2102MB allocated=1794MB
2025-10-09 21:42:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43496245145798, 'train_avg_loss': 0.7036246870954831, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 21:42:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.1106872558594, 'train_avg_loss': 0.6877305984497071, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 21:42:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 330.1106872558594, 'train_avg_loss': 0.6877305984497071, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 21:42:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:43:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:43:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #4, planning to set LR to 1.00e-05
2025-10-09 21:43:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:43:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:43:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:43:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:43:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:43:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:43:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:43:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.966553, avg_loss=0.689514, seen=480, correct=254, accuracy=0.529167
2025-10-09 21:43:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:43:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:43:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:43:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=4 reserved=2156MB allocated=1794MB
2025-10-09 21:43:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 4, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61819326877594, 'train_avg_loss': 0.6801516105731328, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 21:43:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 4, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.966552734375, 'train_avg_loss': 0.6895136515299479, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 21:43:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 4, 'Results_raw': {'train_total': 480, 'train_loss': 330.966552734375, 'train_avg_loss': 0.6895136515299479, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 21:43:34 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #5) -------------
2025-10-09 21:43:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=5 aidx=0 | s=3 (candidates=3)
2025-10-09 21:43:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 2, 11] (from 3)
2025-10-09 21:43:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:43:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:43:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:44:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:44:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.566833, avg_loss=0.688681, seen=480, correct=248, accuracy=0.516667
2025-10-09 21:44:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:44:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:44:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:44:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=2102MB allocated=1794MB
2025-10-09 21:44:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36256206035614, 'train_avg_loss': 0.7030213505029679, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 21:44:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.56683349609375, 'train_avg_loss': 0.688680903116862, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 21:44:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 330.56683349609375, 'train_avg_loss': 0.688680903116862, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 21:44:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:44:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:44:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:44:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:44:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.035797, avg_loss=0.670908, seen=480, correct=292, accuracy=0.608333
2025-10-09 21:44:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:44:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:44:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:44:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=2156MB allocated=1794MB
2025-10-09 21:44:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.89446496963501, 'train_avg_loss': 0.6491205414136251, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-09 21:44:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.0357971191406, 'train_avg_loss': 0.6709079106648763, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 21:44:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 322.0357971191406, 'train_avg_loss': 0.6709079106648763, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 21:44:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #5, planning to set LR to 1.00e-05
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:44:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:44:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:45:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:45:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.006592, avg_loss=0.689597, seen=480, correct=253, accuracy=0.527083
2025-10-09 21:45:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:45:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:45:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:45:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=5 reserved=2128MB allocated=1794MB
2025-10-09 21:45:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 5, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00579881668091, 'train_avg_loss': 0.6833816568056742, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 21:45:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 5, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.006591796875, 'train_avg_loss': 0.6895970662434896, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 21:45:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 5, 'Results_raw': {'train_total': 480, 'train_loss': 331.006591796875, 'train_avg_loss': 0.6895970662434896, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 21:45:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #6) -------------
2025-10-09 21:45:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=6 aidx=0 | s=3 (candidates=3)
2025-10-09 21:45:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 11, 2] (from 3)
2025-10-09 21:45:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:45:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:45:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:46:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:46:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.547180, avg_loss=0.686557, seen=480, correct=252, accuracy=0.525000
2025-10-09 21:46:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:46:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:46:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:46:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=2102MB allocated=1794MB
2025-10-09 21:46:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91427558660507, 'train_avg_loss': 0.6992856298883756, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 21:46:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.54718017578125, 'train_avg_loss': 0.686556625366211, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 21:46:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 329.54718017578125, 'train_avg_loss': 0.686556625366211, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 21:46:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:46:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:46:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:46:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:46:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.589355, avg_loss=0.682478, seen=480, correct=261, accuracy=0.543750
2025-10-09 21:46:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:46:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:46:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:46:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=2128MB allocated=1794MB
2025-10-09 21:46:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31017792224884, 'train_avg_loss': 0.6775848160187403, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 21:46:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.58935546875, 'train_avg_loss': 0.6824778238932292, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 21:46:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 327.58935546875, 'train_avg_loss': 0.6824778238932292, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 21:46:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #6, planning to set LR to 1.00e-05
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:46:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:46:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:47:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:47:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.385193, avg_loss=0.669552, seen=480, correct=285, accuracy=0.593750
2025-10-09 21:47:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:47:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:47:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:47:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=6 reserved=2156MB allocated=1794MB
2025-10-09 21:47:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 6, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.98893570899963, 'train_avg_loss': 0.6415744642416636, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-09 21:47:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 6, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.38519287109375, 'train_avg_loss': 0.6695524851481119, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 21:47:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 6, 'Results_raw': {'train_total': 480, 'train_loss': 321.38519287109375, 'train_avg_loss': 0.6695524851481119, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 21:47:29 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #7) -------------
2025-10-09 21:47:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=7 aidx=0 | s=3 (candidates=3)
2025-10-09 21:47:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 8, 11] (from 3)
2025-10-09 21:47:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:47:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:47:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-09 21:47:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:47:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:47:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:47:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:47:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:47:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:48:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:48:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.651855, avg_loss=0.653441, seen=480, correct=303, accuracy=0.631250
2025-10-09 21:48:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:48:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:48:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:48:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=2156MB allocated=1794MB
2025-10-09 21:48:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.47630774974823, 'train_avg_loss': 0.6123025645812352, 'train_seen': 120, 'train_correct': 91, 'train_acc': 0.7583333333333333}}
2025-10-09 21:48:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.65185546875, 'train_avg_loss': 0.6534413655598958, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 21:48:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 313.65185546875, 'train_avg_loss': 0.6534413655598958, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 21:48:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:48:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:48:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:48:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:48:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.685181, avg_loss=0.682677, seen=480, correct=265, accuracy=0.552083
2025-10-09 21:48:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:48:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:48:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:48:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=2102MB allocated=1794MB
2025-10-09 21:48:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3387656211853, 'train_avg_loss': 0.7028230468432108, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 21:48:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6851806640625, 'train_avg_loss': 0.6826774597167968, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 21:48:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 327.6851806640625, 'train_avg_loss': 0.6826774597167968, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 21:48:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #7, planning to set LR to 1.00e-05
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:48:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:48:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:49:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:49:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.277679, avg_loss=0.679745, seen=480, correct=268, accuracy=0.558333
2025-10-09 21:49:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:49:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:49:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:49:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=7 reserved=2128MB allocated=1794MB
2025-10-09 21:49:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 7, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.89459085464478, 'train_avg_loss': 0.6824549237887064, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 21:49:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 7, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.2776794433594, 'train_avg_loss': 0.6797451655069987, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 21:49:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 7, 'Results_raw': {'train_total': 480, 'train_loss': 326.2776794433594, 'train_avg_loss': 0.6797451655069987, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 21:49:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #8) -------------
2025-10-09 21:49:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=8 aidx=0 | s=3 (candidates=3)
2025-10-09 21:49:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 8, 11] (from 3)
2025-10-09 21:49:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:49:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:49:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-09 21:49:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:49:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:49:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:49:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:49:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:49:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:50:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:50:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.234589, avg_loss=0.648405, seen=480, correct=296, accuracy=0.616667
2025-10-09 21:50:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:50:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:50:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:50:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=2156MB allocated=1794MB
2025-10-09 21:50:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.88585126399994, 'train_avg_loss': 0.5990487605333328, 'train_seen': 120, 'train_correct': 90, 'train_acc': 0.75}}
2025-10-09 21:50:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.2345886230469, 'train_avg_loss': 0.648405392964681, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 21:50:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 311.2345886230469, 'train_avg_loss': 0.648405392964681, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 21:50:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:50:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:50:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:50:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:50:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.676086, avg_loss=0.680575, seen=480, correct=270, accuracy=0.562500
2025-10-09 21:50:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:50:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:50:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:50:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=2102MB allocated=1794MB
2025-10-09 21:50:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.76200836896896, 'train_avg_loss': 0.6980167364080747, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 21:50:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.67608642578125, 'train_avg_loss': 0.680575180053711, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 21:50:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 326.67608642578125, 'train_avg_loss': 0.680575180053711, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 21:50:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #8, planning to set LR to 1.00e-05
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:50:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:50:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:51:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:51:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.695984, avg_loss=0.672283, seen=480, correct=278, accuracy=0.579167
2025-10-09 21:51:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:51:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:51:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:51:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=8 reserved=2128MB allocated=1794MB
2025-10-09 21:51:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 8, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.30701225996017, 'train_avg_loss': 0.6775584354996681, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 21:51:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 8, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.69598388671875, 'train_avg_loss': 0.6722832997639974, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 21:51:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 8, 'Results_raw': {'train_total': 480, 'train_loss': 322.69598388671875, 'train_avg_loss': 0.6722832997639974, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 21:51:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #9) -------------
2025-10-09 21:51:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=9 aidx=0 | s=3 (candidates=3)
2025-10-09 21:51:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 2, 11] (from 3)
2025-10-09 21:51:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:51:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:51:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:52:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:52:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.007690, avg_loss=0.677099, seen=480, correct=277, accuracy=0.577083
2025-10-09 21:52:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:52:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:52:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:52:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=2102MB allocated=1794MB
2025-10-09 21:52:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37361490726471, 'train_avg_loss': 0.6947801242272059, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 21:52:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0076904296875, 'train_avg_loss': 0.6770993550618489, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 21:52:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 325.0076904296875, 'train_avg_loss': 0.6770993550618489, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 21:52:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:52:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:52:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:52:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:52:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.169403, avg_loss=0.646186, seen=480, correct=307, accuracy=0.639583
2025-10-09 21:52:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:52:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:52:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:52:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=2156MB allocated=1794MB
2025-10-09 21:52:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.40612703561783, 'train_avg_loss': 0.5867177252968152, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 21:52:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.1694030761719, 'train_avg_loss': 0.6461862564086914, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 21:52:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 310.1694030761719, 'train_avg_loss': 0.6461862564086914, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 21:52:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:52:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:52:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #9, planning to set LR to 1.00e-05
2025-10-09 21:52:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:52:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:52:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:52:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:52:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:52:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:53:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:53:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.378815, avg_loss=0.663289, seen=480, correct=294, accuracy=0.612500
2025-10-09 21:53:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:53:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:53:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:53:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=9 reserved=2128MB allocated=1794MB
2025-10-09 21:53:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 9, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.32211339473724, 'train_avg_loss': 0.6776842782894771, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 21:53:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 9, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.3788146972656, 'train_avg_loss': 0.66328919728597, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 21:53:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 9, 'Results_raw': {'train_total': 480, 'train_loss': 318.3788146972656, 'train_avg_loss': 0.66328919728597, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 21:53:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #10) -------------
2025-10-09 21:53:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=10 aidx=0 | s=3 (candidates=3)
2025-10-09 21:53:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 21:53:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:53:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:53:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:53:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:53:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.820343, avg_loss=0.641292, seen=480, correct=306, accuracy=0.637500
2025-10-09 21:53:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:53:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:53:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:53:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=2156MB allocated=1794MB
2025-10-09 21:53:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.6660236120224, 'train_avg_loss': 0.57221686343352, 'train_seen': 120, 'train_correct': 96, 'train_acc': 0.8}}
2025-10-09 21:53:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.8203430175781, 'train_avg_loss': 0.6412923812866211, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:53:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 307.8203430175781, 'train_avg_loss': 0.6412923812866211, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 21:53:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:53:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:53:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-09 21:53:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:53:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:53:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:53:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:53:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:53:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:54:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:54:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.011841, avg_loss=0.652108, seen=480, correct=300, accuracy=0.625000
2025-10-09 21:54:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:54:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:54:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:54:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=2128MB allocated=1794MB
2025-10-09 21:54:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58709412813187, 'train_avg_loss': 0.6798924510677655, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 21:54:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.0118408203125, 'train_avg_loss': 0.6521080017089844, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:54:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 313.0118408203125, 'train_avg_loss': 0.6521080017089844, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:54:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #10, planning to set LR to 1.00e-05
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:54:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:54:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:55:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:55:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.083282, avg_loss=0.673090, seen=480, correct=291, accuracy=0.606250
2025-10-09 21:55:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:55:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:55:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:55:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=10 reserved=2102MB allocated=1794MB
2025-10-09 21:55:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 10, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.89620369672775, 'train_avg_loss': 0.6908016974727312, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 21:55:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 10, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0832824707031, 'train_avg_loss': 0.6730901718139648, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 21:55:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 10, 'Results_raw': {'train_total': 480, 'train_loss': 323.0832824707031, 'train_avg_loss': 0.6730901718139648, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 21:55:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #11) -------------
2025-10-09 21:55:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=11 aidx=0 | s=3 (candidates=3)
2025-10-09 21:55:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 21:55:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:55:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:55:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:55:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:55:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.298523, avg_loss=0.642289, seen=480, correct=298, accuracy=0.620833
2025-10-09 21:55:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:55:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:55:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:55:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=2156MB allocated=1794MB
2025-10-09 21:55:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.58907896280289, 'train_avg_loss': 0.5632423246900241, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 21:55:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.29852294921875, 'train_avg_loss': 0.6422885894775391, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 21:55:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 308.29852294921875, 'train_avg_loss': 0.6422885894775391, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-09 21:55:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:55:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:55:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-09 21:55:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:55:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:55:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:55:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:55:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:55:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:56:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:56:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.341614, avg_loss=0.650712, seen=480, correct=302, accuracy=0.629167
2025-10-09 21:56:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:56:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:56:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:56:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=2128MB allocated=1794MB
2025-10-09 21:56:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51112282276154, 'train_avg_loss': 0.6792593568563461, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 21:56:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.34161376953125, 'train_avg_loss': 0.6507116953531901, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 21:56:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 312.34161376953125, 'train_avg_loss': 0.6507116953531901, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 21:56:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #11, planning to set LR to 1.00e-05
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:56:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:56:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:57:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:57:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.864807, avg_loss=0.662218, seen=480, correct=305, accuracy=0.635417
2025-10-09 21:57:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:57:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:57:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:57:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=11 reserved=2102MB allocated=1794MB
2025-10-09 21:57:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 11, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.8111914396286, 'train_avg_loss': 0.6817599286635717, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 21:57:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 11, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.86480712890625, 'train_avg_loss': 0.6622183481852214, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 21:57:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 11, 'Results_raw': {'train_total': 480, 'train_loss': 317.86480712890625, 'train_avg_loss': 0.6622183481852214, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 21:57:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #12) -------------
2025-10-09 21:57:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=12 aidx=0 | s=3 (candidates=3)
2025-10-09 21:57:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 21:57:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:57:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:57:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-09 21:57:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:57:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:57:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:57:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:57:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:57:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:57:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:57:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.985474, avg_loss=0.649970, seen=480, correct=299, accuracy=0.622917
2025-10-09 21:57:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:57:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:57:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:57:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=2166MB allocated=1794MB
2025-10-09 21:57:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3515152335167, 'train_avg_loss': 0.6779292936126391, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 21:57:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.9854736328125, 'train_avg_loss': 0.649969736735026, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 21:57:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 311.9854736328125, 'train_avg_loss': 0.649969736735026, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 21:57:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:57:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:57:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:58:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:58:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.884888, avg_loss=0.647677, seen=480, correct=315, accuracy=0.656250
2025-10-09 21:58:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:58:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:58:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:58:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=2102MB allocated=1794MB
2025-10-09 21:58:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.91449916362762, 'train_avg_loss': 0.6659541596968969, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 21:58:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8848876953125, 'train_avg_loss': 0.6476768493652344, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:58:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 310.8848876953125, 'train_avg_loss': 0.6476768493652344, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-09 21:58:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:58:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:58:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #12, planning to set LR to 1.00e-05
2025-10-09 21:58:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 21:58:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:58:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:58:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:58:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:58:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:59:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:59:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.338409, avg_loss=0.640288, seen=480, correct=288, accuracy=0.600000
2025-10-09 21:59:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:59:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:59:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:59:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=12 reserved=2154MB allocated=1794MB
2025-10-09 21:59:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 12, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 66.64774137735367, 'train_avg_loss': 0.5553978448112805, 'train_seen': 120, 'train_correct': 95, 'train_acc': 0.7916666666666666}}
2025-10-09 21:59:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 12, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.3384094238281, 'train_avg_loss': 0.6402883529663086, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 21:59:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 12, 'Results_raw': {'train_total': 480, 'train_loss': 307.3384094238281, 'train_avg_loss': 0.6402883529663086, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 21:59:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #13) -------------
2025-10-09 21:59:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=13 aidx=0 | s=3 (candidates=3)
2025-10-09 21:59:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 21:59:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 21:59:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:59:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 21:59:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 21:59:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.430603, avg_loss=0.646730, seen=480, correct=300, accuracy=0.625000
2025-10-09 21:59:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 21:59:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:59:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 21:59:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=2128MB allocated=1794MB
2025-10-09 21:59:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51490885019302, 'train_avg_loss': 0.6792909070849419, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 21:59:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.43060302734375, 'train_avg_loss': 0.6467304229736328, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:59:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 310.43060302734375, 'train_avg_loss': 0.6467304229736328, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 21:59:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 21:59:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 21:59:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-09 21:59:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 21:59:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 21:59:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 21:59:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 21:59:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 21:59:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:00:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:00:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.227966, avg_loss=0.648392, seen=480, correct=312, accuracy=0.650000
2025-10-09 22:00:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:00:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:00:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:00:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=2102MB allocated=1794MB
2025-10-09 22:00:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.1418896317482, 'train_avg_loss': 0.6678490802645684, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 22:00:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.22796630859375, 'train_avg_loss': 0.648391596476237, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 22:00:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 311.22796630859375, 'train_avg_loss': 0.648391596476237, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-09 22:00:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #13, planning to set LR to 1.00e-05
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 22:00:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:00:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:00:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:00:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.259674, avg_loss=0.615124, seen=480, correct=307, accuracy=0.639583
2025-10-09 22:00:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:00:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:01:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:01:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=13 reserved=2156MB allocated=1794MB
2025-10-09 22:01:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 13, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 61.59288287162781, 'train_avg_loss': 0.5132740239302317, 'train_seen': 120, 'train_correct': 100, 'train_acc': 0.8333333333333334}}
2025-10-09 22:01:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 13, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.2596740722656, 'train_avg_loss': 0.6151243209838867, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 22:01:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 13, 'Results_raw': {'train_total': 480, 'train_loss': 295.2596740722656, 'train_avg_loss': 0.6151243209838867, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 22:01:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #14) -------------
2025-10-09 22:01:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=14 aidx=0 | s=3 (candidates=3)
2025-10-09 22:01:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 22:01:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 22:01:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:01:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:01:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:01:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.833984, avg_loss=0.647571, seen=480, correct=296, accuracy=0.616667
2025-10-09 22:01:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:01:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:01:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=2128MB allocated=1794MB
2025-10-09 22:01:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.78102868795395, 'train_avg_loss': 0.6898419057329496, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 22:01:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.833984375, 'train_avg_loss': 0.64757080078125, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 22:01:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 310.833984375, 'train_avg_loss': 0.64757080078125, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 22:01:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 22:01:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:01:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:02:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:02:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.685913, avg_loss=0.651429, seen=480, correct=303, accuracy=0.631250
2025-10-09 22:02:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:02:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:02:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:02:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=2102MB allocated=1794MB
2025-10-09 22:02:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.92884594202042, 'train_avg_loss': 0.6744070495168368, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 22:02:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.6859130859375, 'train_avg_loss': 0.6514289855957032, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 22:02:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 312.6859130859375, 'train_avg_loss': 0.6514289855957032, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 22:02:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #14, planning to set LR to 1.00e-05
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 22:02:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:02:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:02:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:02:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=281.481232, avg_loss=0.586419, seen=480, correct=320, accuracy=0.666667
2025-10-09 22:02:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:02:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:03:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:03:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=14 reserved=2156MB allocated=1794MB
2025-10-09 22:03:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 14, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 55.6625372171402, 'train_avg_loss': 0.46385447680950165, 'train_seen': 120, 'train_correct': 99, 'train_acc': 0.825}}
2025-10-09 22:03:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 14, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 281.4812316894531, 'train_avg_loss': 0.5864192326863606, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-09 22:03:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 14, 'Results_raw': {'train_total': 480, 'train_loss': 281.4812316894531, 'train_avg_loss': 0.5864192326863606, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-09 22:03:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #15) -------------
2025-10-09 22:03:02 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=15 aidx=0 | s=3 (candidates=3)
2025-10-09 22:03:02 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 2, 8] (from 3)
2025-10-09 22:03:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 22:03:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:03:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:03:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:03:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.517212, avg_loss=0.651078, seen=480, correct=299, accuracy=0.622917
2025-10-09 22:03:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:03:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:03:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:03:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=2128MB allocated=1794MB
2025-10-09 22:03:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73923271894455, 'train_avg_loss': 0.6978269393245379, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 22:03:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.5172119140625, 'train_avg_loss': 0.6510775248209636, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 22:03:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 312.5172119140625, 'train_avg_loss': 0.6510775248209636, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 22:03:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 22:03:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:03:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:04:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:04:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=265.641907, avg_loss=0.553421, seen=480, correct=345, accuracy=0.718750
2025-10-09 22:04:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:04:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:04:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:04:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=2158MB allocated=1794MB
2025-10-09 22:04:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 49.19089776277542, 'train_avg_loss': 0.4099241480231285, 'train_seen': 120, 'train_correct': 102, 'train_acc': 0.85}}
2025-10-09 22:04:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 265.64190673828125, 'train_avg_loss': 0.5534206390380859, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 22:04:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 265.64190673828125, 'train_avg_loss': 0.5534206390380859, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 22:04:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:04:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:04:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #15, planning to set LR to 1.00e-05
2025-10-09 22:04:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 22:04:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:04:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:04:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:04:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:04:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:04:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:04:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.475037, avg_loss=0.655156, seen=480, correct=299, accuracy=0.622917
2025-10-09 22:04:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:04:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:04:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:04:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=15 reserved=2102MB allocated=1794MB
2025-10-09 22:04:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 15, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.03508114814758, 'train_avg_loss': 0.6752923429012299, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 22:04:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 15, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.47503662109375, 'train_avg_loss': 0.6551563262939453, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 22:04:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 15, 'Results_raw': {'train_total': 480, 'train_loss': 314.47503662109375, 'train_avg_loss': 0.6551563262939453, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 22:04:57 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #16) -------------
2025-10-09 22:04:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=16 aidx=0 | s=3 (candidates=3)
2025-10-09 22:04:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[8, 11, 2] (from 3)
2025-10-09 22:04:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 22:04:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:04:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:05:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:05:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.327637, avg_loss=0.631933, seen=480, correct=322, accuracy=0.670833
2025-10-09 22:05:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:05:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:05:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:05:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=2102MB allocated=1794MB
2025-10-09 22:05:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.77711009979248, 'train_avg_loss': 0.6481425841649373, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 22:05:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.32763671875, 'train_avg_loss': 0.6319325764973959, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 22:05:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 303.32763671875, 'train_avg_loss': 0.6319325764973959, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-09 22:05:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:05:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:05:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-09 22:05:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 22:05:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:05:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:05:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:05:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:05:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:06:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:06:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.692871, avg_loss=0.645193, seen=480, correct=300, accuracy=0.625000
2025-10-09 22:06:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:06:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:06:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:06:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=2128MB allocated=1794MB
2025-10-09 22:06:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.69966812431812, 'train_avg_loss': 0.6724972343693177, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 22:06:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.69287109375, 'train_avg_loss': 0.6451934814453125, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 22:06:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 309.69287109375, 'train_avg_loss': 0.6451934814453125, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 22:06:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:06:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:06:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #16, planning to set LR to 1.00e-05
2025-10-09 22:06:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 22:06:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:06:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:06:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:06:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:06:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:06:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:06:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=267.268585, avg_loss=0.556810, seen=480, correct=334, accuracy=0.695833
2025-10-09 22:06:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:06:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:06:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:06:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=16 reserved=2158MB allocated=1794MB
2025-10-09 22:06:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 16, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 49.542654275894165, 'train_avg_loss': 0.412855452299118, 'train_seen': 120, 'train_correct': 101, 'train_acc': 0.8416666666666667}}
2025-10-09 22:06:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 16, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 267.2685852050781, 'train_avg_loss': 0.5568095525105794, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 22:06:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 16, 'Results_raw': {'train_total': 480, 'train_loss': 267.2685852050781, 'train_avg_loss': 0.5568095525105794, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-09 22:06:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #17) -------------
2025-10-09 22:06:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=17 aidx=0 | s=3 (candidates=3)
2025-10-09 22:06:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[11, 8, 2] (from 3)
2025-10-09 22:06:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 22:06:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:06:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:07:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:07:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.400726, avg_loss=0.652918, seen=480, correct=296, accuracy=0.616667
2025-10-09 22:07:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:07:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:07:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:07:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=2128MB allocated=1794MB
2025-10-09 22:07:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.20344313979149, 'train_avg_loss': 0.693362026164929, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 22:07:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4007263183594, 'train_avg_loss': 0.6529181798299154, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 22:07:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 313.4007263183594, 'train_avg_loss': 0.6529181798299154, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 22:07:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 22:07:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:07:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:08:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:08:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.625122, avg_loss=0.640886, seen=480, correct=305, accuracy=0.635417
2025-10-09 22:08:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:08:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:08:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:08:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=2102MB allocated=1794MB
2025-10-09 22:08:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.54380449652672, 'train_avg_loss': 0.662865037471056, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:08:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.6251220703125, 'train_avg_loss': 0.6408856709798177, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 22:08:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 307.6251220703125, 'train_avg_loss': 0.6408856709798177, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 22:08:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #17, planning to set LR to 1.00e-05
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 22:08:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:08:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:08:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:08:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=250.474762, avg_loss=0.521822, seen=480, correct=357, accuracy=0.743750
2025-10-09 22:08:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:08:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:08:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:08:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=17 reserved=2158MB allocated=1794MB
2025-10-09 22:08:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 17, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 42.83199381828308, 'train_avg_loss': 0.35693328181902567, 'train_seen': 120, 'train_correct': 106, 'train_acc': 0.8833333333333333}}
2025-10-09 22:08:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 17, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 250.47476196289062, 'train_avg_loss': 0.5218224207560221, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-09 22:08:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 17, 'Results_raw': {'train_total': 480, 'train_loss': 250.47476196289062, 'train_avg_loss': 0.5218224207560221, 'train_seen': 480, 'train_correct': 357, 'train_acc': 0.74375}}
2025-10-09 22:08:47 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #18) -------------
2025-10-09 22:08:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=18 aidx=0 | s=3 (candidates=3)
2025-10-09 22:08:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[2, 11, 8] (from 3)
2025-10-09 22:08:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=214)
2025-10-09 22:08:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:08:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:09:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:09:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=236.825241, avg_loss=0.493386, seen=480, correct=358, accuracy=0.745833
2025-10-09 22:09:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:09:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:09:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:09:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=2156MB allocated=1794MB
2025-10-09 22:09:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #2', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 37.55860389769077, 'train_avg_loss': 0.3129883658140898, 'train_seen': 120, 'train_correct': 104, 'train_acc': 0.8666666666666667}}
2025-10-09 22:09:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #2', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 236.8252410888672, 'train_avg_loss': 0.49338591893514, 'train_seen': 480, 'train_correct': 358, 'train_acc': 0.7458333333333333}}
2025-10-09 22:09:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #2', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 236.8252410888672, 'train_avg_loss': 0.49338591893514, 'train_seen': 480, 'train_correct': 358, 'train_acc': 0.7458333333333333}}
2025-10-09 22:09:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=156, total=621)
2025-10-09 22:09:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:09:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=78, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:10:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:10:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.656219, avg_loss=0.659700, seen=480, correct=302, accuracy=0.629167
2025-10-09 22:10:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:10:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:10:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:10:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=2128MB allocated=1794MB
2025-10-09 22:10:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #11', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.59631188213825, 'train_avg_loss': 0.7133025990178188, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 22:10:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #11', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.6562194824219, 'train_avg_loss': 0.6597004572550456, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 22:10:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #11', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 316.6562194824219, 'train_avg_loss': 0.6597004572550456, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 22:10:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #18, planning to set LR to 1.00e-05
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=329, total=1316)
2025-10-09 22:10:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:10:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=165, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:10:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:10:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.746979, avg_loss=0.649473, seen=480, correct=306, accuracy=0.637500
2025-10-09 22:10:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:10:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:10:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:10:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=18 reserved=2102MB allocated=1794MB
2025-10-09 22:10:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #8', 'Round': 18, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09234061837196, 'train_avg_loss': 0.684102838486433, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 22:10:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #8', 'Round': 18, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.7469787597656, 'train_avg_loss': 0.6494728724161783, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 22:10:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #8', 'Round': 18, 'Results_raw': {'train_total': 480, 'train_loss': 311.7469787597656, 'train_avg_loss': 0.6494728724161783, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 22:10:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #19) -------------
2025-10-09 22:10:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=19 aidx=1 | s=5 (candidates=12)
2025-10-09 22:10:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[51, 36, 22, 28, 16] (from 12)
2025-10-09 22:10:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:10:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:10:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-09 22:10:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 22:10:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:10:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:10:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:10:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:10:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:11:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:11:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.417328, avg_loss=0.702953, seen=480, correct=259, accuracy=0.539583
2025-10-09 22:11:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:11:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:11:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:11:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2200MB allocated=1861MB
2025-10-09 22:11:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.02576237916946, 'train_avg_loss': 0.7085480198264122, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:11:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.4173278808594, 'train_avg_loss': 0.702952766418457, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 22:11:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 337.4173278808594, 'train_avg_loss': 0.702952766418457, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 22:11:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:11:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:11:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-09 22:11:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:11:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:11:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:11:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:11:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:11:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:12:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:12:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.633362, avg_loss=0.711736, seen=480, correct=242, accuracy=0.504167
2025-10-09 22:12:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:12:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:12:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:12:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2150MB allocated=1869MB
2025-10-09 22:12:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.19615453481674, 'train_avg_loss': 0.7266346211234729, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 22:12:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.63336181640625, 'train_avg_loss': 0.7117361704508464, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 22:12:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 341.63336181640625, 'train_avg_loss': 0.7117361704508464, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-09 22:12:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:12:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:12:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-09 22:12:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:12:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:12:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:12:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:12:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:12:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:12:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:12:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.770935, avg_loss=0.707856, seen=480, correct=252, accuracy=0.525000
2025-10-09 22:12:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:12:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:12:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:12:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2180MB allocated=1878MB
2025-10-09 22:12:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.31296920776367, 'train_avg_loss': 0.6859414100646972, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 22:12:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.77093505859375, 'train_avg_loss': 0.7078561147054037, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 22:12:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 339.77093505859375, 'train_avg_loss': 0.7078561147054037, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 22:12:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:12:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:12:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-09 22:12:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:12:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:12:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:12:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:12:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:12:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:13:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:13:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.190735, avg_loss=0.710814, seen=480, correct=241, accuracy=0.502083
2025-10-09 22:13:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:13:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:13:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:13:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2136MB allocated=1886MB
2025-10-09 22:13:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.0690605044365, 'train_avg_loss': 0.7089088375369708, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 22:13:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.19073486328125, 'train_avg_loss': 0.7108140309651693, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 22:13:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 341.19073486328125, 'train_avg_loss': 0.7108140309651693, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 22:13:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:13:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:13:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #19, planning to set LR to 1.00e-05
2025-10-09 22:13:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 22:13:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:13:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:13:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:13:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:13:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:13:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:13:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.144165, avg_loss=0.706550, seen=480, correct=243, accuracy=0.506250
2025-10-09 22:13:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:13:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:13:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:13:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=19 reserved=2196MB allocated=1895MB
2025-10-09 22:13:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 19, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.71610903739929, 'train_avg_loss': 0.6809675753116607, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:13:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 19, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.1441650390625, 'train_avg_loss': 0.7065503438313802, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 22:13:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 19, 'Results_raw': {'train_total': 480, 'train_loss': 339.1441650390625, 'train_avg_loss': 0.7065503438313802, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 22:13:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #20) -------------
2025-10-09 22:14:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=20 aidx=1 | s=5 (candidates=12)
2025-10-09 22:14:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 48, 15, 36, 50] (from 12)
2025-10-09 22:14:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:14:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:14:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-09 22:14:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 22:14:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:14:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:14:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:14:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:14:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:14:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:14:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.542969, avg_loss=0.692798, seen=480, correct=266, accuracy=0.554167
2025-10-09 22:14:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:14:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:14:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:14:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2250MB allocated=1962MB
2025-10-09 22:14:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.71559524536133, 'train_avg_loss': 0.7142966270446778, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:14:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.54296875, 'train_avg_loss': 0.6927978515625, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:14:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 332.54296875, 'train_avg_loss': 0.6927978515625, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:14:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:14:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:14:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:15:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:15:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.196106, avg_loss=0.714992, seen=480, correct=237, accuracy=0.493750
2025-10-09 22:15:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:15:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:15:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:15:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2208MB allocated=1970MB
2025-10-09 22:15:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.06944334506989, 'train_avg_loss': 0.7172453612089157, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:15:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.19610595703125, 'train_avg_loss': 0.7149918874104818, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 22:15:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 343.19610595703125, 'train_avg_loss': 0.7149918874104818, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-09 22:15:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:15:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:15:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:15:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:15:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.937897, avg_loss=0.693621, seen=480, correct=259, accuracy=0.539583
2025-10-09 22:15:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:15:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:15:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:15:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2194MB allocated=1979MB
2025-10-09 22:15:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.40181505680084, 'train_avg_loss': 0.7200151254733403, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:15:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.9378967285156, 'train_avg_loss': 0.6936206181844076, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 22:15:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 332.9378967285156, 'train_avg_loss': 0.6936206181844076, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-09 22:15:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:16:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:16:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:16:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:16:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.036316, avg_loss=0.689659, seen=480, correct=261, accuracy=0.543750
2025-10-09 22:16:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:16:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:16:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:16:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2170MB allocated=1920MB
2025-10-09 22:16:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.55501866340637, 'train_avg_loss': 0.6879584888617197, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 22:16:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.03631591796875, 'train_avg_loss': 0.6896589914957683, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:16:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 331.03631591796875, 'train_avg_loss': 0.6896589914957683, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:16:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #20, planning to set LR to 1.00e-05
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:16:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:16:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:17:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:17:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.717499, avg_loss=0.705661, seen=480, correct=253, accuracy=0.527083
2025-10-09 22:17:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:17:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:17:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:17:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=20 reserved=2196MB allocated=1987MB
2025-10-09 22:17:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 20, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.2184909582138, 'train_avg_loss': 0.726820757985115, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:17:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 20, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.7174987792969, 'train_avg_loss': 0.7056614557902018, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 22:17:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 20, 'Results_raw': {'train_total': 480, 'train_loss': 338.7174987792969, 'train_avg_loss': 0.7056614557902018, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 22:17:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #21) -------------
2025-10-09 22:17:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=21 aidx=1 | s=5 (candidates=12)
2025-10-09 22:17:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 6, 51, 16, 20] (from 12)
2025-10-09 22:17:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:17:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:17:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:17:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:17:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.105896, avg_loss=0.698137, seen=480, correct=235, accuracy=0.489583
2025-10-09 22:17:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:17:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:17:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:17:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2170MB allocated=1929MB
2025-10-09 22:17:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.57800781726837, 'train_avg_loss': 0.7048167318105698, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 22:17:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.10589599609375, 'train_avg_loss': 0.6981372833251953, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 22:17:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 335.10589599609375, 'train_avg_loss': 0.6981372833251953, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-09 22:17:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:17:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:17:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-09 22:17:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 22:17:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:17:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:17:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:17:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:17:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:18:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:18:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.901764, avg_loss=0.710212, seen=480, correct=246, accuracy=0.512500
2025-10-09 22:18:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:18:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:18:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:18:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2202MB allocated=1996MB
2025-10-09 22:18:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.68903481960297, 'train_avg_loss': 0.714075290163358, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 22:18:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.9017639160156, 'train_avg_loss': 0.7102120081583659, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 22:18:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 340.9017639160156, 'train_avg_loss': 0.7102120081583659, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-09 22:18:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 22:18:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:18:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:19:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:19:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.910767, avg_loss=0.691481, seen=480, correct=266, accuracy=0.554167
2025-10-09 22:19:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:19:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:19:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:19:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2208MB allocated=1937MB
2025-10-09 22:19:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.65141606330872, 'train_avg_loss': 0.6887618005275726, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 22:19:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.9107666015625, 'train_avg_loss': 0.6914807637532552, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:19:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 331.9107666015625, 'train_avg_loss': 0.6914807637532552, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:19:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 22:19:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:19:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:19:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:19:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.534515, avg_loss=0.694864, seen=480, correct=255, accuracy=0.531250
2025-10-09 22:19:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:19:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:19:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:19:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2202MB allocated=1937MB
2025-10-09 22:19:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.15839326381683, 'train_avg_loss': 0.6846532771984736, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:19:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5345153808594, 'train_avg_loss': 0.6948635737101237, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 22:19:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 333.5345153808594, 'train_avg_loss': 0.6948635737101237, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 22:19:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:19:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:19:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #21, planning to set LR to 1.00e-05
2025-10-09 22:19:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 22:19:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:19:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:19:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:19:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:19:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:20:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:20:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.866516, avg_loss=0.691389, seen=480, correct=257, accuracy=0.535417
2025-10-09 22:20:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:20:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:20:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:20:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=21 reserved=2202MB allocated=1937MB
2025-10-09 22:20:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 21, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.02379059791565, 'train_avg_loss': 0.7085315883159637, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:20:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 21, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.86651611328125, 'train_avg_loss': 0.6913885752360026, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 22:20:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 21, 'Results_raw': {'train_total': 480, 'train_loss': 331.86651611328125, 'train_avg_loss': 0.6913885752360026, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-09 22:20:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #22) -------------
2025-10-09 22:20:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=22 aidx=1 | s=5 (candidates=12)
2025-10-09 22:20:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 43, 50, 48, 40] (from 12)
2025-10-09 22:20:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:20:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:20:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:21:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:21:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.902222, avg_loss=0.693546, seen=480, correct=253, accuracy=0.527083
2025-10-09 22:21:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:21:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:21:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:21:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2112MB allocated=1878MB
2025-10-09 22:21:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.72936069965363, 'train_avg_loss': 0.6977446724971136, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 22:21:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.9022216796875, 'train_avg_loss': 0.6935462951660156, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 22:21:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 332.9022216796875, 'train_avg_loss': 0.6935462951660156, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 22:21:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 22:21:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:21:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:21:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:21:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.453796, avg_loss=0.684279, seen=480, correct=269, accuracy=0.560417
2025-10-09 22:21:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:21:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:21:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:21:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2208MB allocated=1945MB
2025-10-09 22:21:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.30416363477707, 'train_avg_loss': 0.7025346969564755, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:21:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.45379638671875, 'train_avg_loss': 0.6842787424723308, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 22:21:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 328.45379638671875, 'train_avg_loss': 0.6842787424723308, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 22:21:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:21:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:21:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:22:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:22:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.903625, avg_loss=0.695633, seen=480, correct=255, accuracy=0.531250
2025-10-09 22:22:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:22:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:22:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:22:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2108MB allocated=1887MB
2025-10-09 22:22:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.60604280233383, 'train_avg_loss': 0.7050503566861153, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 22:22:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.90362548828125, 'train_avg_loss': 0.6956325531005859, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 22:22:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 333.90362548828125, 'train_avg_loss': 0.6956325531005859, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-09 22:22:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:22:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:22:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:23:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:23:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.938690, avg_loss=0.704039, seen=480, correct=238, accuracy=0.495833
2025-10-09 22:23:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:23:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:23:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:23:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2118MB allocated=1887MB
2025-10-09 22:23:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.92902302742004, 'train_avg_loss': 0.716075191895167, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 22:23:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.9386901855469, 'train_avg_loss': 0.704038937886556, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 22:23:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 337.9386901855469, 'train_avg_loss': 0.704038937886556, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-09 22:23:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:23:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:23:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #22, planning to set LR to 1.00e-05
2025-10-09 22:23:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 22:23:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:23:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:23:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:23:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:23:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:23:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:23:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.069061, avg_loss=0.704311, seen=480, correct=236, accuracy=0.491667
2025-10-09 22:23:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:23:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:23:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:23:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=22 reserved=2138MB allocated=1954MB
2025-10-09 22:23:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 22, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.26952469348907, 'train_avg_loss': 0.7189127057790756, 'train_seen': 120, 'train_correct': 50, 'train_acc': 0.4166666666666667}}
2025-10-09 22:23:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 22, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.0690612792969, 'train_avg_loss': 0.7043105443318685, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 22:23:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 22, 'Results_raw': {'train_total': 480, 'train_loss': 338.0690612792969, 'train_avg_loss': 0.7043105443318685, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-09 22:23:46 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #23) -------------
2025-10-09 22:23:47 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=23 aidx=1 | s=5 (candidates=12)
2025-10-09 22:23:47 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 28, 15, 16, 48] (from 12)
2025-10-09 22:23:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:23:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:23:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-09 22:23:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:23:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:23:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:23:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:23:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:23:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:24:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:24:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.938812, avg_loss=0.689456, seen=480, correct=256, accuracy=0.533333
2025-10-09 22:24:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:24:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:24:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:24:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2170MB allocated=1954MB
2025-10-09 22:24:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.56327241659164, 'train_avg_loss': 0.6880272701382637, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:24:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9388122558594, 'train_avg_loss': 0.6894558588663737, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 22:24:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 330.9388122558594, 'train_avg_loss': 0.6894558588663737, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-09 22:24:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:24:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:24:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-09 22:24:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:24:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:24:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:24:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:24:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:24:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:25:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:25:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.658844, avg_loss=0.693039, seen=480, correct=243, accuracy=0.506250
2025-10-09 22:25:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:25:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:25:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:25:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2170MB allocated=1954MB
2025-10-09 22:25:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.23299407958984, 'train_avg_loss': 0.693608283996582, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 22:25:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.6588439941406, 'train_avg_loss': 0.6930392583211263, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 22:25:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 332.6588439941406, 'train_avg_loss': 0.6930392583211263, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 22:25:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:25:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:25:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:25:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:25:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.196381, avg_loss=0.689992, seen=480, correct=260, accuracy=0.541667
2025-10-09 22:25:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:25:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:25:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:25:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2170MB allocated=1954MB
2025-10-09 22:25:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.59096992015839, 'train_avg_loss': 0.7049247493346532, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 22:25:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1963806152344, 'train_avg_loss': 0.6899924596150716, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 22:25:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 331.1963806152344, 'train_avg_loss': 0.6899924596150716, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-09 22:25:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 22:25:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:25:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:26:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:26:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.896362, avg_loss=0.691451, seen=480, correct=261, accuracy=0.543750
2025-10-09 22:26:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:26:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:26:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:26:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2194MB allocated=1954MB
2025-10-09 22:26:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.67810916900635, 'train_avg_loss': 0.6723175764083862, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:26:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8963623046875, 'train_avg_loss': 0.6914507548014323, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:26:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 331.8963623046875, 'train_avg_loss': 0.6914507548014323, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:26:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:26:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:26:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #23, planning to set LR to 1.00e-05
2025-10-09 22:26:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:26:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:26:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:26:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:26:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:26:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:27:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:27:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.529388, avg_loss=0.701103, seen=480, correct=241, accuracy=0.502083
2025-10-09 22:27:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:27:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:27:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:27:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=23 reserved=2184MB allocated=1954MB
2025-10-09 22:27:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 23, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.34712636470795, 'train_avg_loss': 0.7112260530392329, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 22:27:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 23, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.5293884277344, 'train_avg_loss': 0.7011028925577799, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 22:27:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 23, 'Results_raw': {'train_total': 480, 'train_loss': 336.5293884277344, 'train_avg_loss': 0.7011028925577799, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-09 22:27:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #24) -------------
2025-10-09 22:27:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=24 aidx=1 | s=5 (candidates=12)
2025-10-09 22:27:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 22, 16, 40, 43] (from 12)
2025-10-09 22:27:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:27:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:27:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:27:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:27:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.726440, avg_loss=0.686930, seen=480, correct=252, accuracy=0.525000
2025-10-09 22:27:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:27:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:27:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:27:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2112MB allocated=1895MB
2025-10-09 22:27:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.22448617219925, 'train_avg_loss': 0.6852040514349937, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:27:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7264404296875, 'train_avg_loss': 0.6869300842285156, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 22:27:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 329.7264404296875, 'train_avg_loss': 0.6869300842285156, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 22:27:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:27:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:27:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-09 22:27:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:27:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:27:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:27:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:27:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:27:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:28:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:28:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.308685, avg_loss=0.690226, seen=480, correct=271, accuracy=0.564583
2025-10-09 22:28:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:28:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:28:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:28:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2116MB allocated=1895MB
2025-10-09 22:28:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45554304122925, 'train_avg_loss': 0.6787961920102438, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 22:28:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3086853027344, 'train_avg_loss': 0.69022642771403, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 22:28:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 331.3086853027344, 'train_avg_loss': 0.69022642771403, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 22:28:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 22:28:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:28:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:29:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:29:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.880371, avg_loss=0.691417, seen=480, correct=252, accuracy=0.525000
2025-10-09 22:29:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:29:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:29:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:29:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2134MB allocated=1895MB
2025-10-09 22:29:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.60493570566177, 'train_avg_loss': 0.6717077975471815, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 22:29:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.88037109375, 'train_avg_loss': 0.6914174397786458, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 22:29:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 331.88037109375, 'train_avg_loss': 0.6914174397786458, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-09 22:29:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 22:29:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:29:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:29:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:29:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.053406, avg_loss=0.695945, seen=480, correct=245, accuracy=0.510417
2025-10-09 22:29:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:29:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:29:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:29:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2108MB allocated=1895MB
2025-10-09 22:29:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.26172006130219, 'train_avg_loss': 0.7105143338441848, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-09 22:29:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.05340576171875, 'train_avg_loss': 0.6959445953369141, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 22:29:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 334.05340576171875, 'train_avg_loss': 0.6959445953369141, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-09 22:29:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:29:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:29:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #24, planning to set LR to 1.00e-05
2025-10-09 22:29:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 22:29:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:29:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:29:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:29:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:29:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:30:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:30:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.468689, avg_loss=0.684310, seen=480, correct=269, accuracy=0.560417
2025-10-09 22:30:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:30:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:30:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:30:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=24 reserved=2162MB allocated=1895MB
2025-10-09 22:30:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 24, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.6997400522232, 'train_avg_loss': 0.70583116710186, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 22:30:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 24, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.46868896484375, 'train_avg_loss': 0.6843097686767579, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 22:30:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 24, 'Results_raw': {'train_total': 480, 'train_loss': 328.46868896484375, 'train_avg_loss': 0.6843097686767579, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 22:30:23 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #25) -------------
2025-10-09 22:30:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=25 aidx=1 | s=5 (candidates=12)
2025-10-09 22:30:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 40, 36, 48, 15] (from 12)
2025-10-09 22:30:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:30:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:30:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:31:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:31:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.187561, avg_loss=0.687891, seen=480, correct=264, accuracy=0.550000
2025-10-09 22:31:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:31:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:31:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:31:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2116MB allocated=1895MB
2025-10-09 22:31:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.75425350666046, 'train_avg_loss': 0.6812854458888372, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 22:31:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.18756103515625, 'train_avg_loss': 0.6878907521565755, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 22:31:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 330.18756103515625, 'train_avg_loss': 0.6878907521565755, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 22:31:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:31:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:31:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-09 22:31:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 22:31:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:31:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:31:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:31:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:31:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:31:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:31:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.885681, avg_loss=0.695595, seen=480, correct=254, accuracy=0.529167
2025-10-09 22:31:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:31:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:31:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:31:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2108MB allocated=1895MB
2025-10-09 22:31:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.22550821304321, 'train_avg_loss': 0.7102125684420267, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-09 22:31:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.88568115234375, 'train_avg_loss': 0.6955951690673828, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 22:31:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 333.88568115234375, 'train_avg_loss': 0.6955951690673828, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-09 22:31:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:31:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:31:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-09 22:31:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:31:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:31:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:31:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:31:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:31:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:32:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:32:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.067871, avg_loss=0.683475, seen=480, correct=266, accuracy=0.554167
2025-10-09 22:32:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:32:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:32:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:32:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2114MB allocated=1895MB
2025-10-09 22:32:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36559844017029, 'train_avg_loss': 0.6780466536680857, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 22:32:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.06787109375, 'train_avg_loss': 0.6834747314453125, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:32:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 328.06787109375, 'train_avg_loss': 0.6834747314453125, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:32:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:32:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:32:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:32:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:32:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.017212, avg_loss=0.691703, seen=480, correct=251, accuracy=0.522917
2025-10-09 22:32:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:32:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:32:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:32:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2114MB allocated=1895MB
2025-10-09 22:32:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.78612959384918, 'train_avg_loss': 0.6982177466154098, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:32:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0172119140625, 'train_avg_loss': 0.6917025248209635, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 22:32:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 332.0172119140625, 'train_avg_loss': 0.6917025248209635, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 22:32:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #25, planning to set LR to 1.00e-05
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:32:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:32:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:33:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:33:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.268890, avg_loss=0.685977, seen=480, correct=262, accuracy=0.545833
2025-10-09 22:33:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:33:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:33:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:33:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=25 reserved=2108MB allocated=1895MB
2025-10-09 22:33:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 25, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.39852201938629, 'train_avg_loss': 0.7033210168282191, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 22:33:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 25, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2688903808594, 'train_avg_loss': 0.6859768549601237, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 22:33:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 25, 'Results_raw': {'train_total': 480, 'train_loss': 329.2688903808594, 'train_avg_loss': 0.6859768549601237, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 22:33:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #26) -------------
2025-10-09 22:33:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=26 aidx=1 | s=5 (candidates=12)
2025-10-09 22:33:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 6, 36, 22, 28] (from 12)
2025-10-09 22:33:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:33:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:33:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:34:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:34:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.059235, avg_loss=0.691790, seen=480, correct=248, accuracy=0.516667
2025-10-09 22:34:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:34:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:34:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:34:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2114MB allocated=1895MB
2025-10-09 22:34:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.49373304843903, 'train_avg_loss': 0.7041144420703253, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 22:34:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0592346191406, 'train_avg_loss': 0.6917900721232096, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 22:34:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 332.0592346191406, 'train_avg_loss': 0.6917900721232096, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 22:34:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 22:34:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:34:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:34:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:34:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.499603, avg_loss=0.692708, seen=480, correct=253, accuracy=0.527083
2025-10-09 22:34:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:34:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:34:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:34:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2120MB allocated=1895MB
2025-10-09 22:34:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.58791142702103, 'train_avg_loss': 0.6965659285585085, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 22:34:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.4996032714844, 'train_avg_loss': 0.6927075068155925, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 22:34:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 332.4996032714844, 'train_avg_loss': 0.6927075068155925, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-09 22:34:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:34:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:34:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:35:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:35:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.529541, avg_loss=0.686520, seen=480, correct=262, accuracy=0.545833
2025-10-09 22:35:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:35:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:35:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:35:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2112MB allocated=1895MB
2025-10-09 22:35:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.27497839927673, 'train_avg_loss': 0.6772914866606394, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 22:35:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.529541015625, 'train_avg_loss': 0.6865198771158855, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 22:35:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 329.529541015625, 'train_avg_loss': 0.6865198771158855, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-09 22:35:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:35:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:35:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:36:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:36:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.672882, avg_loss=0.686819, seen=480, correct=270, accuracy=0.562500
2025-10-09 22:36:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:36:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:36:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:36:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2116MB allocated=1895MB
2025-10-09 22:36:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.82636189460754, 'train_avg_loss': 0.6818863491217295, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:36:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6728820800781, 'train_avg_loss': 0.6868185043334961, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 22:36:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 329.6728820800781, 'train_avg_loss': 0.6868185043334961, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 22:36:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #26, planning to set LR to 1.00e-05
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:36:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:36:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:36:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:36:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.021332, avg_loss=0.687544, seen=480, correct=251, accuracy=0.522917
2025-10-09 22:36:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:36:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:36:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:36:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=26 reserved=2108MB allocated=1895MB
2025-10-09 22:36:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 26, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.76353943347931, 'train_avg_loss': 0.6896961619456609, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 22:36:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 26, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.0213317871094, 'train_avg_loss': 0.6875444412231445, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 22:36:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 26, 'Results_raw': {'train_total': 480, 'train_loss': 330.0213317871094, 'train_avg_loss': 0.6875444412231445, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 22:36:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #27) -------------
2025-10-09 22:36:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=27 aidx=1 | s=5 (candidates=12)
2025-10-09 22:36:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 50, 6, 28, 43] (from 12)
2025-10-09 22:36:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 22:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:36:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:37:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:37:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.342499, avg_loss=0.694464, seen=480, correct=251, accuracy=0.522917
2025-10-09 22:37:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:37:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:37:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:37:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2108MB allocated=1895MB
2025-10-09 22:37:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.22683262825012, 'train_avg_loss': 0.7102236052354177, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 22:37:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.3424987792969, 'train_avg_loss': 0.6944635391235352, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 22:37:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 333.3424987792969, 'train_avg_loss': 0.6944635391235352, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-09 22:37:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:37:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:37:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:38:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:38:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.370056, avg_loss=0.688271, seen=480, correct=271, accuracy=0.564583
2025-10-09 22:38:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:38:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:38:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:38:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2108MB allocated=1895MB
2025-10-09 22:38:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12215423583984, 'train_avg_loss': 0.701017951965332, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 22:38:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.37005615234375, 'train_avg_loss': 0.6882709503173828, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 22:38:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 330.37005615234375, 'train_avg_loss': 0.6882709503173828, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 22:38:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 22:38:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:38:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:38:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:38:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.776550, avg_loss=0.695368, seen=480, correct=249, accuracy=0.518750
2025-10-09 22:38:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:38:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:38:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:38:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2120MB allocated=1895MB
2025-10-09 22:38:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.38524973392487, 'train_avg_loss': 0.7032104144493739, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:38:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.77655029296875, 'train_avg_loss': 0.6953678131103516, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 22:38:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 333.77655029296875, 'train_avg_loss': 0.6953678131103516, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 22:38:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:38:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:38:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:39:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:39:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.471527, avg_loss=0.678066, seen=480, correct=273, accuracy=0.568750
2025-10-09 22:39:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:39:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:39:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:39:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2108MB allocated=1895MB
2025-10-09 22:39:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.47086155414581, 'train_avg_loss': 0.6789238462845485, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 22:39:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4715270996094, 'train_avg_loss': 0.6780656814575196, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 22:39:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 325.4715270996094, 'train_avg_loss': 0.6780656814575196, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 22:39:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #27, planning to set LR to 1.00e-05
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 22:39:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:39:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:40:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:40:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.638458, avg_loss=0.678413, seen=480, correct=279, accuracy=0.581250
2025-10-09 22:40:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:40:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:40:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:40:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=27 reserved=2162MB allocated=1895MB
2025-10-09 22:40:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 27, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.46336966753006, 'train_avg_loss': 0.6955280805627505, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:40:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 27, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6384582519531, 'train_avg_loss': 0.678413454691569, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 22:40:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 27, 'Results_raw': {'train_total': 480, 'train_loss': 325.6384582519531, 'train_avg_loss': 0.678413454691569, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 22:40:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #28) -------------
2025-10-09 22:40:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=28 aidx=1 | s=5 (candidates=12)
2025-10-09 22:40:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 15, 22, 48, 50] (from 12)
2025-10-09 22:40:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:40:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:40:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:40:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:40:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.631348, avg_loss=0.676315, seen=480, correct=275, accuracy=0.572917
2025-10-09 22:40:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:40:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:40:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:40:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2108MB allocated=1895MB
2025-10-09 22:40:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.80945551395416, 'train_avg_loss': 0.6817454626162847, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:40:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.63134765625, 'train_avg_loss': 0.6763153076171875, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 22:40:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 324.63134765625, 'train_avg_loss': 0.6763153076171875, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 22:40:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:40:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:40:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:41:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:41:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.353271, avg_loss=0.677819, seen=480, correct=264, accuracy=0.550000
2025-10-09 22:41:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:41:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:41:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:41:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2108MB allocated=1895MB
2025-10-09 22:41:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.53030389547348, 'train_avg_loss': 0.6960858657956124, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 22:41:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.353271484375, 'train_avg_loss': 0.6778193155924479, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 22:41:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 325.353271484375, 'train_avg_loss': 0.6778193155924479, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 22:41:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:41:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:41:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:42:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:42:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.335815, avg_loss=0.681950, seen=480, correct=269, accuracy=0.560417
2025-10-09 22:42:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:42:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:42:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:42:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2116MB allocated=1895MB
2025-10-09 22:42:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.12467086315155, 'train_avg_loss': 0.6760389238595963, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 22:42:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.3358154296875, 'train_avg_loss': 0.6819496154785156, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 22:42:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 327.3358154296875, 'train_avg_loss': 0.6819496154785156, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 22:42:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:42:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:42:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:42:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:42:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.820496, avg_loss=0.687126, seen=480, correct=249, accuracy=0.518750
2025-10-09 22:42:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:42:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:42:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:42:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2114MB allocated=1895MB
2025-10-09 22:42:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5200480222702, 'train_avg_loss': 0.6960004001855851, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 22:42:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.82049560546875, 'train_avg_loss': 0.6871260325113933, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 22:42:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 329.82049560546875, 'train_avg_loss': 0.6871260325113933, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-09 22:42:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #28, planning to set LR to 1.00e-05
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:42:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:42:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:43:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:43:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.765259, avg_loss=0.687011, seen=480, correct=275, accuracy=0.572917
2025-10-09 22:43:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:43:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:43:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:43:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=28 reserved=2108MB allocated=1895MB
2025-10-09 22:43:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 28, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.21770840883255, 'train_avg_loss': 0.7018142367402712, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 22:43:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 28, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7652587890625, 'train_avg_loss': 0.6870109558105468, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 22:43:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 28, 'Results_raw': {'train_total': 480, 'train_loss': 329.7652587890625, 'train_avg_loss': 0.6870109558105468, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 22:43:24 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #29) -------------
2025-10-09 22:43:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=29 aidx=1 | s=5 (candidates=12)
2025-10-09 22:43:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 28, 6, 15, 40] (from 12)
2025-10-09 22:43:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:43:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:43:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:44:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:44:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.942627, avg_loss=0.681130, seen=480, correct=267, accuracy=0.556250
2025-10-09 22:44:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:44:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:44:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:44:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2116MB allocated=1895MB
2025-10-09 22:44:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.15904515981674, 'train_avg_loss': 0.6763253763318062, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 22:44:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.942626953125, 'train_avg_loss': 0.6811304728190104, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:44:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 326.942626953125, 'train_avg_loss': 0.6811304728190104, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:44:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:44:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:44:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-09 22:44:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:44:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:44:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:44:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:44:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:44:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:44:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:44:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.322510, avg_loss=0.677755, seen=480, correct=263, accuracy=0.547917
2025-10-09 22:44:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:44:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:44:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:44:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2108MB allocated=1895MB
2025-10-09 22:44:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.73071503639221, 'train_avg_loss': 0.6810892919699351, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 22:44:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.322509765625, 'train_avg_loss': 0.6777552286783854, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 22:44:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 325.322509765625, 'train_avg_loss': 0.6777552286783854, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 22:44:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 22:44:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:44:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:45:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:45:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.841125, avg_loss=0.695502, seen=480, correct=248, accuracy=0.516667
2025-10-09 22:45:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:45:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:45:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:45:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2120MB allocated=1895MB
2025-10-09 22:45:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12830710411072, 'train_avg_loss': 0.7010692258675894, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 22:45:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.84112548828125, 'train_avg_loss': 0.6955023447672526, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 22:45:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 333.84112548828125, 'train_avg_loss': 0.6955023447672526, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-09 22:45:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:45:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:45:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:45:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:45:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.005524, avg_loss=0.677095, seen=480, correct=265, accuracy=0.552083
2025-10-09 22:45:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:45:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:46:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:46:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2108MB allocated=1895MB
2025-10-09 22:46:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.35828572511673, 'train_avg_loss': 0.6946523810426394, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 22:46:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0055236816406, 'train_avg_loss': 0.677094841003418, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 22:46:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 325.0055236816406, 'train_avg_loss': 0.677094841003418, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-09 22:46:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #29, planning to set LR to 1.00e-05
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 22:46:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:46:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:46:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:46:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.591522, avg_loss=0.694982, seen=480, correct=243, accuracy=0.506250
2025-10-09 22:46:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:46:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:46:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:46:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=29 reserved=2108MB allocated=1895MB
2025-10-09 22:46:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 29, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.09630477428436, 'train_avg_loss': 0.7091358731190364, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-09 22:46:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 29, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5915222167969, 'train_avg_loss': 0.6949823379516602, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 22:46:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 29, 'Results_raw': {'train_total': 480, 'train_loss': 333.5915222167969, 'train_avg_loss': 0.6949823379516602, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-09 22:46:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #30) -------------
2025-10-09 22:46:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=30 aidx=1 | s=5 (candidates=12)
2025-10-09 22:46:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 40, 48, 15, 36] (from 12)
2025-10-09 22:46:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:46:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:46:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-09 22:46:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 22:46:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:46:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:46:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:46:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:46:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:47:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:47:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.091553, avg_loss=0.675191, seen=480, correct=276, accuracy=0.575000
2025-10-09 22:47:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:47:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:47:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:47:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2108MB allocated=1895MB
2025-10-09 22:47:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.17463564872742, 'train_avg_loss': 0.6764552970727284, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 22:47:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.091552734375, 'train_avg_loss': 0.6751907348632813, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 22:47:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 324.091552734375, 'train_avg_loss': 0.6751907348632813, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 22:47:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 22:47:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:47:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:47:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:47:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.698792, avg_loss=0.688956, seen=480, correct=261, accuracy=0.543750
2025-10-09 22:47:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:47:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:47:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:47:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2108MB allocated=1895MB
2025-10-09 22:47:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.28967010974884, 'train_avg_loss': 0.7024139175812404, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 22:47:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.69879150390625, 'train_avg_loss': 0.688955815633138, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:47:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 330.69879150390625, 'train_avg_loss': 0.688955815633138, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:47:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:48:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:48:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:48:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:48:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.621582, avg_loss=0.682545, seen=480, correct=261, accuracy=0.543750
2025-10-09 22:48:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:48:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:48:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:48:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2114MB allocated=1895MB
2025-10-09 22:48:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.5970458984375, 'train_avg_loss': 0.6966420491536458, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:48:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.62158203125, 'train_avg_loss': 0.6825449625651042, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:48:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 327.62158203125, 'train_avg_loss': 0.6825449625651042, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:48:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:48:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:48:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:49:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:49:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.530273, avg_loss=0.680271, seen=480, correct=270, accuracy=0.562500
2025-10-09 22:49:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:49:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:49:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:49:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2108MB allocated=1895MB
2025-10-09 22:49:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.72795498371124, 'train_avg_loss': 0.6977329581975937, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:49:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.5302734375, 'train_avg_loss': 0.6802714029947917, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 22:49:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 326.5302734375, 'train_avg_loss': 0.6802714029947917, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 22:49:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #30, planning to set LR to 1.00e-05
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:49:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:49:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:49:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:49:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.619415, avg_loss=0.686707, seen=480, correct=261, accuracy=0.543750
2025-10-09 22:49:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:49:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:49:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:49:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=30 reserved=2112MB allocated=1895MB
2025-10-09 22:49:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 30, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.56780368089676, 'train_avg_loss': 0.6797316973408063, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 22:49:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 30, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6194152832031, 'train_avg_loss': 0.6867071151733398, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:49:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 30, 'Results_raw': {'train_total': 480, 'train_loss': 329.6194152832031, 'train_avg_loss': 0.6867071151733398, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-09 22:49:57 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #31) -------------
2025-10-09 22:49:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=31 aidx=1 | s=5 (candidates=12)
2025-10-09 22:49:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 51, 50, 48, 15] (from 12)
2025-10-09 22:49:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 22:49:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:49:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:50:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:50:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.806244, avg_loss=0.685013, seen=480, correct=266, accuracy=0.554167
2025-10-09 22:50:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:50:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:50:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:50:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2134MB allocated=1895MB
2025-10-09 22:50:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.67964941263199, 'train_avg_loss': 0.6639970784385999, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 22:50:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.8062438964844, 'train_avg_loss': 0.6850130081176757, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:50:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 328.8062438964844, 'train_avg_loss': 0.6850130081176757, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 22:50:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 22:50:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:50:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:51:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:51:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.985657, avg_loss=0.679137, seen=480, correct=271, accuracy=0.564583
2025-10-09 22:51:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:51:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:51:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:51:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2140MB allocated=1895MB
2025-10-09 22:51:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.17233681678772, 'train_avg_loss': 0.684769473473231, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 22:51:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.98565673828125, 'train_avg_loss': 0.6791367848714193, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 22:51:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 325.98565673828125, 'train_avg_loss': 0.6791367848714193, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 22:51:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:51:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:51:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:51:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:51:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.342834, avg_loss=0.681964, seen=480, correct=267, accuracy=0.556250
2025-10-09 22:51:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:51:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:51:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:51:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2108MB allocated=1895MB
2025-10-09 22:51:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.65773606300354, 'train_avg_loss': 0.6971478005250294, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 22:51:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.34283447265625, 'train_avg_loss': 0.6819642384847006, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:51:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 327.34283447265625, 'train_avg_loss': 0.6819642384847006, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:51:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:51:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:51:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:52:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:52:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.649261, avg_loss=0.682603, seen=480, correct=263, accuracy=0.547917
2025-10-09 22:52:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:52:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:52:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:52:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2114MB allocated=1895MB
2025-10-09 22:52:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3753154873848, 'train_avg_loss': 0.6947942957282066, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:52:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6492614746094, 'train_avg_loss': 0.6826026280721028, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 22:52:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 327.6492614746094, 'train_avg_loss': 0.6826026280721028, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 22:52:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #31, planning to set LR to 1.00e-05
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 22:52:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:52:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:53:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:53:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.020874, avg_loss=0.679210, seen=480, correct=267, accuracy=0.556250
2025-10-09 22:53:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:53:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:53:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:53:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=31 reserved=2108MB allocated=1895MB
2025-10-09 22:53:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 31, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.44828915596008, 'train_avg_loss': 0.6954024096330007, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-09 22:53:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 31, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.0208740234375, 'train_avg_loss': 0.6792101542154948, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:53:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 31, 'Results_raw': {'train_total': 480, 'train_loss': 326.0208740234375, 'train_avg_loss': 0.6792101542154948, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:53:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #32) -------------
2025-10-09 22:53:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=32 aidx=1 | s=5 (candidates=12)
2025-10-09 22:53:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 51, 43, 50, 48] (from 12)
2025-10-09 22:53:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 22:53:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:53:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:53:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:53:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.774170, avg_loss=0.680780, seen=480, correct=267, accuracy=0.556250
2025-10-09 22:53:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:53:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:53:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:53:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2134MB allocated=1895MB
2025-10-09 22:53:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.21528995037079, 'train_avg_loss': 0.6601274162530899, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 22:53:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.774169921875, 'train_avg_loss': 0.6807795206705729, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:53:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 326.774169921875, 'train_avg_loss': 0.6807795206705729, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:53:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 22:53:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:53:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:54:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:54:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.622284, avg_loss=0.678380, seen=480, correct=263, accuracy=0.547917
2025-10-09 22:54:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:54:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:54:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:54:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2144MB allocated=1895MB
2025-10-09 22:54:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.52017843723297, 'train_avg_loss': 0.6876681536436081, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-09 22:54:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.6222839355469, 'train_avg_loss': 0.6783797581990559, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 22:54:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 325.6222839355469, 'train_avg_loss': 0.6783797581990559, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-09 22:54:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:54:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:54:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-09 22:54:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 22:54:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:54:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:54:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:54:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:54:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:55:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:55:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.856964, avg_loss=0.666369, seen=480, correct=288, accuracy=0.600000
2025-10-09 22:55:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:55:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:55:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:55:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2162MB allocated=1895MB
2025-10-09 22:55:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.14938992261887, 'train_avg_loss': 0.6845782493551572, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:55:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.8569641113281, 'train_avg_loss': 0.6663686752319335, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 22:55:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 319.8569641113281, 'train_avg_loss': 0.6663686752319335, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 22:55:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:55:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:55:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:55:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:55:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.664368, avg_loss=0.680551, seen=480, correct=276, accuracy=0.575000
2025-10-09 22:55:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:55:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:55:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:55:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2108MB allocated=1895MB
2025-10-09 22:55:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.63234287500381, 'train_avg_loss': 0.6886028572916985, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 22:55:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.66436767578125, 'train_avg_loss': 0.6805507659912109, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 22:55:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 326.66436767578125, 'train_avg_loss': 0.6805507659912109, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 22:55:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #32, planning to set LR to 1.00e-05
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 22:55:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:55:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:56:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:56:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.127197, avg_loss=0.681515, seen=480, correct=267, accuracy=0.556250
2025-10-09 22:56:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:56:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:56:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:56:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=32 reserved=2114MB allocated=1895MB
2025-10-09 22:56:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 32, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.72166669368744, 'train_avg_loss': 0.6976805557807286, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:56:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 32, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.127197265625, 'train_avg_loss': 0.6815149943033855, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:56:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 32, 'Results_raw': {'train_total': 480, 'train_loss': 327.127197265625, 'train_avg_loss': 0.6815149943033855, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:56:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #33) -------------
2025-10-09 22:56:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=33 aidx=1 | s=5 (candidates=12)
2025-10-09 22:56:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 36, 20, 51, 6] (from 12)
2025-10-09 22:56:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:56:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:56:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-09 22:56:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 22:56:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:56:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:56:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:56:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:56:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:57:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:57:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.322205, avg_loss=0.677755, seen=480, correct=281, accuracy=0.585417
2025-10-09 22:57:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:57:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:57:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:57:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2116MB allocated=1895MB
2025-10-09 22:57:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.86946713924408, 'train_avg_loss': 0.6739122261603673, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:57:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.32220458984375, 'train_avg_loss': 0.6777545928955078, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 22:57:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 325.32220458984375, 'train_avg_loss': 0.6777545928955078, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 22:57:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 22:57:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:57:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:57:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:57:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.339233, avg_loss=0.679873, seen=480, correct=268, accuracy=0.558333
2025-10-09 22:57:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:57:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:57:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:57:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2112MB allocated=1895MB
2025-10-09 22:57:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.95874065160751, 'train_avg_loss': 0.6663228387633959, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:57:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.3392333984375, 'train_avg_loss': 0.6798734029134115, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 22:57:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 326.3392333984375, 'train_avg_loss': 0.6798734029134115, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 22:57:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:57:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:57:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-09 22:57:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 22:57:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:57:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:57:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:57:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:57:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:58:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:58:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.224121, avg_loss=0.671300, seen=480, correct=288, accuracy=0.600000
2025-10-09 22:58:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:58:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:58:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:58:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2134MB allocated=1895MB
2025-10-09 22:58:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.52894258499146, 'train_avg_loss': 0.6794078548749288, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 22:58:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.22412109375, 'train_avg_loss': 0.6713002522786459, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 22:58:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 322.22412109375, 'train_avg_loss': 0.6713002522786459, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 22:58:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 22:58:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:58:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:58:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:58:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.702301, avg_loss=0.678546, seen=480, correct=267, accuracy=0.556250
2025-10-09 22:58:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:58:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:58:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:58:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2140MB allocated=1895MB
2025-10-09 22:58:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.50140738487244, 'train_avg_loss': 0.6875117282072704, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 22:58:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7023010253906, 'train_avg_loss': 0.6785464604695638, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:58:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 325.7023010253906, 'train_avg_loss': 0.6785464604695638, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 22:58:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:58:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:58:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #33, planning to set LR to 1.00e-05
2025-10-09 22:58:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 22:58:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:59:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:59:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:59:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:59:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 22:59:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 22:59:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.211945, avg_loss=0.687942, seen=480, correct=264, accuracy=0.550000
2025-10-09 22:59:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 22:59:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:59:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 22:59:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=33 reserved=2120MB allocated=1895MB
2025-10-09 22:59:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 33, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.86793357133865, 'train_avg_loss': 0.6905661130944888, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 22:59:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 33, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.2119445800781, 'train_avg_loss': 0.6879415512084961, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 22:59:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 33, 'Results_raw': {'train_total': 480, 'train_loss': 330.2119445800781, 'train_avg_loss': 0.6879415512084961, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-09 22:59:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #34) -------------
2025-10-09 22:59:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=34 aidx=1 | s=5 (candidates=12)
2025-10-09 22:59:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 51, 22, 40, 16] (from 12)
2025-10-09 22:59:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 22:59:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 22:59:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:00:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:00:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.961182, avg_loss=0.679086, seen=480, correct=274, accuracy=0.570833
2025-10-09 23:00:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:00:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:00:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:00:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2108MB allocated=1895MB
2025-10-09 23:00:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.75033646821976, 'train_avg_loss': 0.697919470568498, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 23:00:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.961181640625, 'train_avg_loss': 0.6790857950846354, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:00:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 325.961181640625, 'train_avg_loss': 0.6790857950846354, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:00:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 23:00:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:00:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:00:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:00:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.987061, avg_loss=0.674973, seen=480, correct=277, accuracy=0.577083
2025-10-09 23:00:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:00:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:00:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:00:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2140MB allocated=1895MB
2025-10-09 23:00:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.56838321685791, 'train_avg_loss': 0.6797365268071492, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 23:00:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.987060546875, 'train_avg_loss': 0.6749730428059896, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 23:00:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 323.987060546875, 'train_avg_loss': 0.6749730428059896, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 23:00:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:00:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:00:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-09 23:00:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:01:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:01:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:01:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:01:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:01:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:01:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:01:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.157562, avg_loss=0.673245, seen=480, correct=284, accuracy=0.591667
2025-10-09 23:01:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:01:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:01:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:01:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2116MB allocated=1895MB
2025-10-09 23:01:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.21875441074371, 'train_avg_loss': 0.6768229534228642, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 23:01:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.1575622558594, 'train_avg_loss': 0.6732449213663737, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 23:01:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 323.1575622558594, 'train_avg_loss': 0.6732449213663737, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 23:01:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:01:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:01:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-09 23:01:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 23:01:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:01:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:01:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:01:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:01:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:02:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:02:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.719910, avg_loss=0.686916, seen=480, correct=267, accuracy=0.556250
2025-10-09 23:02:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:02:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:02:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:02:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2108MB allocated=1895MB
2025-10-09 23:02:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.97265815734863, 'train_avg_loss': 0.6997721513112386, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 23:02:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.71990966796875, 'train_avg_loss': 0.6869164784749349, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 23:02:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 329.71990966796875, 'train_avg_loss': 0.6869164784749349, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-09 23:02:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #34, planning to set LR to 1.00e-05
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:02:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:02:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:02:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:02:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.001770, avg_loss=0.681254, seen=480, correct=266, accuracy=0.554167
2025-10-09 23:02:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:02:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:02:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:02:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=34 reserved=2134MB allocated=1895MB
2025-10-09 23:02:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 34, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.71434915065765, 'train_avg_loss': 0.6642862429221471, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 23:02:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 34, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.00177001953125, 'train_avg_loss': 0.6812536875406902, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 23:02:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 34, 'Results_raw': {'train_total': 480, 'train_loss': 327.00177001953125, 'train_avg_loss': 0.6812536875406902, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-09 23:02:57 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #35) -------------
2025-10-09 23:02:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=35 aidx=1 | s=5 (candidates=12)
2025-10-09 23:02:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 16, 22, 43, 48] (from 12)
2025-10-09 23:02:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:02:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:02:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:03:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:03:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.976929, avg_loss=0.666619, seen=480, correct=281, accuracy=0.585417
2025-10-09 23:03:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:03:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:03:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:03:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2108MB allocated=1895MB
2025-10-09 23:03:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06281542778015, 'train_avg_loss': 0.6838567952315012, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:03:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.9769287109375, 'train_avg_loss': 0.6666186014811198, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 23:03:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 319.9769287109375, 'train_avg_loss': 0.6666186014811198, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 23:03:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:03:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:03:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-09 23:03:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:03:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:03:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:03:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:03:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:03:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:04:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:04:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.911530, avg_loss=0.674816, seen=480, correct=268, accuracy=0.558333
2025-10-09 23:04:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:04:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:04:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:04:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2134MB allocated=1895MB
2025-10-09 23:04:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.59799218177795, 'train_avg_loss': 0.654983268181483, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:04:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.9115295410156, 'train_avg_loss': 0.6748156865437825, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 23:04:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 323.9115295410156, 'train_avg_loss': 0.6748156865437825, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-09 23:04:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:04:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:04:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:04:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:04:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.593964, avg_loss=0.672071, seen=480, correct=288, accuracy=0.600000
2025-10-09 23:04:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:04:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:04:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:04:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2116MB allocated=1895MB
2025-10-09 23:04:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.85363209247589, 'train_avg_loss': 0.6821136007706324, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 23:04:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.5939636230469, 'train_avg_loss': 0.6720707575480144, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:04:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 322.5939636230469, 'train_avg_loss': 0.6720707575480144, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:04:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:04:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:04:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:05:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:05:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.009583, avg_loss=0.664603, seen=480, correct=285, accuracy=0.593750
2025-10-09 23:05:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:05:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:05:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:05:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2162MB allocated=1895MB
2025-10-09 23:05:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.94631785154343, 'train_avg_loss': 0.6828859820961952, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 23:05:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.00958251953125, 'train_avg_loss': 0.6646032969156901, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 23:05:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 319.00958251953125, 'train_avg_loss': 0.6646032969156901, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 23:05:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:05:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:05:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #35, planning to set LR to 1.00e-05
2025-10-09 23:05:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:05:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:05:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:05:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:05:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:05:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:06:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:06:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.099243, avg_loss=0.675207, seen=480, correct=275, accuracy=0.572917
2025-10-09 23:06:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:06:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:06:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:06:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=35 reserved=2114MB allocated=1895MB
2025-10-09 23:06:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 35, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.84751558303833, 'train_avg_loss': 0.690395963191986, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 23:06:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 35, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0992431640625, 'train_avg_loss': 0.6752067565917969, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:06:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 35, 'Results_raw': {'train_total': 480, 'train_loss': 324.0992431640625, 'train_avg_loss': 0.6752067565917969, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:06:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #36) -------------
2025-10-09 23:06:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=36 aidx=1 | s=5 (candidates=12)
2025-10-09 23:06:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 50, 6, 48, 51] (from 12)
2025-10-09 23:06:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:06:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:06:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:06:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:06:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.755310, avg_loss=0.670324, seen=480, correct=288, accuracy=0.600000
2025-10-09 23:06:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:06:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:06:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:06:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2116MB allocated=1895MB
2025-10-09 23:06:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.88205909729004, 'train_avg_loss': 0.6740171591440837, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:06:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.75531005859375, 'train_avg_loss': 0.6703235626220703, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:06:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 321.75531005859375, 'train_avg_loss': 0.6703235626220703, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:06:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:06:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:06:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-09 23:06:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 23:06:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:06:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:06:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:06:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:06:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:07:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:07:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.158112, avg_loss=0.679496, seen=480, correct=284, accuracy=0.591667
2025-10-09 23:07:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:07:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:07:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:07:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2108MB allocated=1895MB
2025-10-09 23:07:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.50885701179504, 'train_avg_loss': 0.6959071417649587, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 23:07:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1581115722656, 'train_avg_loss': 0.6794960657755534, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 23:07:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 326.1581115722656, 'train_avg_loss': 0.6794960657755534, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 23:07:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:07:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:07:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:08:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:08:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.017365, avg_loss=0.675036, seen=480, correct=275, accuracy=0.572917
2025-10-09 23:08:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:08:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:08:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:08:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2120MB allocated=1895MB
2025-10-09 23:08:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.99753224849701, 'train_avg_loss': 0.6749794354041417, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 23:08:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0173645019531, 'train_avg_loss': 0.6750361760457356, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:08:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 324.0173645019531, 'train_avg_loss': 0.6750361760457356, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:08:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:08:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:08:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:08:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:08:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.775146, avg_loss=0.659948, seen=480, correct=295, accuracy=0.614583
2025-10-09 23:08:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:08:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:08:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:08:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2114MB allocated=1895MB
2025-10-09 23:08:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.72915542125702, 'train_avg_loss': 0.6810762951771419, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:08:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.775146484375, 'train_avg_loss': 0.659948221842448, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 23:08:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 316.775146484375, 'train_avg_loss': 0.659948221842448, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 23:08:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #36, planning to set LR to 1.00e-05
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 23:08:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:08:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:09:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:09:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.807495, avg_loss=0.672516, seen=480, correct=274, accuracy=0.570833
2025-10-09 23:09:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:09:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:09:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:09:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=36 reserved=2140MB allocated=1895MB
2025-10-09 23:09:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 36, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.19219595193863, 'train_avg_loss': 0.6849349662661552, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 23:09:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 36, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.8074951171875, 'train_avg_loss': 0.6725156148274739, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:09:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 36, 'Results_raw': {'train_total': 480, 'train_loss': 322.8074951171875, 'train_avg_loss': 0.6725156148274739, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:09:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #37) -------------
2025-10-09 23:09:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=37 aidx=1 | s=5 (candidates=12)
2025-10-09 23:09:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 43, 15, 6, 28] (from 12)
2025-10-09 23:09:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:09:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:09:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:10:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:10:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.027710, avg_loss=0.664641, seen=480, correct=293, accuracy=0.610417
2025-10-09 23:10:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:10:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:10:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:10:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2116MB allocated=1895MB
2025-10-09 23:10:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.64401984214783, 'train_avg_loss': 0.6720334986845652, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:10:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0277099609375, 'train_avg_loss': 0.6646410624186198, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 23:10:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 319.0277099609375, 'train_avg_loss': 0.6646410624186198, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 23:10:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:10:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:10:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-09 23:10:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:10:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:10:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:10:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:10:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:10:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:10:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:10:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.644226, avg_loss=0.661759, seen=480, correct=299, accuracy=0.622917
2025-10-09 23:10:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:10:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:10:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:10:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2162MB allocated=1895MB
2025-10-09 23:10:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.75722855329514, 'train_avg_loss': 0.6813102379441262, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 23:10:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.64422607421875, 'train_avg_loss': 0.6617588043212891, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 23:10:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 317.64422607421875, 'train_avg_loss': 0.6617588043212891, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 23:10:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:10:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:10:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-09 23:10:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:10:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:10:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:10:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:10:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:10:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:11:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:11:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.158569, avg_loss=0.666997, seen=480, correct=279, accuracy=0.581250
2025-10-09 23:11:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:11:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:11:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:11:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2108MB allocated=1895MB
2025-10-09 23:11:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.81702107191086, 'train_avg_loss': 0.6901418422659238, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 23:11:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.1585693359375, 'train_avg_loss': 0.6669970194498698, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 23:11:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 320.1585693359375, 'train_avg_loss': 0.6669970194498698, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 23:11:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:11:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:11:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:12:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:12:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.382324, avg_loss=0.677880, seen=480, correct=276, accuracy=0.575000
2025-10-09 23:12:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:12:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:12:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:12:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2120MB allocated=1895MB
2025-10-09 23:12:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.46571016311646, 'train_avg_loss': 0.6788809180259705, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:12:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.38232421875, 'train_avg_loss': 0.6778798421223958, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:12:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 325.38232421875, 'train_avg_loss': 0.6778798421223958, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:12:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #37, planning to set LR to 1.00e-05
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 23:12:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:12:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:12:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:12:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.276581, avg_loss=0.663076, seen=480, correct=290, accuracy=0.604167
2025-10-09 23:12:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:12:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:12:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:12:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=37 reserved=2108MB allocated=1895MB
2025-10-09 23:12:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 37, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.92489475011826, 'train_avg_loss': 0.6660407895843188, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 23:12:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 37, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.2765808105469, 'train_avg_loss': 0.6630762100219727, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 23:12:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 37, 'Results_raw': {'train_total': 480, 'train_loss': 318.2765808105469, 'train_avg_loss': 0.6630762100219727, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 23:12:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #38) -------------
2025-10-09 23:12:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=38 aidx=1 | s=5 (candidates=12)
2025-10-09 23:12:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 36, 48, 6, 43] (from 12)
2025-10-09 23:12:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 23:12:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:12:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:13:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:13:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.726898, avg_loss=0.655681, seen=480, correct=294, accuracy=0.612500
2025-10-09 23:13:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:13:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:13:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:13:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2134MB allocated=1895MB
2025-10-09 23:13:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.22686207294464, 'train_avg_loss': 0.6768905172745386, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 23:13:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.7268981933594, 'train_avg_loss': 0.655681037902832, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 23:13:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 314.7268981933594, 'train_avg_loss': 0.655681037902832, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 23:13:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 23:13:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:13:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:14:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:14:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.577026, avg_loss=0.678285, seen=480, correct=271, accuracy=0.564583
2025-10-09 23:14:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:14:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:14:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:14:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2112MB allocated=1895MB
2025-10-09 23:14:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.23353439569473, 'train_avg_loss': 0.6519461199641228, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 23:14:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.5770263671875, 'train_avg_loss': 0.6782854715983073, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 23:14:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 325.5770263671875, 'train_avg_loss': 0.6782854715983073, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-09 23:14:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:14:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:14:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:14:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:14:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.442993, avg_loss=0.655090, seen=480, correct=297, accuracy=0.618750
2025-10-09 23:14:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:14:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:14:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:14:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2114MB allocated=1895MB
2025-10-09 23:14:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06754976511002, 'train_avg_loss': 0.6838962480425834, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 23:14:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.4429931640625, 'train_avg_loss': 0.6550895690917968, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 23:14:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 314.4429931640625, 'train_avg_loss': 0.6550895690917968, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 23:14:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:14:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:14:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:15:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:15:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.803650, avg_loss=0.678758, seen=480, correct=275, accuracy=0.572917
2025-10-09 23:15:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:15:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:15:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:15:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2120MB allocated=1895MB
2025-10-09 23:15:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.0290955901146, 'train_avg_loss': 0.6752424632509549, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:15:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.80364990234375, 'train_avg_loss': 0.6787576039632162, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:15:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 325.80364990234375, 'train_avg_loss': 0.6787576039632162, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:15:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #38, planning to set LR to 1.00e-05
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:15:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:15:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:15:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:15:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.519531, avg_loss=0.659416, seen=480, correct=302, accuracy=0.629167
2025-10-09 23:15:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:15:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:15:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:15:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=38 reserved=2162MB allocated=1895MB
2025-10-09 23:16:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 38, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.08361619710922, 'train_avg_loss': 0.6840301349759101, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 23:16:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 38, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.51953125, 'train_avg_loss': 0.6594156901041667, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 23:16:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 38, 'Results_raw': {'train_total': 480, 'train_loss': 316.51953125, 'train_avg_loss': 0.6594156901041667, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 23:16:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #39) -------------
2025-10-09 23:16:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=39 aidx=1 | s=5 (candidates=12)
2025-10-09 23:16:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 15, 50, 51, 48] (from 12)
2025-10-09 23:16:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:16:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:16:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-09 23:16:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 23:16:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:16:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:16:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:16:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:16:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:16:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:16:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.401123, avg_loss=0.650836, seen=480, correct=287, accuracy=0.597917
2025-10-09 23:16:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:16:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:16:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:16:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2134MB allocated=1895MB
2025-10-09 23:16:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.35307627916336, 'train_avg_loss': 0.6779423023263613, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 23:16:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.401123046875, 'train_avg_loss': 0.6508356730143229, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 23:16:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 312.401123046875, 'train_avg_loss': 0.6508356730143229, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-09 23:16:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:16:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:16:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:17:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:17:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.685974, avg_loss=0.666012, seen=480, correct=288, accuracy=0.600000
2025-10-09 23:17:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:17:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:17:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:17:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2108MB allocated=1895MB
2025-10-09 23:17:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.1565318107605, 'train_avg_loss': 0.6929710984230042, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 23:17:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.68597412109375, 'train_avg_loss': 0.6660124460856119, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:17:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 319.68597412109375, 'train_avg_loss': 0.6660124460856119, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:17:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 23:17:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:17:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:17:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:17:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.317688, avg_loss=0.679829, seen=480, correct=278, accuracy=0.579167
2025-10-09 23:17:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:17:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:17:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:17:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2108MB allocated=1895MB
2025-10-09 23:17:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.93914371728897, 'train_avg_loss': 0.6994928643107414, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 23:17:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.31768798828125, 'train_avg_loss': 0.6798285166422526, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 23:17:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 326.31768798828125, 'train_avg_loss': 0.6798285166422526, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 23:17:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 23:18:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:18:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:18:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:18:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.802490, avg_loss=0.662089, seen=480, correct=284, accuracy=0.591667
2025-10-09 23:18:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:18:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:18:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:18:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2144MB allocated=1895MB
2025-10-09 23:18:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.74288499355316, 'train_avg_loss': 0.6728573749462764, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 23:18:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.802490234375, 'train_avg_loss': 0.6620885213216146, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 23:18:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 317.802490234375, 'train_avg_loss': 0.6620885213216146, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-09 23:18:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #39, planning to set LR to 1.00e-05
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:18:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:18:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:19:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:19:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.058777, avg_loss=0.654289, seen=480, correct=297, accuracy=0.618750
2025-10-09 23:19:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:19:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:19:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:19:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=39 reserved=2114MB allocated=1895MB
2025-10-09 23:19:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 39, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.46994912624359, 'train_avg_loss': 0.68724957605203, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 23:19:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 39, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.05877685546875, 'train_avg_loss': 0.6542891184488933, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 23:19:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 39, 'Results_raw': {'train_total': 480, 'train_loss': 314.05877685546875, 'train_avg_loss': 0.6542891184488933, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 23:19:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #40) -------------
2025-10-09 23:19:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=40 aidx=1 | s=5 (candidates=12)
2025-10-09 23:19:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 50, 36, 28, 22] (from 12)
2025-10-09 23:19:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:19:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:19:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:19:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:19:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.395813, avg_loss=0.659158, seen=480, correct=291, accuracy=0.606250
2025-10-09 23:19:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:19:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:19:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:19:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2134MB allocated=1895MB
2025-10-09 23:19:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.06316727399826, 'train_avg_loss': 0.6255263939499855, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 23:19:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.39581298828125, 'train_avg_loss': 0.6591579437255859, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 23:19:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 316.39581298828125, 'train_avg_loss': 0.6591579437255859, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 23:19:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 23:19:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:19:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:20:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:20:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.076355, avg_loss=0.677242, seen=480, correct=288, accuracy=0.600000
2025-10-09 23:20:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:20:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:20:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:20:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2108MB allocated=1895MB
2025-10-09 23:20:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.85481238365173, 'train_avg_loss': 0.6987901031970978, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-09 23:20:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.07635498046875, 'train_avg_loss': 0.6772424062093099, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:20:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 325.07635498046875, 'train_avg_loss': 0.6772424062093099, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-09 23:20:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:20:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:20:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-09 23:20:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 23:20:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:20:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:20:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:20:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:20:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:21:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:21:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.165955, avg_loss=0.679512, seen=480, correct=270, accuracy=0.562500
2025-10-09 23:21:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:21:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:21:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:21:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2112MB allocated=1895MB
2025-10-09 23:21:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.34063827991486, 'train_avg_loss': 0.6445053189992904, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 23:21:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.16595458984375, 'train_avg_loss': 0.6795124053955078, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 23:21:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 326.16595458984375, 'train_avg_loss': 0.6795124053955078, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-09 23:21:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 23:21:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:21:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:21:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:21:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.532715, avg_loss=0.644860, seen=480, correct=305, accuracy=0.635417
2025-10-09 23:21:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:21:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:21:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:21:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2108MB allocated=1895MB
2025-10-09 23:21:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.4987969994545, 'train_avg_loss': 0.6458233083287875, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:21:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.53271484375, 'train_avg_loss': 0.6448598225911458, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:21:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 309.53271484375, 'train_avg_loss': 0.6448598225911458, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:21:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #40, planning to set LR to 1.00e-05
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:21:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:21:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:22:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:22:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.112793, avg_loss=0.660652, seen=480, correct=305, accuracy=0.635417
2025-10-09 23:22:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:22:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:22:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:22:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=40 reserved=2116MB allocated=1895MB
2025-10-09 23:22:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 40, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.04778146743774, 'train_avg_loss': 0.6670648455619812, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 23:22:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 40, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.11279296875, 'train_avg_loss': 0.6606516520182292, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:22:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 40, 'Results_raw': {'train_total': 480, 'train_loss': 317.11279296875, 'train_avg_loss': 0.6606516520182292, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:22:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #41) -------------
2025-10-09 23:22:30 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=41 aidx=1 | s=5 (candidates=12)
2025-10-09 23:22:30 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 48, 22, 43, 50] (from 12)
2025-10-09 23:22:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:22:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:22:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-09 23:22:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:22:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:22:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:22:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:22:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:22:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:23:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:23:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.315216, avg_loss=0.677740, seen=480, correct=276, accuracy=0.575000
2025-10-09 23:23:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:23:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:23:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:23:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2120MB allocated=1895MB
2025-10-09 23:23:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.2325753569603, 'train_avg_loss': 0.6686047946413358, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-09 23:23:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.3152160644531, 'train_avg_loss': 0.6777400334676107, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:23:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 325.3152160644531, 'train_avg_loss': 0.6777400334676107, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:23:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:23:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:23:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-09 23:23:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:23:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:23:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:23:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:23:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:23:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:23:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:23:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.360321, avg_loss=0.642417, seen=480, correct=299, accuracy=0.622917
2025-10-09 23:23:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:23:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:23:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:23:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2114MB allocated=1895MB
2025-10-09 23:23:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.02815645933151, 'train_avg_loss': 0.6835679704944293, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:23:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.3603210449219, 'train_avg_loss': 0.6424173355102539, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 23:23:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 308.3603210449219, 'train_avg_loss': 0.6424173355102539, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-09 23:23:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:23:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:23:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-09 23:23:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:23:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:23:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:23:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:23:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:23:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:24:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:24:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.864288, avg_loss=0.626801, seen=480, correct=318, accuracy=0.662500
2025-10-09 23:24:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:24:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:24:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:24:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2116MB allocated=1895MB
2025-10-09 23:24:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.77274560928345, 'train_avg_loss': 0.6397728800773621, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 23:24:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.8642883300781, 'train_avg_loss': 0.6268006006876627, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 23:24:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 300.8642883300781, 'train_avg_loss': 0.6268006006876627, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 23:24:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:24:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:24:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-09 23:24:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:24:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:24:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:24:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:24:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:24:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:25:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:25:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.799225, avg_loss=0.645415, seen=480, correct=305, accuracy=0.635417
2025-10-09 23:25:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:25:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:25:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:25:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2162MB allocated=1895MB
2025-10-09 23:25:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.83721995353699, 'train_avg_loss': 0.6736434996128082, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:25:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.7992248535156, 'train_avg_loss': 0.6454150517781575, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:25:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 309.7992248535156, 'train_avg_loss': 0.6454150517781575, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:25:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #41, planning to set LR to 1.00e-05
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 23:25:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:25:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:25:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:25:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.261658, avg_loss=0.679712, seen=480, correct=280, accuracy=0.583333
2025-10-09 23:25:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:25:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:25:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:25:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=41 reserved=2108MB allocated=1895MB
2025-10-09 23:25:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 41, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6747362613678, 'train_avg_loss': 0.6972894688447316, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 23:25:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 41, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.26165771484375, 'train_avg_loss': 0.6797117869059245, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 23:25:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 41, 'Results_raw': {'train_total': 480, 'train_loss': 326.26165771484375, 'train_avg_loss': 0.6797117869059245, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 23:25:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #42) -------------
2025-10-09 23:25:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=42 aidx=1 | s=5 (candidates=12)
2025-10-09 23:25:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 36, 15, 20, 50] (from 12)
2025-10-09 23:25:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:25:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:25:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:26:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:26:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.409790, avg_loss=0.677937, seen=480, correct=274, accuracy=0.570833
2025-10-09 23:26:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:26:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:26:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:26:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2120MB allocated=1895MB
2025-10-09 23:26:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.09528487920761, 'train_avg_loss': 0.6674607073267301, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 23:26:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.4097900390625, 'train_avg_loss': 0.6779370625813802, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:26:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 325.4097900390625, 'train_avg_loss': 0.6779370625813802, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:26:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:26:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:26:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-09 23:26:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 23:26:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:26:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:26:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:26:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:26:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:27:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:27:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.405701, avg_loss=0.673762, seen=480, correct=273, accuracy=0.568750
2025-10-09 23:27:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:27:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:27:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:27:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2112MB allocated=1895MB
2025-10-09 23:27:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.56411668658257, 'train_avg_loss': 0.6380343057215214, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:27:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.40570068359375, 'train_avg_loss': 0.6737618764241536, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 23:27:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 323.40570068359375, 'train_avg_loss': 0.6737618764241536, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 23:27:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:27:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:27:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:27:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:27:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.890198, avg_loss=0.662271, seen=480, correct=285, accuracy=0.593750
2025-10-09 23:27:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:27:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:27:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:27:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2108MB allocated=1895MB
2025-10-09 23:27:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.93291771411896, 'train_avg_loss': 0.6827743142843247, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 23:27:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.89019775390625, 'train_avg_loss': 0.662271245320638, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 23:27:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 317.89019775390625, 'train_avg_loss': 0.662271245320638, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-09 23:27:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:27:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:27:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-09 23:27:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 23:27:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:27:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:27:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:27:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:27:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:28:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:28:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.539185, avg_loss=0.649040, seen=480, correct=304, accuracy=0.633333
2025-10-09 23:28:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:28:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:28:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:28:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2134MB allocated=1895MB
2025-10-09 23:28:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.00116437673569, 'train_avg_loss': 0.6666763698061308, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:28:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.5391845703125, 'train_avg_loss': 0.6490399678548177, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 23:28:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 311.5391845703125, 'train_avg_loss': 0.6490399678548177, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-09 23:28:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #42, planning to set LR to 1.00e-05
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 23:28:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:28:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:28:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:28:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.935638, avg_loss=0.666533, seen=480, correct=277, accuracy=0.577083
2025-10-09 23:28:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:28:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:28:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:28:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=42 reserved=2108MB allocated=1895MB
2025-10-09 23:28:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 42, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.84861147403717, 'train_avg_loss': 0.6904050956169764, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 23:28:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 42, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.9356384277344, 'train_avg_loss': 0.6665325800577799, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 23:28:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 42, 'Results_raw': {'train_total': 480, 'train_loss': 319.9356384277344, 'train_avg_loss': 0.6665325800577799, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-09 23:28:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #43) -------------
2025-10-09 23:28:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=43 aidx=1 | s=5 (candidates=12)
2025-10-09 23:28:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 43, 48, 28, 20] (from 12)
2025-10-09 23:29:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:29:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:29:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-09 23:29:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:29:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:29:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:29:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:29:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:29:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:29:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:29:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.753815, avg_loss=0.678654, seen=480, correct=275, accuracy=0.572917
2025-10-09 23:29:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:29:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:29:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:29:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2120MB allocated=1895MB
2025-10-09 23:29:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.96824580430984, 'train_avg_loss': 0.6664020483692487, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 23:29:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7538146972656, 'train_avg_loss': 0.6786537806193034, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:29:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 325.7538146972656, 'train_avg_loss': 0.6786537806193034, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-09 23:29:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:29:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:29:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:30:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:30:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.910767, avg_loss=0.641481, seen=480, correct=310, accuracy=0.645833
2025-10-09 23:30:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:30:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:30:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:30:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2162MB allocated=1895MB
2025-10-09 23:30:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.7236196398735, 'train_avg_loss': 0.6560301636656125, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 23:30:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.9107666015625, 'train_avg_loss': 0.6414807637532552, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 23:30:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 307.9107666015625, 'train_avg_loss': 0.6414807637532552, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-09 23:30:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:30:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:30:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-09 23:30:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:30:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:30:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:30:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:30:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:30:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:30:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:30:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.963715, avg_loss=0.641591, seen=480, correct=309, accuracy=0.643750
2025-10-09 23:30:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:30:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:30:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:30:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2114MB allocated=1895MB
2025-10-09 23:30:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.16831088066101, 'train_avg_loss': 0.6764025906721751, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 23:30:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.9637145996094, 'train_avg_loss': 0.6415910720825195, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 23:30:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 307.9637145996094, 'train_avg_loss': 0.6415910720825195, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 23:30:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 23:30:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:30:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:31:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:31:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.441498, avg_loss=0.646753, seen=480, correct=305, accuracy=0.635417
2025-10-09 23:31:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:31:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:31:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:31:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2108MB allocated=1895MB
2025-10-09 23:31:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.76799023151398, 'train_avg_loss': 0.6480665852626165, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 23:31:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.4414978027344, 'train_avg_loss': 0.6467531204223633, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:31:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 310.4414978027344, 'train_avg_loss': 0.6467531204223633, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:31:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #43, planning to set LR to 1.00e-05
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 23:31:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:31:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:32:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:32:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.440338, avg_loss=0.646751, seen=480, correct=303, accuracy=0.631250
2025-10-09 23:32:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:32:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:32:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:32:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=43 reserved=2134MB allocated=1895MB
2025-10-09 23:32:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 43, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.95168596506119, 'train_avg_loss': 0.6745973830421765, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:32:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 43, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.4403381347656, 'train_avg_loss': 0.6467507044474284, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 23:32:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 43, 'Results_raw': {'train_total': 480, 'train_loss': 310.4403381347656, 'train_avg_loss': 0.6467507044474284, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-09 23:32:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #44) -------------
2025-10-09 23:32:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=44 aidx=1 | s=5 (candidates=12)
2025-10-09 23:32:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 43, 51, 36, 22] (from 12)
2025-10-09 23:32:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:32:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:32:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-09 23:32:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 23:32:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:32:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:32:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:32:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:32:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:32:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:32:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.731232, avg_loss=0.682773, seen=480, correct=274, accuracy=0.570833
2025-10-09 23:32:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:32:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:32:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:32:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2108MB allocated=1895MB
2025-10-09 23:32:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.52029579877853, 'train_avg_loss': 0.7126691316564878, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:32:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.7312316894531, 'train_avg_loss': 0.6827733993530274, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:32:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 327.7312316894531, 'train_avg_loss': 0.6827733993530274, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:32:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:32:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:32:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:33:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:33:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.991760, avg_loss=0.631233, seen=480, correct=306, accuracy=0.637500
2025-10-09 23:33:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:33:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:33:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:33:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2162MB allocated=1895MB
2025-10-09 23:33:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.34752559661865, 'train_avg_loss': 0.6612293799718221, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 23:33:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.99176025390625, 'train_avg_loss': 0.6312328338623047, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 23:33:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 302.99176025390625, 'train_avg_loss': 0.6312328338623047, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 23:33:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 23:33:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:33:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:34:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:34:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.844635, avg_loss=0.662176, seen=480, correct=274, accuracy=0.570833
2025-10-09 23:34:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:34:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:34:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:34:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2140MB allocated=1895MB
2025-10-09 23:34:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0566474199295, 'train_avg_loss': 0.6838053951660792, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-09 23:34:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8446350097656, 'train_avg_loss': 0.6621763229370117, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:34:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 317.8446350097656, 'train_avg_loss': 0.6621763229370117, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-09 23:34:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 23:34:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:34:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:34:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:34:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.568512, avg_loss=0.682434, seen=480, correct=276, accuracy=0.575000
2025-10-09 23:34:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:34:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:34:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:34:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2112MB allocated=1895MB
2025-10-09 23:34:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.88110291957855, 'train_avg_loss': 0.6406758576631546, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 23:34:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.5685119628906, 'train_avg_loss': 0.6824343999226888, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:34:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 327.5685119628906, 'train_avg_loss': 0.6824343999226888, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:34:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:34:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:34:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #44, planning to set LR to 1.00e-05
2025-10-09 23:34:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:34:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:34:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:34:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:34:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:34:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:35:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:35:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.101685, avg_loss=0.627295, seen=480, correct=326, accuracy=0.679167
2025-10-09 23:35:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:35:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:35:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:35:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=44 reserved=2116MB allocated=1895MB
2025-10-09 23:35:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 44, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.00366002321243, 'train_avg_loss': 0.6500305001934369, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 23:35:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 44, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.1016845703125, 'train_avg_loss': 0.627295176188151, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 23:35:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 44, 'Results_raw': {'train_total': 480, 'train_loss': 301.1016845703125, 'train_avg_loss': 0.627295176188151, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-09 23:35:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #45) -------------
2025-10-09 23:35:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=45 aidx=1 | s=5 (candidates=12)
2025-10-09 23:35:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 40, 28, 20, 48] (from 12)
2025-10-09 23:35:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:35:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:35:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:36:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:36:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.678772, avg_loss=0.668081, seen=480, correct=283, accuracy=0.589583
2025-10-09 23:36:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:36:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:36:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:36:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2108MB allocated=1895MB
2025-10-09 23:36:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.24153190851212, 'train_avg_loss': 0.7020127659042676, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-09 23:36:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.67877197265625, 'train_avg_loss': 0.6680807749430339, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 23:36:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 320.67877197265625, 'train_avg_loss': 0.6680807749430339, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 23:36:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:36:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:36:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-09 23:36:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 23:36:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:36:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:36:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:36:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:36:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:36:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:36:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.001770, avg_loss=0.685420, seen=480, correct=279, accuracy=0.581250
2025-10-09 23:36:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:36:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:36:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:36:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2108MB allocated=1895MB
2025-10-09 23:36:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.42323875427246, 'train_avg_loss': 0.7118603229522705, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 23:36:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.00177001953125, 'train_avg_loss': 0.6854203542073568, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 23:36:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 329.00177001953125, 'train_avg_loss': 0.6854203542073568, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 23:36:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 23:36:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:36:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:37:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:37:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.961212, avg_loss=0.649919, seen=480, correct=293, accuracy=0.610417
2025-10-09 23:37:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:37:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:37:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:37:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2108MB allocated=1895MB
2025-10-09 23:37:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.65385821461678, 'train_avg_loss': 0.6471154851218065, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 23:37:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.9612121582031, 'train_avg_loss': 0.6499191919962565, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 23:37:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 311.9612121582031, 'train_avg_loss': 0.6499191919962565, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 23:37:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 23:37:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:37:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:38:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:38:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.629669, avg_loss=0.632562, seen=480, correct=302, accuracy=0.629167
2025-10-09 23:38:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:38:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:38:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:38:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2134MB allocated=1895MB
2025-10-09 23:38:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.20043605566025, 'train_avg_loss': 0.6516703004638355, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:38:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.6296691894531, 'train_avg_loss': 0.6325618108113606, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 23:38:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 303.6296691894531, 'train_avg_loss': 0.6325618108113606, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-09 23:38:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #45, planning to set LR to 1.00e-05
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:38:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:38:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:38:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:38:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.892792, avg_loss=0.637277, seen=480, correct=300, accuracy=0.625000
2025-10-09 23:38:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:38:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:38:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:38:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=45 reserved=2114MB allocated=1895MB
2025-10-09 23:38:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 45, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26414889097214, 'train_avg_loss': 0.7022012407581012, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:38:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 45, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.8927917480469, 'train_avg_loss': 0.6372766494750977, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 23:38:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 45, 'Results_raw': {'train_total': 480, 'train_loss': 305.8927917480469, 'train_avg_loss': 0.6372766494750977, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-09 23:38:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #46) -------------
2025-10-09 23:38:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=46 aidx=1 | s=5 (candidates=12)
2025-10-09 23:38:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 22, 43, 50, 15] (from 12)
2025-10-09 23:38:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 23:38:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:38:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:39:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:39:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.216553, avg_loss=0.679618, seen=480, correct=269, accuracy=0.560417
2025-10-09 23:39:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:39:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:39:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:39:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2112MB allocated=1895MB
2025-10-09 23:39:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.47267872095108, 'train_avg_loss': 0.628938989341259, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 23:39:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.216552734375, 'train_avg_loss': 0.6796178181966146, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 23:39:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 326.216552734375, 'train_avg_loss': 0.6796178181966146, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-09 23:39:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:39:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:39:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:39:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:39:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.452301, avg_loss=0.590526, seen=480, correct=337, accuracy=0.702083
2025-10-09 23:39:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:39:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:39:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:39:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2116MB allocated=1895MB
2025-10-09 23:39:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.1733974814415, 'train_avg_loss': 0.6181116456786792, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-09 23:39:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.4523010253906, 'train_avg_loss': 0.5905256271362305, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-09 23:39:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 283.4523010253906, 'train_avg_loss': 0.5905256271362305, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-09 23:39:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:40:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:40:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:40:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:40:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.681335, avg_loss=0.636836, seen=480, correct=307, accuracy=0.639583
2025-10-09 23:40:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:40:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:40:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:40:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2162MB allocated=1895MB
2025-10-09 23:40:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.73198181390762, 'train_avg_loss': 0.6644331817825635, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 23:40:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.68133544921875, 'train_avg_loss': 0.6368361155192057, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 23:40:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 305.68133544921875, 'train_avg_loss': 0.6368361155192057, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 23:40:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-09 23:40:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:40:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:41:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:41:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.162659, avg_loss=0.658672, seen=480, correct=294, accuracy=0.612500
2025-10-09 23:41:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:41:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:41:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:41:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2108MB allocated=1895MB
2025-10-09 23:41:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.41306674480438, 'train_avg_loss': 0.6784422228733699, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:41:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.16265869140625, 'train_avg_loss': 0.6586722056070964, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 23:41:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 316.16265869140625, 'train_avg_loss': 0.6586722056070964, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-09 23:41:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #46, planning to set LR to 1.00e-05
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:41:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:41:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:41:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:41:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.472412, avg_loss=0.667651, seen=480, correct=291, accuracy=0.606250
2025-10-09 23:41:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:41:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:41:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:41:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=46 reserved=2108MB allocated=1895MB
2025-10-09 23:41:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 46, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.38129913806915, 'train_avg_loss': 0.6948441594839097, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-09 23:41:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 46, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.472412109375, 'train_avg_loss': 0.6676508585611979, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 23:41:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 46, 'Results_raw': {'train_total': 480, 'train_loss': 320.472412109375, 'train_avg_loss': 0.6676508585611979, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-09 23:41:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #47) -------------
2025-10-09 23:41:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=47 aidx=1 | s=5 (candidates=12)
2025-10-09 23:41:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 20, 43, 40, 28] (from 12)
2025-10-09 23:41:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:41:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:41:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-09 23:41:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:41:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:41:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:41:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:41:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:41:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:42:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:42:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.568237, avg_loss=0.657434, seen=480, correct=292, accuracy=0.608333
2025-10-09 23:42:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:42:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:42:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:42:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2108MB allocated=1895MB
2025-10-09 23:42:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.2777589559555, 'train_avg_loss': 0.6773146579662959, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:42:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.5682373046875, 'train_avg_loss': 0.657433827718099, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 23:42:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 315.5682373046875, 'train_avg_loss': 0.657433827718099, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-09 23:42:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-09 23:42:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:42:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:43:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:43:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.425781, avg_loss=0.634220, seen=480, correct=308, accuracy=0.641667
2025-10-09 23:43:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:43:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:43:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:43:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2134MB allocated=1895MB
2025-10-09 23:43:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.84470331668854, 'train_avg_loss': 0.6570391943057378, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 23:43:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.42578125, 'train_avg_loss': 0.6342203776041667, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 23:43:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 304.42578125, 'train_avg_loss': 0.6342203776041667, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-09 23:43:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:43:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:43:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-09 23:43:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:43:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:43:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:43:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:43:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:43:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:43:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:43:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.077942, avg_loss=0.635579, seen=480, correct=307, accuracy=0.639583
2025-10-09 23:43:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:43:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:43:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:43:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2162MB allocated=1895MB
2025-10-09 23:43:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.64182394742966, 'train_avg_loss': 0.6553485328952472, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:43:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.07794189453125, 'train_avg_loss': 0.6355790456136068, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 23:43:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 305.07794189453125, 'train_avg_loss': 0.6355790456136068, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-09 23:43:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 23:43:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:43:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:44:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:44:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.491760, avg_loss=0.680191, seen=480, correct=279, accuracy=0.581250
2025-10-09 23:44:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:44:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:44:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:44:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2108MB allocated=1895MB
2025-10-09 23:44:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9282814860344, 'train_avg_loss': 0.6994023457169533, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-09 23:44:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.49176025390625, 'train_avg_loss': 0.680191167195638, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 23:44:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 326.49176025390625, 'train_avg_loss': 0.680191167195638, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-09 23:44:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #47, planning to set LR to 1.00e-05
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 23:44:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:44:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:45:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:45:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.830811, avg_loss=0.645481, seen=480, correct=305, accuracy=0.635417
2025-10-09 23:45:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:45:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:45:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:45:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=47 reserved=2108MB allocated=1895MB
2025-10-09 23:45:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 47, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.95140051841736, 'train_avg_loss': 0.6412616709868113, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 23:45:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 47, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.830810546875, 'train_avg_loss': 0.6454808553059895, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:45:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 47, 'Results_raw': {'train_total': 480, 'train_loss': 309.830810546875, 'train_avg_loss': 0.6454808553059895, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-09 23:45:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #48) -------------
2025-10-09 23:45:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=48 aidx=1 | s=5 (candidates=12)
2025-10-09 23:45:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 15, 22, 43] (from 12)
2025-10-09 23:45:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:45:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:45:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:45:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:45:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.455475, avg_loss=0.621782, seen=480, correct=318, accuracy=0.662500
2025-10-09 23:45:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:45:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:45:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:45:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2114MB allocated=1895MB
2025-10-09 23:45:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.16393837332726, 'train_avg_loss': 0.6846994864443938, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-09 23:45:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.4554748535156, 'train_avg_loss': 0.6217822392781576, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 23:45:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 298.4554748535156, 'train_avg_loss': 0.6217822392781576, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-09 23:45:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:45:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:45:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:46:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:46:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.753357, avg_loss=0.655736, seen=480, correct=290, accuracy=0.604167
2025-10-09 23:46:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:46:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:46:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:46:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2134MB allocated=1895MB
2025-10-09 23:46:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.28138273954391, 'train_avg_loss': 0.627344856162866, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 23:46:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.75335693359375, 'train_avg_loss': 0.6557361602783203, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 23:46:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 314.75335693359375, 'train_avg_loss': 0.6557361602783203, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-09 23:46:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:46:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:46:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-09 23:46:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-09 23:46:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:46:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:46:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:46:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:46:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:47:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:47:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.452026, avg_loss=0.655108, seen=480, correct=296, accuracy=0.616667
2025-10-09 23:47:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:47:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:47:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:47:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2108MB allocated=1895MB
2025-10-09 23:47:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99630463123322, 'train_avg_loss': 0.6833025385936101, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:47:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.4520263671875, 'train_avg_loss': 0.655108388264974, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 23:47:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 314.4520263671875, 'train_avg_loss': 0.655108388264974, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-09 23:47:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:47:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:47:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-09 23:47:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:47:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:47:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:47:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:47:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:47:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:47:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:47:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.330505, avg_loss=0.598605, seen=480, correct=339, accuracy=0.706250
2025-10-09 23:47:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:47:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:47:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:47:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2116MB allocated=1895MB
2025-10-09 23:47:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.10914367437363, 'train_avg_loss': 0.6259095306197803, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-09 23:47:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.33050537109375, 'train_avg_loss': 0.598605219523112, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-09 23:47:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 287.33050537109375, 'train_avg_loss': 0.598605219523112, 'train_seen': 480, 'train_correct': 339, 'train_acc': 0.70625}}
2025-10-09 23:47:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #48, planning to set LR to 1.00e-05
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:47:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:47:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:48:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:48:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.845612, avg_loss=0.635095, seen=480, correct=316, accuracy=0.658333
2025-10-09 23:48:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:48:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:48:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:48:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=48 reserved=2162MB allocated=1895MB
2025-10-09 23:48:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 48, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.91271567344666, 'train_avg_loss': 0.6576059639453888, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:48:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 48, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.8456115722656, 'train_avg_loss': 0.6350950241088867, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 23:48:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 48, 'Results_raw': {'train_total': 480, 'train_loss': 304.8456115722656, 'train_avg_loss': 0.6350950241088867, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 23:48:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #49) -------------
2025-10-09 23:48:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=49 aidx=1 | s=5 (candidates=12)
2025-10-09 23:48:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 6, 48, 16, 43] (from 12)
2025-10-09 23:48:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-09 23:48:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:48:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:49:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:49:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.056458, avg_loss=0.629284, seen=480, correct=311, accuracy=0.647917
2025-10-09 23:49:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:49:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:49:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:49:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2108MB allocated=1895MB
2025-10-09 23:49:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.2236642241478, 'train_avg_loss': 0.626863868534565, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-09 23:49:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.05645751953125, 'train_avg_loss': 0.6292842864990235, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 23:49:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 302.05645751953125, 'train_avg_loss': 0.6292842864990235, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-09 23:49:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:49:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:49:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:49:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:49:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.448853, avg_loss=0.684268, seen=480, correct=276, accuracy=0.575000
2025-10-09 23:49:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:49:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:49:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:49:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2120MB allocated=1895MB
2025-10-09 23:49:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.78201621770859, 'train_avg_loss': 0.6648501351475715, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 23:49:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4488525390625, 'train_avg_loss': 0.6842684427897135, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:49:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 328.4488525390625, 'train_avg_loss': 0.6842684427897135, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-09 23:49:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:49:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:49:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:50:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:50:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.675293, avg_loss=0.624324, seen=480, correct=306, accuracy=0.637500
2025-10-09 23:50:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:50:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:50:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:50:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2114MB allocated=1895MB
2025-10-09 23:50:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.09654247760773, 'train_avg_loss': 0.6924711873133977, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:50:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.67529296875, 'train_avg_loss': 0.6243235270182291, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 23:50:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 299.67529296875, 'train_avg_loss': 0.6243235270182291, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 23:50:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:50:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:50:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:51:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:51:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.776886, avg_loss=0.651619, seen=480, correct=295, accuracy=0.614583
2025-10-09 23:51:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:51:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:51:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:51:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2134MB allocated=1895MB
2025-10-09 23:51:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.90545570850372, 'train_avg_loss': 0.6158787975708644, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-09 23:51:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.7768859863281, 'train_avg_loss': 0.6516185124715169, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 23:51:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 312.7768859863281, 'train_avg_loss': 0.6516185124715169, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 23:51:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #49, planning to set LR to 1.00e-05
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-09 23:51:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:51:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:51:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:51:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.942444, avg_loss=0.616547, seen=480, correct=316, accuracy=0.658333
2025-10-09 23:51:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:51:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:51:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:51:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=49 reserved=2162MB allocated=1895MB
2025-10-09 23:51:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 49, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.94283410906792, 'train_avg_loss': 0.649523617575566, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-09 23:51:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 49, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.94244384765625, 'train_avg_loss': 0.6165467580159505, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 23:51:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 49, 'Results_raw': {'train_total': 480, 'train_loss': 295.94244384765625, 'train_avg_loss': 0.6165467580159505, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-09 23:51:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #50) -------------
2025-10-09 23:51:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=50 aidx=1 | s=5 (candidates=12)
2025-10-09 23:51:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 51, 22, 48, 6] (from 12)
2025-10-09 23:51:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:51:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:51:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-09 23:51:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-09 23:51:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:51:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:51:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:51:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:51:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:52:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:52:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.926666, avg_loss=0.683181, seen=480, correct=280, accuracy=0.583333
2025-10-09 23:52:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:52:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:52:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:52:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2112MB allocated=1895MB
2025-10-09 23:52:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.4115538597107, 'train_avg_loss': 0.6367629488309224, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 23:52:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.9266662597656, 'train_avg_loss': 0.683180554707845, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 23:52:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 327.9266662597656, 'train_avg_loss': 0.683180554707845, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-09 23:52:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 23:52:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:52:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:53:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:53:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.310272, avg_loss=0.667313, seen=480, correct=278, accuracy=0.579167
2025-10-09 23:53:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:53:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:53:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:53:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2144MB allocated=1895MB
2025-10-09 23:53:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.86324352025986, 'train_avg_loss': 0.6988603626688321, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-09 23:53:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.3102722167969, 'train_avg_loss': 0.6673130671183268, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 23:53:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 320.3102722167969, 'train_avg_loss': 0.6673130671183268, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-09 23:53:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:53:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:53:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-09 23:53:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:53:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:53:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:53:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:53:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:53:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:53:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:53:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.296478, avg_loss=0.598534, seen=480, correct=345, accuracy=0.718750
2025-10-09 23:53:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:53:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:53:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:53:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2116MB allocated=1895MB
2025-10-09 23:53:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.80037397146225, 'train_avg_loss': 0.6233364497621854, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-09 23:53:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.2964782714844, 'train_avg_loss': 0.5985343297322591, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 23:53:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 287.2964782714844, 'train_avg_loss': 0.5985343297322591, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-09 23:53:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:53:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:53:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-09 23:53:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:53:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:53:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:53:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:53:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:53:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:54:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:54:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.656311, avg_loss=0.626367, seen=480, correct=309, accuracy=0.643750
2025-10-09 23:54:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:54:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:54:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:54:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2114MB allocated=1895MB
2025-10-09 23:54:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26086604595184, 'train_avg_loss': 0.7021738837162653, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-09 23:54:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.65631103515625, 'train_avg_loss': 0.6263673146565755, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 23:54:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 300.65631103515625, 'train_avg_loss': 0.6263673146565755, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-09 23:54:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #50, planning to set LR to 1.00e-05
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:54:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:54:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:54:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:54:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.701843, avg_loss=0.688962, seen=480, correct=273, accuracy=0.568750
2025-10-09 23:54:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:54:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:54:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:54:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=50 reserved=2120MB allocated=1895MB
2025-10-09 23:54:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 50, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.21391671895981, 'train_avg_loss': 0.6684493059913318, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-09 23:54:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 50, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.70184326171875, 'train_avg_loss': 0.688962173461914, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 23:54:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 50, 'Results_raw': {'train_total': 480, 'train_loss': 330.70184326171875, 'train_avg_loss': 0.688962173461914, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-09 23:54:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #51) -------------
2025-10-09 23:54:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=51 aidx=1 | s=5 (candidates=12)
2025-10-09 23:54:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 22, 51, 40] (from 12)
2025-10-09 23:55:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:55:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:55:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-09 23:55:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-09 23:55:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:55:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:55:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:55:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:55:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:55:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:55:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.426849, avg_loss=0.627973, seen=480, correct=306, accuracy=0.637500
2025-10-09 23:55:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:55:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:55:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:55:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2114MB allocated=1895MB
2025-10-09 23:55:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.26609808206558, 'train_avg_loss': 0.6855508173505466, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-09 23:55:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.4268493652344, 'train_avg_loss': 0.6279726028442383, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 23:55:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 301.4268493652344, 'train_avg_loss': 0.6279726028442383, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-09 23:55:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:55:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:55:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-09 23:55:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:55:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:55:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:55:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:55:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:55:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:56:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:56:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.996857, avg_loss=0.654160, seen=480, correct=295, accuracy=0.614583
2025-10-09 23:56:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:56:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:56:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:56:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2134MB allocated=1895MB
2025-10-09 23:56:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.13312065601349, 'train_avg_loss': 0.617776005466779, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-09 23:56:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.9968566894531, 'train_avg_loss': 0.6541601181030273, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 23:56:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 313.9968566894531, 'train_avg_loss': 0.6541601181030273, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-09 23:56:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-09 23:56:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:56:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:56:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:56:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.650116, avg_loss=0.609688, seen=480, correct=328, accuracy=0.683333
2025-10-09 23:56:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:56:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:56:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:56:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2116MB allocated=1895MB
2025-10-09 23:56:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.86066353321075, 'train_avg_loss': 0.6321721961100896, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-09 23:56:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.6501159667969, 'train_avg_loss': 0.6096877415974935, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-09 23:56:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 292.6501159667969, 'train_avg_loss': 0.6096877415974935, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-09 23:56:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-09 23:56:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:56:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:57:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:57:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.815002, avg_loss=0.662115, seen=480, correct=283, accuracy=0.589583
2025-10-09 23:57:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:57:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:57:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:57:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2144MB allocated=1895MB
2025-10-09 23:57:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.83145070075989, 'train_avg_loss': 0.690262089172999, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-09 23:57:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.81500244140625, 'train_avg_loss': 0.6621145884195964, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 23:57:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 317.81500244140625, 'train_avg_loss': 0.6621145884195964, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-09 23:57:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #51, planning to set LR to 1.00e-05
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 23:57:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:57:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:58:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:58:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.232239, avg_loss=0.671317, seen=480, correct=293, accuracy=0.610417
2025-10-09 23:58:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:58:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:58:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:58:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=51 reserved=2108MB allocated=1895MB
2025-10-09 23:58:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 51, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.20070564746857, 'train_avg_loss': 0.6850058803955714, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-09 23:58:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 51, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.23223876953125, 'train_avg_loss': 0.6713171641031901, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 23:58:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 51, 'Results_raw': {'train_total': 480, 'train_loss': 322.23223876953125, 'train_avg_loss': 0.6713171641031901, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-09 23:58:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #52) -------------
2025-10-09 23:58:09 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=52 aidx=1 | s=5 (candidates=12)
2025-10-09 23:58:09 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 6, 16, 28, 22] (from 12)
2025-10-09 23:58:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-09 23:58:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:58:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:58:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:58:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.133148, avg_loss=0.658611, seen=480, correct=297, accuracy=0.618750
2025-10-09 23:58:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:58:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:58:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:58:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2108MB allocated=1895MB
2025-10-09 23:58:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.612613260746, 'train_avg_loss': 0.6717717771728834, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-09 23:58:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.1331481933594, 'train_avg_loss': 0.658610725402832, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 23:58:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 316.1331481933594, 'train_avg_loss': 0.658610725402832, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-09 23:58:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-09 23:58:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:58:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-09 23:59:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-09 23:59:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.092804, avg_loss=0.671027, seen=480, correct=281, accuracy=0.585417
2025-10-09 23:59:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-09 23:59:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:59:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-09 23:59:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2120MB allocated=1895MB
2025-10-09 23:59:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.13292986154556, 'train_avg_loss': 0.651107748846213, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-09 23:59:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.0928039550781, 'train_avg_loss': 0.6710266749064128, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 23:59:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 322.0928039550781, 'train_avg_loss': 0.6710266749064128, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-09 23:59:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-09 23:59:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-09 23:59:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-09 23:59:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-09 23:59:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-09 23:59:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-09 23:59:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-09 23:59:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-09 23:59:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:00:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:00:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.660278, avg_loss=0.651376, seen=480, correct=298, accuracy=0.620833
2025-10-10 00:00:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:00:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:00:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:00:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2134MB allocated=1895MB
2025-10-10 00:00:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.89769798517227, 'train_avg_loss': 0.6158141498764356, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 00:00:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.6602783203125, 'train_avg_loss': 0.6513755798339844, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 00:00:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 312.6602783203125, 'train_avg_loss': 0.6513755798339844, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 00:00:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:00:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:00:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:00:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:00:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.011597, avg_loss=0.629191, seen=480, correct=316, accuracy=0.658333
2025-10-10 00:00:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:00:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:00:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:00:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2108MB allocated=1895MB
2025-10-10 00:00:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.08985012769699, 'train_avg_loss': 0.6174154177308082, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 00:00:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.0115966796875, 'train_avg_loss': 0.6291908264160156, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 00:00:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 302.0115966796875, 'train_avg_loss': 0.6291908264160156, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 00:00:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #52, planning to set LR to 1.00e-05
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 00:00:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:00:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:01:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:01:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.635498, avg_loss=0.611741, seen=480, correct=325, accuracy=0.677083
2025-10-10 00:01:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:01:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:01:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:01:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=52 reserved=2116MB allocated=1895MB
2025-10-10 00:01:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 52, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.50671058893204, 'train_avg_loss': 0.6292225882411003, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 00:01:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 52, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.635498046875, 'train_avg_loss': 0.6117406209309896, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 00:01:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 52, 'Results_raw': {'train_total': 480, 'train_loss': 293.635498046875, 'train_avg_loss': 0.6117406209309896, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 00:01:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #53) -------------
2025-10-10 00:01:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=53 aidx=1 | s=5 (candidates=12)
2025-10-10 00:01:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[20, 50, 48, 15, 28] (from 12)
2025-10-10 00:01:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 00:01:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:01:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:02:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:02:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.518463, avg_loss=0.628163, seen=480, correct=303, accuracy=0.631250
2025-10-10 00:02:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:02:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:02:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:02:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2134MB allocated=1895MB
2025-10-10 00:02:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.21067136526108, 'train_avg_loss': 0.651755594710509, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 00:02:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.5184631347656, 'train_avg_loss': 0.628163464864095, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 00:02:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 301.5184631347656, 'train_avg_loss': 0.628163464864095, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 00:02:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:02:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:02:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:02:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:02:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.469635, avg_loss=0.657228, seen=480, correct=290, accuracy=0.604167
2025-10-10 00:02:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:02:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:02:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:02:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2108MB allocated=1895MB
2025-10-10 00:02:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.34625744819641, 'train_avg_loss': 0.6695521454016368, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 00:02:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.4696350097656, 'train_avg_loss': 0.6572284062703451, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 00:02:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 315.4696350097656, 'train_avg_loss': 0.6572284062703451, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 00:02:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:02:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:02:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 00:02:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:02:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:02:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:02:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:02:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:02:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:03:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:03:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.994476, avg_loss=0.627072, seen=480, correct=299, accuracy=0.622917
2025-10-10 00:03:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:03:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:03:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:03:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2114MB allocated=1895MB
2025-10-10 00:03:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26839280128479, 'train_avg_loss': 0.7022366066773732, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 00:03:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.9944763183594, 'train_avg_loss': 0.6270718256632487, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 00:03:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 300.9944763183594, 'train_avg_loss': 0.6270718256632487, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 00:03:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 00:03:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:03:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:03:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:03:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.754395, avg_loss=0.657822, seen=480, correct=299, accuracy=0.622917
2025-10-10 00:03:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:03:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:04:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:04:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2108MB allocated=1895MB
2025-10-10 00:04:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.54934626817703, 'train_avg_loss': 0.6879112189014752, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 00:04:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.75439453125, 'train_avg_loss': 0.6578216552734375, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 00:04:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 315.75439453125, 'train_avg_loss': 0.6578216552734375, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 00:04:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #53, planning to set LR to 1.00e-05
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:04:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:04:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:04:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:04:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.597046, avg_loss=0.632494, seen=480, correct=306, accuracy=0.637500
2025-10-10 00:04:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:04:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:04:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:04:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=53 reserved=2108MB allocated=1895MB
2025-10-10 00:04:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 53, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.80571269989014, 'train_avg_loss': 0.6233809391657511, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 00:04:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 53, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.5970458984375, 'train_avg_loss': 0.6324938456217448, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 00:04:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 53, 'Results_raw': {'train_total': 480, 'train_loss': 303.5970458984375, 'train_avg_loss': 0.6324938456217448, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 00:04:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #54) -------------
2025-10-10 00:04:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=54 aidx=1 | s=5 (candidates=12)
2025-10-10 00:04:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 16, 50, 36, 40] (from 12)
2025-10-10 00:04:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 00:04:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:04:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:05:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:05:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.022491, avg_loss=0.675047, seen=480, correct=279, accuracy=0.581250
2025-10-10 00:05:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:05:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:05:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:05:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2120MB allocated=1895MB
2025-10-10 00:05:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.66188955307007, 'train_avg_loss': 0.6471824129422505, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 00:05:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0224914550781, 'train_avg_loss': 0.6750468571980794, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 00:05:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 324.0224914550781, 'train_avg_loss': 0.6750468571980794, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 00:05:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:05:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:05:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 00:05:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:05:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:05:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:05:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:05:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:05:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:05:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:05:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.779877, avg_loss=0.651625, seen=480, correct=293, accuracy=0.610417
2025-10-10 00:05:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:05:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:05:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:05:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2134MB allocated=1895MB
2025-10-10 00:05:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.41152167320251, 'train_avg_loss': 0.6117626806100209, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 00:05:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.7798767089844, 'train_avg_loss': 0.6516247431437174, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 00:05:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 312.7798767089844, 'train_avg_loss': 0.6516247431437174, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 00:05:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:05:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:05:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 00:05:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:05:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:05:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:05:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:05:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:05:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:06:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:06:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.468964, avg_loss=0.653060, seen=480, correct=293, accuracy=0.610417
2025-10-10 00:06:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:06:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:06:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:06:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2108MB allocated=1895MB
2025-10-10 00:06:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.02278292179108, 'train_avg_loss': 0.6751898576815923, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 00:06:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.4689636230469, 'train_avg_loss': 0.6530603408813477, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 00:06:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 313.4689636230469, 'train_avg_loss': 0.6530603408813477, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 00:06:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:06:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:06:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 00:06:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 00:06:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:06:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:06:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:06:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:06:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:07:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:07:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.661865, avg_loss=0.678462, seen=480, correct=277, accuracy=0.577083
2025-10-10 00:07:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:07:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:07:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:07:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2112MB allocated=1895MB
2025-10-10 00:07:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.23509839177132, 'train_avg_loss': 0.6269591532647609, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 00:07:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.661865234375, 'train_avg_loss': 0.6784622192382812, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 00:07:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 325.661865234375, 'train_avg_loss': 0.6784622192382812, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 00:07:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #54, planning to set LR to 1.00e-05
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 00:07:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:07:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:07:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:07:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.496826, avg_loss=0.661452, seen=480, correct=297, accuracy=0.618750
2025-10-10 00:07:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:07:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:07:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:07:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=54 reserved=2108MB allocated=1895MB
2025-10-10 00:07:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 54, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.0009335577488, 'train_avg_loss': 0.6750077796479066, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 00:07:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 54, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.496826171875, 'train_avg_loss': 0.6614517211914063, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 00:07:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 54, 'Results_raw': {'train_total': 480, 'train_loss': 317.496826171875, 'train_avg_loss': 0.6614517211914063, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 00:07:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #55) -------------
2025-10-10 00:07:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=55 aidx=1 | s=5 (candidates=12)
2025-10-10 00:07:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[28, 16, 22, 51, 6] (from 12)
2025-10-10 00:07:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:07:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:07:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:08:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:08:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.549927, avg_loss=0.611562, seen=480, correct=322, accuracy=0.670833
2025-10-10 00:08:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:08:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:08:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:08:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2108MB allocated=1895MB
2025-10-10 00:08:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.74757409095764, 'train_avg_loss': 0.6062297840913137, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 00:08:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.5499267578125, 'train_avg_loss': 0.6115623474121094, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 00:08:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 293.5499267578125, 'train_avg_loss': 0.6115623474121094, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 00:08:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:08:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:08:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:09:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:09:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.130310, avg_loss=0.652355, seen=480, correct=296, accuracy=0.616667
2025-10-10 00:09:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:09:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:09:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:09:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2134MB allocated=1895MB
2025-10-10 00:09:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.83764517307281, 'train_avg_loss': 0.6153137097756068, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 00:09:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.13031005859375, 'train_avg_loss': 0.6523548126220703, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 00:09:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 313.13031005859375, 'train_avg_loss': 0.6523548126220703, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 00:09:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 00:09:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:09:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:09:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:09:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=275.149902, avg_loss=0.573229, seen=480, correct=343, accuracy=0.714583
2025-10-10 00:09:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:09:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:09:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:09:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2116MB allocated=1895MB
2025-10-10 00:09:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.04101765155792, 'train_avg_loss': 0.6003418137629827, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 00:09:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 275.14990234375, 'train_avg_loss': 0.5732289632161458, 'train_seen': 480, 'train_correct': 343, 'train_acc': 0.7145833333333333}}
2025-10-10 00:09:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 275.14990234375, 'train_avg_loss': 0.5732289632161458, 'train_seen': 480, 'train_correct': 343, 'train_acc': 0.7145833333333333}}
2025-10-10 00:09:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:09:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:09:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 00:09:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 00:09:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:09:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:09:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:09:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:09:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:10:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:10:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.690613, avg_loss=0.663939, seen=480, correct=276, accuracy=0.575000
2025-10-10 00:10:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:10:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:10:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:10:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2140MB allocated=1895MB
2025-10-10 00:10:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.22741270065308, 'train_avg_loss': 0.6768951058387757, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 00:10:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.69061279296875, 'train_avg_loss': 0.6639387766520183, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 00:10:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 318.69061279296875, 'train_avg_loss': 0.6639387766520183, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 00:10:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #55, planning to set LR to 1.00e-05
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 00:10:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:10:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:10:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:10:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.742889, avg_loss=0.674464, seen=480, correct=282, accuracy=0.587500
2025-10-10 00:10:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:10:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:11:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:11:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=55 reserved=2120MB allocated=1895MB
2025-10-10 00:11:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 55, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.16547524929047, 'train_avg_loss': 0.6513789604107539, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 00:11:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 55, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.7428894042969, 'train_avg_loss': 0.6744643529256185, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 00:11:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 55, 'Results_raw': {'train_total': 480, 'train_loss': 323.7428894042969, 'train_avg_loss': 0.6744643529256185, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 00:11:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #56) -------------
2025-10-10 00:11:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=56 aidx=1 | s=5 (candidates=12)
2025-10-10 00:11:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[50, 48, 40, 43, 51] (from 12)
2025-10-10 00:11:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:11:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:11:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:11:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:11:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.716675, avg_loss=0.653576, seen=480, correct=288, accuracy=0.600000
2025-10-10 00:11:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:11:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:11:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:11:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2108MB allocated=1895MB
2025-10-10 00:11:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62045395374298, 'train_avg_loss': 0.6801704496145249, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 00:11:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.7166748046875, 'train_avg_loss': 0.653576405843099, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 00:11:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 313.7166748046875, 'train_avg_loss': 0.653576405843099, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 00:11:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:11:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:11:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:12:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:12:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.740662, avg_loss=0.624460, seen=480, correct=303, accuracy=0.631250
2025-10-10 00:12:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:12:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:12:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:12:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2114MB allocated=1895MB
2025-10-10 00:12:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60099136829376, 'train_avg_loss': 0.6883415947357814, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 00:12:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.74066162109375, 'train_avg_loss': 0.624459711710612, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 00:12:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 299.74066162109375, 'train_avg_loss': 0.624459711710612, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 00:12:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 00:12:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:12:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:12:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:12:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.492920, avg_loss=0.642694, seen=480, correct=306, accuracy=0.637500
2025-10-10 00:12:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:12:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:12:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:12:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2108MB allocated=1895MB
2025-10-10 00:13:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.09817785024643, 'train_avg_loss': 0.6508181487520536, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 00:13:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.492919921875, 'train_avg_loss': 0.6426935831705729, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 00:13:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 308.492919921875, 'train_avg_loss': 0.6426935831705729, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 00:13:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 00:13:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:13:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:13:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:13:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.461853, avg_loss=0.617629, seen=480, correct=322, accuracy=0.670833
2025-10-10 00:13:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:13:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:13:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:13:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2164MB allocated=1895MB
2025-10-10 00:13:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.96161925792694, 'train_avg_loss': 0.6413468271493912, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 00:13:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.46185302734375, 'train_avg_loss': 0.6176288604736329, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 00:13:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 296.46185302734375, 'train_avg_loss': 0.6176288604736329, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 00:13:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #56, planning to set LR to 1.00e-05
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 00:13:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:13:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:14:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:14:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.005646, avg_loss=0.664595, seen=480, correct=278, accuracy=0.579167
2025-10-10 00:14:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:14:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:14:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:14:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=56 reserved=2142MB allocated=1895MB
2025-10-10 00:14:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 56, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.25830787420273, 'train_avg_loss': 0.677152565618356, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 00:14:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 56, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0056457519531, 'train_avg_loss': 0.664595095316569, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 00:14:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 56, 'Results_raw': {'train_total': 480, 'train_loss': 319.0056457519531, 'train_avg_loss': 0.664595095316569, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 00:14:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #57) -------------
2025-10-10 00:14:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=57 aidx=1 | s=5 (candidates=12)
2025-10-10 00:14:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[40, 16, 50, 28, 20] (from 12)
2025-10-10 00:14:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:14:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:14:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 00:14:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 00:14:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:14:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:14:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:14:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:14:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:14:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:14:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.111023, avg_loss=0.650231, seen=480, correct=298, accuracy=0.620833
2025-10-10 00:14:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:14:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:14:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:14:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2108MB allocated=1895MB
2025-10-10 00:14:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.6962947845459, 'train_avg_loss': 0.6641357898712158, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 00:14:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.11102294921875, 'train_avg_loss': 0.6502312978108724, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 00:14:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 312.11102294921875, 'train_avg_loss': 0.6502312978108724, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 00:14:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:14:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:14:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 00:14:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:14:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:14:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:14:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:14:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:14:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:15:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:15:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.831787, avg_loss=0.651733, seen=480, correct=292, accuracy=0.608333
2025-10-10 00:15:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:15:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:15:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:15:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2134MB allocated=1895MB
2025-10-10 00:15:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.84419298171997, 'train_avg_loss': 0.6153682748476664, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 00:15:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.831787109375, 'train_avg_loss': 0.6517328898111979, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 00:15:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 312.831787109375, 'train_avg_loss': 0.6517328898111979, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 00:15:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:15:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:15:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 00:15:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:15:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:15:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:15:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:15:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:15:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:16:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:16:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.822510, avg_loss=0.653797, seen=480, correct=292, accuracy=0.608333
2025-10-10 00:16:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:16:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:16:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:16:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2108MB allocated=1895MB
2025-10-10 00:16:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.42195290327072, 'train_avg_loss': 0.6785162741939227, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 00:16:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.822509765625, 'train_avg_loss': 0.653796895345052, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 00:16:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 313.822509765625, 'train_avg_loss': 0.653796895345052, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 00:16:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:16:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:16:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:16:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:16:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.558472, avg_loss=0.617830, seen=480, correct=317, accuracy=0.660417
2025-10-10 00:16:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:16:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:16:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:16:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2108MB allocated=1895MB
2025-10-10 00:16:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.65050715208054, 'train_avg_loss': 0.6137542262673378, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 00:16:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.5584716796875, 'train_avg_loss': 0.6178301493326823, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 00:16:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 296.5584716796875, 'train_avg_loss': 0.6178301493326823, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 00:16:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #57, planning to set LR to 1.00e-05
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=600, total=2399)
2025-10-10 00:16:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:16:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=300, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:17:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:17:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.745483, avg_loss=0.628636, seen=480, correct=308, accuracy=0.641667
2025-10-10 00:17:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:17:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:17:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:17:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=57 reserved=2136MB allocated=1895MB
2025-10-10 00:17:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #20', 'Round': 57, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.43992614746094, 'train_avg_loss': 0.6536660512288411, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 00:17:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #20', 'Round': 57, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.7454833984375, 'train_avg_loss': 0.6286364237467448, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 00:17:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #20', 'Round': 57, 'Results_raw': {'train_total': 480, 'train_loss': 301.7454833984375, 'train_avg_loss': 0.6286364237467448, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 00:17:33 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #58) -------------
2025-10-10 00:17:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=58 aidx=1 | s=5 (candidates=12)
2025-10-10 00:17:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[6, 36, 43, 48, 28] (from 12)
2025-10-10 00:17:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 00:17:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:17:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:18:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:18:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.085510, avg_loss=0.662678, seen=480, correct=285, accuracy=0.593750
2025-10-10 00:18:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:18:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:18:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:18:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2120MB allocated=1895MB
2025-10-10 00:18:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.82390296459198, 'train_avg_loss': 0.6485325247049332, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 00:18:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.08551025390625, 'train_avg_loss': 0.6626781463623047, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 00:18:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 318.08551025390625, 'train_avg_loss': 0.6626781463623047, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 00:18:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 00:18:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:18:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:18:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:18:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.236511, avg_loss=0.677576, seen=480, correct=274, accuracy=0.570833
2025-10-10 00:18:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:18:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:18:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:18:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2112MB allocated=1895MB
2025-10-10 00:18:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.35219985246658, 'train_avg_loss': 0.6279349987705548, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 00:18:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.23651123046875, 'train_avg_loss': 0.6775760650634766, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 00:18:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 325.23651123046875, 'train_avg_loss': 0.6775760650634766, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 00:18:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 00:18:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:18:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:19:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:19:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.658020, avg_loss=0.609704, seen=480, correct=325, accuracy=0.677083
2025-10-10 00:19:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:19:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:19:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:19:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2164MB allocated=1895MB
2025-10-10 00:19:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.99404466152191, 'train_avg_loss': 0.6499503721793493, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 00:19:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.65802001953125, 'train_avg_loss': 0.6097042083740234, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 00:19:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 292.65802001953125, 'train_avg_loss': 0.6097042083740234, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 00:19:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:19:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:19:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:20:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:20:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.021301, avg_loss=0.627128, seen=480, correct=304, accuracy=0.633333
2025-10-10 00:20:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:20:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:20:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:20:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2114MB allocated=1895MB
2025-10-10 00:20:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.89781850576401, 'train_avg_loss': 0.7074818208813667, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 00:20:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.02130126953125, 'train_avg_loss': 0.6271277109781901, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 00:20:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 301.02130126953125, 'train_avg_loss': 0.6271277109781901, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 00:20:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:20:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:20:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #58, planning to set LR to 1.00e-05
2025-10-10 00:20:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:20:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:20:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:20:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:20:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:20:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:20:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:20:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.085236, avg_loss=0.616844, seen=480, correct=316, accuracy=0.658333
2025-10-10 00:20:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:20:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:20:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:20:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=58 reserved=2108MB allocated=1895MB
2025-10-10 00:20:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 58, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.0290824174881, 'train_avg_loss': 0.6085756868124008, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 00:20:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 58, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.0852355957031, 'train_avg_loss': 0.6168442408243815, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 00:20:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 58, 'Results_raw': {'train_total': 480, 'train_loss': 296.0852355957031, 'train_avg_loss': 0.6168442408243815, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 00:20:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #59) -------------
2025-10-10 00:20:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=59 aidx=1 | s=5 (candidates=12)
2025-10-10 00:20:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[36, 48, 51, 15, 16] (from 12)
2025-10-10 00:20:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 00:20:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:20:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:21:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:21:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.646881, avg_loss=0.676348, seen=480, correct=278, accuracy=0.579167
2025-10-10 00:21:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:21:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:21:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:21:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2112MB allocated=1895MB
2025-10-10 00:21:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.6495570242405, 'train_avg_loss': 0.6304129752020041, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 00:21:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.6468811035156, 'train_avg_loss': 0.6763476689656576, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 00:21:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 324.6468811035156, 'train_avg_loss': 0.6763476689656576, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 00:21:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:21:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:21:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:22:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:22:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.809021, avg_loss=0.620435, seen=480, correct=302, accuracy=0.629167
2025-10-10 00:22:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:22:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:22:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:22:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2114MB allocated=1895MB
2025-10-10 00:22:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.0935671031475, 'train_avg_loss': 0.7007797258595626, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 00:22:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.80902099609375, 'train_avg_loss': 0.6204354604085286, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 00:22:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 297.80902099609375, 'train_avg_loss': 0.6204354604085286, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 00:22:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:22:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:22:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 00:22:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 00:22:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:22:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:22:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:22:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:22:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:22:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:22:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.049622, avg_loss=0.645937, seen=480, correct=296, accuracy=0.616667
2025-10-10 00:22:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:22:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:22:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:22:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2138MB allocated=1895MB
2025-10-10 00:22:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.93052399158478, 'train_avg_loss': 0.6660876999298732, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 00:22:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.04962158203125, 'train_avg_loss': 0.6459367116292317, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 00:22:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 310.04962158203125, 'train_avg_loss': 0.6459367116292317, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 00:22:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:22:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:22:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 00:22:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 00:22:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:22:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:22:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:22:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:22:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:23:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:23:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.130920, avg_loss=0.656523, seen=480, correct=295, accuracy=0.614583
2025-10-10 00:23:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:23:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:23:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:23:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2108MB allocated=1895MB
2025-10-10 00:23:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.19314017891884, 'train_avg_loss': 0.693276168157657, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 00:23:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.13092041015625, 'train_avg_loss': 0.6565227508544922, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 00:23:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 315.13092041015625, 'train_avg_loss': 0.6565227508544922, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 00:23:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #59, planning to set LR to 1.00e-05
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:23:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:23:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:24:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:24:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.213135, avg_loss=0.644194, seen=480, correct=298, accuracy=0.620833
2025-10-10 00:24:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:24:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:24:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:24:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=59 reserved=2134MB allocated=1895MB
2025-10-10 00:24:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 59, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.49293780326843, 'train_avg_loss': 0.604107815027237, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 00:24:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 59, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.213134765625, 'train_avg_loss': 0.6441940307617188, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 00:24:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 59, 'Results_raw': {'train_total': 480, 'train_loss': 309.213134765625, 'train_avg_loss': 0.6441940307617188, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 00:24:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #60) -------------
2025-10-10 00:24:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=60 aidx=1 | s=5 (candidates=12)
2025-10-10 00:24:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[16, 48, 50, 36, 40] (from 12)
2025-10-10 00:24:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:24:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:24:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:24:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:24:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.635468, avg_loss=0.638824, seen=480, correct=300, accuracy=0.625000
2025-10-10 00:24:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:24:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:24:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:24:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2134MB allocated=1895MB
2025-10-10 00:24:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.90531224012375, 'train_avg_loss': 0.5992109353343645, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 00:24:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.6354675292969, 'train_avg_loss': 0.6388238906860352, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 00:24:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 306.6354675292969, 'train_avg_loss': 0.6388238906860352, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 00:24:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:24:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:24:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:25:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:25:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.401642, avg_loss=0.625837, seen=480, correct=311, accuracy=0.647917
2025-10-10 00:25:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:25:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:25:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:25:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2114MB allocated=1895MB
2025-10-10 00:25:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.93630886077881, 'train_avg_loss': 0.6994692405064901, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 00:25:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.4016418457031, 'train_avg_loss': 0.6258367538452149, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 00:25:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 300.4016418457031, 'train_avg_loss': 0.6258367538452149, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 00:25:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:25:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:25:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:26:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:26:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.169067, avg_loss=0.654519, seen=480, correct=283, accuracy=0.589583
2025-10-10 00:26:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:26:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:26:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:26:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2108MB allocated=1895MB
2025-10-10 00:26:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.95538678765297, 'train_avg_loss': 0.6829615565637748, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 00:26:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.1690673828125, 'train_avg_loss': 0.6545188903808594, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 00:26:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 314.1690673828125, 'train_avg_loss': 0.6545188903808594, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 00:26:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 00:26:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:26:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:26:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:26:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.701355, avg_loss=0.674378, seen=480, correct=278, accuracy=0.579167
2025-10-10 00:26:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:26:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:26:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:26:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2112MB allocated=1895MB
2025-10-10 00:26:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.82185244560242, 'train_avg_loss': 0.6318487703800202, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 00:26:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.70135498046875, 'train_avg_loss': 0.6743778228759766, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 00:26:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 323.70135498046875, 'train_avg_loss': 0.6743778228759766, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 00:26:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:26:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:26:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #60, planning to set LR to 1.00e-05
2025-10-10 00:26:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 00:26:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:26:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:26:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:26:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:26:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:27:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:27:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.926849, avg_loss=0.643598, seen=480, correct=299, accuracy=0.622917
2025-10-10 00:27:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:27:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:27:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:27:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=60 reserved=2108MB allocated=1895MB
2025-10-10 00:27:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 60, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.26879933476448, 'train_avg_loss': 0.660573327789704, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 00:27:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 60, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.9268493652344, 'train_avg_loss': 0.6435976028442383, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 00:27:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 60, 'Results_raw': {'train_total': 480, 'train_loss': 308.9268493652344, 'train_avg_loss': 0.6435976028442383, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 00:27:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #61) -------------
2025-10-10 00:27:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=61 aidx=1 | s=5 (candidates=12)
2025-10-10 00:27:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[15, 6, 16, 50, 48] (from 12)
2025-10-10 00:27:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=3638, total=14550)
2025-10-10 00:27:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:27:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=1819, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:28:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:28:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.463715, avg_loss=0.657216, seen=480, correct=296, accuracy=0.616667
2025-10-10 00:28:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:28:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:28:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:28:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2108MB allocated=1895MB
2025-10-10 00:28:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #15', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.54740208387375, 'train_avg_loss': 0.6878950173656145, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 00:28:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #15', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.4637145996094, 'train_avg_loss': 0.6572160720825195, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 00:28:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #15', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 315.4637145996094, 'train_avg_loss': 0.6572160720825195, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 00:28:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=637, total=2547)
2025-10-10 00:28:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:28:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=319, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:28:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:28:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.580475, avg_loss=0.665793, seen=480, correct=287, accuracy=0.597917
2025-10-10 00:28:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:28:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:28:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:28:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2120MB allocated=1895MB
2025-10-10 00:28:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #6', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.83091279864311, 'train_avg_loss': 0.6402576066553592, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 00:28:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #6', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.5804748535156, 'train_avg_loss': 0.6657926559448242, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 00:28:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #6', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 319.5804748535156, 'train_avg_loss': 0.6657926559448242, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 00:28:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:28:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:28:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 00:28:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:28:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:28:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:28:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:28:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:28:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:29:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:29:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.153564, avg_loss=0.635737, seen=480, correct=304, accuracy=0.633333
2025-10-10 00:29:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:29:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:29:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:29:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2134MB allocated=1895MB
2025-10-10 00:29:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.56737521290779, 'train_avg_loss': 0.5963947934408983, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 00:29:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.153564453125, 'train_avg_loss': 0.635736592610677, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 00:29:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 305.153564453125, 'train_avg_loss': 0.635736592610677, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 00:29:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:29:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:29:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:30:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:30:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.300415, avg_loss=0.654793, seen=480, correct=280, accuracy=0.583333
2025-10-10 00:30:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:30:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:30:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:30:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2108MB allocated=1895MB
2025-10-10 00:30:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.29498100280762, 'train_avg_loss': 0.6857915083567302, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 00:30:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.3004150390625, 'train_avg_loss': 0.6547925313313802, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 00:30:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 314.3004150390625, 'train_avg_loss': 0.6547925313313802, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 00:30:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #61, planning to set LR to 1.00e-05
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:30:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:30:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:30:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:30:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.693237, avg_loss=0.624361, seen=480, correct=302, accuracy=0.629167
2025-10-10 00:30:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:30:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:30:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:30:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=61 reserved=2114MB allocated=1895MB
2025-10-10 00:30:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 61, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.27580341696739, 'train_avg_loss': 0.7022983618080616, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 00:30:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 61, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.6932373046875, 'train_avg_loss': 0.6243609110514323, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 00:30:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 61, 'Results_raw': {'train_total': 480, 'train_loss': 299.6932373046875, 'train_avg_loss': 0.6243609110514323, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 00:30:46 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #62) -------------
2025-10-10 00:30:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=62 aidx=1 | s=5 (candidates=12)
2025-10-10 00:30:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[48, 16, 43, 22, 36] (from 12)
2025-10-10 00:30:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:30:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:30:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 00:30:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:30:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:30:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:30:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:30:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:30:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:31:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:31:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=290.027039, avg_loss=0.604223, seen=480, correct=314, accuracy=0.654167
2025-10-10 00:31:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:31:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:31:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:31:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2114MB allocated=1895MB
2025-10-10 00:31:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3721535205841, 'train_avg_loss': 0.6781012793382009, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 00:31:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 290.02703857421875, 'train_avg_loss': 0.6042229970296223, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 00:31:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 290.02703857421875, 'train_avg_loss': 0.6042229970296223, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 00:31:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:31:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:31:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:32:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:32:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.650543, avg_loss=0.636772, seen=480, correct=306, accuracy=0.637500
2025-10-10 00:32:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:32:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:32:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:32:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2134MB allocated=1895MB
2025-10-10 00:32:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.43777853250504, 'train_avg_loss': 0.6036481544375419, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 00:32:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.6505432128906, 'train_avg_loss': 0.6367719650268555, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 00:32:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 305.6505432128906, 'train_avg_loss': 0.6367719650268555, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 00:32:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 00:32:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:32:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:32:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:32:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.938049, avg_loss=0.614454, seen=480, correct=324, accuracy=0.675000
2025-10-10 00:32:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:32:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:32:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:32:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2164MB allocated=1895MB
2025-10-10 00:32:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.12581968307495, 'train_avg_loss': 0.651048497358958, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 00:32:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.93804931640625, 'train_avg_loss': 0.6144542694091797, 'train_seen': 480, 'train_correct': 324, 'train_acc': 0.675}}
2025-10-10 00:32:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 294.93804931640625, 'train_avg_loss': 0.6144542694091797, 'train_seen': 480, 'train_correct': 324, 'train_acc': 0.675}}
2025-10-10 00:32:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 00:32:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:32:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:33:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:33:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=278.566895, avg_loss=0.580348, seen=480, correct=342, accuracy=0.712500
2025-10-10 00:33:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:33:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:33:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:33:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2116MB allocated=1895MB
2025-10-10 00:33:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.11543595790863, 'train_avg_loss': 0.6092952996492386, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 00:33:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 278.56689453125, 'train_avg_loss': 0.5803476969401041, 'train_seen': 480, 'train_correct': 342, 'train_acc': 0.7125}}
2025-10-10 00:33:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 278.56689453125, 'train_avg_loss': 0.5803476969401041, 'train_seen': 480, 'train_correct': 342, 'train_acc': 0.7125}}
2025-10-10 00:33:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #62, planning to set LR to 1.00e-05
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=258, total=1030)
2025-10-10 00:33:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:33:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=129, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:34:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:34:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.289124, avg_loss=0.677686, seen=480, correct=284, accuracy=0.591667
2025-10-10 00:34:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:34:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:34:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:34:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=62 reserved=2112MB allocated=1895MB
2025-10-10 00:34:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #36', 'Round': 62, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.6028126180172, 'train_avg_loss': 0.6300234384834766, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 00:34:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #36', 'Round': 62, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.28912353515625, 'train_avg_loss': 0.6776856740315755, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 00:34:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #36', 'Round': 62, 'Results_raw': {'train_total': 480, 'train_loss': 325.28912353515625, 'train_avg_loss': 0.6776856740315755, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 00:34:04 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #63) -------------
2025-10-10 00:34:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=63 aidx=1 | s=5 (candidates=12)
2025-10-10 00:34:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[22, 40, 50, 28, 48] (from 12)
2025-10-10 00:34:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=56, total=224)
2025-10-10 00:34:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:34:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=28, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:34:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:34:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=284.223663, avg_loss=0.592133, seen=480, correct=345, accuracy=0.718750
2025-10-10 00:34:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:34:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:34:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:34:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2116MB allocated=1895MB
2025-10-10 00:34:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #22', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.12583243846893, 'train_avg_loss': 0.6177152703205745, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 00:34:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #22', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 284.2236633300781, 'train_avg_loss': 0.5921326319376627, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-10 00:34:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #22', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 284.2236633300781, 'train_avg_loss': 0.5921326319376627, 'train_seen': 480, 'train_correct': 345, 'train_acc': 0.71875}}
2025-10-10 00:34:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 00:34:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:34:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:35:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:35:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.612030, avg_loss=0.634608, seen=480, correct=314, accuracy=0.654167
2025-10-10 00:35:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:35:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:35:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:35:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2108MB allocated=1895MB
2025-10-10 00:35:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.77964669466019, 'train_avg_loss': 0.6481637224555016, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 00:35:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.6120300292969, 'train_avg_loss': 0.6346083958943685, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 00:35:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 304.6120300292969, 'train_avg_loss': 0.6346083958943685, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 00:35:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=632, total=2527)
2025-10-10 00:35:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:35:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:35:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:35:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.547150, avg_loss=0.655307, seen=480, correct=292, accuracy=0.608333
2025-10-10 00:35:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:35:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:36:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:36:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2108MB allocated=1895MB
2025-10-10 00:36:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #50', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.93730926513672, 'train_avg_loss': 0.6911442438761394, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 00:36:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #50', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.5471496582031, 'train_avg_loss': 0.6553065617879231, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 00:36:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #50', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 314.5471496582031, 'train_avg_loss': 0.6553065617879231, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 00:36:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:36:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:36:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:36:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:36:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=289.318573, avg_loss=0.602747, seen=480, correct=327, accuracy=0.681250
2025-10-10 00:36:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:36:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:36:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:36:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2108MB allocated=1895MB
2025-10-10 00:36:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.22634345293045, 'train_avg_loss': 0.5935528621077537, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 00:36:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 289.3185729980469, 'train_avg_loss': 0.6027470270792643, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 00:36:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 289.3185729980469, 'train_avg_loss': 0.6027470270792643, 'train_seen': 480, 'train_correct': 327, 'train_acc': 0.68125}}
2025-10-10 00:36:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:36:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:36:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #63, planning to set LR to 1.00e-05
2025-10-10 00:36:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=220, total=880)
2025-10-10 00:36:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:36:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:36:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:36:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:36:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=110, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:37:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:37:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.036102, avg_loss=0.608409, seen=480, correct=321, accuracy=0.668750
2025-10-10 00:37:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:37:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:37:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:37:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=63 reserved=2114MB allocated=1895MB
2025-10-10 00:37:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #48', 'Round': 63, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.50674343109131, 'train_avg_loss': 0.6708895285924276, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 00:37:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #48', 'Round': 63, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.0361022949219, 'train_avg_loss': 0.6084085464477539, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 00:37:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #48', 'Round': 63, 'Results_raw': {'train_total': 480, 'train_loss': 292.0361022949219, 'train_avg_loss': 0.6084085464477539, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 00:37:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #64) -------------
2025-10-10 00:37:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=64 aidx=1 | s=5 (candidates=12)
2025-10-10 00:37:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[51, 28, 43, 16, 40] (from 12)
2025-10-10 00:37:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=395, total=1580)
2025-10-10 00:37:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:37:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=198, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:37:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:37:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.247437, avg_loss=0.652599, seen=480, correct=281, accuracy=0.585417
2025-10-10 00:37:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:37:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:37:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:37:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2140MB allocated=1895MB
2025-10-10 00:37:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #51', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.29665231704712, 'train_avg_loss': 0.669138769308726, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 00:37:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #51', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.2474365234375, 'train_avg_loss': 0.6525988260904948, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 00:37:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #51', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 313.2474365234375, 'train_avg_loss': 0.6525988260904948, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 00:37:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=359, total=1434)
2025-10-10 00:37:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:37:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=180, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:38:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:38:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.280945, avg_loss=0.598502, seen=480, correct=329, accuracy=0.685417
2025-10-10 00:38:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:38:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:38:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:38:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2108MB allocated=1895MB
2025-10-10 00:38:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #28', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.76005190610886, 'train_avg_loss': 0.5896670992175738, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 00:38:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #28', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.28094482421875, 'train_avg_loss': 0.5985019683837891, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 00:38:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #28', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 287.28094482421875, 'train_avg_loss': 0.5985019683837891, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 00:38:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=424, total=1694)
2025-10-10 00:38:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:38:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=212, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:39:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:39:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.417480, avg_loss=0.617536, seen=480, correct=320, accuracy=0.666667
2025-10-10 00:39:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:39:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:39:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:39:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2162MB allocated=1895MB
2025-10-10 00:39:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #43', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.3589945435524, 'train_avg_loss': 0.65299162119627, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 00:39:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #43', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.41748046875, 'train_avg_loss': 0.6175364176432292, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 00:39:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #43', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 296.41748046875, 'train_avg_loss': 0.6175364176432292, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 00:39:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:39:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:39:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 00:39:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=648, total=2589)
2025-10-10 00:39:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:39:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:39:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:39:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:39:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=324, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:39:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:39:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.994324, avg_loss=0.637488, seen=480, correct=305, accuracy=0.635417
2025-10-10 00:39:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:39:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:39:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:39:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2134MB allocated=1895MB
2025-10-10 00:39:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #16', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.70085138082504, 'train_avg_loss': 0.605840428173542, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 00:39:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #16', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.99432373046875, 'train_avg_loss': 0.6374881744384766, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 00:39:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #16', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 305.99432373046875, 'train_avg_loss': 0.6374881744384766, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 00:39:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #64, planning to set LR to 1.00e-05
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1002, total=4005)
2025-10-10 00:39:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:39:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=501, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:40:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:40:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.749207, avg_loss=0.630728, seen=480, correct=315, accuracy=0.656250
2025-10-10 00:40:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:40:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:40:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:40:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=64 reserved=2108MB allocated=1895MB
2025-10-10 00:40:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #40', 'Round': 64, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.52473559975624, 'train_avg_loss': 0.646039463331302, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 00:40:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #40', 'Round': 64, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.74920654296875, 'train_avg_loss': 0.6307275136311848, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 00:40:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #40', 'Round': 64, 'Results_raw': {'train_total': 480, 'train_loss': 302.74920654296875, 'train_avg_loss': 0.6307275136311848, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 00:40:33 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #65) -------------
2025-10-10 00:40:34 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=65 aidx=2 | s=5 (candidates=7)
2025-10-10 00:40:34 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 7, 12, 35, 17] (from 7)
2025-10-10 00:40:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:40:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:40:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 00:40:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 00:40:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:40:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:40:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:40:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:40:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:41:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:41:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.844055, avg_loss=0.708008, seen=480, correct=237, accuracy=0.493750
2025-10-10 00:41:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:41:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:41:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:41:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2174MB allocated=1962MB
2025-10-10 00:41:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.23997211456299, 'train_avg_loss': 0.7103331009546916, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 00:41:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.84405517578125, 'train_avg_loss': 0.7080084482828776, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 00:41:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 339.84405517578125, 'train_avg_loss': 0.7080084482828776, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 00:41:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 00:41:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:41:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:41:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:41:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=346.685120, avg_loss=0.722261, seen=480, correct=235, accuracy=0.489583
2025-10-10 00:41:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:41:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:41:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:41:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2154MB allocated=1971MB
2025-10-10 00:41:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.12021392583847, 'train_avg_loss': 0.7260017827153206, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 00:41:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 346.68511962890625, 'train_avg_loss': 0.7222606658935546, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 00:41:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 346.68511962890625, 'train_avg_loss': 0.7222606658935546, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 00:41:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:41:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:41:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 00:41:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 00:41:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:41:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:41:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:41:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:41:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:42:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:42:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.877808, avg_loss=0.716412, seen=480, correct=246, accuracy=0.512500
2025-10-10 00:42:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:42:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:42:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:42:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2150MB allocated=1980MB
2025-10-10 00:42:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.71655362844467, 'train_avg_loss': 0.7143046135703722, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 00:42:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.8778076171875, 'train_avg_loss': 0.716412099202474, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 00:42:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 343.8778076171875, 'train_avg_loss': 0.716412099202474, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 00:42:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:42:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:42:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 00:42:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 00:42:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:42:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:42:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:42:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:42:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:43:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:43:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.485291, avg_loss=0.719761, seen=480, correct=240, accuracy=0.500000
2025-10-10 00:43:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:43:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:43:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:43:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2178MB allocated=1988MB
2025-10-10 00:43:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.96836769580841, 'train_avg_loss': 0.7330697307984034, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 00:43:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.48529052734375, 'train_avg_loss': 0.7197610219319661, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 00:43:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 345.48529052734375, 'train_avg_loss': 0.7197610219319661, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 00:43:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #65, planning to set LR to 1.00e-05
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 00:43:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:43:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:43:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:43:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.628784, avg_loss=0.713810, seen=480, correct=248, accuracy=0.516667
2025-10-10 00:43:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:43:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:43:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:43:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=65 reserved=2184MB allocated=1996MB
2025-10-10 00:43:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 65, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.06235724687576, 'train_avg_loss': 0.733852977057298, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 00:43:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 65, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.6287841796875, 'train_avg_loss': 0.7138099670410156, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 00:43:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 65, 'Results_raw': {'train_total': 480, 'train_loss': 342.6287841796875, 'train_avg_loss': 0.7138099670410156, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 00:43:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #66) -------------
2025-10-10 00:43:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=66 aidx=2 | s=5 (candidates=7)
2025-10-10 00:43:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 7, 12, 42, 33] (from 7)
2025-10-10 00:44:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 00:44:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:44:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:44:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:44:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.492432, avg_loss=0.705193, seen=480, correct=238, accuracy=0.495833
2025-10-10 00:44:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:44:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:44:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:44:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2192MB allocated=1996MB
2025-10-10 00:44:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.13851189613342, 'train_avg_loss': 0.7094875991344451, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 00:44:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.492431640625, 'train_avg_loss': 0.7051925659179688, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 00:44:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 338.492431640625, 'train_avg_loss': 0.7051925659179688, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 00:44:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 00:44:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:44:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:45:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:45:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.095947, avg_loss=0.706450, seen=480, correct=236, accuracy=0.491667
2025-10-10 00:45:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:45:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:45:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:45:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2180MB allocated=1996MB
2025-10-10 00:45:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.0325517654419, 'train_avg_loss': 0.7252712647120158, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 00:45:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.095947265625, 'train_avg_loss': 0.7064498901367188, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 00:45:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 339.095947265625, 'train_avg_loss': 0.7064498901367188, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 00:45:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 00:45:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:45:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:45:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:45:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.843323, avg_loss=0.710090, seen=480, correct=228, accuracy=0.475000
2025-10-10 00:45:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:45:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:45:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:45:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2168MB allocated=1996MB
2025-10-10 00:45:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.9026757478714, 'train_avg_loss': 0.7158556312322617, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 00:45:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.84332275390625, 'train_avg_loss': 0.7100902557373047, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-10 00:45:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 340.84332275390625, 'train_avg_loss': 0.7100902557373047, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-10 00:45:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 00:46:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:46:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:46:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:46:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.202118, avg_loss=0.704588, seen=480, correct=238, accuracy=0.495833
2025-10-10 00:46:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:46:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:46:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:46:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2172MB allocated=1996MB
2025-10-10 00:46:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.94556391239166, 'train_avg_loss': 0.6995463659365971, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 00:46:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.2021179199219, 'train_avg_loss': 0.704587745666504, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 00:46:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 338.2021179199219, 'train_avg_loss': 0.704587745666504, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 00:46:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #66, planning to set LR to 1.00e-05
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 00:46:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:46:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:47:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:47:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.694183, avg_loss=0.711863, seen=480, correct=242, accuracy=0.504167
2025-10-10 00:47:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:47:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:47:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:47:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=66 reserved=2202MB allocated=2064MB
2025-10-10 00:47:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 66, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.11351627111435, 'train_avg_loss': 0.7176126355926196, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 00:47:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 66, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.6941833496094, 'train_avg_loss': 0.7118628819783529, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 00:47:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 66, 'Results_raw': {'train_total': 480, 'train_loss': 341.6941833496094, 'train_avg_loss': 0.7118628819783529, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 00:47:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #67) -------------
2025-10-10 00:47:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=67 aidx=2 | s=5 (candidates=7)
2025-10-10 00:47:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 7, 42, 17, 35] (from 7)
2025-10-10 00:47:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 00:47:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:47:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:47:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:47:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.361267, avg_loss=0.696586, seen=480, correct=253, accuracy=0.527083
2025-10-10 00:47:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:47:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:47:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:47:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2174MB allocated=2005MB
2025-10-10 00:47:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.63288933038712, 'train_avg_loss': 0.7052740777532259, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 00:47:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.36126708984375, 'train_avg_loss': 0.6965859731038412, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 00:47:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 334.36126708984375, 'train_avg_loss': 0.6965859731038412, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 00:47:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 00:48:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:48:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:48:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:48:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.499390, avg_loss=0.705207, seen=480, correct=231, accuracy=0.481250
2025-10-10 00:48:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:48:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:48:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:48:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2178MB allocated=2005MB
2025-10-10 00:48:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.45433062314987, 'train_avg_loss': 0.7121194218595822, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 00:48:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.4993896484375, 'train_avg_loss': 0.7052070617675781, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 00:48:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 338.4993896484375, 'train_avg_loss': 0.7052070617675781, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 00:48:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 00:48:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:48:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:49:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:49:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.638428, avg_loss=0.699247, seen=480, correct=241, accuracy=0.502083
2025-10-10 00:49:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:49:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:49:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:49:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2178MB allocated=2005MB
2025-10-10 00:49:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3629966378212, 'train_avg_loss': 0.69469163864851, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 00:49:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.638427734375, 'train_avg_loss': 0.6992467244466146, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 00:49:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 335.638427734375, 'train_avg_loss': 0.6992467244466146, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 00:49:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 00:49:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:49:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:49:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:49:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.919708, avg_loss=0.695666, seen=480, correct=245, accuracy=0.510417
2025-10-10 00:49:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:49:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:49:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:49:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2184MB allocated=2005MB
2025-10-10 00:49:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.11841380596161, 'train_avg_loss': 0.7093201150496801, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 00:49:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9197082519531, 'train_avg_loss': 0.6956660588582356, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 00:49:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 333.9197082519531, 'train_avg_loss': 0.6956660588582356, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 00:49:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #67, planning to set LR to 1.00e-05
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 00:49:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:49:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:50:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:50:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.962585, avg_loss=0.704089, seen=480, correct=249, accuracy=0.518750
2025-10-10 00:50:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:50:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:50:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:50:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=67 reserved=2216MB allocated=2005MB
2025-10-10 00:50:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 67, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.39758884906769, 'train_avg_loss': 0.7116465737422307, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 00:50:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 67, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.96258544921875, 'train_avg_loss': 0.7040887196858724, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 00:50:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 67, 'Results_raw': {'train_total': 480, 'train_loss': 337.96258544921875, 'train_avg_loss': 0.7040887196858724, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 00:50:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #68) -------------
2025-10-10 00:50:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=68 aidx=2 | s=5 (candidates=7)
2025-10-10 00:50:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 7, 17, 35, 42] (from 7)
2025-10-10 00:50:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:50:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:50:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 00:50:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 00:50:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:50:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:50:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:50:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:50:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:51:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:51:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.145294, avg_loss=0.694053, seen=480, correct=237, accuracy=0.493750
2025-10-10 00:51:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:51:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:51:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:51:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2158MB allocated=2013MB
2025-10-10 00:51:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26321244239807, 'train_avg_loss': 0.7021934370199839, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 00:51:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.1452941894531, 'train_avg_loss': 0.6940526962280273, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 00:51:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 333.1452941894531, 'train_avg_loss': 0.6940526962280273, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 00:51:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 00:51:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:51:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:51:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:51:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.418915, avg_loss=0.696706, seen=480, correct=243, accuracy=0.506250
2025-10-10 00:51:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:51:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:52:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:52:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2120MB allocated=1955MB
2025-10-10 00:52:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.17731440067291, 'train_avg_loss': 0.709810953338941, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 00:52:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.4189147949219, 'train_avg_loss': 0.6967060724894206, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 00:52:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 334.4189147949219, 'train_avg_loss': 0.6967060724894206, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 00:52:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 00:52:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:52:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:52:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:52:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.476685, avg_loss=0.694743, seen=480, correct=258, accuracy=0.537500
2025-10-10 00:52:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:52:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:52:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:52:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2124MB allocated=1955MB
2025-10-10 00:52:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.99033534526825, 'train_avg_loss': 0.6999194612105687, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 00:52:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.4766845703125, 'train_avg_loss': 0.6947430928548177, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 00:52:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 333.4766845703125, 'train_avg_loss': 0.6947430928548177, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 00:52:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 00:52:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:52:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:53:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:53:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.072052, avg_loss=0.695983, seen=480, correct=253, accuracy=0.527083
2025-10-10 00:53:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:53:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:53:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:53:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2162MB allocated=1955MB
2025-10-10 00:53:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.69489216804504, 'train_avg_loss': 0.6974574347337087, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 00:53:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0720520019531, 'train_avg_loss': 0.6959834416707357, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 00:53:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 334.0720520019531, 'train_avg_loss': 0.6959834416707357, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 00:53:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #68, planning to set LR to 1.00e-05
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 00:53:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:53:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:53:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:53:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.916718, avg_loss=0.695660, seen=480, correct=255, accuracy=0.531250
2025-10-10 00:53:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:53:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:53:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:54:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=68 reserved=2118MB allocated=1955MB
2025-10-10 00:54:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 68, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.30535304546356, 'train_avg_loss': 0.6858779420455297, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 00:54:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 68, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.9167175292969, 'train_avg_loss': 0.6956598281860351, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 00:54:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 68, 'Results_raw': {'train_total': 480, 'train_loss': 333.9167175292969, 'train_avg_loss': 0.6956598281860351, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 00:54:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #69) -------------
2025-10-10 00:54:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=69 aidx=2 | s=5 (candidates=7)
2025-10-10 00:54:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 42, 12, 17, 33] (from 7)
2025-10-10 00:54:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:54:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:54:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 00:54:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 00:54:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:54:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:54:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:54:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:54:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:54:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:54:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.551422, avg_loss=0.692815, seen=480, correct=239, accuracy=0.497917
2025-10-10 00:54:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:54:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:54:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:54:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2120MB allocated=1955MB
2025-10-10 00:54:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.48162591457367, 'train_avg_loss': 0.7040135492881139, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 00:54:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5514221191406, 'train_avg_loss': 0.6928154627482096, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 00:54:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 332.5514221191406, 'train_avg_loss': 0.6928154627482096, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 00:54:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:54:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:54:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 00:54:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 00:54:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:54:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:54:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:54:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:54:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:55:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:55:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.184448, avg_loss=0.689968, seen=480, correct=268, accuracy=0.558333
2025-10-10 00:55:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:55:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:55:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:55:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2118MB allocated=1955MB
2025-10-10 00:55:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62169694900513, 'train_avg_loss': 0.6801808079083761, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 00:55:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1844482421875, 'train_avg_loss': 0.6899676005045573, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 00:55:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 331.1844482421875, 'train_avg_loss': 0.6899676005045573, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 00:55:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 00:55:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:55:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:55:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:55:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.753693, avg_loss=0.703654, seen=480, correct=230, accuracy=0.479167
2025-10-10 00:55:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:55:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:55:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:56:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2112MB allocated=1955MB
2025-10-10 00:56:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.0277464389801, 'train_avg_loss': 0.7085645536581675, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 00:56:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.7536926269531, 'train_avg_loss': 0.7036535263061523, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 00:56:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 337.7536926269531, 'train_avg_loss': 0.7036535263061523, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 00:56:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 00:56:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:56:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:56:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:56:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.399475, avg_loss=0.692499, seen=480, correct=254, accuracy=0.529167
2025-10-10 00:56:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:56:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:56:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:56:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2124MB allocated=1955MB
2025-10-10 00:56:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.02208745479584, 'train_avg_loss': 0.7001840621232986, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 00:56:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.39947509765625, 'train_avg_loss': 0.6924989064534505, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 00:56:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 332.39947509765625, 'train_avg_loss': 0.6924989064534505, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 00:56:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:56:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:56:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #69, planning to set LR to 1.00e-05
2025-10-10 00:56:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 00:56:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:56:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:56:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:56:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:56:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:57:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:57:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.534607, avg_loss=0.690697, seen=480, correct=252, accuracy=0.525000
2025-10-10 00:57:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:57:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:57:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:57:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=69 reserved=2112MB allocated=1955MB
2025-10-10 00:57:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 69, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.35167169570923, 'train_avg_loss': 0.6945972641309103, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 00:57:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 69, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.53460693359375, 'train_avg_loss': 0.6906970977783203, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 00:57:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 69, 'Results_raw': {'train_total': 480, 'train_loss': 331.53460693359375, 'train_avg_loss': 0.6906970977783203, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 00:57:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #70) -------------
2025-10-10 00:57:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=70 aidx=2 | s=5 (candidates=7)
2025-10-10 00:57:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 42, 35, 9, 17] (from 7)
2025-10-10 00:57:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 00:57:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:57:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:57:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:57:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.671783, avg_loss=0.682650, seen=480, correct=268, accuracy=0.558333
2025-10-10 00:57:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:58:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:58:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:58:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2112MB allocated=1955MB
2025-10-10 00:58:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.80858725309372, 'train_avg_loss': 0.6817382271091144, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 00:58:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.6717834472656, 'train_avg_loss': 0.6826495488484701, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 00:58:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 327.6717834472656, 'train_avg_loss': 0.6826495488484701, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 00:58:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 00:58:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:58:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:58:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:58:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.005219, avg_loss=0.685428, seen=480, correct=266, accuracy=0.554167
2025-10-10 00:58:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:58:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:58:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:58:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2118MB allocated=1955MB
2025-10-10 00:58:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.1162143945694, 'train_avg_loss': 0.6759684532880783, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 00:58:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0052185058594, 'train_avg_loss': 0.6854275385538737, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 00:58:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 329.0052185058594, 'train_avg_loss': 0.6854275385538737, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 00:58:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 00:58:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:58:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 00:59:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 00:59:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.379639, avg_loss=0.694541, seen=480, correct=257, accuracy=0.535417
2025-10-10 00:59:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 00:59:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:59:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 00:59:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2162MB allocated=1955MB
2025-10-10 00:59:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.84836995601654, 'train_avg_loss': 0.7070697496334711, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 00:59:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.379638671875, 'train_avg_loss': 0.6945409138997396, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 00:59:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 333.379638671875, 'train_avg_loss': 0.6945409138997396, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 00:59:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 00:59:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 00:59:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:00:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:00:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.358704, avg_loss=0.692414, seen=480, correct=247, accuracy=0.514583
2025-10-10 01:00:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:00:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:00:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:00:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2120MB allocated=1955MB
2025-10-10 01:00:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73505306243896, 'train_avg_loss': 0.697792108853658, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 01:00:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.35870361328125, 'train_avg_loss': 0.6924139658610026, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 01:00:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 332.35870361328125, 'train_avg_loss': 0.6924139658610026, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 01:00:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:00:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:00:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #70, planning to set LR to 1.00e-05
2025-10-10 01:00:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:00:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:00:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:00:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:00:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:00:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:00:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:00:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.784058, avg_loss=0.689133, seen=480, correct=252, accuracy=0.525000
2025-10-10 01:00:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:00:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:00:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:00:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=70 reserved=2124MB allocated=1955MB
2025-10-10 01:00:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 70, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.97134119272232, 'train_avg_loss': 0.6997611766060193, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 01:00:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 70, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.7840576171875, 'train_avg_loss': 0.6891334533691407, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 01:00:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 70, 'Results_raw': {'train_total': 480, 'train_loss': 330.7840576171875, 'train_avg_loss': 0.6891334533691407, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 01:00:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #71) -------------
2025-10-10 01:00:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=71 aidx=2 | s=5 (candidates=7)
2025-10-10 01:00:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 17, 33, 12, 9] (from 7)
2025-10-10 01:00:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:00:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:00:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:01:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:01:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.656799, avg_loss=0.693035, seen=480, correct=258, accuracy=0.537500
2025-10-10 01:01:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:01:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:01:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:01:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2120MB allocated=1955MB
2025-10-10 01:01:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.25465953350067, 'train_avg_loss': 0.7021221627791723, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:01:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.65679931640625, 'train_avg_loss': 0.6930349985758464, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 01:01:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 332.65679931640625, 'train_avg_loss': 0.6930349985758464, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 01:01:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:01:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:01:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:02:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:02:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.838379, avg_loss=0.682997, seen=480, correct=268, accuracy=0.558333
2025-10-10 01:02:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:02:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:02:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:02:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2124MB allocated=1955MB
2025-10-10 01:02:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.01989442110062, 'train_avg_loss': 0.6834991201758385, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 01:02:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.83837890625, 'train_avg_loss': 0.6829966227213542, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 01:02:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 327.83837890625, 'train_avg_loss': 0.6829966227213542, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 01:02:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:02:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:02:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:02:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:02:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.969452, avg_loss=0.685353, seen=480, correct=258, accuracy=0.537500
2025-10-10 01:02:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:02:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:02:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:02:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2112MB allocated=1955MB
2025-10-10 01:02:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.81175374984741, 'train_avg_loss': 0.6817646145820617, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 01:02:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.9694519042969, 'train_avg_loss': 0.6853530248006184, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 01:02:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 328.9694519042969, 'train_avg_loss': 0.6853530248006184, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 01:02:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:02:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:02:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:03:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:03:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.475128, avg_loss=0.700990, seen=480, correct=225, accuracy=0.468750
2025-10-10 01:03:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:03:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:03:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:03:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2112MB allocated=1955MB
2025-10-10 01:03:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.40692573785782, 'train_avg_loss': 0.7033910478154818, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 01:03:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4751281738281, 'train_avg_loss': 0.7009898503621419, 'train_seen': 480, 'train_correct': 225, 'train_acc': 0.46875}}
2025-10-10 01:03:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 336.4751281738281, 'train_avg_loss': 0.7009898503621419, 'train_seen': 480, 'train_correct': 225, 'train_acc': 0.46875}}
2025-10-10 01:03:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #71, planning to set LR to 1.00e-05
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:03:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:03:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:03:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:03:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.734070, avg_loss=0.691113, seen=480, correct=248, accuracy=0.516667
2025-10-10 01:03:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:03:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:03:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:04:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=71 reserved=2120MB allocated=1955MB
2025-10-10 01:04:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 71, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.7067164182663, 'train_avg_loss': 0.6975559701522192, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 01:04:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 71, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.73406982421875, 'train_avg_loss': 0.6911126454671224, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 01:04:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 71, 'Results_raw': {'train_total': 480, 'train_loss': 331.73406982421875, 'train_avg_loss': 0.6911126454671224, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 01:04:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #72) -------------
2025-10-10 01:04:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=72 aidx=2 | s=5 (candidates=7)
2025-10-10 01:04:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 7, 42, 35, 9] (from 7)
2025-10-10 01:04:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:04:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:04:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:04:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:04:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.158478, avg_loss=0.681580, seen=480, correct=269, accuracy=0.560417
2025-10-10 01:04:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:04:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:04:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:04:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2124MB allocated=1955MB
2025-10-10 01:04:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.01295828819275, 'train_avg_loss': 0.6834413190682729, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:04:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.1584777832031, 'train_avg_loss': 0.6815801620483398, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 01:04:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 327.1584777832031, 'train_avg_loss': 0.6815801620483398, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 01:04:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:04:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:04:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:05:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:05:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.492615, avg_loss=0.692693, seen=480, correct=247, accuracy=0.514583
2025-10-10 01:05:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:05:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:05:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:05:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2120MB allocated=1955MB
2025-10-10 01:05:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00340282917023, 'train_avg_loss': 0.7000283569097518, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 01:05:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.49261474609375, 'train_avg_loss': 0.6926929473876953, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 01:05:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 332.49261474609375, 'train_avg_loss': 0.6926929473876953, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 01:05:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:05:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:05:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:05:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:05:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.466370, avg_loss=0.684305, seen=480, correct=267, accuracy=0.556250
2025-10-10 01:05:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:05:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:06:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:06:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2118MB allocated=1955MB
2025-10-10 01:06:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.84487664699554, 'train_avg_loss': 0.6737073053916295, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 01:06:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.46636962890625, 'train_avg_loss': 0.684304936726888, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 01:06:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 328.46636962890625, 'train_avg_loss': 0.684304936726888, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 01:06:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:06:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:06:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:06:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:06:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.602814, avg_loss=0.695006, seen=480, correct=260, accuracy=0.541667
2025-10-10 01:06:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:06:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:06:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:06:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2162MB allocated=1955MB
2025-10-10 01:06:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.93808805942535, 'train_avg_loss': 0.6994840671618779, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:06:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.6028137207031, 'train_avg_loss': 0.6950058619181315, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 01:06:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 333.6028137207031, 'train_avg_loss': 0.6950058619181315, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 01:06:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #72, planning to set LR to 1.00e-05
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:06:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:06:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:07:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:07:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.169708, avg_loss=0.683687, seen=480, correct=266, accuracy=0.554167
2025-10-10 01:07:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:07:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:07:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:07:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=72 reserved=2120MB allocated=1955MB
2025-10-10 01:07:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 72, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.44253432750702, 'train_avg_loss': 0.6953544527292251, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 01:07:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 72, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1697082519531, 'train_avg_loss': 0.683686892191569, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 01:07:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 72, 'Results_raw': {'train_total': 480, 'train_loss': 328.1697082519531, 'train_avg_loss': 0.683686892191569, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 01:07:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #73) -------------
2025-10-10 01:07:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=73 aidx=2 | s=5 (candidates=7)
2025-10-10 01:07:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 9, 7, 12, 17] (from 7)
2025-10-10 01:07:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:07:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:07:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:08:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:08:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.869690, avg_loss=0.683062, seen=480, correct=264, accuracy=0.550000
2025-10-10 01:08:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:08:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:08:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:08:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2118MB allocated=1955MB
2025-10-10 01:08:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.81483060121536, 'train_avg_loss': 0.6734569216767947, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 01:08:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.86968994140625, 'train_avg_loss': 0.6830618540445964, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 01:08:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 327.86968994140625, 'train_avg_loss': 0.6830618540445964, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 01:08:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:08:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:08:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:08:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:08:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.654053, avg_loss=0.676363, seen=480, correct=276, accuracy=0.575000
2025-10-10 01:08:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:08:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:08:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:08:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2120MB allocated=1955MB
2025-10-10 01:08:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.08897250890732, 'train_avg_loss': 0.684074770907561, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 01:08:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.654052734375, 'train_avg_loss': 0.6763626098632812, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 01:08:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 324.654052734375, 'train_avg_loss': 0.6763626098632812, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 01:08:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:08:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:08:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 01:08:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:08:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:08:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:08:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:08:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:08:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:09:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:09:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.089355, avg_loss=0.691853, seen=480, correct=260, accuracy=0.541667
2025-10-10 01:09:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:09:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:09:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:09:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2120MB allocated=1955MB
2025-10-10 01:09:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.78927886486053, 'train_avg_loss': 0.6982439905405045, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 01:09:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.08935546875, 'train_avg_loss': 0.6918528238932292, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 01:09:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 332.08935546875, 'train_avg_loss': 0.6918528238932292, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 01:09:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:09:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:09:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 01:09:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:09:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:09:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:09:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:09:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:09:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:10:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:10:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.016449, avg_loss=0.695868, seen=480, correct=246, accuracy=0.512500
2025-10-10 01:10:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:10:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:10:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:10:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2112MB allocated=1955MB
2025-10-10 01:10:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.64715248346329, 'train_avg_loss': 0.6970596040288607, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 01:10:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0164489746094, 'train_avg_loss': 0.6958676020304362, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 01:10:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 334.0164489746094, 'train_avg_loss': 0.6958676020304362, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 01:10:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #73, planning to set LR to 1.00e-05
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:10:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:10:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:10:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:10:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.396362, avg_loss=0.679992, seen=480, correct=262, accuracy=0.545833
2025-10-10 01:10:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:10:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:10:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:10:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=73 reserved=2124MB allocated=1955MB
2025-10-10 01:10:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 73, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.70417404174805, 'train_avg_loss': 0.6808681170145671, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 01:10:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 73, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.3963623046875, 'train_avg_loss': 0.6799924214680989, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 01:10:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 73, 'Results_raw': {'train_total': 480, 'train_loss': 326.3963623046875, 'train_avg_loss': 0.6799924214680989, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 01:10:41 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #74) -------------
2025-10-10 01:10:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=74 aidx=2 | s=5 (candidates=7)
2025-10-10 01:10:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 7, 9, 42, 33] (from 7)
2025-10-10 01:10:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:10:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:10:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:11:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:11:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.896545, avg_loss=0.670618, seen=480, correct=276, accuracy=0.575000
2025-10-10 01:11:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:11:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:11:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:11:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2124MB allocated=1955MB
2025-10-10 01:11:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.49363321065903, 'train_avg_loss': 0.6707802767554919, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 01:11:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.89654541015625, 'train_avg_loss': 0.6706178029378255, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 01:11:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 321.89654541015625, 'train_avg_loss': 0.6706178029378255, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 01:11:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:11:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:11:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:12:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:12:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.179199, avg_loss=0.692040, seen=480, correct=261, accuracy=0.543750
2025-10-10 01:12:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:12:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:12:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:12:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2120MB allocated=1955MB
2025-10-10 01:12:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.26238644123077, 'train_avg_loss': 0.7021865536769231, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 01:12:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.17919921875, 'train_avg_loss': 0.6920399983723958, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 01:12:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 332.17919921875, 'train_avg_loss': 0.6920399983723958, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 01:12:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:12:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:12:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:12:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:12:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.732147, avg_loss=0.676525, seen=480, correct=267, accuracy=0.556250
2025-10-10 01:12:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:12:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:12:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:12:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2120MB allocated=1955MB
2025-10-10 01:12:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32474446296692, 'train_avg_loss': 0.686039537191391, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 01:12:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7321472167969, 'train_avg_loss': 0.6765253067016601, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 01:12:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 324.7321472167969, 'train_avg_loss': 0.6765253067016601, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 01:12:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:12:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:12:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:13:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:13:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.958160, avg_loss=0.681163, seen=480, correct=270, accuracy=0.562500
2025-10-10 01:13:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:13:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:13:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:13:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2118MB allocated=1955MB
2025-10-10 01:13:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.44476127624512, 'train_avg_loss': 0.670373010635376, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 01:13:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.9581604003906, 'train_avg_loss': 0.6811628341674805, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 01:13:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 326.9581604003906, 'train_avg_loss': 0.6811628341674805, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 01:13:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #74, planning to set LR to 1.00e-05
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:13:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:13:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:13:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:13:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.821503, avg_loss=0.680878, seen=480, correct=266, accuracy=0.554167
2025-10-10 01:13:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:13:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:13:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:13:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=74 reserved=2112MB allocated=1955MB
2025-10-10 01:13:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 74, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.3883216381073, 'train_avg_loss': 0.6699026803175608, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 01:13:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 74, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.8215026855469, 'train_avg_loss': 0.6808781305948893, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 01:13:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 74, 'Results_raw': {'train_total': 480, 'train_loss': 326.8215026855469, 'train_avg_loss': 0.6808781305948893, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 01:13:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #75) -------------
2025-10-10 01:13:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=75 aidx=2 | s=5 (candidates=7)
2025-10-10 01:13:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 12, 35, 42, 7] (from 7)
2025-10-10 01:13:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:13:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:13:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:14:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:14:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.647247, avg_loss=0.668015, seen=480, correct=279, accuracy=0.581250
2025-10-10 01:14:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:14:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:14:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:14:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2124MB allocated=1955MB
2025-10-10 01:14:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.94400602579117, 'train_avg_loss': 0.6745333835482598, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 01:14:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.6472473144531, 'train_avg_loss': 0.6680150985717773, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 01:14:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 320.6472473144531, 'train_avg_loss': 0.6680150985717773, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 01:14:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:14:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:14:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:15:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:15:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.175018, avg_loss=0.696198, seen=480, correct=248, accuracy=0.516667
2025-10-10 01:15:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:15:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:15:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:15:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2112MB allocated=1955MB
2025-10-10 01:15:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.94614565372467, 'train_avg_loss': 0.6995512137810389, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 01:15:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1750183105469, 'train_avg_loss': 0.6961979548136393, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 01:15:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 334.1750183105469, 'train_avg_loss': 0.6961979548136393, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 01:15:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:15:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:15:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:15:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:15:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.112488, avg_loss=0.696068, seen=480, correct=248, accuracy=0.516667
2025-10-10 01:15:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:15:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:15:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:15:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2162MB allocated=1955MB
2025-10-10 01:15:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.54691743850708, 'train_avg_loss': 0.7045576453208924, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 01:15:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.11248779296875, 'train_avg_loss': 0.6960676829020183, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 01:15:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 334.11248779296875, 'train_avg_loss': 0.6960676829020183, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 01:15:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:15:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:15:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 01:15:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:15:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:15:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:15:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:15:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:15:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:16:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:16:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.957031, avg_loss=0.676994, seen=480, correct=278, accuracy=0.579167
2025-10-10 01:16:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:16:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:16:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:16:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2118MB allocated=1955MB
2025-10-10 01:16:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.81899559497833, 'train_avg_loss': 0.6651582966248194, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 01:16:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.95703125, 'train_avg_loss': 0.6769938151041667, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 01:16:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 324.95703125, 'train_avg_loss': 0.6769938151041667, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 01:16:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #75, planning to set LR to 1.00e-05
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:16:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:16:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:17:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:17:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.384338, avg_loss=0.688301, seen=480, correct=272, accuracy=0.566667
2025-10-10 01:17:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:17:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:17:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:17:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=75 reserved=2120MB allocated=1955MB
2025-10-10 01:17:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 75, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.88782155513763, 'train_avg_loss': 0.6907318462928136, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 01:17:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 75, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.38433837890625, 'train_avg_loss': 0.6883007049560547, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 01:17:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 75, 'Results_raw': {'train_total': 480, 'train_loss': 330.38433837890625, 'train_avg_loss': 0.6883007049560547, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 01:17:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #76) -------------
2025-10-10 01:17:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=76 aidx=2 | s=5 (candidates=7)
2025-10-10 01:17:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 9, 33, 42, 12] (from 7)
2025-10-10 01:17:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:17:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:17:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:17:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:17:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.620667, avg_loss=0.692960, seen=480, correct=256, accuracy=0.533333
2025-10-10 01:17:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:17:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:17:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:17:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2162MB allocated=1955MB
2025-10-10 01:17:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.05726623535156, 'train_avg_loss': 0.7004772186279297, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 01:17:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.62066650390625, 'train_avg_loss': 0.692959721883138, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 01:17:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 332.62066650390625, 'train_avg_loss': 0.692959721883138, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 01:17:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:17:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:17:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 01:17:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:17:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:17:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:17:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:17:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:17:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:18:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:18:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.968811, avg_loss=0.670768, seen=480, correct=277, accuracy=0.577083
2025-10-10 01:18:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:18:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:18:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:18:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2120MB allocated=1955MB
2025-10-10 01:18:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.91758418083191, 'train_avg_loss': 0.6743132015069325, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 01:18:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.96881103515625, 'train_avg_loss': 0.6707683563232422, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:18:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 321.96881103515625, 'train_avg_loss': 0.6707683563232422, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:18:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:18:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:18:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:19:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:19:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.232910, avg_loss=0.671319, seen=480, correct=280, accuracy=0.583333
2025-10-10 01:19:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:19:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:19:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:19:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2112MB allocated=1955MB
2025-10-10 01:19:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.85710716247559, 'train_avg_loss': 0.6654758930206299, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 01:19:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.23291015625, 'train_avg_loss': 0.6713185628255208, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 01:19:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 322.23291015625, 'train_avg_loss': 0.6713185628255208, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 01:19:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:19:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:19:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:19:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:19:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.393311, avg_loss=0.675819, seen=480, correct=280, accuracy=0.583333
2025-10-10 01:19:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:19:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:19:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:19:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2118MB allocated=1955MB
2025-10-10 01:19:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.70355850458145, 'train_avg_loss': 0.6641963208715121, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 01:19:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.393310546875, 'train_avg_loss': 0.6758193969726562, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 01:19:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 324.393310546875, 'train_avg_loss': 0.6758193969726562, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 01:19:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #76, planning to set LR to 1.00e-05
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:19:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:19:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:20:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:20:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.467834, avg_loss=0.692641, seen=480, correct=253, accuracy=0.527083
2025-10-10 01:20:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:20:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:20:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:20:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=76 reserved=2112MB allocated=1955MB
2025-10-10 01:20:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 76, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.99387490749359, 'train_avg_loss': 0.6999489575624466, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:20:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 76, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.46783447265625, 'train_avg_loss': 0.6926413218180338, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 01:20:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 76, 'Results_raw': {'train_total': 480, 'train_loss': 332.46783447265625, 'train_avg_loss': 0.6926413218180338, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 01:20:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #77) -------------
2025-10-10 01:20:35 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=77 aidx=2 | s=5 (candidates=7)
2025-10-10 01:20:35 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 17, 33, 35, 9] (from 7)
2025-10-10 01:20:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:20:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:20:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 01:20:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:20:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:20:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:20:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:20:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:20:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:21:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:21:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.808105, avg_loss=0.685017, seen=480, correct=257, accuracy=0.535417
2025-10-10 01:21:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:21:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:21:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:21:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2112MB allocated=1955MB
2025-10-10 01:21:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.12457811832428, 'train_avg_loss': 0.6927048176527023, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 01:21:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.80810546875, 'train_avg_loss': 0.6850168863932292, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 01:21:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 328.80810546875, 'train_avg_loss': 0.6850168863932292, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 01:21:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:21:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:21:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:21:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:21:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.124390, avg_loss=0.669009, seen=480, correct=291, accuracy=0.606250
2025-10-10 01:21:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:21:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:21:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:21:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2124MB allocated=1955MB
2025-10-10 01:21:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5202807188034, 'train_avg_loss': 0.6710023393233617, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 01:21:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.1243896484375, 'train_avg_loss': 0.6690091451009115, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 01:21:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 321.1243896484375, 'train_avg_loss': 0.6690091451009115, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 01:21:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:21:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:21:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:22:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:22:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.633850, avg_loss=0.672154, seen=480, correct=270, accuracy=0.562500
2025-10-10 01:22:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:22:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:22:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:22:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2112MB allocated=1955MB
2025-10-10 01:22:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.83726191520691, 'train_avg_loss': 0.6653105159600575, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 01:22:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.63385009765625, 'train_avg_loss': 0.6721538543701172, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 01:22:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 322.63385009765625, 'train_avg_loss': 0.6721538543701172, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 01:22:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:22:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:22:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:23:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:23:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.266663, avg_loss=0.692222, seen=480, correct=269, accuracy=0.560417
2025-10-10 01:23:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:23:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:23:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:23:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2162MB allocated=1955MB
2025-10-10 01:23:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.80767631530762, 'train_avg_loss': 0.6983973026275635, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 01:23:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.26666259765625, 'train_avg_loss': 0.6922222137451172, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 01:23:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 332.26666259765625, 'train_avg_loss': 0.6922222137451172, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 01:23:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #77, planning to set LR to 1.00e-05
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:23:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:23:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:23:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:23:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.416290, avg_loss=0.671701, seen=480, correct=270, accuracy=0.562500
2025-10-10 01:23:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:23:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:23:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:23:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=77 reserved=2120MB allocated=1955MB
2025-10-10 01:23:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 77, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.96193319559097, 'train_avg_loss': 0.6830161099632581, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:23:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 77, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.4162902832031, 'train_avg_loss': 0.6717006047566731, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 01:23:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 77, 'Results_raw': {'train_total': 480, 'train_loss': 322.4162902832031, 'train_avg_loss': 0.6717006047566731, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 01:23:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #78) -------------
2025-10-10 01:23:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=78 aidx=2 | s=5 (candidates=7)
2025-10-10 01:23:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 35, 9, 42, 33] (from 7)
2025-10-10 01:23:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:23:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:23:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:24:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:24:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.147308, avg_loss=0.675307, seen=480, correct=283, accuracy=0.589583
2025-10-10 01:24:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:24:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:24:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:24:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2120MB allocated=1955MB
2025-10-10 01:24:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.81182181835175, 'train_avg_loss': 0.6984318484862645, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:24:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.1473083496094, 'train_avg_loss': 0.6753068923950195, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 01:24:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 324.1473083496094, 'train_avg_loss': 0.6753068923950195, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 01:24:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:24:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:24:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:25:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:25:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.263916, avg_loss=0.694300, seen=480, correct=265, accuracy=0.552083
2025-10-10 01:25:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:25:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:25:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:25:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2162MB allocated=1955MB
2025-10-10 01:25:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.79886150360107, 'train_avg_loss': 0.6983238458633423, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:25:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.263916015625, 'train_avg_loss': 0.694299825032552, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 01:25:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 333.263916015625, 'train_avg_loss': 0.694299825032552, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 01:25:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:25:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:25:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:25:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:25:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.896454, avg_loss=0.662284, seen=480, correct=287, accuracy=0.597917
2025-10-10 01:25:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:25:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:25:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:26:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2120MB allocated=1955MB
2025-10-10 01:26:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.5148543715477, 'train_avg_loss': 0.6709571197628975, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 01:26:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8964538574219, 'train_avg_loss': 0.6622842788696289, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 01:26:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 317.8964538574219, 'train_avg_loss': 0.6622842788696289, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 01:26:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:26:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:26:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 01:26:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:26:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:26:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:26:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:26:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:26:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:26:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:26:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.801392, avg_loss=0.674586, seen=480, correct=278, accuracy=0.579167
2025-10-10 01:26:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:26:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:26:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:26:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2118MB allocated=1955MB
2025-10-10 01:26:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.62954366207123, 'train_avg_loss': 0.6635795305172603, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 01:26:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.8013916015625, 'train_avg_loss': 0.6745862325032552, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 01:26:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 323.8013916015625, 'train_avg_loss': 0.6745862325032552, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 01:26:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #78, planning to set LR to 1.00e-05
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:26:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:26:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:27:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:27:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.225586, avg_loss=0.673387, seen=480, correct=265, accuracy=0.552083
2025-10-10 01:27:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:27:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:27:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:27:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=78 reserved=2112MB allocated=1955MB
2025-10-10 01:27:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 78, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.28027254343033, 'train_avg_loss': 0.6690022711952527, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 01:27:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 78, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.2255859375, 'train_avg_loss': 0.6733866373697917, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 01:27:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 78, 'Results_raw': {'train_total': 480, 'train_loss': 323.2255859375, 'train_avg_loss': 0.6733866373697917, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 01:27:18 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #79) -------------
2025-10-10 01:27:18 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=79 aidx=2 | s=5 (candidates=7)
2025-10-10 01:27:18 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 9, 35, 12, 33] (from 7)
2025-10-10 01:27:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:27:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:27:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 01:27:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:27:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:27:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:27:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:27:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:27:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:27:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:27:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.296387, avg_loss=0.673534, seen=480, correct=277, accuracy=0.577083
2025-10-10 01:27:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:27:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:27:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:27:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2118MB allocated=1955MB
2025-10-10 01:27:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.08427083492279, 'train_avg_loss': 0.6590355902910232, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 01:27:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.29638671875, 'train_avg_loss': 0.6735341389973958, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:27:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 323.29638671875, 'train_avg_loss': 0.6735341389973958, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:27:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:27:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:27:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:28:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:28:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.043091, avg_loss=0.662590, seen=480, correct=286, accuracy=0.595833
2025-10-10 01:28:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:28:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:28:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:28:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2120MB allocated=1955MB
2025-10-10 01:28:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.33942192792892, 'train_avg_loss': 0.669495182732741, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 01:28:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.0430908203125, 'train_avg_loss': 0.6625897725423177, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 01:28:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 318.0430908203125, 'train_avg_loss': 0.6625897725423177, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 01:28:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:28:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:28:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:29:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:29:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.224579, avg_loss=0.696301, seen=480, correct=254, accuracy=0.529167
2025-10-10 01:29:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:29:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:29:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:29:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2162MB allocated=1955MB
2025-10-10 01:29:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.53462672233582, 'train_avg_loss': 0.7044552226861318, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 01:29:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2245788574219, 'train_avg_loss': 0.6963012059529622, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 01:29:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 334.2245788574219, 'train_avg_loss': 0.6963012059529622, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 01:29:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:29:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:29:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:29:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:29:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.071655, avg_loss=0.685566, seen=480, correct=269, accuracy=0.560417
2025-10-10 01:29:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:29:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:29:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:29:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2112MB allocated=1955MB
2025-10-10 01:29:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.53627407550812, 'train_avg_loss': 0.696135617295901, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 01:29:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0716552734375, 'train_avg_loss': 0.6855659484863281, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 01:29:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 329.0716552734375, 'train_avg_loss': 0.6855659484863281, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 01:29:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:29:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:29:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #79, planning to set LR to 1.00e-05
2025-10-10 01:29:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:29:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:29:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:29:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:29:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:29:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:30:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:30:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.313782, avg_loss=0.661070, seen=480, correct=292, accuracy=0.608333
2025-10-10 01:30:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:30:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:30:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:30:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=79 reserved=2112MB allocated=1955MB
2025-10-10 01:30:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 79, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.3964319229126, 'train_avg_loss': 0.653303599357605, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 01:30:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 79, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.31378173828125, 'train_avg_loss': 0.6610703786214193, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 01:30:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 79, 'Results_raw': {'train_total': 480, 'train_loss': 317.31378173828125, 'train_avg_loss': 0.6610703786214193, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 01:30:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #80) -------------
2025-10-10 01:30:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=80 aidx=2 | s=5 (candidates=7)
2025-10-10 01:30:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 9, 35, 7, 33] (from 7)
2025-10-10 01:30:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:30:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:30:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:31:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:31:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.201599, avg_loss=0.660837, seen=480, correct=296, accuracy=0.616667
2025-10-10 01:31:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:31:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:31:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:31:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2124MB allocated=1955MB
2025-10-10 01:31:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.5088621377945, 'train_avg_loss': 0.6625738511482875, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:31:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.20159912109375, 'train_avg_loss': 0.660836664835612, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 01:31:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 317.20159912109375, 'train_avg_loss': 0.660836664835612, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 01:31:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:31:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:31:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:31:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:31:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.893677, avg_loss=0.662278, seen=480, correct=289, accuracy=0.602083
2025-10-10 01:31:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:31:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:31:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:31:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2120MB allocated=1955MB
2025-10-10 01:31:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.4875499010086, 'train_avg_loss': 0.6623962491750717, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 01:31:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8936767578125, 'train_avg_loss': 0.6622784932454427, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 01:31:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 317.8936767578125, 'train_avg_loss': 0.6622784932454427, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 01:31:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:31:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:31:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:32:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:32:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.904022, avg_loss=0.697717, seen=480, correct=266, accuracy=0.554167
2025-10-10 01:32:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:32:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:32:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:32:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2162MB allocated=1955MB
2025-10-10 01:32:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2482470870018, 'train_avg_loss': 0.7104020590583483, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 01:32:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9040222167969, 'train_avg_loss': 0.6977167129516602, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 01:32:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 334.9040222167969, 'train_avg_loss': 0.6977167129516602, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 01:32:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:32:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:32:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:33:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:33:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.040741, avg_loss=0.675085, seen=480, correct=277, accuracy=0.577083
2025-10-10 01:33:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:33:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:33:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:33:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2120MB allocated=1955MB
2025-10-10 01:33:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.92072129249573, 'train_avg_loss': 0.699339344104131, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:33:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0407409667969, 'train_avg_loss': 0.6750848770141602, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:33:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 324.0407409667969, 'train_avg_loss': 0.6750848770141602, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:33:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:33:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:33:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #80, planning to set LR to 1.00e-05
2025-10-10 01:33:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:33:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:33:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:33:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:33:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:33:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:33:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:33:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.559937, avg_loss=0.651167, seen=480, correct=294, accuracy=0.612500
2025-10-10 01:33:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:33:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:34:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:34:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=80 reserved=2112MB allocated=1955MB
2025-10-10 01:34:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 80, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.53122746944427, 'train_avg_loss': 0.646093562245369, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 01:34:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 80, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.5599365234375, 'train_avg_loss': 0.6511665344238281, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 01:34:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 80, 'Results_raw': {'train_total': 480, 'train_loss': 312.5599365234375, 'train_avg_loss': 0.6511665344238281, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 01:34:01 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #81) -------------
2025-10-10 01:34:01 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=81 aidx=2 | s=5 (candidates=7)
2025-10-10 01:34:01 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[42, 33, 12, 7, 9] (from 7)
2025-10-10 01:34:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:34:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:34:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 01:34:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:34:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:34:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:34:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:34:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:34:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:34:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:34:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.917480, avg_loss=0.668578, seen=480, correct=285, accuracy=0.593750
2025-10-10 01:34:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:34:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:34:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:34:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2118MB allocated=1955MB
2025-10-10 01:34:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.34200936555862, 'train_avg_loss': 0.6528500780463219, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 01:34:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.91748046875, 'train_avg_loss': 0.6685780843098958, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 01:34:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 320.91748046875, 'train_avg_loss': 0.6685780843098958, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 01:34:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:34:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:34:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:35:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:35:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.219604, avg_loss=0.635874, seen=480, correct=309, accuracy=0.643750
2025-10-10 01:35:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:35:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:35:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:35:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2112MB allocated=1955MB
2025-10-10 01:35:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.52067631483078, 'train_avg_loss': 0.6293389692902565, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 01:35:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.2196044921875, 'train_avg_loss': 0.6358741760253906, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 01:35:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 305.2196044921875, 'train_avg_loss': 0.6358741760253906, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 01:35:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:35:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:35:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:35:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:35:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.122070, avg_loss=0.689838, seen=480, correct=264, accuracy=0.550000
2025-10-10 01:35:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:35:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:36:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:36:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2112MB allocated=1955MB
2025-10-10 01:36:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.15386140346527, 'train_avg_loss': 0.7096155116955439, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 01:36:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1220703125, 'train_avg_loss': 0.689837646484375, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 01:36:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 331.1220703125, 'train_avg_loss': 0.689837646484375, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 01:36:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:36:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:36:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:36:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:36:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.886414, avg_loss=0.672680, seen=480, correct=277, accuracy=0.577083
2025-10-10 01:36:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:36:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:36:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:36:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2120MB allocated=1955MB
2025-10-10 01:36:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.89423060417175, 'train_avg_loss': 0.6991185883680979, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 01:36:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.88641357421875, 'train_avg_loss': 0.6726800282796224, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:36:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 322.88641357421875, 'train_avg_loss': 0.6726800282796224, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 01:36:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #81, planning to set LR to 1.00e-05
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:36:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:36:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:37:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:37:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.008179, avg_loss=0.662517, seen=480, correct=296, accuracy=0.616667
2025-10-10 01:37:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:37:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:37:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:37:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=81 reserved=2120MB allocated=1955MB
2025-10-10 01:37:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 81, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.96477842330933, 'train_avg_loss': 0.6580398201942443, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 01:37:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 81, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.0081787109375, 'train_avg_loss': 0.6625170389811198, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 01:37:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 81, 'Results_raw': {'train_total': 480, 'train_loss': 318.0081787109375, 'train_avg_loss': 0.6625170389811198, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 01:37:24 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #82) -------------
2025-10-10 01:37:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=82 aidx=2 | s=5 (candidates=7)
2025-10-10 01:37:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 12, 33, 42, 9] (from 7)
2025-10-10 01:37:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:37:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:37:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:38:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:38:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.422699, avg_loss=0.667547, seen=480, correct=287, accuracy=0.597917
2025-10-10 01:38:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:38:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:38:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:38:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2120MB allocated=1955MB
2025-10-10 01:38:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.24646240472794, 'train_avg_loss': 0.7103871867060662, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 01:38:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.4226989746094, 'train_avg_loss': 0.6675472895304362, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 01:38:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 320.4226989746094, 'train_avg_loss': 0.6675472895304362, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 01:38:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:38:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:38:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:38:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:38:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.309387, avg_loss=0.688145, seen=480, correct=264, accuracy=0.550000
2025-10-10 01:38:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:38:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:38:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:38:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2112MB allocated=1955MB
2025-10-10 01:38:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.76565700769424, 'train_avg_loss': 0.7063804750641187, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:38:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.30938720703125, 'train_avg_loss': 0.6881445566813151, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 01:38:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 330.30938720703125, 'train_avg_loss': 0.6881445566813151, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 01:38:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:38:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:38:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:39:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:39:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.411255, avg_loss=0.642523, seen=480, correct=297, accuracy=0.618750
2025-10-10 01:39:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:39:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:39:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:39:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2112MB allocated=1955MB
2025-10-10 01:39:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.60779696702957, 'train_avg_loss': 0.6300649747252465, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 01:39:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.4112548828125, 'train_avg_loss': 0.642523447672526, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 01:39:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 308.4112548828125, 'train_avg_loss': 0.642523447672526, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 01:39:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:39:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:39:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 01:39:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:39:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:39:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:39:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:39:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:39:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:39:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:39:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.706573, avg_loss=0.668139, seen=480, correct=283, accuracy=0.589583
2025-10-10 01:39:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:39:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:40:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:40:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2118MB allocated=1955MB
2025-10-10 01:40:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.1100087761879, 'train_avg_loss': 0.6592500731348991, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 01:40:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.7065734863281, 'train_avg_loss': 0.6681386947631835, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 01:40:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 320.7065734863281, 'train_avg_loss': 0.6681386947631835, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 01:40:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #82, planning to set LR to 1.00e-05
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:40:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:40:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:40:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:40:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.749115, avg_loss=0.651561, seen=480, correct=299, accuracy=0.622917
2025-10-10 01:40:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:40:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:40:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:40:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=82 reserved=2120MB allocated=1955MB
2025-10-10 01:40:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 82, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.58935379981995, 'train_avg_loss': 0.6549112816651662, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 01:40:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 82, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.7491149902344, 'train_avg_loss': 0.651560656229655, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 01:40:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 82, 'Results_raw': {'train_total': 480, 'train_loss': 312.7491149902344, 'train_avg_loss': 0.651560656229655, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 01:40:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #83) -------------
2025-10-10 01:40:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=83 aidx=2 | s=5 (candidates=7)
2025-10-10 01:40:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 42, 17, 33, 9] (from 7)
2025-10-10 01:40:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:40:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:40:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:41:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:41:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.986084, avg_loss=0.702054, seen=480, correct=259, accuracy=0.539583
2025-10-10 01:41:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:41:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:41:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:41:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2162MB allocated=1955MB
2025-10-10 01:41:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.36451822519302, 'train_avg_loss': 0.7113709852099419, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 01:41:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.986083984375, 'train_avg_loss': 0.7020543416341146, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 01:41:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 336.986083984375, 'train_avg_loss': 0.7020543416341146, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 01:41:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:41:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:41:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 01:41:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:41:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:41:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:41:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:41:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:41:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:41:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:41:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.894470, avg_loss=0.668530, seen=480, correct=287, accuracy=0.597917
2025-10-10 01:41:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:41:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:42:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:42:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2118MB allocated=1955MB
2025-10-10 01:42:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.91939324140549, 'train_avg_loss': 0.6576616103450458, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 01:42:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.89447021484375, 'train_avg_loss': 0.6685301462809244, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 01:42:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 320.89447021484375, 'train_avg_loss': 0.6685301462809244, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 01:42:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:42:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:42:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:42:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:42:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.733826, avg_loss=0.657779, seen=480, correct=300, accuracy=0.625000
2025-10-10 01:42:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:42:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:42:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:42:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2126MB allocated=1955MB
2025-10-10 01:42:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.00645768642426, 'train_avg_loss': 0.6500538140535355, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 01:42:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.73382568359375, 'train_avg_loss': 0.657778803507487, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 01:42:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 315.73382568359375, 'train_avg_loss': 0.657778803507487, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 01:42:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:42:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:42:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:43:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:43:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.577423, avg_loss=0.647036, seen=480, correct=296, accuracy=0.616667
2025-10-10 01:43:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:43:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:43:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:43:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2112MB allocated=1955MB
2025-10-10 01:43:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.57518702745438, 'train_avg_loss': 0.6297932252287864, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 01:43:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.5774230957031, 'train_avg_loss': 0.6470362981160481, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 01:43:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 310.5774230957031, 'train_avg_loss': 0.6470362981160481, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 01:43:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #83, planning to set LR to 1.00e-05
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:43:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:43:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:43:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:43:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.424744, avg_loss=0.642552, seen=480, correct=306, accuracy=0.637500
2025-10-10 01:43:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:43:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:43:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:43:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=83 reserved=2120MB allocated=1955MB
2025-10-10 01:43:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 83, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.80733770132065, 'train_avg_loss': 0.6483944808443387, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 01:43:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 83, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.42474365234375, 'train_avg_loss': 0.6425515492757161, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 01:43:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 83, 'Results_raw': {'train_total': 480, 'train_loss': 308.42474365234375, 'train_avg_loss': 0.6425515492757161, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 01:43:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #84) -------------
2025-10-10 01:43:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=84 aidx=2 | s=5 (candidates=7)
2025-10-10 01:43:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 17, 33, 12, 9] (from 7)
2025-10-10 01:43:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:43:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:43:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:44:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:44:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.995361, avg_loss=0.704157, seen=480, correct=262, accuracy=0.545833
2025-10-10 01:44:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:44:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:44:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:44:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2162MB allocated=1955MB
2025-10-10 01:44:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.7040730714798, 'train_avg_loss': 0.7142006089289983, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 01:44:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.995361328125, 'train_avg_loss': 0.704157002766927, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 01:44:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 337.995361328125, 'train_avg_loss': 0.704157002766927, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 01:44:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:44:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:44:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 01:44:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:44:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:44:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:44:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:44:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:44:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:45:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:45:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.241577, avg_loss=0.656753, seen=480, correct=299, accuracy=0.622917
2025-10-10 01:45:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:45:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:45:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:45:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2126MB allocated=1955MB
2025-10-10 01:45:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.54200267791748, 'train_avg_loss': 0.6461833556493123, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 01:45:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.2415771484375, 'train_avg_loss': 0.6567532857259114, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 01:45:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 315.2415771484375, 'train_avg_loss': 0.6567532857259114, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 01:45:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:45:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:45:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:45:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:45:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.621155, avg_loss=0.645044, seen=480, correct=294, accuracy=0.612500
2025-10-10 01:45:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:45:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:45:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:45:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2112MB allocated=1955MB
2025-10-10 01:45:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.07211697101593, 'train_avg_loss': 0.6256009747584661, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 01:45:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.62115478515625, 'train_avg_loss': 0.6450440724690755, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 01:45:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 309.62115478515625, 'train_avg_loss': 0.6450440724690755, 'train_seen': 480, 'train_correct': 294, 'train_acc': 0.6125}}
2025-10-10 01:45:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:45:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:45:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 01:45:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:45:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:46:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:46:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:46:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:46:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:46:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:46:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.039154, avg_loss=0.689665, seen=480, correct=271, accuracy=0.564583
2025-10-10 01:46:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:46:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:46:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:46:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2112MB allocated=1955MB
2025-10-10 01:46:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.67116671800613, 'train_avg_loss': 0.7055930559833844, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 01:46:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.0391540527344, 'train_avg_loss': 0.6896649042765299, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 01:46:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 331.0391540527344, 'train_avg_loss': 0.6896649042765299, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 01:46:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #84, planning to set LR to 1.00e-05
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:46:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:46:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:47:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:47:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.894318, avg_loss=0.633113, seen=480, correct=309, accuracy=0.643750
2025-10-10 01:47:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:47:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:47:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:47:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=84 reserved=2120MB allocated=1955MB
2025-10-10 01:47:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 84, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.36340725421906, 'train_avg_loss': 0.6363617271184921, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 01:47:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 84, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.8943176269531, 'train_avg_loss': 0.6331131617228191, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 01:47:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 84, 'Results_raw': {'train_total': 480, 'train_loss': 303.8943176269531, 'train_avg_loss': 0.6331131617228191, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 01:47:20 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #85) -------------
2025-10-10 01:47:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=85 aidx=2 | s=5 (candidates=7)
2025-10-10 01:47:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[7, 42, 17, 12, 33] (from 7)
2025-10-10 01:47:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:47:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:47:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:47:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:47:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.942596, avg_loss=0.670714, seen=480, correct=286, accuracy=0.595833
2025-10-10 01:47:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:47:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:48:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:48:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2120MB allocated=1955MB
2025-10-10 01:48:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.56871795654297, 'train_avg_loss': 0.7214059829711914, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 01:48:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.9425964355469, 'train_avg_loss': 0.670713742574056, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 01:48:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 321.9425964355469, 'train_avg_loss': 0.670713742574056, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 01:48:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:48:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:48:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:48:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:48:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.356995, avg_loss=0.675744, seen=480, correct=283, accuracy=0.589583
2025-10-10 01:48:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:48:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:48:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:48:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2118MB allocated=1955MB
2025-10-10 01:48:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.47269695997238, 'train_avg_loss': 0.6622724746664365, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 01:48:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.35699462890625, 'train_avg_loss': 0.6757437388102213, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 01:48:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 324.35699462890625, 'train_avg_loss': 0.6757437388102213, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 01:48:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:48:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:48:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:49:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:49:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.362244, avg_loss=0.657005, seen=480, correct=304, accuracy=0.633333
2025-10-10 01:49:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:49:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:49:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:49:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2126MB allocated=1955MB
2025-10-10 01:49:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.24459302425385, 'train_avg_loss': 0.643704941868782, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 01:49:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.36224365234375, 'train_avg_loss': 0.6570046742757162, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 01:49:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 315.36224365234375, 'train_avg_loss': 0.6570046742757162, 'train_seen': 480, 'train_correct': 304, 'train_acc': 0.6333333333333333}}
2025-10-10 01:49:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:49:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:49:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:49:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:49:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.310303, avg_loss=0.694396, seen=480, correct=274, accuracy=0.570833
2025-10-10 01:49:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:49:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:49:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:49:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2112MB allocated=1955MB
2025-10-10 01:49:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.79469364881516, 'train_avg_loss': 0.714955780406793, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:49:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.310302734375, 'train_avg_loss': 0.6943964640299479, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 01:49:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 333.310302734375, 'train_avg_loss': 0.6943964640299479, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 01:49:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #85, planning to set LR to 1.00e-05
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:49:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:49:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:50:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:50:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.703735, avg_loss=0.649383, seen=480, correct=295, accuracy=0.614583
2025-10-10 01:50:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:50:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:50:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:50:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=85 reserved=2112MB allocated=1955MB
2025-10-10 01:50:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 85, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.96325141191483, 'train_avg_loss': 0.6246937617659569, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 01:50:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 85, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.7037353515625, 'train_avg_loss': 0.6493827819824218, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 01:50:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 85, 'Results_raw': {'train_total': 480, 'train_loss': 311.7037353515625, 'train_avg_loss': 0.6493827819824218, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 01:50:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #86) -------------
2025-10-10 01:50:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=86 aidx=2 | s=5 (candidates=7)
2025-10-10 01:50:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[9, 35, 33, 12, 17] (from 7)
2025-10-10 01:50:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:50:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:50:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 01:50:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:50:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:50:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:50:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:50:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:50:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:51:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:51:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.883545, avg_loss=0.624757, seen=480, correct=316, accuracy=0.658333
2025-10-10 01:51:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:51:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:51:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:51:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2118MB allocated=1955MB
2025-10-10 01:51:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.29590743780136, 'train_avg_loss': 0.619132561981678, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 01:51:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.883544921875, 'train_avg_loss': 0.6247573852539062, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 01:51:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 299.883544921875, 'train_avg_loss': 0.6247573852539062, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 01:51:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:51:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:51:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:51:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:51:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.105774, avg_loss=0.712720, seen=480, correct=261, accuracy=0.543750
2025-10-10 01:51:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:51:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:52:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:52:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2162MB allocated=1955MB
2025-10-10 01:52:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.11971861124039, 'train_avg_loss': 0.7176643217603366, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:52:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.10577392578125, 'train_avg_loss': 0.7127203623453776, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 01:52:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 342.10577392578125, 'train_avg_loss': 0.7127203623453776, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 01:52:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:52:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:52:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:52:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:52:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.268494, avg_loss=0.631809, seen=480, correct=317, accuracy=0.660417
2025-10-10 01:52:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:52:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:52:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:52:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2112MB allocated=1955MB
2025-10-10 01:52:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.47720885276794, 'train_avg_loss': 0.6206434071063995, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 01:52:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.26849365234375, 'train_avg_loss': 0.6318093617757161, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 01:52:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 303.26849365234375, 'train_avg_loss': 0.6318093617757161, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 01:52:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:52:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:52:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:53:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:53:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.901489, avg_loss=0.687295, seen=480, correct=275, accuracy=0.572917
2025-10-10 01:53:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:53:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:53:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:53:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2112MB allocated=1955MB
2025-10-10 01:53:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.11766225099564, 'train_avg_loss': 0.7176471854249636, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 01:53:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.9014892578125, 'train_avg_loss': 0.6872947692871094, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 01:53:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 329.9014892578125, 'train_avg_loss': 0.6872947692871094, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 01:53:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #86, planning to set LR to 1.00e-05
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:53:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:53:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:54:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:54:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.999817, avg_loss=0.650000, seen=480, correct=299, accuracy=0.622917
2025-10-10 01:54:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:54:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:54:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:54:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=86 reserved=2126MB allocated=1955MB
2025-10-10 01:54:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 86, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.95646327733994, 'train_avg_loss': 0.6496371939778328, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 01:54:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 86, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.99981689453125, 'train_avg_loss': 0.6499996185302734, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 01:54:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 86, 'Results_raw': {'train_total': 480, 'train_loss': 311.99981689453125, 'train_avg_loss': 0.6499996185302734, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 01:54:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #87) -------------
2025-10-10 01:54:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=87 aidx=2 | s=5 (candidates=7)
2025-10-10 01:54:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[12, 7, 33, 35, 42] (from 7)
2025-10-10 01:54:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 01:54:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:54:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:54:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:54:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.443390, avg_loss=0.692590, seen=480, correct=273, accuracy=0.568750
2025-10-10 01:54:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:54:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:54:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:54:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2112MB allocated=1955MB
2025-10-10 01:54:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1931101679802, 'train_avg_loss': 0.7099425847331683, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 01:54:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.4433898925781, 'train_avg_loss': 0.6925903956095377, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 01:54:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 332.4433898925781, 'train_avg_loss': 0.6925903956095377, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 01:54:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:54:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:54:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:55:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:55:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.213257, avg_loss=0.671278, seen=480, correct=281, accuracy=0.585417
2025-10-10 01:55:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:55:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:55:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:55:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2120MB allocated=1955MB
2025-10-10 01:55:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.90142440795898, 'train_avg_loss': 0.7158452033996582, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 01:55:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.2132568359375, 'train_avg_loss': 0.6712776184082031, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 01:55:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 322.2132568359375, 'train_avg_loss': 0.6712776184082031, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 01:55:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:55:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:55:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:56:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:56:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.194214, avg_loss=0.635821, seen=480, correct=297, accuracy=0.618750
2025-10-10 01:56:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:56:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:56:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:56:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2112MB allocated=1955MB
2025-10-10 01:56:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.85788923501968, 'train_avg_loss': 0.6154824102918307, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 01:56:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.1942138671875, 'train_avg_loss': 0.635821278889974, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 01:56:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 305.1942138671875, 'train_avg_loss': 0.635821278889974, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 01:56:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:56:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:56:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 01:56:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 01:56:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:56:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:56:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:56:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:56:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:56:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:56:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.178650, avg_loss=0.708706, seen=480, correct=256, accuracy=0.533333
2025-10-10 01:56:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:56:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:56:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:56:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2162MB allocated=1955MB
2025-10-10 01:56:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.06318181753159, 'train_avg_loss': 0.7171931818127633, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 01:56:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.17864990234375, 'train_avg_loss': 0.7087055206298828, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 01:56:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 340.17864990234375, 'train_avg_loss': 0.7087055206298828, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 01:56:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #87, planning to set LR to 1.00e-05
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 01:56:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:56:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:57:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:57:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.108917, avg_loss=0.668977, seen=480, correct=291, accuracy=0.606250
2025-10-10 01:57:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:57:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:57:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:57:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=87 reserved=2118MB allocated=1955MB
2025-10-10 01:57:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 87, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.98345482349396, 'train_avg_loss': 0.6581954568624496, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 01:57:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 87, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.1089172363281, 'train_avg_loss': 0.6689769109090169, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 01:57:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 87, 'Results_raw': {'train_total': 480, 'train_loss': 321.1089172363281, 'train_avg_loss': 0.6689769109090169, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 01:57:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #88) -------------
2025-10-10 01:57:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=88 aidx=2 | s=5 (candidates=7)
2025-10-10 01:57:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[17, 33, 9, 7, 42] (from 7)
2025-10-10 01:57:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 01:57:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:57:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:58:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:58:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.908661, avg_loss=0.641476, seen=480, correct=303, accuracy=0.631250
2025-10-10 01:58:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:58:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:58:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:58:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2124MB allocated=1955MB
2025-10-10 01:58:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.37655901908875, 'train_avg_loss': 0.6364713251590729, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 01:58:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.9086608886719, 'train_avg_loss': 0.6414763768513997, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 01:58:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 307.9086608886719, 'train_avg_loss': 0.6414763768513997, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 01:58:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:58:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:58:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 01:58:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 01:58:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:58:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:58:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:58:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:58:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:58:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:58:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.656311, avg_loss=0.638867, seen=480, correct=300, accuracy=0.625000
2025-10-10 01:58:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:58:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:58:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:58:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2112MB allocated=1955MB
2025-10-10 01:58:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.7429148554802, 'train_avg_loss': 0.6228576237956683, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 01:58:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.65631103515625, 'train_avg_loss': 0.6388673146565755, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 01:58:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 306.65631103515625, 'train_avg_loss': 0.6388673146565755, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 01:58:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 01:58:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:58:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 01:59:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 01:59:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.961853, avg_loss=0.627004, seen=480, correct=312, accuracy=0.650000
2025-10-10 01:59:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 01:59:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:59:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 01:59:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2120MB allocated=1955MB
2025-10-10 01:59:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.57151612639427, 'train_avg_loss': 0.6380959677199523, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 01:59:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.96185302734375, 'train_avg_loss': 0.6270038604736328, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 01:59:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 300.96185302734375, 'train_avg_loss': 0.6270038604736328, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 01:59:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 01:59:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 01:59:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:00:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:00:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.442505, avg_loss=0.667589, seen=480, correct=284, accuracy=0.591667
2025-10-10 02:00:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:00:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:00:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:00:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2120MB allocated=1955MB
2025-10-10 02:00:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.55021786689758, 'train_avg_loss': 0.7129184822241466, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:00:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.4425048828125, 'train_avg_loss': 0.6675885518391927, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 02:00:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 320.4425048828125, 'train_avg_loss': 0.6675885518391927, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 02:00:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #88, planning to set LR to 1.00e-05
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 02:00:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:00:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:00:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:00:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.323090, avg_loss=0.654840, seen=480, correct=296, accuracy=0.616667
2025-10-10 02:00:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:00:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:00:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:00:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=88 reserved=2118MB allocated=1955MB
2025-10-10 02:00:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 88, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.27618891000748, 'train_avg_loss': 0.643968240916729, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 02:00:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 88, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.3230895996094, 'train_avg_loss': 0.6548397699991862, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 02:00:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 88, 'Results_raw': {'train_total': 480, 'train_loss': 314.3230895996094, 'train_avg_loss': 0.6548397699991862, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 02:00:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #89) -------------
2025-10-10 02:00:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=89 aidx=2 | s=5 (candidates=7)
2025-10-10 02:00:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 12, 35, 9, 17] (from 7)
2025-10-10 02:00:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 02:00:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:00:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:01:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:01:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.571014, avg_loss=0.636606, seen=480, correct=309, accuracy=0.643750
2025-10-10 02:01:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:01:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:01:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:01:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2112MB allocated=1955MB
2025-10-10 02:01:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.46569788455963, 'train_avg_loss': 0.6205474823713303, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 02:01:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.5710144042969, 'train_avg_loss': 0.6366062800089518, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 02:01:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 305.5710144042969, 'train_avg_loss': 0.6366062800089518, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 02:01:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 02:01:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:01:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:02:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:02:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.727264, avg_loss=0.691098, seen=480, correct=274, accuracy=0.570833
2025-10-10 02:02:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:02:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:02:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:02:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2112MB allocated=1955MB
2025-10-10 02:02:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.55765229463577, 'train_avg_loss': 0.7129804357886315, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:02:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.7272644042969, 'train_avg_loss': 0.6910984675089519, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 02:02:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 331.7272644042969, 'train_avg_loss': 0.6910984675089519, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 02:02:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 02:02:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:02:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:02:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:02:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.330353, avg_loss=0.700688, seen=480, correct=261, accuracy=0.543750
2025-10-10 02:02:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:02:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:02:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:02:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2162MB allocated=1955MB
2025-10-10 02:02:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.4599032998085, 'train_avg_loss': 0.7121658608317375, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 02:02:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.3303527832031, 'train_avg_loss': 0.7006882349650065, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 02:02:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 336.3303527832031, 'train_avg_loss': 0.7006882349650065, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 02:02:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:02:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:02:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 02:02:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=893, total=3572)
2025-10-10 02:02:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:02:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:02:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:02:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:02:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=447, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:03:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:03:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.194214, avg_loss=0.629571, seen=480, correct=315, accuracy=0.656250
2025-10-10 02:03:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:03:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:03:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:03:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2120MB allocated=1955MB
2025-10-10 02:03:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #9', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.42044737935066, 'train_avg_loss': 0.6451703948279222, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 02:03:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #9', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.1942138671875, 'train_avg_loss': 0.629571278889974, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 02:03:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #9', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 302.1942138671875, 'train_avg_loss': 0.629571278889974, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 02:03:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #89, planning to set LR to 1.00e-05
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 02:03:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:03:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:04:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:04:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.597778, avg_loss=0.640829, seen=480, correct=302, accuracy=0.629167
2025-10-10 02:04:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:04:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:04:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:04:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=89 reserved=2126MB allocated=1955MB
2025-10-10 02:04:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 89, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.7396149635315, 'train_avg_loss': 0.6394967913627625, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 02:04:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 89, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.5977783203125, 'train_avg_loss': 0.6408287048339844, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 02:04:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 89, 'Results_raw': {'train_total': 480, 'train_loss': 307.5977783203125, 'train_avg_loss': 0.6408287048339844, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 02:04:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #90) -------------
2025-10-10 02:04:05 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=90 aidx=2 | s=5 (candidates=7)
2025-10-10 02:04:05 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[33, 17, 42, 35, 7] (from 7)
2025-10-10 02:04:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:04:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:04:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 02:04:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 02:04:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:04:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:04:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:04:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:04:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:04:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:04:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.705688, avg_loss=0.638970, seen=480, correct=307, accuracy=0.639583
2025-10-10 02:04:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:04:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:04:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:04:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2112MB allocated=1955MB
2025-10-10 02:04:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.31497246026993, 'train_avg_loss': 0.6192914371689161, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 02:04:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.7056884765625, 'train_avg_loss': 0.6389701843261719, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 02:04:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 306.7056884765625, 'train_avg_loss': 0.6389701843261719, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 02:04:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 02:04:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:04:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:05:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:05:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.104370, avg_loss=0.631467, seen=480, correct=310, accuracy=0.645833
2025-10-10 02:05:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:05:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:05:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:05:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2124MB allocated=1955MB
2025-10-10 02:05:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.58167564868927, 'train_avg_loss': 0.6298472970724106, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 02:05:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.1043701171875, 'train_avg_loss': 0.6314674377441406, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 02:05:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 303.1043701171875, 'train_avg_loss': 0.6314674377441406, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 02:05:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1443, total=5772)
2025-10-10 02:05:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:05:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=722, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:06:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:06:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=308.717163, avg_loss=0.643161, seen=480, correct=300, accuracy=0.625000
2025-10-10 02:06:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:06:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:06:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:06:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2118MB allocated=1955MB
2025-10-10 02:06:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #42', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.39102005958557, 'train_avg_loss': 0.6199251671632131, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 02:06:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #42', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 308.7171630859375, 'train_avg_loss': 0.6431607564290365, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 02:06:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #42', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 308.7171630859375, 'train_avg_loss': 0.6431607564290365, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 02:06:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 02:06:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:06:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:06:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:06:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.119446, avg_loss=0.700249, seen=480, correct=267, accuracy=0.556250
2025-10-10 02:06:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:06:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:06:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:06:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2164MB allocated=1955MB
2025-10-10 02:06:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.87460082769394, 'train_avg_loss': 0.7239550068974495, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 02:06:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.11944580078125, 'train_avg_loss': 0.7002488454182942, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 02:06:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 336.11944580078125, 'train_avg_loss': 0.7002488454182942, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 02:06:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #90, planning to set LR to 1.00e-05
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 02:06:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:06:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:07:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:07:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.891235, avg_loss=0.668523, seen=480, correct=285, accuracy=0.593750
2025-10-10 02:07:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:07:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:07:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:07:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=90 reserved=2120MB allocated=1955MB
2025-10-10 02:07:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 90, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.1088690161705, 'train_avg_loss': 0.7092405751347541, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 02:07:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 90, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.8912353515625, 'train_avg_loss': 0.6685234069824219, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 02:07:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 90, 'Results_raw': {'train_total': 480, 'train_loss': 320.8912353515625, 'train_avg_loss': 0.6685234069824219, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 02:07:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #91) -------------
2025-10-10 02:07:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=91 aidx=2 | s=5 (candidates=7)
2025-10-10 02:07:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[35, 33, 7, 12, 17] (from 7)
2025-10-10 02:07:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1184, total=4736)
2025-10-10 02:07:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:07:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=592, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:08:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:08:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.323975, avg_loss=0.696508, seen=480, correct=264, accuracy=0.550000
2025-10-10 02:08:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:08:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:08:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:08:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2162MB allocated=1955MB
2025-10-10 02:08:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #35', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.63913434743881, 'train_avg_loss': 0.7136594528953234, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:08:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #35', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.323974609375, 'train_avg_loss': 0.696508280436198, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:08:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #35', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 334.323974609375, 'train_avg_loss': 0.696508280436198, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:08:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:08:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:08:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 02:08:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=353, total=1409)
2025-10-10 02:08:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:08:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:08:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:08:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:08:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=177, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:08:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:08:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.717590, avg_loss=0.632745, seen=480, correct=306, accuracy=0.637500
2025-10-10 02:08:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:08:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:08:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:08:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2112MB allocated=1955MB
2025-10-10 02:08:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #33', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.51333075761795, 'train_avg_loss': 0.6209444229801496, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 02:08:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #33', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.71759033203125, 'train_avg_loss': 0.6327449798583984, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 02:08:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #33', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 303.71759033203125, 'train_avg_loss': 0.6327449798583984, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 02:08:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=272, total=1088)
2025-10-10 02:08:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:08:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=136, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:09:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:09:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.384949, avg_loss=0.652885, seen=480, correct=293, accuracy=0.610417
2025-10-10 02:09:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:09:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:09:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:09:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2120MB allocated=1955MB
2025-10-10 02:09:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #7', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.34136468172073, 'train_avg_loss': 0.6945113723476728, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 02:09:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #7', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.38494873046875, 'train_avg_loss': 0.6528853098551433, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 02:09:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #7', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 313.38494873046875, 'train_avg_loss': 0.6528853098551433, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 02:09:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:09:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:09:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 02:09:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=652, total=2605)
2025-10-10 02:09:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:09:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:09:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:09:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:09:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=326, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:10:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:10:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.343414, avg_loss=0.686132, seen=480, correct=276, accuracy=0.575000
2025-10-10 02:10:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:10:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:10:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:10:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2112MB allocated=1955MB
2025-10-10 02:10:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #12', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.28680437803268, 'train_avg_loss': 0.7190567031502724, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 02:10:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #12', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.3434143066406, 'train_avg_loss': 0.6861321131388346, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 02:10:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #12', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 329.3434143066406, 'train_avg_loss': 0.6861321131388346, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 02:10:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #91, planning to set LR to 1.00e-05
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1471, total=5883)
2025-10-10 02:10:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:10:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=736, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:10:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:10:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.018463, avg_loss=0.631288, seen=480, correct=308, accuracy=0.641667
2025-10-10 02:10:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:10:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:10:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:10:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=91 reserved=2126MB allocated=1955MB
2025-10-10 02:10:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #17', 'Round': 91, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.02747315168381, 'train_avg_loss': 0.6335622762640317, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 02:10:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #17', 'Round': 91, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.0184631347656, 'train_avg_loss': 0.6312884648640951, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 02:10:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #17', 'Round': 91, 'Results_raw': {'train_total': 480, 'train_loss': 303.0184631347656, 'train_avg_loss': 0.6312884648640951, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 02:10:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #92) -------------
2025-10-10 02:10:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=92 aidx=3 | s=5 (candidates=6)
2025-10-10 02:10:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 31, 3, 37, 41] (from 6)
2025-10-10 02:10:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:10:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:10:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 02:10:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:10:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:10:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:10:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:10:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:10:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:11:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:11:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.127258, avg_loss=0.712765, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:11:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:11:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:11:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:11:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2138MB allocated=2022MB
2025-10-10 02:11:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.631875872612, 'train_avg_loss': 0.7135989656050999, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:11:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.12725830078125, 'train_avg_loss': 0.712765121459961, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:11:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 342.12725830078125, 'train_avg_loss': 0.712765121459961, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:11:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:11:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:11:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 02:11:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:11:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:11:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:11:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:11:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:11:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:12:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:12:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.556335, avg_loss=0.713659, seen=480, correct=240, accuracy=0.500000
2025-10-10 02:12:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:12:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:12:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:12:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2148MB allocated=2030MB
2025-10-10 02:12:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.27025699615479, 'train_avg_loss': 0.7022521416346232, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 02:12:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.55633544921875, 'train_avg_loss': 0.7136590321858723, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 02:12:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 342.55633544921875, 'train_avg_loss': 0.7136590321858723, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 02:12:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:12:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:12:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 02:12:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:12:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:12:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:12:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:12:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:12:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:12:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:12:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.421814, avg_loss=0.717545, seen=480, correct=229, accuracy=0.477083
2025-10-10 02:12:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:12:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:12:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:12:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2172MB allocated=2039MB
2025-10-10 02:12:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2865115404129, 'train_avg_loss': 0.7107209295034409, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 02:12:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.42181396484375, 'train_avg_loss': 0.7175454457600912, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 02:12:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 344.42181396484375, 'train_avg_loss': 0.7175454457600912, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 02:12:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:12:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:12:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 02:12:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:12:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:12:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:12:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:12:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:12:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:13:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:13:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.077667, avg_loss=0.718912, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:13:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:13:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:13:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:13:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2134MB allocated=2047MB
2025-10-10 02:13:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 93.25498658418655, 'train_avg_loss': 0.7771248882015546, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 02:13:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.0776672363281, 'train_avg_loss': 0.7189118067423502, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:13:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 345.0776672363281, 'train_avg_loss': 0.7189118067423502, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:13:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:13:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:13:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #92, planning to set LR to 1.00e-05
2025-10-10 02:13:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:13:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:13:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:13:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:13:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:13:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:14:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:14:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=350.287354, avg_loss=0.729765, seen=480, correct=231, accuracy=0.481250
2025-10-10 02:14:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:14:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:14:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:14:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=92 reserved=2134MB allocated=2056MB
2025-10-10 02:14:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 92, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.79502499103546, 'train_avg_loss': 0.7149585415919621, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 02:14:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 92, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 350.287353515625, 'train_avg_loss': 0.7297653198242188, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 02:14:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 92, 'Results_raw': {'train_total': 480, 'train_loss': 350.287353515625, 'train_avg_loss': 0.7297653198242188, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 02:14:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #93) -------------
2025-10-10 02:14:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=93 aidx=3 | s=5 (candidates=6)
2025-10-10 02:14:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 21, 41, 32, 31] (from 6)
2025-10-10 02:14:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:14:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:14:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:14:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:14:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.491241, avg_loss=0.701023, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:14:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:14:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:14:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:14:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2168MB allocated=2056MB
2025-10-10 02:14:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.59496396780014, 'train_avg_loss': 0.7549580330650012, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:14:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4912414550781, 'train_avg_loss': 0.7010234196980795, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:14:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 336.4912414550781, 'train_avg_loss': 0.7010234196980795, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:14:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:14:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:14:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 02:14:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:14:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:14:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:14:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:14:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:14:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:15:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:15:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.623260, avg_loss=0.695048, seen=480, correct=257, accuracy=0.535417
2025-10-10 02:15:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:15:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:15:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:15:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2228MB allocated=2123MB
2025-10-10 02:15:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.12618625164032, 'train_avg_loss': 0.709384885430336, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:15:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.6232604980469, 'train_avg_loss': 0.695048459370931, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 02:15:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 333.6232604980469, 'train_avg_loss': 0.695048459370931, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 02:15:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:15:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:15:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:16:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:16:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.238251, avg_loss=0.708830, seen=480, correct=238, accuracy=0.495833
2025-10-10 02:16:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:16:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:16:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:16:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2168MB allocated=2064MB
2025-10-10 02:16:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.22693336009979, 'train_avg_loss': 0.6935577780008316, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:16:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.2382507324219, 'train_avg_loss': 0.708829689025879, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 02:16:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 340.2382507324219, 'train_avg_loss': 0.708829689025879, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 02:16:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:16:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:16:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:16:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:16:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.103577, avg_loss=0.704382, seen=480, correct=247, accuracy=0.514583
2025-10-10 02:16:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:16:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:16:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:16:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2168MB allocated=2064MB
2025-10-10 02:16:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6077151298523, 'train_avg_loss': 0.6967309594154358, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 02:16:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.10357666015625, 'train_avg_loss': 0.7043824513753255, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 02:16:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 338.10357666015625, 'train_avg_loss': 0.7043824513753255, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 02:16:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #93, planning to set LR to 1.00e-05
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:16:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:16:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:17:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:17:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.736359, avg_loss=0.709867, seen=480, correct=228, accuracy=0.475000
2025-10-10 02:17:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:17:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:17:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:17:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=93 reserved=2178MB allocated=2064MB
2025-10-10 02:17:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 93, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.71566933393478, 'train_avg_loss': 0.7059639111161232, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 02:17:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 93, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.7363586425781, 'train_avg_loss': 0.7098674138387044, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-10 02:17:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 93, 'Results_raw': {'train_total': 480, 'train_loss': 340.7363586425781, 'train_avg_loss': 0.7098674138387044, 'train_seen': 480, 'train_correct': 228, 'train_acc': 0.475}}
2025-10-10 02:17:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #94) -------------
2025-10-10 02:17:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=94 aidx=3 | s=5 (candidates=6)
2025-10-10 02:17:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 37, 21, 3, 32] (from 6)
2025-10-10 02:17:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:17:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:17:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:18:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:18:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.992706, avg_loss=0.702068, seen=480, correct=244, accuracy=0.508333
2025-10-10 02:18:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:18:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:18:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:18:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2104MB allocated=2006MB
2025-10-10 02:18:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.44770061969757, 'train_avg_loss': 0.6870641718308131, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:18:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9927062988281, 'train_avg_loss': 0.7020681381225586, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 02:18:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 336.9927062988281, 'train_avg_loss': 0.7020681381225586, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 02:18:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:18:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:18:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:18:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:18:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.211823, avg_loss=0.700441, seen=480, correct=259, accuracy=0.539583
2025-10-10 02:18:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:18:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:18:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:18:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2104MB allocated=2006MB
2025-10-10 02:18:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 89.57662934064865, 'train_avg_loss': 0.7464719111720721, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 02:18:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.2118225097656, 'train_avg_loss': 0.7004412968953451, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:18:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 336.2118225097656, 'train_avg_loss': 0.7004412968953451, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:18:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:18:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:18:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:19:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:19:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.234039, avg_loss=0.694238, seen=480, correct=261, accuracy=0.543750
2025-10-10 02:19:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:19:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:19:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:19:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2138MB allocated=2006MB
2025-10-10 02:19:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.96459066867828, 'train_avg_loss': 0.708038255572319, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:19:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.2340393066406, 'train_avg_loss': 0.6942375818888347, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 02:19:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 333.2340393066406, 'train_avg_loss': 0.6942375818888347, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 02:19:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:19:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:19:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:20:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:20:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.153503, avg_loss=0.702403, seen=480, correct=244, accuracy=0.508333
2025-10-10 02:20:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:20:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:20:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:20:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2144MB allocated=2006MB
2025-10-10 02:20:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.78752255439758, 'train_avg_loss': 0.6898960212866465, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 02:20:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.15350341796875, 'train_avg_loss': 0.7024031321207682, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 02:20:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 337.15350341796875, 'train_avg_loss': 0.7024031321207682, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 02:20:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #94, planning to set LR to 1.00e-05
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:20:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:20:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:20:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:20:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.840027, avg_loss=0.699667, seen=480, correct=257, accuracy=0.535417
2025-10-10 02:20:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:20:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:20:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:20:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=94 reserved=2104MB allocated=2006MB
2025-10-10 02:20:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 94, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5552351474762, 'train_avg_loss': 0.687960292895635, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 02:20:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 94, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.84002685546875, 'train_avg_loss': 0.6996667226155598, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 02:20:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 94, 'Results_raw': {'train_total': 480, 'train_loss': 335.84002685546875, 'train_avg_loss': 0.6996667226155598, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 02:20:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #95) -------------
2025-10-10 02:20:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=95 aidx=3 | s=5 (candidates=6)
2025-10-10 02:20:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 41, 21, 31, 37] (from 6)
2025-10-10 02:20:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:20:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:20:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 02:20:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:20:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:20:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:20:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:20:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:20:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:21:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:21:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.050659, avg_loss=0.691772, seen=480, correct=256, accuracy=0.533333
2025-10-10 02:21:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:21:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:21:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:21:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2104MB allocated=2006MB
2025-10-10 02:21:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.75402474403381, 'train_avg_loss': 0.6812835395336151, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:21:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0506591796875, 'train_avg_loss': 0.6917722066243489, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 02:21:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 332.0506591796875, 'train_avg_loss': 0.6917722066243489, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 02:21:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:21:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:21:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 02:21:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:21:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:21:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:21:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:21:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:21:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:22:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:22:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.348572, avg_loss=0.698643, seen=480, correct=253, accuracy=0.527083
2025-10-10 02:22:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:22:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:22:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:22:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2104MB allocated=2006MB
2025-10-10 02:22:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.11318391561508, 'train_avg_loss': 0.6842765326301257, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 02:22:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.34857177734375, 'train_avg_loss': 0.6986428578694661, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 02:22:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 335.34857177734375, 'train_avg_loss': 0.6986428578694661, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 02:22:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:22:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:22:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:22:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:22:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.478516, avg_loss=0.692664, seen=480, correct=254, accuracy=0.529167
2025-10-10 02:22:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:22:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:22:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:22:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2138MB allocated=2006MB
2025-10-10 02:22:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.22410082817078, 'train_avg_loss': 0.7018675069014232, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:22:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.478515625, 'train_avg_loss': 0.69266357421875, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:22:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 332.478515625, 'train_avg_loss': 0.69266357421875, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:22:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:22:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:22:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 02:22:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:22:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:22:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:22:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:22:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:22:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:23:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:23:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.289368, avg_loss=0.702686, seen=480, correct=238, accuracy=0.495833
2025-10-10 02:23:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:23:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:23:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:23:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2106MB allocated=2006MB
2025-10-10 02:23:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.17441248893738, 'train_avg_loss': 0.7014534374078115, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 02:23:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.28936767578125, 'train_avg_loss': 0.7026861826578776, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 02:23:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 337.28936767578125, 'train_avg_loss': 0.7026861826578776, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 02:23:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:23:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:23:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #95, planning to set LR to 1.00e-05
2025-10-10 02:23:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:23:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:23:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:23:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:23:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:23:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:24:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:24:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.625427, avg_loss=0.697136, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:24:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:24:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:24:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:24:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=95 reserved=2104MB allocated=2006MB
2025-10-10 02:24:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 95, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.9383442401886, 'train_avg_loss': 0.7411528686682384, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 02:24:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 95, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.62542724609375, 'train_avg_loss': 0.6971363067626953, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:24:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 95, 'Results_raw': {'train_total': 480, 'train_loss': 334.62542724609375, 'train_avg_loss': 0.6971363067626953, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:24:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #96) -------------
2025-10-10 02:24:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=96 aidx=3 | s=5 (candidates=6)
2025-10-10 02:24:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[31, 21, 41, 3, 32] (from 6)
2025-10-10 02:24:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:24:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:24:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:24:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:24:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.573120, avg_loss=0.709527, seen=480, correct=236, accuracy=0.491667
2025-10-10 02:24:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:24:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:24:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:24:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2106MB allocated=2006MB
2025-10-10 02:24:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.75686377286911, 'train_avg_loss': 0.7063071981072426, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 02:24:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.5731201171875, 'train_avg_loss': 0.709527333577474, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 02:24:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 340.5731201171875, 'train_avg_loss': 0.709527333577474, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 02:24:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:24:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:24:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:25:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:25:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.780396, avg_loss=0.693292, seen=480, correct=260, accuracy=0.541667
2025-10-10 02:25:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:25:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:25:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:25:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2138MB allocated=2006MB
2025-10-10 02:25:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.62374997138977, 'train_avg_loss': 0.7051979164282481, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 02:25:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.7803955078125, 'train_avg_loss': 0.6932924906412761, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 02:25:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 332.7803955078125, 'train_avg_loss': 0.6932924906412761, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 02:25:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:25:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:25:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:26:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:26:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.217133, avg_loss=0.698369, seen=480, correct=247, accuracy=0.514583
2025-10-10 02:26:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:26:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:26:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:26:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2104MB allocated=2006MB
2025-10-10 02:26:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.07149761915207, 'train_avg_loss': 0.6839291468262673, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 02:26:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.2171325683594, 'train_avg_loss': 0.698369026184082, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 02:26:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 335.2171325683594, 'train_avg_loss': 0.698369026184082, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 02:26:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:26:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:26:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 02:26:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:26:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:26:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:26:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:26:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:26:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:26:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:26:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.695465, avg_loss=0.699366, seen=480, correct=248, accuracy=0.516667
2025-10-10 02:26:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:26:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:26:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:26:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2146MB allocated=2006MB
2025-10-10 02:26:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.30036354064941, 'train_avg_loss': 0.6941696961720785, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 02:26:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.6954650878906, 'train_avg_loss': 0.6993655522664388, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 02:26:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 335.6954650878906, 'train_avg_loss': 0.6993655522664388, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 02:26:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:26:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:26:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #96, planning to set LR to 1.00e-05
2025-10-10 02:26:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:26:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:26:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:26:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:26:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:26:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:27:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:27:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.668243, avg_loss=0.695142, seen=480, correct=246, accuracy=0.512500
2025-10-10 02:27:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:27:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:27:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:27:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=96 reserved=2104MB allocated=2006MB
2025-10-10 02:27:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 96, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.95479691028595, 'train_avg_loss': 0.6829566409190496, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 02:27:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 96, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.6682434082031, 'train_avg_loss': 0.6951421737670899, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 02:27:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 96, 'Results_raw': {'train_total': 480, 'train_loss': 333.6682434082031, 'train_avg_loss': 0.6951421737670899, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 02:27:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #97) -------------
2025-10-10 02:27:22 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=97 aidx=3 | s=5 (candidates=6)
2025-10-10 02:27:22 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 32, 31, 21, 3] (from 6)
2025-10-10 02:27:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:27:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:27:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 02:27:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:27:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:27:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:27:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:27:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:27:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:27:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:27:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.443268, avg_loss=0.696757, seen=480, correct=250, accuracy=0.520833
2025-10-10 02:27:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:27:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:27:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:28:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2104MB allocated=2006MB
2025-10-10 02:28:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.2769181728363, 'train_avg_loss': 0.6856409847736359, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:28:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.4432678222656, 'train_avg_loss': 0.6967568079630534, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 02:28:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 334.4432678222656, 'train_avg_loss': 0.6967568079630534, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 02:28:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:28:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:28:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:28:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:28:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.269562, avg_loss=0.685978, seen=480, correct=266, accuracy=0.554167
2025-10-10 02:28:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:28:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:28:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:28:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2104MB allocated=2006MB
2025-10-10 02:28:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.54166281223297, 'train_avg_loss': 0.6795138567686081, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 02:28:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.2695617675781, 'train_avg_loss': 0.6859782536824545, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 02:28:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 329.2695617675781, 'train_avg_loss': 0.6859782536824545, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 02:28:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:28:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:28:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:29:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:29:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.930878, avg_loss=0.701939, seen=480, correct=233, accuracy=0.485417
2025-10-10 02:29:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:29:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:29:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:29:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2106MB allocated=2006MB
2025-10-10 02:29:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.23752450942993, 'train_avg_loss': 0.7019793709119161, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:29:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9308776855469, 'train_avg_loss': 0.7019393285115559, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 02:29:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 336.9308776855469, 'train_avg_loss': 0.7019393285115559, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 02:29:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:29:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:29:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:29:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:29:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.224060, avg_loss=0.692133, seen=480, correct=264, accuracy=0.550000
2025-10-10 02:29:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:29:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:29:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:29:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2138MB allocated=2006MB
2025-10-10 02:29:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.10931473970413, 'train_avg_loss': 0.7009109561642011, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:29:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.22406005859375, 'train_avg_loss': 0.6921334584554036, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:29:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 332.22406005859375, 'train_avg_loss': 0.6921334584554036, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:29:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #97, planning to set LR to 1.00e-05
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:29:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:29:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:30:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:30:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.200165, avg_loss=0.698334, seen=480, correct=241, accuracy=0.502083
2025-10-10 02:30:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:30:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:30:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:30:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=97 reserved=2146MB allocated=2006MB
2025-10-10 02:30:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 97, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.15088653564453, 'train_avg_loss': 0.6929240544637044, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 02:30:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 97, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.2001647949219, 'train_avg_loss': 0.6983336766560873, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 02:30:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 97, 'Results_raw': {'train_total': 480, 'train_loss': 335.2001647949219, 'train_avg_loss': 0.6983336766560873, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 02:30:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #98) -------------
2025-10-10 02:30:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=98 aidx=3 | s=5 (candidates=6)
2025-10-10 02:30:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 32, 37, 41, 31] (from 6)
2025-10-10 02:30:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:30:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:30:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:31:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:31:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.210266, avg_loss=0.692105, seen=480, correct=251, accuracy=0.522917
2025-10-10 02:31:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:31:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:31:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:31:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2146MB allocated=2006MB
2025-10-10 02:31:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.82071673870087, 'train_avg_loss': 0.6901726394891738, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:31:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.21026611328125, 'train_avg_loss': 0.692104721069336, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 02:31:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 332.21026611328125, 'train_avg_loss': 0.692104721069336, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 02:31:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:31:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:31:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:31:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:31:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.719452, avg_loss=0.684832, seen=480, correct=265, accuracy=0.552083
2025-10-10 02:31:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:31:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:31:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:31:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2104MB allocated=2006MB
2025-10-10 02:31:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63195788860321, 'train_avg_loss': 0.68026631573836, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 02:31:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.7194519042969, 'train_avg_loss': 0.6848321914672851, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 02:31:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 328.7194519042969, 'train_avg_loss': 0.6848321914672851, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 02:31:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:32:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:32:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:32:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:32:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.123627, avg_loss=0.689841, seen=480, correct=270, accuracy=0.562500
2025-10-10 02:32:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:32:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:32:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:32:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2104MB allocated=2006MB
2025-10-10 02:32:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.15746533870697, 'train_avg_loss': 0.7263122111558914, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:32:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1236267089844, 'train_avg_loss': 0.6898408889770508, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 02:32:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 331.1236267089844, 'train_avg_loss': 0.6898408889770508, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 02:32:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:32:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:32:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:33:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:33:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.313416, avg_loss=0.698570, seen=480, correct=252, accuracy=0.525000
2025-10-10 02:33:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:33:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:33:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:33:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2104MB allocated=2006MB
2025-10-10 02:33:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.74430549144745, 'train_avg_loss': 0.6895358790953954, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 02:33:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.31341552734375, 'train_avg_loss': 0.6985696156819662, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 02:33:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 335.31341552734375, 'train_avg_loss': 0.6985696156819662, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 02:33:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #98, planning to set LR to 1.00e-05
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:33:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:33:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:33:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:33:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.946808, avg_loss=0.697806, seen=480, correct=242, accuracy=0.504167
2025-10-10 02:33:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:33:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:33:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:33:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=98 reserved=2106MB allocated=2006MB
2025-10-10 02:33:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 98, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.00677621364594, 'train_avg_loss': 0.7000564684470495, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:33:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 98, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9468078613281, 'train_avg_loss': 0.6978058497111003, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 02:33:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 98, 'Results_raw': {'train_total': 480, 'train_loss': 334.9468078613281, 'train_avg_loss': 0.6978058497111003, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 02:33:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #99) -------------
2025-10-10 02:33:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=99 aidx=3 | s=5 (candidates=6)
2025-10-10 02:33:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 21, 37, 3, 31] (from 6)
2025-10-10 02:33:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:34:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:34:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:34:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:34:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.820892, avg_loss=0.695460, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:34:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:34:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:34:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:34:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2104MB allocated=2006MB
2025-10-10 02:34:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32181131839752, 'train_avg_loss': 0.6860150943199793, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:34:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.8208923339844, 'train_avg_loss': 0.6954601923624675, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:34:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 333.8208923339844, 'train_avg_loss': 0.6954601923624675, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:34:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:34:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:34:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:35:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:35:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.944458, avg_loss=0.691551, seen=480, correct=259, accuracy=0.539583
2025-10-10 02:35:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:35:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:35:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:35:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2138MB allocated=2006MB
2025-10-10 02:35:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.87941634654999, 'train_avg_loss': 0.6989951362212499, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 02:35:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.9444580078125, 'train_avg_loss': 0.6915509541829427, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:35:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 331.9444580078125, 'train_avg_loss': 0.6915509541829427, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:35:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:35:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:35:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:35:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:35:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.364441, avg_loss=0.690343, seen=480, correct=267, accuracy=0.556250
2025-10-10 02:35:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:35:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:35:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:35:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2104MB allocated=2006MB
2025-10-10 02:35:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.15651345252991, 'train_avg_loss': 0.7263042787710826, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 02:35:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.36444091796875, 'train_avg_loss': 0.6903425852457682, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 02:35:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 331.36444091796875, 'train_avg_loss': 0.6903425852457682, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 02:35:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:35:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:35:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:36:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:36:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.123840, avg_loss=0.694008, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:36:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:36:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:36:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:36:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2146MB allocated=2006MB
2025-10-10 02:36:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.75136280059814, 'train_avg_loss': 0.6895946900049845, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:36:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.12384033203125, 'train_avg_loss': 0.6940080006917317, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:36:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 333.12384033203125, 'train_avg_loss': 0.6940080006917317, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:36:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #99, planning to set LR to 1.00e-05
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:36:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:36:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:37:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:37:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.482422, avg_loss=0.694755, seen=480, correct=248, accuracy=0.516667
2025-10-10 02:37:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:37:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:37:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:37:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=99 reserved=2106MB allocated=2006MB
2025-10-10 02:37:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 99, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12613487243652, 'train_avg_loss': 0.701051123936971, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:37:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 99, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.482421875, 'train_avg_loss': 0.6947550455729167, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 02:37:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 99, 'Results_raw': {'train_total': 480, 'train_loss': 333.482421875, 'train_avg_loss': 0.6947550455729167, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 02:37:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #100) -------------
2025-10-10 02:37:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=100 aidx=3 | s=5 (candidates=6)
2025-10-10 02:37:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 41, 32, 31, 3] (from 6)
2025-10-10 02:37:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:37:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:37:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:37:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:37:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.587311, avg_loss=0.690807, seen=480, correct=265, accuracy=0.552083
2025-10-10 02:37:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:37:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:37:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:37:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2138MB allocated=2006MB
2025-10-10 02:37:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.66998827457428, 'train_avg_loss': 0.697249902288119, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:37:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5873107910156, 'train_avg_loss': 0.6908068974812825, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 02:37:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 331.5873107910156, 'train_avg_loss': 0.6908068974812825, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 02:37:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:37:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:37:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:38:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:38:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.027466, avg_loss=0.693807, seen=480, correct=251, accuracy=0.522917
2025-10-10 02:38:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:38:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:38:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:38:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2104MB allocated=2006MB
2025-10-10 02:38:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.33612620830536, 'train_avg_loss': 0.6861343850692113, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 02:38:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0274658203125, 'train_avg_loss': 0.6938072204589844, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 02:38:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 333.0274658203125, 'train_avg_loss': 0.6938072204589844, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 02:38:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:38:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:38:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:39:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:39:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.002502, avg_loss=0.683339, seen=480, correct=271, accuracy=0.564583
2025-10-10 02:39:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:39:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:39:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:39:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2104MB allocated=2006MB
2025-10-10 02:39:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.74650859832764, 'train_avg_loss': 0.6812209049860637, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:39:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.00250244140625, 'train_avg_loss': 0.6833385467529297, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 02:39:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 328.00250244140625, 'train_avg_loss': 0.6833385467529297, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 02:39:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:39:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:39:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 02:39:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:39:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:39:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:39:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:39:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:39:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:39:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:39:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.824768, avg_loss=0.689218, seen=480, correct=246, accuracy=0.512500
2025-10-10 02:39:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:39:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:39:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:39:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2106MB allocated=2006MB
2025-10-10 02:39:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3350979089737, 'train_avg_loss': 0.6944591492414475, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:39:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.82476806640625, 'train_avg_loss': 0.689218266805013, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 02:39:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 330.82476806640625, 'train_avg_loss': 0.689218266805013, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 02:39:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:39:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:39:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #100, planning to set LR to 1.00e-05
2025-10-10 02:39:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:39:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:39:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:39:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:39:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:39:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:40:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:40:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.195160, avg_loss=0.694157, seen=480, correct=259, accuracy=0.539583
2025-10-10 02:40:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:40:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:40:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:40:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=100 reserved=2146MB allocated=2006MB
2025-10-10 02:40:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 100, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.63769555091858, 'train_avg_loss': 0.6886474629243214, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:40:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 100, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.1951599121094, 'train_avg_loss': 0.6941565831502279, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:40:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 100, 'Results_raw': {'train_total': 480, 'train_loss': 333.1951599121094, 'train_avg_loss': 0.6941565831502279, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:40:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #101) -------------
2025-10-10 02:40:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=101 aidx=3 | s=5 (candidates=6)
2025-10-10 02:40:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 32, 41, 3, 37] (from 6)
2025-10-10 02:40:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:40:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:40:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:41:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:41:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.298492, avg_loss=0.690205, seen=480, correct=262, accuracy=0.545833
2025-10-10 02:41:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:41:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:41:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:41:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2138MB allocated=2006MB
2025-10-10 02:41:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.55879807472229, 'train_avg_loss': 0.6963233172893524, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:41:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.2984924316406, 'train_avg_loss': 0.690205192565918, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 02:41:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 331.2984924316406, 'train_avg_loss': 0.690205192565918, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 02:41:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:41:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:41:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:41:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:41:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.295349, avg_loss=0.681865, seen=480, correct=269, accuracy=0.560417
2025-10-10 02:41:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:41:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:41:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:41:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2104MB allocated=2006MB
2025-10-10 02:41:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.53697276115417, 'train_avg_loss': 0.6794747730096181, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:41:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.29534912109375, 'train_avg_loss': 0.6818653106689453, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 02:41:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 327.29534912109375, 'train_avg_loss': 0.6818653106689453, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 02:41:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:41:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:41:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:42:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:42:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.955017, avg_loss=0.695740, seen=480, correct=253, accuracy=0.527083
2025-10-10 02:42:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:42:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:42:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:42:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2104MB allocated=2006MB
2025-10-10 02:42:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60504102706909, 'train_avg_loss': 0.6883753418922425, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 02:42:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.95501708984375, 'train_avg_loss': 0.6957396189371745, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 02:42:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 333.95501708984375, 'train_avg_loss': 0.6957396189371745, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 02:42:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:42:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:42:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:43:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:43:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.254639, avg_loss=0.688030, seen=480, correct=255, accuracy=0.531250
2025-10-10 02:43:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:43:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:43:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:43:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2146MB allocated=2006MB
2025-10-10 02:43:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.15671622753143, 'train_avg_loss': 0.6846393018960952, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:43:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.254638671875, 'train_avg_loss': 0.688030497233073, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:43:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 330.254638671875, 'train_avg_loss': 0.688030497233073, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 02:43:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #101, planning to set LR to 1.00e-05
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:43:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:43:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:43:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:43:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.527527, avg_loss=0.686516, seen=480, correct=271, accuracy=0.564583
2025-10-10 02:43:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:43:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:43:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:43:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=101 reserved=2104MB allocated=2006MB
2025-10-10 02:43:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 101, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.4593665599823, 'train_avg_loss': 0.7204947213331858, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:43:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 101, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.52752685546875, 'train_avg_loss': 0.6865156809488933, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 02:43:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 101, 'Results_raw': {'train_total': 480, 'train_loss': 329.52752685546875, 'train_avg_loss': 0.6865156809488933, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 02:43:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #102) -------------
2025-10-10 02:43:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=102 aidx=3 | s=5 (candidates=6)
2025-10-10 02:43:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 41, 32, 3, 31] (from 6)
2025-10-10 02:43:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:43:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:43:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 02:43:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:43:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:43:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:43:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:43:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:43:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:44:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:44:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.625061, avg_loss=0.686719, seen=480, correct=270, accuracy=0.562500
2025-10-10 02:44:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:44:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:44:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:44:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2104MB allocated=2006MB
2025-10-10 02:44:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.045474588871, 'train_avg_loss': 0.7253789549072583, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 02:44:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.62506103515625, 'train_avg_loss': 0.6867188771565755, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 02:44:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 329.62506103515625, 'train_avg_loss': 0.6867188771565755, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 02:44:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:44:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:44:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:44:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:44:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.609802, avg_loss=0.692937, seen=480, correct=262, accuracy=0.545833
2025-10-10 02:44:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:44:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:44:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:44:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2104MB allocated=2006MB
2025-10-10 02:44:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.98382890224457, 'train_avg_loss': 0.6831985741853714, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:44:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.60980224609375, 'train_avg_loss': 0.6929370880126953, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 02:44:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 332.60980224609375, 'train_avg_loss': 0.6929370880126953, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 02:44:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:45:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:45:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:45:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:45:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.276306, avg_loss=0.688076, seen=480, correct=254, accuracy=0.529167
2025-10-10 02:45:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:45:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:45:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:45:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2104MB allocated=2006MB
2025-10-10 02:45:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.40109974145889, 'train_avg_loss': 0.6783424978454907, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:45:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.27630615234375, 'train_avg_loss': 0.6880756378173828, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:45:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 330.27630615234375, 'train_avg_loss': 0.6880756378173828, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:45:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:45:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:45:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:46:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:46:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.065430, avg_loss=0.687636, seen=480, correct=264, accuracy=0.550000
2025-10-10 02:46:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:46:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:46:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:46:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2146MB allocated=2006MB
2025-10-10 02:46:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.45554172992706, 'train_avg_loss': 0.6787961810827255, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 02:46:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.0654296875, 'train_avg_loss': 0.6876363118489583, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:46:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 330.0654296875, 'train_avg_loss': 0.6876363118489583, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:46:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #102, planning to set LR to 1.00e-05
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:46:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:46:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:46:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:46:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.908081, avg_loss=0.699809, seen=480, correct=244, accuracy=0.508333
2025-10-10 02:46:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:46:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:46:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:46:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=102 reserved=2106MB allocated=2006MB
2025-10-10 02:46:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 102, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.25859695672989, 'train_avg_loss': 0.7021549746394158, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 02:46:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 102, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.9080810546875, 'train_avg_loss': 0.6998085021972656, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 02:46:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 102, 'Results_raw': {'train_total': 480, 'train_loss': 335.9080810546875, 'train_avg_loss': 0.6998085021972656, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 02:46:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #103) -------------
2025-10-10 02:46:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=103 aidx=3 | s=5 (candidates=6)
2025-10-10 02:46:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 31, 3, 41, 37] (from 6)
2025-10-10 02:46:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:46:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:46:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:47:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:47:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.930603, avg_loss=0.683189, seen=480, correct=275, accuracy=0.572917
2025-10-10 02:47:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:47:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:47:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:47:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2104MB allocated=2006MB
2025-10-10 02:47:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62102782726288, 'train_avg_loss': 0.6801752318938573, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 02:47:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.93060302734375, 'train_avg_loss': 0.6831887563069662, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 02:47:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 327.93060302734375, 'train_avg_loss': 0.6831887563069662, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 02:47:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:47:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:47:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:48:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:48:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.859070, avg_loss=0.687206, seen=480, correct=253, accuracy=0.527083
2025-10-10 02:48:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:48:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:48:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:48:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2106MB allocated=2006MB
2025-10-10 02:48:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.98502969741821, 'train_avg_loss': 0.6915419141451518, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 02:48:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.85906982421875, 'train_avg_loss': 0.6872063954671224, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 02:48:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 329.85906982421875, 'train_avg_loss': 0.6872063954671224, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 02:48:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:48:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:48:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 02:48:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:48:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:48:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:48:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:48:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:48:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:48:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:48:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.026306, avg_loss=0.687555, seen=480, correct=262, accuracy=0.545833
2025-10-10 02:48:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:48:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:48:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:48:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2146MB allocated=2006MB
2025-10-10 02:48:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.90841889381409, 'train_avg_loss': 0.6825701574484507, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:48:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.02630615234375, 'train_avg_loss': 0.6875548044840495, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 02:48:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 330.02630615234375, 'train_avg_loss': 0.6875548044840495, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 02:48:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:48:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:48:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:49:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:49:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.322510, avg_loss=0.694422, seen=480, correct=254, accuracy=0.529167
2025-10-10 02:49:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:49:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:49:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:49:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2104MB allocated=2006MB
2025-10-10 02:49:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.37874066829681, 'train_avg_loss': 0.6864895055691401, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 02:49:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.322509765625, 'train_avg_loss': 0.694421895345052, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:49:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 333.322509765625, 'train_avg_loss': 0.694421895345052, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:49:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #103, planning to set LR to 1.00e-05
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:49:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:49:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:50:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:50:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.150513, avg_loss=0.683647, seen=480, correct=264, accuracy=0.550000
2025-10-10 02:50:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:50:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:50:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:50:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=103 reserved=2104MB allocated=2006MB
2025-10-10 02:50:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 103, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.59295278787613, 'train_avg_loss': 0.7216079398989678, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 02:50:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 103, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1505126953125, 'train_avg_loss': 0.6836469014485677, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:50:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 103, 'Results_raw': {'train_total': 480, 'train_loss': 328.1505126953125, 'train_avg_loss': 0.6836469014485677, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 02:50:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #104) -------------
2025-10-10 02:50:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=104 aidx=3 | s=5 (candidates=6)
2025-10-10 02:50:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 32, 3, 31, 21] (from 6)
2025-10-10 02:50:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:50:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:50:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:50:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:50:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.259003, avg_loss=0.694290, seen=480, correct=254, accuracy=0.529167
2025-10-10 02:50:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:50:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:50:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:50:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2104MB allocated=2006MB
2025-10-10 02:50:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.95079439878464, 'train_avg_loss': 0.6829232866565387, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 02:50:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.2590026855469, 'train_avg_loss': 0.6942895889282227, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:50:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 333.2590026855469, 'train_avg_loss': 0.6942895889282227, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 02:50:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:50:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:50:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:51:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:51:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.183228, avg_loss=0.685798, seen=480, correct=260, accuracy=0.541667
2025-10-10 02:51:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:51:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:51:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:51:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2104MB allocated=2006MB
2025-10-10 02:51:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31895393133163, 'train_avg_loss': 0.6776579494277636, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 02:51:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1832275390625, 'train_avg_loss': 0.6857983907063802, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 02:51:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 329.1832275390625, 'train_avg_loss': 0.6857983907063802, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 02:51:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:51:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:51:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:52:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:52:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.983704, avg_loss=0.687466, seen=480, correct=263, accuracy=0.547917
2025-10-10 02:52:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:52:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:52:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:52:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2146MB allocated=2006MB
2025-10-10 02:52:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.98806095123291, 'train_avg_loss': 0.6832338412602742, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 02:52:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.98370361328125, 'train_avg_loss': 0.687466049194336, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 02:52:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 329.98370361328125, 'train_avg_loss': 0.687466049194336, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 02:52:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:52:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:52:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:52:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:52:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.894043, avg_loss=0.693529, seen=480, correct=256, accuracy=0.533333
2025-10-10 02:52:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:52:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:52:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:52:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2106MB allocated=2006MB
2025-10-10 02:52:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.44160282611847, 'train_avg_loss': 0.6953466902176539, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:52:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.89404296875, 'train_avg_loss': 0.6935292561848958, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 02:52:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 332.89404296875, 'train_avg_loss': 0.6935292561848958, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 02:52:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #104, planning to set LR to 1.00e-05
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:52:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:52:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:53:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:53:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.057434, avg_loss=0.689703, seen=480, correct=259, accuracy=0.539583
2025-10-10 02:53:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:53:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:53:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:53:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=104 reserved=2138MB allocated=2006MB
2025-10-10 02:53:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 104, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.59893226623535, 'train_avg_loss': 0.6966577688852946, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 02:53:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 104, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.05743408203125, 'train_avg_loss': 0.6897029876708984, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:53:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 104, 'Results_raw': {'train_total': 480, 'train_loss': 331.05743408203125, 'train_avg_loss': 0.6897029876708984, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 02:53:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #105) -------------
2025-10-10 02:53:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=105 aidx=3 | s=5 (candidates=6)
2025-10-10 02:53:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 37, 41, 31, 3] (from 6)
2025-10-10 02:53:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 02:53:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:53:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:54:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:54:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.439453, avg_loss=0.684249, seen=480, correct=267, accuracy=0.556250
2025-10-10 02:54:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:54:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:54:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:54:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2104MB allocated=2006MB
2025-10-10 02:54:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.68487668037415, 'train_avg_loss': 0.6807073056697845, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:54:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.439453125, 'train_avg_loss': 0.6842488606770833, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 02:54:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 328.439453125, 'train_avg_loss': 0.6842488606770833, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 02:54:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:54:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:54:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:54:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:54:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.893951, avg_loss=0.681029, seen=480, correct=280, accuracy=0.583333
2025-10-10 02:54:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:54:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:54:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:54:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2104MB allocated=2006MB
2025-10-10 02:54:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.89860665798187, 'train_avg_loss': 0.715821722149849, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:54:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.8939514160156, 'train_avg_loss': 0.6810290654500325, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 02:54:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 326.8939514160156, 'train_avg_loss': 0.6810290654500325, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 02:54:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:54:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:54:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:55:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:55:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.594421, avg_loss=0.697072, seen=480, correct=249, accuracy=0.518750
2025-10-10 02:55:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:55:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:55:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:55:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2104MB allocated=2006MB
2025-10-10 02:55:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.68095129728317, 'train_avg_loss': 0.6890079274773597, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 02:55:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.59442138671875, 'train_avg_loss': 0.6970717112223307, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 02:55:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 334.59442138671875, 'train_avg_loss': 0.6970717112223307, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 02:55:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:55:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:55:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:56:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:56:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.903961, avg_loss=0.689383, seen=480, correct=252, accuracy=0.525000
2025-10-10 02:56:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:56:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:56:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:56:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2106MB allocated=2006MB
2025-10-10 02:56:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.1188827753067, 'train_avg_loss': 0.6926573564608892, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 02:56:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9039611816406, 'train_avg_loss': 0.6893832524617513, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 02:56:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 330.9039611816406, 'train_avg_loss': 0.6893832524617513, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 02:56:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:56:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:56:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #105, planning to set LR to 1.00e-05
2025-10-10 02:56:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:56:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:56:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:56:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:56:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:56:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:56:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:56:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.327209, avg_loss=0.686098, seen=480, correct=270, accuracy=0.562500
2025-10-10 02:56:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:56:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:56:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:56:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=105 reserved=2146MB allocated=2006MB
2025-10-10 02:56:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 105, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.03596210479736, 'train_avg_loss': 0.6836330175399781, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 02:56:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 105, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.32720947265625, 'train_avg_loss': 0.6860983530680339, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 02:56:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 105, 'Results_raw': {'train_total': 480, 'train_loss': 329.32720947265625, 'train_avg_loss': 0.6860983530680339, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 02:56:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #106) -------------
2025-10-10 02:56:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=106 aidx=3 | s=5 (candidates=6)
2025-10-10 02:56:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 41, 3, 31, 21] (from 6)
2025-10-10 02:56:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:56:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:56:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 02:56:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 02:56:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:56:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:56:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:56:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:56:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:57:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:57:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.097565, avg_loss=0.679370, seen=480, correct=275, accuracy=0.572917
2025-10-10 02:57:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:57:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:57:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:57:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2104MB allocated=2006MB
2025-10-10 02:57:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.70742928981781, 'train_avg_loss': 0.7225619107484818, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 02:57:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.0975646972656, 'train_avg_loss': 0.6793699264526367, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 02:57:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 326.0975646972656, 'train_avg_loss': 0.6793699264526367, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 02:57:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 02:57:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:57:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:58:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:58:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.220825, avg_loss=0.698377, seen=480, correct=249, accuracy=0.518750
2025-10-10 02:58:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:58:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:58:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:58:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2104MB allocated=2006MB
2025-10-10 02:58:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61380958557129, 'train_avg_loss': 0.688448413213094, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 02:58:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.2208251953125, 'train_avg_loss': 0.698376719156901, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 02:58:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 335.2208251953125, 'train_avg_loss': 0.698376719156901, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 02:58:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 02:58:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:58:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:58:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:58:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.518738, avg_loss=0.678164, seen=480, correct=272, accuracy=0.566667
2025-10-10 02:58:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:58:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:58:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:58:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2146MB allocated=2006MB
2025-10-10 02:58:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.69134831428528, 'train_avg_loss': 0.672427902619044, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 02:58:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.51873779296875, 'train_avg_loss': 0.6781640370686849, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 02:58:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 325.51873779296875, 'train_avg_loss': 0.6781640370686849, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 02:58:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:59:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:59:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 02:59:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 02:59:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:59:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:59:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:59:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:59:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 02:59:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 02:59:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.502869, avg_loss=0.686464, seen=480, correct=257, accuracy=0.535417
2025-10-10 02:59:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 02:59:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:59:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 02:59:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2106MB allocated=2006MB
2025-10-10 02:59:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32555377483368, 'train_avg_loss': 0.6860462814569473, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 02:59:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.50286865234375, 'train_avg_loss': 0.6864643096923828, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 02:59:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 329.50286865234375, 'train_avg_loss': 0.6864643096923828, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 02:59:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #106, planning to set LR to 1.00e-05
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 02:59:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 02:59:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:00:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:00:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.067566, avg_loss=0.685557, seen=480, correct=267, accuracy=0.556250
2025-10-10 03:00:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:00:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:00:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:00:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=106 reserved=2138MB allocated=2006MB
2025-10-10 03:00:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 106, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.56423437595367, 'train_avg_loss': 0.696368619799614, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 03:00:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 106, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.06756591796875, 'train_avg_loss': 0.6855574289957682, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:00:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 106, 'Results_raw': {'train_total': 480, 'train_loss': 329.06756591796875, 'train_avg_loss': 0.6855574289957682, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:00:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #107) -------------
2025-10-10 03:00:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=107 aidx=3 | s=5 (candidates=6)
2025-10-10 03:00:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 21, 31, 3, 41] (from 6)
2025-10-10 03:00:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:00:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:00:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:01:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:01:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.874298, avg_loss=0.683071, seen=480, correct=264, accuracy=0.550000
2025-10-10 03:01:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:01:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:01:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:01:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2104MB allocated=2006MB
2025-10-10 03:01:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.04607665538788, 'train_avg_loss': 0.6837173054615656, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:01:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.8742980957031, 'train_avg_loss': 0.6830714543660482, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 03:01:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 327.8742980957031, 'train_avg_loss': 0.6830714543660482, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 03:01:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:01:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:01:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:01:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:01:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.327759, avg_loss=0.679849, seen=480, correct=266, accuracy=0.554167
2025-10-10 03:01:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:01:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:01:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:01:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2138MB allocated=2006MB
2025-10-10 03:01:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.93148690462112, 'train_avg_loss': 0.6910957242051761, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 03:01:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.3277587890625, 'train_avg_loss': 0.6798494974772136, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 03:01:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 326.3277587890625, 'train_avg_loss': 0.6798494974772136, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 03:01:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 03:01:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:01:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:02:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:02:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.363983, avg_loss=0.690342, seen=480, correct=245, accuracy=0.510417
2025-10-10 03:02:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:02:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:02:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:02:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2106MB allocated=2006MB
2025-10-10 03:02:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.12524461746216, 'train_avg_loss': 0.6927103718121846, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:02:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3639831542969, 'train_avg_loss': 0.6903416315714518, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 03:02:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 331.3639831542969, 'train_avg_loss': 0.6903416315714518, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 03:02:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 03:02:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:02:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:03:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:03:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.149933, avg_loss=0.677396, seen=480, correct=283, accuracy=0.589583
2025-10-10 03:03:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:03:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:03:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:03:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2146MB allocated=2006MB
2025-10-10 03:03:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.82059472799301, 'train_avg_loss': 0.6735049560666084, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 03:03:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.1499328613281, 'train_avg_loss': 0.6773956934611003, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 03:03:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 325.1499328613281, 'train_avg_loss': 0.6773956934611003, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 03:03:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #107, planning to set LR to 1.00e-05
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:03:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:03:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:03:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:03:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.415558, avg_loss=0.696699, seen=480, correct=251, accuracy=0.522917
2025-10-10 03:03:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:03:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:03:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:03:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=107 reserved=2104MB allocated=2006MB
2025-10-10 03:03:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 107, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.032723903656, 'train_avg_loss': 0.6919393658638, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:03:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 107, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.4155578613281, 'train_avg_loss': 0.6966990788777669, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 03:03:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 107, 'Results_raw': {'train_total': 480, 'train_loss': 334.4155578613281, 'train_avg_loss': 0.6966990788777669, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 03:03:48 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #108) -------------
2025-10-10 03:03:49 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=108 aidx=3 | s=5 (candidates=6)
2025-10-10 03:03:49 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 37, 41, 32, 31] (from 6)
2025-10-10 03:03:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:03:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:03:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:04:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:04:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.935852, avg_loss=0.683200, seen=480, correct=271, accuracy=0.564583
2025-10-10 03:04:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:04:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:04:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:04:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2138MB allocated=2006MB
2025-10-10 03:04:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.27659463882446, 'train_avg_loss': 0.6939716219902039, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:04:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.93585205078125, 'train_avg_loss': 0.683199691772461, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 03:04:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 327.93585205078125, 'train_avg_loss': 0.683199691772461, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 03:04:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 03:04:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:04:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:05:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:05:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.059875, avg_loss=0.679291, seen=480, correct=271, accuracy=0.564583
2025-10-10 03:05:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:05:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:05:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:05:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2104MB allocated=2006MB
2025-10-10 03:05:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.81944388151169, 'train_avg_loss': 0.7151620323459308, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 03:05:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.05987548828125, 'train_avg_loss': 0.6792914072672526, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 03:05:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 326.05987548828125, 'train_avg_loss': 0.6792914072672526, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 03:05:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:05:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:05:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:05:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:05:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.589996, avg_loss=0.692896, seen=480, correct=260, accuracy=0.541667
2025-10-10 03:05:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:05:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:05:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:05:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2104MB allocated=2006MB
2025-10-10 03:05:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00960350036621, 'train_avg_loss': 0.6834133625030517, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 03:05:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.5899963378906, 'train_avg_loss': 0.6928958257039388, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 03:05:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 332.5899963378906, 'train_avg_loss': 0.6928958257039388, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 03:05:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:05:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:05:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:06:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:06:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.730896, avg_loss=0.678606, seen=480, correct=283, accuracy=0.589583
2025-10-10 03:06:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:06:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:06:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:06:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2104MB allocated=2006MB
2025-10-10 03:06:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.4301882982254, 'train_avg_loss': 0.686918235818545, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 03:06:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.73089599609375, 'train_avg_loss': 0.6786060333251953, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 03:06:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 325.73089599609375, 'train_avg_loss': 0.6786060333251953, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 03:06:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #108, planning to set LR to 1.00e-05
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 03:06:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:06:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:07:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:07:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.830078, avg_loss=0.685063, seen=480, correct=263, accuracy=0.547917
2025-10-10 03:07:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:07:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:07:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:07:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=108 reserved=2106MB allocated=2006MB
2025-10-10 03:07:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 108, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.30320596694946, 'train_avg_loss': 0.6858600497245788, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 03:07:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 108, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.830078125, 'train_avg_loss': 0.6850626627604167, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 03:07:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 108, 'Results_raw': {'train_total': 480, 'train_loss': 328.830078125, 'train_avg_loss': 0.6850626627604167, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 03:07:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #109) -------------
2025-10-10 03:07:12 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=109 aidx=3 | s=5 (candidates=6)
2025-10-10 03:07:12 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 37, 21, 3, 32] (from 6)
2025-10-10 03:07:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:07:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:07:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:07:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:07:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.169922, avg_loss=0.689937, seen=480, correct=261, accuracy=0.543750
2025-10-10 03:07:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:07:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:07:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:07:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2104MB allocated=2006MB
2025-10-10 03:07:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5037836432457, 'train_avg_loss': 0.6791981970270474, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 03:07:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.169921875, 'train_avg_loss': 0.6899373372395833, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 03:07:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 331.169921875, 'train_avg_loss': 0.6899373372395833, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 03:07:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:07:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:07:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 03:07:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 03:07:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:07:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:07:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:07:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:07:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:08:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:08:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.155792, avg_loss=0.679491, seen=480, correct=277, accuracy=0.577083
2025-10-10 03:08:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:08:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:08:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:08:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2104MB allocated=2006MB
2025-10-10 03:08:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.88362854719162, 'train_avg_loss': 0.7156969045599302, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 03:08:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1557922363281, 'train_avg_loss': 0.6794912338256835, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 03:08:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 326.1557922363281, 'train_avg_loss': 0.6794912338256835, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 03:08:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:08:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:08:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 03:08:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:08:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:08:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:08:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:08:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:08:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:09:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:09:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.148773, avg_loss=0.679477, seen=480, correct=275, accuracy=0.572917
2025-10-10 03:09:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:09:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:09:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:09:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2138MB allocated=2006MB
2025-10-10 03:09:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.64384031295776, 'train_avg_loss': 0.6886986692746481, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:09:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1487731933594, 'train_avg_loss': 0.6794766108194987, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:09:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 326.1487731933594, 'train_avg_loss': 0.6794766108194987, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:09:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 03:09:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:09:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:09:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:09:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.290100, avg_loss=0.679771, seen=480, correct=281, accuracy=0.585417
2025-10-10 03:09:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:09:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:09:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:09:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2146MB allocated=2006MB
2025-10-10 03:09:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.20094108581543, 'train_avg_loss': 0.6766745090484619, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 03:09:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.29010009765625, 'train_avg_loss': 0.6797710418701172, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 03:09:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 326.29010009765625, 'train_avg_loss': 0.6797710418701172, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 03:09:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #109, planning to set LR to 1.00e-05
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:09:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:09:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:10:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:10:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.291626, avg_loss=0.677691, seen=480, correct=275, accuracy=0.572917
2025-10-10 03:10:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:10:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:10:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:10:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=109 reserved=2104MB allocated=2006MB
2025-10-10 03:10:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 109, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.82143330574036, 'train_avg_loss': 0.673511944214503, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 03:10:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 109, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.2916259765625, 'train_avg_loss': 0.6776908874511719, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:10:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 109, 'Results_raw': {'train_total': 480, 'train_loss': 325.2916259765625, 'train_avg_loss': 0.6776908874511719, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:10:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #110) -------------
2025-10-10 03:10:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=110 aidx=3 | s=5 (candidates=6)
2025-10-10 03:10:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[41, 21, 37, 32, 31] (from 6)
2025-10-10 03:10:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:10:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:10:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:11:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:11:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.718628, avg_loss=0.686914, seen=480, correct=261, accuracy=0.543750
2025-10-10 03:11:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:11:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:11:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:11:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2104MB allocated=2006MB
2025-10-10 03:11:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.3513822555542, 'train_avg_loss': 0.6779281854629516, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:11:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7186279296875, 'train_avg_loss': 0.686913808186849, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 03:11:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 329.7186279296875, 'train_avg_loss': 0.686913808186849, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 03:11:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:11:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:11:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 03:11:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:11:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:11:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:11:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:11:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:11:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:11:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:11:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.597168, avg_loss=0.680411, seen=480, correct=279, accuracy=0.581250
2025-10-10 03:11:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:11:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:11:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:11:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2138MB allocated=2006MB
2025-10-10 03:11:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.60806059837341, 'train_avg_loss': 0.6884005049864451, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:11:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.59716796875, 'train_avg_loss': 0.6804107666015625, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 03:11:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 326.59716796875, 'train_avg_loss': 0.6804107666015625, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 03:11:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 03:12:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:12:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:12:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:12:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.005920, avg_loss=0.679179, seen=480, correct=274, accuracy=0.570833
2025-10-10 03:12:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:12:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:12:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:12:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2104MB allocated=2006MB
2025-10-10 03:12:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.68588322401047, 'train_avg_loss': 0.7140490268667539, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:12:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.00592041015625, 'train_avg_loss': 0.6791790008544922, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 03:12:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 326.00592041015625, 'train_avg_loss': 0.6791790008544922, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 03:12:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:12:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:12:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:13:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:13:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.893738, avg_loss=0.670612, seen=480, correct=286, accuracy=0.595833
2025-10-10 03:13:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:13:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:13:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:13:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2104MB allocated=2006MB
2025-10-10 03:13:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.88018882274628, 'train_avg_loss': 0.6656682401895523, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 03:13:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.89373779296875, 'train_avg_loss': 0.6706119537353515, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 03:13:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 321.89373779296875, 'train_avg_loss': 0.6706119537353515, 'train_seen': 480, 'train_correct': 286, 'train_acc': 0.5958333333333333}}
2025-10-10 03:13:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:13:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:13:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #110, planning to set LR to 1.00e-05
2025-10-10 03:13:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 03:13:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:13:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:13:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:13:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:13:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:14:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:14:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.575562, avg_loss=0.684532, seen=480, correct=267, accuracy=0.556250
2025-10-10 03:14:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:14:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:14:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:14:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=110 reserved=2106MB allocated=2006MB
2025-10-10 03:14:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 110, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.42938005924225, 'train_avg_loss': 0.6869115004936854, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 03:14:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 110, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.5755615234375, 'train_avg_loss': 0.6845324198404948, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:14:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 110, 'Results_raw': {'train_total': 480, 'train_loss': 328.5755615234375, 'train_avg_loss': 0.6845324198404948, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:14:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #111) -------------
2025-10-10 03:14:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=111 aidx=3 | s=5 (candidates=6)
2025-10-10 03:14:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[37, 3, 41, 31, 21] (from 6)
2025-10-10 03:14:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:14:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:14:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 03:14:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 03:14:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:14:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:14:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:14:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:14:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:14:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:14:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.252777, avg_loss=0.681777, seen=480, correct=270, accuracy=0.562500
2025-10-10 03:14:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:14:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:14:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:14:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2104MB allocated=2006MB
2025-10-10 03:14:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.07003164291382, 'train_avg_loss': 0.7172502636909485, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 03:14:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.2527770996094, 'train_avg_loss': 0.6817766189575195, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 03:14:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 327.2527770996094, 'train_avg_loss': 0.6817766189575195, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 03:14:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:14:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:14:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 03:14:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 03:14:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:14:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:14:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:14:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:14:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:15:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:15:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.459717, avg_loss=0.682208, seen=480, correct=275, accuracy=0.572917
2025-10-10 03:15:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:15:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:15:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:15:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2146MB allocated=2006MB
2025-10-10 03:15:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31629276275635, 'train_avg_loss': 0.6776357730229695, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 03:15:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.459716796875, 'train_avg_loss': 0.6822077433268229, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:15:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 327.459716796875, 'train_avg_loss': 0.6822077433268229, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:15:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:15:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:15:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 03:15:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:15:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:15:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:15:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:15:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:15:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:16:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:16:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.555481, avg_loss=0.688657, seen=480, correct=254, accuracy=0.529167
2025-10-10 03:16:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:16:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:16:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:16:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2104MB allocated=2006MB
2025-10-10 03:16:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.42679560184479, 'train_avg_loss': 0.6785566300153733, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 03:16:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.55548095703125, 'train_avg_loss': 0.6886572519938151, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 03:16:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 330.55548095703125, 'train_avg_loss': 0.6886572519938151, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 03:16:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:16:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:16:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 03:16:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 03:16:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:16:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:16:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:16:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:16:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:16:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:16:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.111786, avg_loss=0.677316, seen=480, correct=265, accuracy=0.552083
2025-10-10 03:16:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:16:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:16:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:16:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2106MB allocated=2006MB
2025-10-10 03:16:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5755842924118, 'train_avg_loss': 0.6797965357700984, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 03:16:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.1117858886719, 'train_avg_loss': 0.6773162206013997, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 03:16:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 325.1117858886719, 'train_avg_loss': 0.6773162206013997, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 03:16:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #111, planning to set LR to 1.00e-05
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:16:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:16:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:17:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:17:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.663055, avg_loss=0.680548, seen=480, correct=278, accuracy=0.579167
2025-10-10 03:17:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:17:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:17:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:17:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=111 reserved=2138MB allocated=2006MB
2025-10-10 03:17:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 111, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.67959880828857, 'train_avg_loss': 0.6889966567357381, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:17:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 111, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.6630554199219, 'train_avg_loss': 0.6805480321248373, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 03:17:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 111, 'Results_raw': {'train_total': 480, 'train_loss': 326.6630554199219, 'train_avg_loss': 0.6805480321248373, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 03:17:29 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #112) -------------
2025-10-10 03:17:29 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=112 aidx=3 | s=5 (candidates=6)
2025-10-10 03:17:29 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[21, 3, 41, 32, 37] (from 6)
2025-10-10 03:17:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:17:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:17:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:18:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:18:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.483154, avg_loss=0.673923, seen=480, correct=279, accuracy=0.581250
2025-10-10 03:18:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:18:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:18:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:18:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2138MB allocated=2006MB
2025-10-10 03:18:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.93763017654419, 'train_avg_loss': 0.6828135848045349, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 03:18:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.483154296875, 'train_avg_loss': 0.6739232381184895, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 03:18:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 323.483154296875, 'train_avg_loss': 0.6739232381184895, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 03:18:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:18:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:18:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 03:18:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 03:18:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:18:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:18:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:18:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:18:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:18:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:18:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.530548, avg_loss=0.680272, seen=480, correct=269, accuracy=0.560417
2025-10-10 03:18:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:18:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:18:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:18:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2146MB allocated=2006MB
2025-10-10 03:18:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.92801642417908, 'train_avg_loss': 0.674400136868159, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 03:18:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.5305480957031, 'train_avg_loss': 0.6802719751993815, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 03:18:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 326.5305480957031, 'train_avg_loss': 0.6802719751993815, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 03:18:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:18:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:18:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:19:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:19:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.766541, avg_loss=0.687014, seen=480, correct=270, accuracy=0.562500
2025-10-10 03:19:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:19:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:19:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:19:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2104MB allocated=2006MB
2025-10-10 03:19:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.41200709342957, 'train_avg_loss': 0.6784333924452464, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:19:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.76654052734375, 'train_avg_loss': 0.6870136260986328, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 03:19:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 329.76654052734375, 'train_avg_loss': 0.6870136260986328, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 03:19:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:19:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:19:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:20:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:20:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.868652, avg_loss=0.670560, seen=480, correct=280, accuracy=0.583333
2025-10-10 03:20:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:20:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:20:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:20:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2104MB allocated=2006MB
2025-10-10 03:20:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.02626693248749, 'train_avg_loss': 0.6668855577707291, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 03:20:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.86865234375, 'train_avg_loss': 0.6705596923828125, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 03:20:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 321.86865234375, 'train_avg_loss': 0.6705596923828125, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 03:20:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:20:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:20:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #112, planning to set LR to 1.00e-05
2025-10-10 03:20:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 03:20:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:20:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:20:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:20:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:20:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:20:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:20:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.013855, avg_loss=0.679196, seen=480, correct=277, accuracy=0.577083
2025-10-10 03:20:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:20:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:20:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:20:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=112 reserved=2104MB allocated=2006MB
2025-10-10 03:20:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 112, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.90222370624542, 'train_avg_loss': 0.7158518642187118, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:20:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 112, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.01385498046875, 'train_avg_loss': 0.6791955312093099, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 03:20:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 112, 'Results_raw': {'train_total': 480, 'train_loss': 326.01385498046875, 'train_avg_loss': 0.6791955312093099, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 03:20:54 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #113) -------------
2025-10-10 03:20:55 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=113 aidx=3 | s=5 (candidates=6)
2025-10-10 03:20:55 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[32, 3, 41, 31, 21] (from 6)
2025-10-10 03:20:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:20:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:20:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 03:20:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:20:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:20:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:20:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:20:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:20:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:21:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:21:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.815430, avg_loss=0.672532, seen=480, correct=273, accuracy=0.568750
2025-10-10 03:21:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:21:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:21:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:21:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2104MB allocated=2006MB
2025-10-10 03:21:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.74981379508972, 'train_avg_loss': 0.6645817816257477, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:21:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.8154296875, 'train_avg_loss': 0.6725321451822917, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 03:21:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 322.8154296875, 'train_avg_loss': 0.6725321451822917, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 03:21:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:21:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:21:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 03:21:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 03:21:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:21:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:21:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:21:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:21:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:22:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:22:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.153992, avg_loss=0.679487, seen=480, correct=273, accuracy=0.568750
2025-10-10 03:22:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:22:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:22:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:22:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2146MB allocated=2006MB
2025-10-10 03:22:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.20904022455215, 'train_avg_loss': 0.676742001871268, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 03:22:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.15399169921875, 'train_avg_loss': 0.6794874827067058, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 03:22:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 326.15399169921875, 'train_avg_loss': 0.6794874827067058, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 03:22:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:22:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:22:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:22:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:22:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.126831, avg_loss=0.685681, seen=480, correct=271, accuracy=0.564583
2025-10-10 03:22:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:22:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:22:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:22:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2104MB allocated=2006MB
2025-10-10 03:22:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.99488878250122, 'train_avg_loss': 0.6749574065208435, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 03:22:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1268310546875, 'train_avg_loss': 0.685680898030599, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 03:22:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 329.1268310546875, 'train_avg_loss': 0.685680898030599, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 03:22:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 03:22:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:22:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:23:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:23:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.928558, avg_loss=0.683184, seen=480, correct=259, accuracy=0.539583
2025-10-10 03:23:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:23:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:23:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:23:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2106MB allocated=2006MB
2025-10-10 03:23:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.10282409191132, 'train_avg_loss': 0.6841902007659276, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 03:23:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.9285583496094, 'train_avg_loss': 0.6831844965616862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:23:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 327.9285583496094, 'train_avg_loss': 0.6831844965616862, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:23:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #113, planning to set LR to 1.00e-05
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=729, total=2915)
2025-10-10 03:23:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:23:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=365, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:24:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:24:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.681976, avg_loss=0.674337, seen=480, correct=281, accuracy=0.585417
2025-10-10 03:24:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:24:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:24:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:24:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=113 reserved=2138MB allocated=2006MB
2025-10-10 03:24:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #21', 'Round': 113, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.10183107852936, 'train_avg_loss': 0.6841819256544113, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 03:24:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #21', 'Round': 113, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.6819763183594, 'train_avg_loss': 0.6743374506632487, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 03:24:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #21', 'Round': 113, 'Results_raw': {'train_total': 480, 'train_loss': 323.6819763183594, 'train_avg_loss': 0.6743374506632487, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 03:24:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #114) -------------
2025-10-10 03:24:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=114 aidx=3 | s=5 (candidates=6)
2025-10-10 03:24:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[3, 32, 31, 41, 37] (from 6)
2025-10-10 03:24:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=173, total=691)
2025-10-10 03:24:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:24:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=87, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:25:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:25:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.773590, avg_loss=0.676612, seen=480, correct=275, accuracy=0.572917
2025-10-10 03:25:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:25:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:25:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:25:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2146MB allocated=2006MB
2025-10-10 03:25:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #3', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.11311143636703, 'train_avg_loss': 0.6759425953030587, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 03:25:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #3', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7735900878906, 'train_avg_loss': 0.6766116460164388, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:25:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #3', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 324.7735900878906, 'train_avg_loss': 0.6766116460164388, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 03:25:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=536, total=2144)
2025-10-10 03:25:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:25:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=268, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:25:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:25:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.081940, avg_loss=0.668921, seen=480, correct=282, accuracy=0.587500
2025-10-10 03:25:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:25:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:25:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:25:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2104MB allocated=2006MB
2025-10-10 03:25:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #32', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.82385981082916, 'train_avg_loss': 0.6651988317569096, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 03:25:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #32', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.0819396972656, 'train_avg_loss': 0.6689207077026367, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 03:25:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #32', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 321.0819396972656, 'train_avg_loss': 0.6689207077026367, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 03:25:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=920, total=3679)
2025-10-10 03:25:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:25:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=460, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:26:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:26:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.969208, avg_loss=0.677019, seen=480, correct=265, accuracy=0.552083
2025-10-10 03:26:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:26:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:26:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:26:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2106MB allocated=2006MB
2025-10-10 03:26:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #31', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.34277778863907, 'train_avg_loss': 0.6778564815719922, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 03:26:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #31', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.9692077636719, 'train_avg_loss': 0.6770191828409831, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 03:26:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #31', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 324.9692077636719, 'train_avg_loss': 0.6770191828409831, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 03:26:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:26:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:26:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 03:26:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=569, total=2275)
2025-10-10 03:26:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:26:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:26:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:26:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:26:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=285, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:27:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:27:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.729736, avg_loss=0.686937, seen=480, correct=267, accuracy=0.556250
2025-10-10 03:27:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:27:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:27:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:27:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2104MB allocated=2006MB
2025-10-10 03:27:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #41', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.00895166397095, 'train_avg_loss': 0.6750745971997579, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 03:27:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #41', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.729736328125, 'train_avg_loss': 0.6869369506835937, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:27:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #41', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 329.729736328125, 'train_avg_loss': 0.6869369506835937, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:27:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:27:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:27:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #114, planning to set LR to 1.00e-05
2025-10-10 03:27:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1069, total=4273)
2025-10-10 03:27:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:27:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:27:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:27:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:27:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=535, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:27:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:27:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.407959, avg_loss=0.671683, seen=480, correct=281, accuracy=0.585417
2025-10-10 03:27:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:27:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:27:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:27:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=114 reserved=2104MB allocated=2006MB
2025-10-10 03:27:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #37', 'Round': 114, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.91266971826553, 'train_avg_loss': 0.7076055809855462, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 03:27:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #37', 'Round': 114, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.407958984375, 'train_avg_loss': 0.6716832478841146, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 03:27:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #37', 'Round': 114, 'Results_raw': {'train_total': 480, 'train_loss': 322.407958984375, 'train_avg_loss': 0.6716832478841146, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 03:27:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #115) -------------
2025-10-10 03:27:50 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=115 aidx=4 | s=5 (candidates=6)
2025-10-10 03:27:50 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 4, 24, 44, 27] (from 6)
2025-10-10 03:27:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:27:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:27:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 03:27:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 03:27:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:27:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:27:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:27:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:27:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:28:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:28:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.838043, avg_loss=0.718413, seen=480, correct=237, accuracy=0.493750
2025-10-10 03:28:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:28:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:28:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:28:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2134MB allocated=2073MB
2025-10-10 03:28:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 88.09287118911743, 'train_avg_loss': 0.7341072599093119, 'train_seen': 120, 'train_correct': 50, 'train_acc': 0.4166666666666667}}
2025-10-10 03:28:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.8380432128906, 'train_avg_loss': 0.7184125900268554, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 03:28:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 344.8380432128906, 'train_avg_loss': 0.7184125900268554, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 03:28:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:28:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:28:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 03:28:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:28:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:28:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:28:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:28:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:28:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:29:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:29:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=353.099854, avg_loss=0.735625, seen=480, correct=220, accuracy=0.458333
2025-10-10 03:29:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:29:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:29:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:29:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2204MB allocated=2081MB
2025-10-10 03:29:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.08488714694977, 'train_avg_loss': 0.6840407262245815, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:29:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 353.099853515625, 'train_avg_loss': 0.7356246948242188, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-10 03:29:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 353.099853515625, 'train_avg_loss': 0.7356246948242188, 'train_seen': 480, 'train_correct': 220, 'train_acc': 0.4583333333333333}}
2025-10-10 03:29:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:29:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:29:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 03:29:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:29:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:29:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:29:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:29:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:29:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:29:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:29:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=352.537048, avg_loss=0.734452, seen=480, correct=231, accuracy=0.481250
2025-10-10 03:29:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:29:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:29:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:29:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2136MB allocated=2090MB
2025-10-10 03:29:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.4014144539833, 'train_avg_loss': 0.7283451204498609, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:29:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 352.53704833984375, 'train_avg_loss': 0.7344521840413412, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 03:29:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 352.53704833984375, 'train_avg_loss': 0.7344521840413412, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 03:29:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:29:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:29:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 03:29:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:29:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:29:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:29:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:29:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:29:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:30:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:30:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=347.166931, avg_loss=0.723264, seen=480, correct=231, accuracy=0.481250
2025-10-10 03:30:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:30:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:30:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:30:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2136MB allocated=2098MB
2025-10-10 03:30:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.48359435796738, 'train_avg_loss': 0.7040299529830615, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:30:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 347.16693115234375, 'train_avg_loss': 0.7232644399007161, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 03:30:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 347.16693115234375, 'train_avg_loss': 0.7232644399007161, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 03:30:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:30:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:30:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #115, planning to set LR to 1.00e-05
2025-10-10 03:30:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:30:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:30:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:30:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:30:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:30:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:31:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:31:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.712280, avg_loss=0.713984, seen=480, correct=237, accuracy=0.493750
2025-10-10 03:31:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:31:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:31:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:31:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=115 reserved=2144MB allocated=2107MB
2025-10-10 03:31:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 115, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.56116044521332, 'train_avg_loss': 0.7130096703767776, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 03:31:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 115, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.7122802734375, 'train_avg_loss': 0.7139839172363281, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 03:31:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 115, 'Results_raw': {'train_total': 480, 'train_loss': 342.7122802734375, 'train_avg_loss': 0.7139839172363281, 'train_seen': 480, 'train_correct': 237, 'train_acc': 0.49375}}
2025-10-10 03:31:17 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #116) -------------
2025-10-10 03:31:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=116 aidx=4 | s=5 (candidates=6)
2025-10-10 03:31:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 4, 30, 27, 44] (from 6)
2025-10-10 03:31:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:31:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:31:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:31:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:31:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.511536, avg_loss=0.717732, seen=480, correct=231, accuracy=0.481250
2025-10-10 03:31:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:31:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:31:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:31:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2168MB allocated=2107MB
2025-10-10 03:31:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.93794196844101, 'train_avg_loss': 0.7161495164036751, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 03:31:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.51153564453125, 'train_avg_loss': 0.7177323659261068, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 03:31:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 344.51153564453125, 'train_avg_loss': 0.7177323659261068, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 03:31:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:31:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:31:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 03:31:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:31:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:31:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:31:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:31:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:31:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:32:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:32:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.349487, avg_loss=0.713228, seen=480, correct=219, accuracy=0.456250
2025-10-10 03:32:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:32:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:32:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:32:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2192MB allocated=2107MB
2025-10-10 03:32:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.32346922159195, 'train_avg_loss': 0.6693622435132662, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:32:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.3494873046875, 'train_avg_loss': 0.7132280985514323, 'train_seen': 480, 'train_correct': 219, 'train_acc': 0.45625}}
2025-10-10 03:32:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 342.3494873046875, 'train_avg_loss': 0.7132280985514323, 'train_seen': 480, 'train_correct': 219, 'train_acc': 0.45625}}
2025-10-10 03:32:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 03:32:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:32:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:33:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:33:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.862701, avg_loss=0.705964, seen=480, correct=233, accuracy=0.485417
2025-10-10 03:33:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:33:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:33:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:33:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2168MB allocated=2107MB
2025-10-10 03:33:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.41969811916351, 'train_avg_loss': 0.7118308176596959, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:33:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.8627014160156, 'train_avg_loss': 0.7059639612833659, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 03:33:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 338.8627014160156, 'train_avg_loss': 0.7059639612833659, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 03:33:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:33:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:33:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:33:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:33:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.843079, avg_loss=0.705923, seen=480, correct=255, accuracy=0.531250
2025-10-10 03:33:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:33:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:33:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:33:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2172MB allocated=2107MB
2025-10-10 03:33:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.93947327136993, 'train_avg_loss': 0.7161622772614161, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:33:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.84307861328125, 'train_avg_loss': 0.7059230804443359, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 03:33:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 338.84307861328125, 'train_avg_loss': 0.7059230804443359, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 03:33:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #116, planning to set LR to 1.00e-05
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:33:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:33:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:34:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:34:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.256653, avg_loss=0.708868, seen=480, correct=240, accuracy=0.500000
2025-10-10 03:34:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:34:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:34:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:34:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=116 reserved=2168MB allocated=2107MB
2025-10-10 03:34:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 116, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.14576888084412, 'train_avg_loss': 0.6928814073403676, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 03:34:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 116, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.25665283203125, 'train_avg_loss': 0.7088680267333984, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 03:34:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 116, 'Results_raw': {'train_total': 480, 'train_loss': 340.25665283203125, 'train_avg_loss': 0.7088680267333984, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 03:34:39 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #117) -------------
2025-10-10 03:34:39 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=117 aidx=4 | s=5 (candidates=6)
2025-10-10 03:34:39 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 30, 4, 27, 24] (from 6)
2025-10-10 03:34:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:34:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:34:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:35:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:35:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.390564, avg_loss=0.709147, seen=480, correct=241, accuracy=0.502083
2025-10-10 03:35:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:35:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:35:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:35:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2134MB allocated=2115MB
2025-10-10 03:35:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.11185002326965, 'train_avg_loss': 0.7009320835272471, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:35:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.39056396484375, 'train_avg_loss': 0.7091470082600911, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 03:35:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 340.39056396484375, 'train_avg_loss': 0.7091470082600911, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 03:35:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 03:35:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:35:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:35:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:35:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.789673, avg_loss=0.701645, seen=480, correct=242, accuracy=0.504167
2025-10-10 03:35:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:35:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:35:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:35:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2110MB allocated=2057MB
2025-10-10 03:35:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.4177702665329, 'train_avg_loss': 0.7118147522211075, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:35:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.7896728515625, 'train_avg_loss': 0.7016451517740886, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 03:35:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 336.7896728515625, 'train_avg_loss': 0.7016451517740886, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 03:35:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:36:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:36:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 03:36:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:36:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:36:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:36:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:36:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:36:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:36:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:36:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.157776, avg_loss=0.704495, seen=480, correct=240, accuracy=0.500000
2025-10-10 03:36:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:36:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:36:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:36:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2130MB allocated=2057MB
2025-10-10 03:36:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.79815924167633, 'train_avg_loss': 0.6649846603473027, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 03:36:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.15777587890625, 'train_avg_loss': 0.704495366414388, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 03:36:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 338.15777587890625, 'train_avg_loss': 0.704495366414388, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 03:36:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:36:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:36:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:37:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:37:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.741577, avg_loss=0.699462, seen=480, correct=256, accuracy=0.533333
2025-10-10 03:37:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:37:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:37:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:37:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2114MB allocated=2057MB
2025-10-10 03:37:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.9373260140419, 'train_avg_loss': 0.7078110501170158, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:37:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.7415771484375, 'train_avg_loss': 0.6994616190592448, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 03:37:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 335.7415771484375, 'train_avg_loss': 0.6994616190592448, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 03:37:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:37:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:37:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #117, planning to set LR to 1.00e-05
2025-10-10 03:37:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:37:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:37:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:37:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:37:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:37:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:37:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:37:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.838196, avg_loss=0.712163, seen=480, correct=239, accuracy=0.497917
2025-10-10 03:37:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:37:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:37:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:37:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=117 reserved=2110MB allocated=2057MB
2025-10-10 03:37:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 117, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.10836100578308, 'train_avg_loss': 0.709236341714859, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:37:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 117, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.83819580078125, 'train_avg_loss': 0.7121629079182943, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 03:37:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 117, 'Results_raw': {'train_total': 480, 'train_loss': 341.83819580078125, 'train_avg_loss': 0.7121629079182943, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 03:38:00 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #118) -------------
2025-10-10 03:38:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=118 aidx=4 | s=5 (candidates=6)
2025-10-10 03:38:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 4, 25, 24, 27] (from 6)
2025-10-10 03:38:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:38:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:38:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:38:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:38:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.068970, avg_loss=0.695977, seen=480, correct=252, accuracy=0.525000
2025-10-10 03:38:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:38:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:38:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:38:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2110MB allocated=2057MB
2025-10-10 03:38:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99509263038635, 'train_avg_loss': 0.683292438586553, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:38:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0689697265625, 'train_avg_loss': 0.6959770202636719, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 03:38:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 334.0689697265625, 'train_avg_loss': 0.6959770202636719, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 03:38:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:38:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:38:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:39:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:39:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.060181, avg_loss=0.695959, seen=480, correct=242, accuracy=0.504167
2025-10-10 03:39:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:39:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:39:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:39:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2130MB allocated=2057MB
2025-10-10 03:39:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.94929647445679, 'train_avg_loss': 0.6579108039538065, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 03:39:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0601806640625, 'train_avg_loss': 0.6959587097167969, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 03:39:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 334.0601806640625, 'train_avg_loss': 0.6959587097167969, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 03:39:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:39:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:39:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:39:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:39:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.344238, avg_loss=0.704884, seen=480, correct=244, accuracy=0.508333
2025-10-10 03:39:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:39:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:39:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:39:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2110MB allocated=2057MB
2025-10-10 03:39:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.41304326057434, 'train_avg_loss': 0.6951086938381195, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 03:39:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.34423828125, 'train_avg_loss': 0.7048838297526042, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 03:39:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 338.34423828125, 'train_avg_loss': 0.7048838297526042, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 03:39:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:39:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:39:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:40:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:40:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.341248, avg_loss=0.702794, seen=480, correct=242, accuracy=0.504167
2025-10-10 03:40:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:40:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:40:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:40:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2110MB allocated=2057MB
2025-10-10 03:40:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.01343870162964, 'train_avg_loss': 0.700111989180247, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:40:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.34124755859375, 'train_avg_loss': 0.7027942657470703, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 03:40:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 337.34124755859375, 'train_avg_loss': 0.7027942657470703, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 03:40:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #118, planning to set LR to 1.00e-05
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:40:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:40:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:41:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:41:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.887146, avg_loss=0.697682, seen=480, correct=260, accuracy=0.541667
2025-10-10 03:41:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:41:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:41:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:41:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=118 reserved=2114MB allocated=2057MB
2025-10-10 03:41:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 118, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.51084595918655, 'train_avg_loss': 0.704257049659888, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 03:41:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 118, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.88714599609375, 'train_avg_loss': 0.6976815541585286, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 03:41:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 118, 'Results_raw': {'train_total': 480, 'train_loss': 334.88714599609375, 'train_avg_loss': 0.6976815541585286, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 03:41:18 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #119) -------------
2025-10-10 03:41:19 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=119 aidx=4 | s=5 (candidates=6)
2025-10-10 03:41:19 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[44, 27, 24, 25, 4] (from 6)
2025-10-10 03:41:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:41:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:41:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 03:41:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:41:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:41:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:41:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:41:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:41:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:41:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:41:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.242676, avg_loss=0.694256, seen=480, correct=250, accuracy=0.520833
2025-10-10 03:41:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:41:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:41:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:41:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2110MB allocated=2057MB
2025-10-10 03:41:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.37571001052856, 'train_avg_loss': 0.6781309167544047, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 03:41:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.24267578125, 'train_avg_loss': 0.6942555745442708, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 03:41:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 333.24267578125, 'train_avg_loss': 0.6942555745442708, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 03:42:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:42:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:42:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:42:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:42:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.167389, avg_loss=0.692015, seen=480, correct=267, accuracy=0.556250
2025-10-10 03:42:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:42:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:42:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:42:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2114MB allocated=2057MB
2025-10-10 03:42:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.73008227348328, 'train_avg_loss': 0.6977506856123606, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:42:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.1673889160156, 'train_avg_loss': 0.6920153935750325, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:42:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 332.1673889160156, 'train_avg_loss': 0.6920153935750325, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:42:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:42:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:42:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 03:42:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:42:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:42:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:42:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:42:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:42:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:43:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:43:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.005524, avg_loss=0.700012, seen=480, correct=236, accuracy=0.491667
2025-10-10 03:43:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:43:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:43:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:43:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2110MB allocated=2057MB
2025-10-10 03:43:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.50884342193604, 'train_avg_loss': 0.6959070285161336, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:43:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.0055236816406, 'train_avg_loss': 0.7000115076700847, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 03:43:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 336.0055236816406, 'train_avg_loss': 0.7000115076700847, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 03:43:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:43:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:43:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:43:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:43:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.203979, avg_loss=0.704592, seen=480, correct=246, accuracy=0.512500
2025-10-10 03:43:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:43:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:43:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:43:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2110MB allocated=2057MB
2025-10-10 03:43:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.83042705059052, 'train_avg_loss': 0.6985868920882543, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 03:43:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.2039794921875, 'train_avg_loss': 0.7045916239420573, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 03:43:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 338.2039794921875, 'train_avg_loss': 0.7045916239420573, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 03:43:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #119, planning to set LR to 1.00e-05
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:43:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:43:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:44:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:44:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.241669, avg_loss=0.696337, seen=480, correct=250, accuracy=0.520833
2025-10-10 03:44:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:44:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:44:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:44:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=119 reserved=2130MB allocated=2057MB
2025-10-10 03:44:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 119, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.29923129081726, 'train_avg_loss': 0.6608269274234772, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 03:44:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 119, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2416687011719, 'train_avg_loss': 0.6963368097941081, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 03:44:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 119, 'Results_raw': {'train_total': 480, 'train_loss': 334.2416687011719, 'train_avg_loss': 0.6963368097941081, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 03:44:36 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #120) -------------
2025-10-10 03:44:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=120 aidx=4 | s=5 (candidates=6)
2025-10-10 03:44:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 4, 27, 24, 44] (from 6)
2025-10-10 03:44:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:44:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:44:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:45:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:45:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.683899, avg_loss=0.697258, seen=480, correct=263, accuracy=0.547917
2025-10-10 03:45:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:45:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:45:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:45:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2110MB allocated=2057MB
2025-10-10 03:45:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.02457427978516, 'train_avg_loss': 0.691871452331543, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 03:45:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.68389892578125, 'train_avg_loss': 0.6972581227620442, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 03:45:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 334.68389892578125, 'train_avg_loss': 0.6972581227620442, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 03:45:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:45:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:45:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:45:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:45:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.064667, avg_loss=0.673051, seen=480, correct=280, accuracy=0.583333
2025-10-10 03:45:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:45:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:45:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:45:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2130MB allocated=2057MB
2025-10-10 03:45:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.56416839361191, 'train_avg_loss': 0.6463680699467659, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 03:45:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.0646667480469, 'train_avg_loss': 0.673051389058431, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 03:45:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 323.0646667480469, 'train_avg_loss': 0.673051389058431, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 03:45:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:45:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:45:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:46:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:46:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.434753, avg_loss=0.692572, seen=480, correct=259, accuracy=0.539583
2025-10-10 03:46:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:46:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:46:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:46:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2114MB allocated=2057MB
2025-10-10 03:46:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.17379885911942, 'train_avg_loss': 0.6931149904926618, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:46:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.43475341796875, 'train_avg_loss': 0.6925724029541016, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:46:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 332.43475341796875, 'train_avg_loss': 0.6925724029541016, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:46:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:46:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:46:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 03:46:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:46:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:46:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:46:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:46:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:46:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:47:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:47:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.963257, avg_loss=0.697840, seen=480, correct=239, accuracy=0.497917
2025-10-10 03:47:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:47:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:47:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:47:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2110MB allocated=2057MB
2025-10-10 03:47:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.88184583187103, 'train_avg_loss': 0.6990153819322587, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 03:47:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9632568359375, 'train_avg_loss': 0.6978401184082031, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 03:47:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 334.9632568359375, 'train_avg_loss': 0.6978401184082031, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 03:47:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #120, planning to set LR to 1.00e-05
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:47:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:47:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:47:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:47:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.296265, avg_loss=0.692284, seen=480, correct=247, accuracy=0.514583
2025-10-10 03:47:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:47:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:47:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:47:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=120 reserved=2110MB allocated=2057MB
2025-10-10 03:47:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 120, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.92412149906158, 'train_avg_loss': 0.6827010124921798, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:47:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 120, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.2962646484375, 'train_avg_loss': 0.6922838846842448, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 03:47:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 120, 'Results_raw': {'train_total': 480, 'train_loss': 332.2962646484375, 'train_avg_loss': 0.6922838846842448, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 03:47:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #121) -------------
2025-10-10 03:47:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=121 aidx=4 | s=5 (candidates=6)
2025-10-10 03:47:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 27, 25, 44, 4] (from 6)
2025-10-10 03:47:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:47:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:47:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 03:47:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:47:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:48:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:48:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:48:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:48:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:48:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:48:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.159302, avg_loss=0.698249, seen=480, correct=235, accuracy=0.489583
2025-10-10 03:48:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:48:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:48:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:48:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2110MB allocated=2057MB
2025-10-10 03:48:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.44288486242294, 'train_avg_loss': 0.6953573738535245, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:48:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.1593017578125, 'train_avg_loss': 0.698248545328776, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 03:48:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 335.1593017578125, 'train_avg_loss': 0.698248545328776, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 03:48:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:48:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:48:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:49:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:49:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.303589, avg_loss=0.690216, seen=480, correct=259, accuracy=0.539583
2025-10-10 03:49:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:49:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:49:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:49:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2114MB allocated=2057MB
2025-10-10 03:49:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.44918775558472, 'train_avg_loss': 0.6870765646298727, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 03:49:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3035888671875, 'train_avg_loss': 0.6902158101399739, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:49:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 331.3035888671875, 'train_avg_loss': 0.6902158101399739, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:49:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:49:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:49:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 03:49:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:49:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:49:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:49:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:49:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:49:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:49:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:49:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.579285, avg_loss=0.697040, seen=480, correct=267, accuracy=0.556250
2025-10-10 03:49:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:49:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:49:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:50:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2110MB allocated=2057MB
2025-10-10 03:50:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.97123515605927, 'train_avg_loss': 0.6914269596338272, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 03:50:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.57928466796875, 'train_avg_loss': 0.6970401763916015, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:50:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 334.57928466796875, 'train_avg_loss': 0.6970401763916015, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 03:50:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:50:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:50:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 03:50:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:50:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:50:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:50:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:50:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:50:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:50:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:50:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.876801, avg_loss=0.689327, seen=480, correct=254, accuracy=0.529167
2025-10-10 03:50:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:50:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:50:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:50:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2110MB allocated=2057MB
2025-10-10 03:50:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.67397999763489, 'train_avg_loss': 0.6806164999802907, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:50:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8768005371094, 'train_avg_loss': 0.6893266677856446, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 03:50:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 330.8768005371094, 'train_avg_loss': 0.6893266677856446, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 03:50:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #121, planning to set LR to 1.00e-05
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:50:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:50:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:51:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:51:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.778992, avg_loss=0.674540, seen=480, correct=279, accuracy=0.581250
2025-10-10 03:51:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:51:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:51:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:51:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=121 reserved=2130MB allocated=2057MB
2025-10-10 03:51:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 121, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.31474995613098, 'train_avg_loss': 0.6526229163010915, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 03:51:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 121, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.77899169921875, 'train_avg_loss': 0.6745395660400391, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 03:51:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 121, 'Results_raw': {'train_total': 480, 'train_loss': 323.77899169921875, 'train_avg_loss': 0.6745395660400391, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 03:51:19 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #122) -------------
2025-10-10 03:51:20 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=122 aidx=4 | s=5 (candidates=6)
2025-10-10 03:51:20 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 25, 4, 24, 27] (from 6)
2025-10-10 03:51:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:51:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:51:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 03:51:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 03:51:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:51:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:51:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:51:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:51:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:51:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:51:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.297821, avg_loss=0.694370, seen=480, correct=249, accuracy=0.518750
2025-10-10 03:51:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:51:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:52:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:52:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2110MB allocated=2057MB
2025-10-10 03:52:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.57714629173279, 'train_avg_loss': 0.7048095524311065, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 03:52:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.2978210449219, 'train_avg_loss': 0.6943704605102539, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 03:52:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 333.2978210449219, 'train_avg_loss': 0.6943704605102539, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 03:52:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:52:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:52:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 03:52:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:52:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:52:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:52:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:52:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:52:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:52:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:52:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.162842, avg_loss=0.696173, seen=480, correct=251, accuracy=0.522917
2025-10-10 03:52:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:52:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:52:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:52:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2110MB allocated=2057MB
2025-10-10 03:52:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.26278829574585, 'train_avg_loss': 0.6938565691312154, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:52:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.162841796875, 'train_avg_loss': 0.696172587076823, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 03:52:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 334.162841796875, 'train_avg_loss': 0.696172587076823, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 03:52:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 03:52:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:52:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:53:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:53:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.439667, avg_loss=0.648833, seen=480, correct=309, accuracy=0.643750
2025-10-10 03:53:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:53:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:53:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:53:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2130MB allocated=2057MB
2025-10-10 03:53:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.4203782081604, 'train_avg_loss': 0.6368364850680034, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 03:53:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.4396667480469, 'train_avg_loss': 0.648832639058431, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 03:53:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 311.4396667480469, 'train_avg_loss': 0.648832639058431, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 03:53:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:53:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:53:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:54:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:54:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.182434, avg_loss=0.696213, seen=480, correct=235, accuracy=0.489583
2025-10-10 03:54:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:54:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:54:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:54:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2110MB allocated=2057MB
2025-10-10 03:54:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.86584228277206, 'train_avg_loss': 0.6988820190231005, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 03:54:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.18243408203125, 'train_avg_loss': 0.6962134043375651, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 03:54:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 334.18243408203125, 'train_avg_loss': 0.6962134043375651, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 03:54:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #122, planning to set LR to 1.00e-05
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:54:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:54:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:54:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:54:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.030975, avg_loss=0.693815, seen=480, correct=254, accuracy=0.529167
2025-10-10 03:54:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:54:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:54:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:54:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=122 reserved=2114MB allocated=2057MB
2025-10-10 03:54:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 122, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.22826504707336, 'train_avg_loss': 0.6935688753922781, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 03:54:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 122, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0309753417969, 'train_avg_loss': 0.6938145319620769, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 03:54:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 122, 'Results_raw': {'train_total': 480, 'train_loss': 333.0309753417969, 'train_avg_loss': 0.6938145319620769, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 03:54:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #123) -------------
2025-10-10 03:54:52 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=123 aidx=4 | s=5 (candidates=6)
2025-10-10 03:54:52 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 30, 27, 25, 44] (from 6)
2025-10-10 03:54:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 03:54:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:54:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:55:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:55:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.728699, avg_loss=0.695268, seen=480, correct=244, accuracy=0.508333
2025-10-10 03:55:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:55:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:55:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:55:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2110MB allocated=2057MB
2025-10-10 03:55:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.67005687952042, 'train_avg_loss': 0.6972504739960035, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:55:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.72869873046875, 'train_avg_loss': 0.6952681223551432, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 03:55:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 333.72869873046875, 'train_avg_loss': 0.6952681223551432, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 03:55:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 03:55:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:55:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:56:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:56:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.781036, avg_loss=0.695377, seen=480, correct=248, accuracy=0.516667
2025-10-10 03:56:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:56:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:56:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:56:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2110MB allocated=2057MB
2025-10-10 03:56:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.62473213672638, 'train_avg_loss': 0.7052061011393865, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 03:56:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.7810363769531, 'train_avg_loss': 0.6953771591186524, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 03:56:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 333.7810363769531, 'train_avg_loss': 0.6953771591186524, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 03:56:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:56:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:56:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:56:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:56:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.897705, avg_loss=0.687287, seen=480, correct=270, accuracy=0.562500
2025-10-10 03:56:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:56:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:56:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:56:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2114MB allocated=2057MB
2025-10-10 03:56:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.00549864768982, 'train_avg_loss': 0.6833791553974151, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 03:56:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.897705078125, 'train_avg_loss': 0.6872868855794271, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 03:56:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 329.897705078125, 'train_avg_loss': 0.6872868855794271, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 03:56:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:56:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:56:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 03:56:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:56:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:56:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:56:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:56:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:56:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:57:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:57:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.172974, avg_loss=0.698277, seen=480, correct=250, accuracy=0.520833
2025-10-10 03:57:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:57:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:57:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:57:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2110MB allocated=2057MB
2025-10-10 03:57:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.81257891654968, 'train_avg_loss': 0.6984381576379141, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 03:57:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.1729736328125, 'train_avg_loss': 0.6982770284016927, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 03:57:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 335.1729736328125, 'train_avg_loss': 0.6982770284016927, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 03:57:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #123, planning to set LR to 1.00e-05
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 03:57:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:57:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:58:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:58:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.761047, avg_loss=0.687002, seen=480, correct=259, accuracy=0.539583
2025-10-10 03:58:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:58:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:58:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:58:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=123 reserved=2110MB allocated=2057MB
2025-10-10 03:58:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 123, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61730563640594, 'train_avg_loss': 0.6801442136367162, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 03:58:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 123, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.76104736328125, 'train_avg_loss': 0.6870021820068359, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:58:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 123, 'Results_raw': {'train_total': 480, 'train_loss': 329.76104736328125, 'train_avg_loss': 0.6870021820068359, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 03:58:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #124) -------------
2025-10-10 03:58:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=124 aidx=4 | s=5 (candidates=6)
2025-10-10 03:58:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[30, 27, 25, 24, 4] (from 6)
2025-10-10 03:58:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:58:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:58:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 03:58:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 03:58:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:58:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:58:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:58:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:58:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:58:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:58:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.739197, avg_loss=0.693207, seen=480, correct=262, accuracy=0.545833
2025-10-10 03:58:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:58:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:58:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:58:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2110MB allocated=2057MB
2025-10-10 03:58:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.06691694259644, 'train_avg_loss': 0.708890974521637, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 03:58:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.73919677734375, 'train_avg_loss': 0.6932066599527995, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 03:58:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 332.73919677734375, 'train_avg_loss': 0.6932066599527995, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 03:58:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:58:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:58:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 03:58:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 03:58:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:58:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:58:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:58:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:58:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 03:59:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 03:59:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.478210, avg_loss=0.684330, seen=480, correct=262, accuracy=0.545833
2025-10-10 03:59:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 03:59:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:59:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 03:59:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2114MB allocated=2057MB
2025-10-10 03:59:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.76975309848785, 'train_avg_loss': 0.6814146091540655, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 03:59:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.47821044921875, 'train_avg_loss': 0.684329605102539, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 03:59:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 328.47821044921875, 'train_avg_loss': 0.684329605102539, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 03:59:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 03:59:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 03:59:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:00:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:00:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.923920, avg_loss=0.693591, seen=480, correct=257, accuracy=0.535417
2025-10-10 04:00:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:00:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:00:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:00:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2110MB allocated=2057MB
2025-10-10 04:00:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.38919603824615, 'train_avg_loss': 0.6865766336520512, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:00:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.9239196777344, 'train_avg_loss': 0.6935914993286133, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 04:00:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 332.9239196777344, 'train_avg_loss': 0.6935914993286133, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 04:00:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:00:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:00:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 04:00:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:00:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:00:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:00:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:00:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:00:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:00:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:00:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.541748, avg_loss=0.696962, seen=480, correct=241, accuracy=0.502083
2025-10-10 04:00:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:00:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:00:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:01:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2110MB allocated=2057MB
2025-10-10 04:01:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3334499001503, 'train_avg_loss': 0.7027787491679192, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 04:01:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.541748046875, 'train_avg_loss': 0.6969619750976562, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 04:01:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 334.541748046875, 'train_avg_loss': 0.6969619750976562, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 04:01:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #124, planning to set LR to 1.00e-05
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:01:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:01:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:01:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:01:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.271729, avg_loss=0.654733, seen=480, correct=307, accuracy=0.639583
2025-10-10 04:01:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:01:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:01:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:01:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=124 reserved=2130MB allocated=2057MB
2025-10-10 04:01:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 124, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.67328482866287, 'train_avg_loss': 0.6389440402388573, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 04:01:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 124, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.271728515625, 'train_avg_loss': 0.6547327677408854, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 04:01:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 124, 'Results_raw': {'train_total': 480, 'train_loss': 314.271728515625, 'train_avg_loss': 0.6547327677408854, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 04:01:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #125) -------------
2025-10-10 04:01:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=125 aidx=4 | s=5 (candidates=6)
2025-10-10 04:01:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 24, 4, 44, 30] (from 6)
2025-10-10 04:01:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:01:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:01:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 04:01:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:01:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:01:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:01:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:01:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:01:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:02:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:02:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.866577, avg_loss=0.693472, seen=480, correct=264, accuracy=0.550000
2025-10-10 04:02:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:02:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:02:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:02:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2110MB allocated=2057MB
2025-10-10 04:02:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.13850545883179, 'train_avg_loss': 0.6928208788235982, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 04:02:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.8665771484375, 'train_avg_loss': 0.6934720357259114, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 04:02:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 332.8665771484375, 'train_avg_loss': 0.6934720357259114, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 04:02:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:02:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:02:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:03:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:03:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.144104, avg_loss=0.696134, seen=480, correct=238, accuracy=0.495833
2025-10-10 04:03:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:03:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:03:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:03:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2110MB allocated=2057MB
2025-10-10 04:03:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47953140735626, 'train_avg_loss': 0.7039960950613022, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 04:03:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.14410400390625, 'train_avg_loss': 0.696133550008138, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 04:03:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 334.14410400390625, 'train_avg_loss': 0.696133550008138, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 04:03:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:03:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:03:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 04:03:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:03:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:03:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:03:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:03:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:03:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:03:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:03:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.668091, avg_loss=0.630559, seen=480, correct=316, accuracy=0.658333
2025-10-10 04:03:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:03:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:03:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:03:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2130MB allocated=2057MB
2025-10-10 04:03:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.36297607421875, 'train_avg_loss': 0.6280248006184895, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 04:03:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.6680908203125, 'train_avg_loss': 0.6305585225423177, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 04:03:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 302.6680908203125, 'train_avg_loss': 0.6305585225423177, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 04:03:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:03:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:03:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:04:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:04:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.784058, avg_loss=0.680800, seen=480, correct=272, accuracy=0.566667
2025-10-10 04:04:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:04:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:04:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:04:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2110MB allocated=2057MB
2025-10-10 04:04:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.61878484487534, 'train_avg_loss': 0.6801565403739611, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 04:04:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.7840576171875, 'train_avg_loss': 0.6808001200358073, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 04:04:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 326.7840576171875, 'train_avg_loss': 0.6808001200358073, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 04:04:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:04:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:04:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #125, planning to set LR to 1.00e-05
2025-10-10 04:04:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:04:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:04:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:04:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:04:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:04:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:05:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:05:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.120636, avg_loss=0.694001, seen=480, correct=251, accuracy=0.522917
2025-10-10 04:05:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:05:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:05:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:05:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=125 reserved=2110MB allocated=2057MB
2025-10-10 04:05:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 125, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.49756014347076, 'train_avg_loss': 0.7041463345289231, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 04:05:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 125, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.1206359863281, 'train_avg_loss': 0.6940013249715169, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:05:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 125, 'Results_raw': {'train_total': 480, 'train_loss': 333.1206359863281, 'train_avg_loss': 0.6940013249715169, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:05:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #126) -------------
2025-10-10 04:05:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=126 aidx=4 | s=5 (candidates=6)
2025-10-10 04:05:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 27, 24, 25, 44] (from 6)
2025-10-10 04:05:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:05:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:05:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 04:05:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:05:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:05:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:05:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:05:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:05:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:05:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:05:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.354126, avg_loss=0.629904, seen=480, correct=320, accuracy=0.666667
2025-10-10 04:05:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:05:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:05:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:05:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2130MB allocated=2057MB
2025-10-10 04:05:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.23987835645676, 'train_avg_loss': 0.6269989863038063, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 04:05:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.3541259765625, 'train_avg_loss': 0.6299044291178385, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:05:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 302.3541259765625, 'train_avg_loss': 0.6299044291178385, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:05:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:05:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:05:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:06:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:06:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.759430, avg_loss=0.686999, seen=480, correct=270, accuracy=0.562500
2025-10-10 04:06:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:06:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:06:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:06:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2114MB allocated=2057MB
2025-10-10 04:06:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.28855419158936, 'train_avg_loss': 0.6857379515965779, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:06:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.7594299316406, 'train_avg_loss': 0.6869988123575846, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:06:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 329.7594299316406, 'train_avg_loss': 0.6869988123575846, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:06:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:06:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:06:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 04:06:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:06:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:06:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:06:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:06:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:06:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:07:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:07:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.514618, avg_loss=0.694822, seen=480, correct=244, accuracy=0.508333
2025-10-10 04:07:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:07:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:07:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:07:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2110MB allocated=2057MB
2025-10-10 04:07:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3742373585701, 'train_avg_loss': 0.7031186446547508, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 04:07:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.5146179199219, 'train_avg_loss': 0.694822120666504, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 04:07:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 333.5146179199219, 'train_avg_loss': 0.694822120666504, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 04:07:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:07:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:07:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:07:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:07:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.802795, avg_loss=0.691256, seen=480, correct=262, accuracy=0.545833
2025-10-10 04:07:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:07:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:07:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:07:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2110MB allocated=2057MB
2025-10-10 04:07:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.21327656507492, 'train_avg_loss': 0.685110638042291, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:07:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.80279541015625, 'train_avg_loss': 0.6912558237711589, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:07:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 331.80279541015625, 'train_avg_loss': 0.6912558237711589, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:07:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #126, planning to set LR to 1.00e-05
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:07:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:07:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:08:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:08:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.613464, avg_loss=0.678361, seen=480, correct=278, accuracy=0.579167
2025-10-10 04:08:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:08:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:08:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:08:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=126 reserved=2110MB allocated=2057MB
2025-10-10 04:08:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 126, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.96993434429169, 'train_avg_loss': 0.6664161195357641, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:08:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 126, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.61346435546875, 'train_avg_loss': 0.6783613840738932, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 04:08:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 126, 'Results_raw': {'train_total': 480, 'train_loss': 325.61346435546875, 'train_avg_loss': 0.6783613840738932, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 04:08:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #127) -------------
2025-10-10 04:08:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=127 aidx=4 | s=5 (candidates=6)
2025-10-10 04:08:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 27, 24, 4, 44] (from 6)
2025-10-10 04:08:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:08:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:08:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:09:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:09:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.344208, avg_loss=0.690300, seen=480, correct=255, accuracy=0.531250
2025-10-10 04:09:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:09:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:09:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:09:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2110MB allocated=2057MB
2025-10-10 04:09:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.75612306594849, 'train_avg_loss': 0.6813010255495707, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:09:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.3442077636719, 'train_avg_loss': 0.6903004328409831, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 04:09:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 331.3442077636719, 'train_avg_loss': 0.6903004328409831, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 04:09:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:09:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:09:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:09:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:09:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.169189, avg_loss=0.685769, seen=480, correct=259, accuracy=0.539583
2025-10-10 04:09:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:09:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:09:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:09:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2114MB allocated=2057MB
2025-10-10 04:09:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.50839179754257, 'train_avg_loss': 0.6792365983128548, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 04:09:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.169189453125, 'train_avg_loss': 0.6857691446940104, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 04:09:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 329.169189453125, 'train_avg_loss': 0.6857691446940104, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 04:09:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:09:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:09:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:10:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:10:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.113037, avg_loss=0.693985, seen=480, correct=247, accuracy=0.514583
2025-10-10 04:10:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:10:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:10:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:10:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2110MB allocated=2057MB
2025-10-10 04:10:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.0829701423645, 'train_avg_loss': 0.7006914178530376, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 04:10:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.113037109375, 'train_avg_loss': 0.6939854939778646, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 04:10:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 333.113037109375, 'train_avg_loss': 0.6939854939778646, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 04:10:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:10:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:10:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 04:10:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:10:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:10:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:10:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:10:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:10:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:11:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:11:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.361877, avg_loss=0.629921, seen=480, correct=320, accuracy=0.666667
2025-10-10 04:11:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:11:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:11:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:11:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2130MB allocated=2057MB
2025-10-10 04:11:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.17763632535934, 'train_avg_loss': 0.6264803027113278, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 04:11:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.36187744140625, 'train_avg_loss': 0.6299205780029297, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:11:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 302.36187744140625, 'train_avg_loss': 0.6299205780029297, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:11:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #127, planning to set LR to 1.00e-05
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:11:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:11:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:11:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:11:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.255066, avg_loss=0.673448, seen=480, correct=285, accuracy=0.593750
2025-10-10 04:11:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:11:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:11:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:11:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=127 reserved=2110MB allocated=2057MB
2025-10-10 04:11:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 127, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.91460424661636, 'train_avg_loss': 0.6659550353884697, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 04:11:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 127, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.25506591796875, 'train_avg_loss': 0.6734480539957682, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 04:11:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 127, 'Results_raw': {'train_total': 480, 'train_loss': 323.25506591796875, 'train_avg_loss': 0.6734480539957682, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 04:11:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #128) -------------
2025-10-10 04:11:57 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=128 aidx=4 | s=5 (candidates=6)
2025-10-10 04:11:57 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 44, 24, 27, 30] (from 6)
2025-10-10 04:11:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:11:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:11:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 04:11:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:11:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:11:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:11:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:11:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:11:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:12:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:12:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=301.864807, avg_loss=0.628885, seen=480, correct=322, accuracy=0.670833
2025-10-10 04:12:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:12:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:12:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:12:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2130MB allocated=2057MB
2025-10-10 04:12:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.69363737106323, 'train_avg_loss': 0.6224469780921936, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 04:12:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 301.86480712890625, 'train_avg_loss': 0.628885014851888, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 04:12:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 301.86480712890625, 'train_avg_loss': 0.628885014851888, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 04:12:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:12:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:12:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:13:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:13:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.598022, avg_loss=0.667913, seen=480, correct=290, accuracy=0.604167
2025-10-10 04:13:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:13:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:13:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:13:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2110MB allocated=2057MB
2025-10-10 04:13:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.24379402399063, 'train_avg_loss': 0.6520316168665886, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 04:13:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.5980224609375, 'train_avg_loss': 0.6679125467936198, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 04:13:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 320.5980224609375, 'train_avg_loss': 0.6679125467936198, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 04:13:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:13:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:13:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 04:13:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:13:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:13:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:13:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:13:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:13:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:13:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:13:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.878265, avg_loss=0.695580, seen=480, correct=242, accuracy=0.504167
2025-10-10 04:13:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:13:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:13:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:13:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2110MB allocated=2057MB
2025-10-10 04:13:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.62036979198456, 'train_avg_loss': 0.705169748266538, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 04:13:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.8782653808594, 'train_avg_loss': 0.695579719543457, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 04:13:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 333.8782653808594, 'train_avg_loss': 0.695579719543457, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 04:13:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:13:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:13:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 04:13:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:13:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:14:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:14:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:14:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:14:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:14:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:14:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.014893, avg_loss=0.685448, seen=480, correct=263, accuracy=0.547917
2025-10-10 04:14:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:14:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:14:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:14:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2114MB allocated=2057MB
2025-10-10 04:14:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.63877952098846, 'train_avg_loss': 0.6803231626749039, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 04:14:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.014892578125, 'train_avg_loss': 0.6854476928710938, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 04:14:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 329.014892578125, 'train_avg_loss': 0.6854476928710938, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 04:14:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:14:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:14:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #128, planning to set LR to 1.00e-05
2025-10-10 04:14:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:14:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:14:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:14:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:14:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:14:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:15:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:15:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.559967, avg_loss=0.686583, seen=480, correct=260, accuracy=0.541667
2025-10-10 04:15:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:15:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:15:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:15:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=128 reserved=2110MB allocated=2057MB
2025-10-10 04:15:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 128, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.15801358222961, 'train_avg_loss': 0.7013167798519134, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 04:15:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 128, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5599670410156, 'train_avg_loss': 0.6865832646687825, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 04:15:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 128, 'Results_raw': {'train_total': 480, 'train_loss': 329.5599670410156, 'train_avg_loss': 0.6865832646687825, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 04:15:21 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #129) -------------
2025-10-10 04:15:21 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=129 aidx=4 | s=5 (candidates=6)
2025-10-10 04:15:21 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 25, 30, 24, 44] (from 6)
2025-10-10 04:15:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:15:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:15:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:16:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:16:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.037933, avg_loss=0.685496, seen=480, correct=267, accuracy=0.556250
2025-10-10 04:16:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:16:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:16:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:16:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2114MB allocated=2057MB
2025-10-10 04:16:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.06891775131226, 'train_avg_loss': 0.6839076479276022, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:16:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.0379333496094, 'train_avg_loss': 0.6854956944783529, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:16:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 329.0379333496094, 'train_avg_loss': 0.6854956944783529, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:16:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:16:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:16:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:16:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:16:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.020538, avg_loss=0.691709, seen=480, correct=258, accuracy=0.537500
2025-10-10 04:16:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:16:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:16:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:16:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2110MB allocated=2057MB
2025-10-10 04:16:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.91369163990021, 'train_avg_loss': 0.6826140969991684, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:16:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0205383300781, 'train_avg_loss': 0.6917094548543294, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 04:16:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 332.0205383300781, 'train_avg_loss': 0.6917094548543294, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 04:16:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:16:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:16:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 04:16:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:16:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:16:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:16:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:16:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:16:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:17:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:17:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.021637, avg_loss=0.679212, seen=480, correct=270, accuracy=0.562500
2025-10-10 04:17:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:17:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:17:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:17:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2110MB allocated=2057MB
2025-10-10 04:17:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.10894322395325, 'train_avg_loss': 0.6925745268662771, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 04:17:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.0216369628906, 'train_avg_loss': 0.6792117436726888, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:17:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 326.0216369628906, 'train_avg_loss': 0.6792117436726888, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:17:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:17:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:17:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 04:17:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:17:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:17:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:17:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:17:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:17:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:18:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:18:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.632843, avg_loss=0.692985, seen=480, correct=240, accuracy=0.500000
2025-10-10 04:18:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:18:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:18:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:18:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2110MB allocated=2057MB
2025-10-10 04:18:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.50140523910522, 'train_avg_loss': 0.7041783769925435, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 04:18:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.6328430175781, 'train_avg_loss': 0.6929850896199544, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 04:18:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 332.6328430175781, 'train_avg_loss': 0.6929850896199544, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 04:18:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:18:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:18:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #129, planning to set LR to 1.00e-05
2025-10-10 04:18:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:18:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:18:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:18:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:18:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:18:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:18:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:18:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.494965, avg_loss=0.665615, seen=480, correct=281, accuracy=0.585417
2025-10-10 04:18:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:18:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:18:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:18:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=129 reserved=2110MB allocated=2057MB
2025-10-10 04:18:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 129, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.71636670827866, 'train_avg_loss': 0.6476363892356555, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:18:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 129, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.4949645996094, 'train_avg_loss': 0.6656145095825196, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 04:18:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 129, 'Results_raw': {'train_total': 480, 'train_loss': 319.4949645996094, 'train_avg_loss': 0.6656145095825196, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 04:18:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #130) -------------
2025-10-10 04:18:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=130 aidx=4 | s=5 (candidates=6)
2025-10-10 04:18:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 27, 30, 25, 4] (from 6)
2025-10-10 04:18:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:18:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:18:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:19:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:19:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.753357, avg_loss=0.693236, seen=480, correct=250, accuracy=0.520833
2025-10-10 04:19:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:19:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:19:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:19:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2110MB allocated=2057MB
2025-10-10 04:19:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47340226173401, 'train_avg_loss': 0.7039450188477834, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 04:19:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.75335693359375, 'train_avg_loss': 0.6932361602783204, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 04:19:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 332.75335693359375, 'train_avg_loss': 0.6932361602783204, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 04:19:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:19:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:19:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:20:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:20:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.157623, avg_loss=0.685745, seen=480, correct=264, accuracy=0.550000
2025-10-10 04:20:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:20:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:20:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:20:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2114MB allocated=2057MB
2025-10-10 04:20:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.9937247633934, 'train_avg_loss': 0.683281039694945, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:20:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.1576232910156, 'train_avg_loss': 0.6857450485229493, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 04:20:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 329.1576232910156, 'train_avg_loss': 0.6857450485229493, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 04:20:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:20:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:20:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:20:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:20:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.793976, avg_loss=0.678737, seen=480, correct=267, accuracy=0.556250
2025-10-10 04:20:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:20:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:20:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:20:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2110MB allocated=2057MB
2025-10-10 04:20:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.57303750514984, 'train_avg_loss': 0.6964419792095821, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 04:20:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7939758300781, 'train_avg_loss': 0.6787374496459961, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:20:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 325.7939758300781, 'train_avg_loss': 0.6787374496459961, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:20:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:20:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:20:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:21:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:21:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.916504, avg_loss=0.687326, seen=480, correct=263, accuracy=0.547917
2025-10-10 04:21:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:21:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:21:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:21:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2110MB allocated=2057MB
2025-10-10 04:21:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.68714636564255, 'train_avg_loss': 0.6807262197136879, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:21:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.91650390625, 'train_avg_loss': 0.6873260498046875, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 04:21:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 329.91650390625, 'train_avg_loss': 0.6873260498046875, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 04:21:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:21:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:21:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #130, planning to set LR to 1.00e-05
2025-10-10 04:21:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:21:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:21:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:21:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:21:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:21:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:22:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:22:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.471497, avg_loss=0.625982, seen=480, correct=320, accuracy=0.666667
2025-10-10 04:22:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:22:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:22:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:22:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=130 reserved=2130MB allocated=2057MB
2025-10-10 04:22:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 130, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.17223286628723, 'train_avg_loss': 0.6181019405523936, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 04:22:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 130, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.47149658203125, 'train_avg_loss': 0.6259822845458984, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:22:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 130, 'Results_raw': {'train_total': 480, 'train_loss': 300.47149658203125, 'train_avg_loss': 0.6259822845458984, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 04:22:08 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #131) -------------
2025-10-10 04:22:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=131 aidx=4 | s=5 (candidates=6)
2025-10-10 04:22:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[27, 25, 4, 30, 44] (from 6)
2025-10-10 04:22:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:22:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:22:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:22:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:22:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.040253, avg_loss=0.691751, seen=480, correct=264, accuracy=0.550000
2025-10-10 04:22:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:22:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:22:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:22:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2114MB allocated=2057MB
2025-10-10 04:22:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.64397746324539, 'train_avg_loss': 0.6886998121937116, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:22:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.0402526855469, 'train_avg_loss': 0.6917505264282227, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 04:22:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 332.0402526855469, 'train_avg_loss': 0.6917505264282227, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 04:22:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:22:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:22:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:23:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:23:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.795959, avg_loss=0.691242, seen=480, correct=263, accuracy=0.547917
2025-10-10 04:23:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:23:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:23:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:23:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2110MB allocated=2057MB
2025-10-10 04:23:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.49880909919739, 'train_avg_loss': 0.6874900758266449, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:23:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.79595947265625, 'train_avg_loss': 0.6912415822347006, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 04:23:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 331.79595947265625, 'train_avg_loss': 0.6912415822347006, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 04:23:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:23:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:23:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:24:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:24:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.059204, avg_loss=0.598040, seen=480, correct=332, accuracy=0.691667
2025-10-10 04:24:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:24:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:24:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:24:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2130MB allocated=2057MB
2025-10-10 04:24:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.57499414682388, 'train_avg_loss': 0.604791617890199, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 04:24:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.0592041015625, 'train_avg_loss': 0.5980400085449219, 'train_seen': 480, 'train_correct': 332, 'train_acc': 0.6916666666666667}}
2025-10-10 04:24:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 287.0592041015625, 'train_avg_loss': 0.5980400085449219, 'train_seen': 480, 'train_correct': 332, 'train_acc': 0.6916666666666667}}
2025-10-10 04:24:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:24:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:24:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:24:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:24:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.447510, avg_loss=0.682182, seen=480, correct=255, accuracy=0.531250
2025-10-10 04:24:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:24:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:25:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2110MB allocated=2057MB
2025-10-10 04:25:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.16188913583755, 'train_avg_loss': 0.7013490761319796, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 04:25:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.447509765625, 'train_avg_loss': 0.6821823120117188, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 04:25:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 327.447509765625, 'train_avg_loss': 0.6821823120117188, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 04:25:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #131, planning to set LR to 1.00e-05
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:25:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:25:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:25:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:25:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.688293, avg_loss=0.657684, seen=480, correct=290, accuracy=0.604167
2025-10-10 04:25:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:25:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:25:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=131 reserved=2110MB allocated=2057MB
2025-10-10 04:25:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 131, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.04768478870392, 'train_avg_loss': 0.642064039905866, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 04:25:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 131, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.68829345703125, 'train_avg_loss': 0.6576839447021484, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 04:25:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 131, 'Results_raw': {'train_total': 480, 'train_loss': 315.68829345703125, 'train_avg_loss': 0.6576839447021484, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 04:25:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #132) -------------
2025-10-10 04:25:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=132 aidx=4 | s=5 (candidates=6)
2025-10-10 04:25:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 44, 27, 4, 30] (from 6)
2025-10-10 04:25:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:25:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:25:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:26:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:26:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.480621, avg_loss=0.690585, seen=480, correct=262, accuracy=0.545833
2025-10-10 04:26:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:26:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:26:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:26:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2110MB allocated=2057MB
2025-10-10 04:26:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0980874300003, 'train_avg_loss': 0.6841507285833359, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:26:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.4806213378906, 'train_avg_loss': 0.6905846277872721, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:26:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 331.4806213378906, 'train_avg_loss': 0.6905846277872721, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:26:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:26:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:26:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:27:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:27:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.988220, avg_loss=0.645809, seen=480, correct=293, accuracy=0.610417
2025-10-10 04:27:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:27:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:27:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2110MB allocated=2057MB
2025-10-10 04:27:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.60654640197754, 'train_avg_loss': 0.6217212200164794, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 04:27:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.98822021484375, 'train_avg_loss': 0.6458087921142578, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 04:27:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 309.98822021484375, 'train_avg_loss': 0.6458087921142578, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 04:27:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:27:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:27:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 04:27:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:27:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:27:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:27:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:27:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:27:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:27:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.486206, avg_loss=0.688513, seen=480, correct=262, accuracy=0.545833
2025-10-10 04:27:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:27:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:27:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2114MB allocated=2057MB
2025-10-10 04:27:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.59469056129456, 'train_avg_loss': 0.6882890880107879, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:27:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4862060546875, 'train_avg_loss': 0.6885129292805989, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:27:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 330.4862060546875, 'train_avg_loss': 0.6885129292805989, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:27:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:27:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:27:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 04:27:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:27:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:27:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:27:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:27:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:27:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:28:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:28:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=285.813812, avg_loss=0.595445, seen=480, correct=333, accuracy=0.693750
2025-10-10 04:28:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:28:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:28:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2130MB allocated=2057MB
2025-10-10 04:28:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.73610278964043, 'train_avg_loss': 0.5978008565803369, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 04:28:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 285.8138122558594, 'train_avg_loss': 0.5954454421997071, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 04:28:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 285.8138122558594, 'train_avg_loss': 0.5954454421997071, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 04:28:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #132, planning to set LR to 1.00e-05
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:28:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:28:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:29:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:29:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.488708, avg_loss=0.680185, seen=480, correct=268, accuracy=0.558333
2025-10-10 04:29:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:29:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:29:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:29:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=132 reserved=2110MB allocated=2057MB
2025-10-10 04:29:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 132, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.76918280124664, 'train_avg_loss': 0.698076523343722, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 04:29:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 132, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.48870849609375, 'train_avg_loss': 0.680184809366862, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 04:29:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 132, 'Results_raw': {'train_total': 480, 'train_loss': 326.48870849609375, 'train_avg_loss': 0.680184809366862, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 04:29:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #133) -------------
2025-10-10 04:29:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=133 aidx=4 | s=5 (candidates=6)
2025-10-10 04:29:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 4, 44, 30, 25] (from 6)
2025-10-10 04:29:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:29:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:29:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:30:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:30:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.129822, avg_loss=0.696104, seen=480, correct=248, accuracy=0.516667
2025-10-10 04:30:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:30:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:30:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2110MB allocated=2057MB
2025-10-10 04:30:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.08202928304672, 'train_avg_loss': 0.709016910692056, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 04:30:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.12982177734375, 'train_avg_loss': 0.6961037953694661, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 04:30:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 334.12982177734375, 'train_avg_loss': 0.6961037953694661, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 04:30:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:30:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:30:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:30:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:30:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.295746, avg_loss=0.596449, seen=480, correct=338, accuracy=0.704167
2025-10-10 04:30:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:30:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:30:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2130MB allocated=2057MB
2025-10-10 04:30:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.71902093291283, 'train_avg_loss': 0.5976585077742735, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 04:30:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.2957458496094, 'train_avg_loss': 0.5964494705200195, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 04:30:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 286.2957458496094, 'train_avg_loss': 0.5964494705200195, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 04:30:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:30:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:30:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 04:30:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:30:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:30:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:30:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:30:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:30:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:31:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:31:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.749542, avg_loss=0.645312, seen=480, correct=299, accuracy=0.622917
2025-10-10 04:31:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:31:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:31:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:31:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2110MB allocated=2057MB
2025-10-10 04:31:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.23204827308655, 'train_avg_loss': 0.6186004022757212, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 04:31:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.7495422363281, 'train_avg_loss': 0.6453115463256835, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:31:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 309.7495422363281, 'train_avg_loss': 0.6453115463256835, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 04:31:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:31:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:31:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:32:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:32:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.475098, avg_loss=0.669740, seen=480, correct=277, accuracy=0.577083
2025-10-10 04:32:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:32:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:32:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:32:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2110MB allocated=2057MB
2025-10-10 04:32:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.12503796815872, 'train_avg_loss': 0.6843753164013227, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:32:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.47509765625, 'train_avg_loss': 0.6697397867838542, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 04:32:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 321.47509765625, 'train_avg_loss': 0.6697397867838542, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 04:32:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #133, planning to set LR to 1.00e-05
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:32:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:32:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:33:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:33:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.650818, avg_loss=0.690939, seen=480, correct=267, accuracy=0.556250
2025-10-10 04:33:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:33:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:33:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:33:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=133 reserved=2110MB allocated=2057MB
2025-10-10 04:33:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 133, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.70698261260986, 'train_avg_loss': 0.6808915217717488, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:33:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 133, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.65081787109375, 'train_avg_loss': 0.690939203898112, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:33:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 133, 'Results_raw': {'train_total': 480, 'train_loss': 331.65081787109375, 'train_avg_loss': 0.690939203898112, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 04:33:10 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #134) -------------
2025-10-10 04:33:10 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=134 aidx=4 | s=5 (candidates=6)
2025-10-10 04:33:10 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 24, 30, 44, 25] (from 6)
2025-10-10 04:33:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:33:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:33:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 04:33:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:33:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:33:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:33:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:33:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:33:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:33:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:33:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.832214, avg_loss=0.599650, seen=480, correct=329, accuracy=0.685417
2025-10-10 04:33:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:33:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:33:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:33:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2130MB allocated=2057MB
2025-10-10 04:33:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.8841010928154, 'train_avg_loss': 0.5990341757734616, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 04:33:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.83221435546875, 'train_avg_loss': 0.5996504465738932, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 04:33:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 287.83221435546875, 'train_avg_loss': 0.5996504465738932, 'train_seen': 480, 'train_correct': 329, 'train_acc': 0.6854166666666667}}
2025-10-10 04:33:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:33:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:33:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:34:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:34:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.453705, avg_loss=0.694695, seen=480, correct=262, accuracy=0.545833
2025-10-10 04:34:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:34:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:34:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:34:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2110MB allocated=2057MB
2025-10-10 04:34:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.94507187604904, 'train_avg_loss': 0.7078755989670753, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 04:34:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.4537048339844, 'train_avg_loss': 0.6946952184041341, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:34:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 333.4537048339844, 'train_avg_loss': 0.6946952184041341, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 04:34:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:34:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:34:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:35:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:35:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.163544, avg_loss=0.671174, seen=480, correct=274, accuracy=0.570833
2025-10-10 04:35:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:35:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:35:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:35:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2110MB allocated=2057MB
2025-10-10 04:35:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.8824952840805, 'train_avg_loss': 0.6906874607006709, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:35:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1635437011719, 'train_avg_loss': 0.6711740493774414, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 04:35:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 322.1635437011719, 'train_avg_loss': 0.6711740493774414, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 04:35:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:35:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:35:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 04:35:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:35:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:35:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:35:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:35:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:35:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:36:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:36:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.493317, avg_loss=0.646861, seen=480, correct=295, accuracy=0.614583
2025-10-10 04:36:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:36:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:36:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:36:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2110MB allocated=2057MB
2025-10-10 04:36:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.80047577619553, 'train_avg_loss': 0.6233372981349627, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 04:36:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.4933166503906, 'train_avg_loss': 0.6468610763549805, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 04:36:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 310.4933166503906, 'train_avg_loss': 0.6468610763549805, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 04:36:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:36:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:36:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #134, planning to set LR to 1.00e-05
2025-10-10 04:36:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:36:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:36:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:36:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:36:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:36:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:36:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:36:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.540924, avg_loss=0.676127, seen=480, correct=280, accuracy=0.583333
2025-10-10 04:36:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:36:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:36:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:36:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=134 reserved=2110MB allocated=2057MB
2025-10-10 04:36:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 134, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.25228935480118, 'train_avg_loss': 0.6687690779566765, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:36:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 134, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.5409240722656, 'train_avg_loss': 0.6761269251505534, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 04:36:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 134, 'Results_raw': {'train_total': 480, 'train_loss': 324.5409240722656, 'train_avg_loss': 0.6761269251505534, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 04:36:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #135) -------------
2025-10-10 04:36:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=135 aidx=4 | s=5 (candidates=6)
2025-10-10 04:36:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[4, 27, 24, 30, 44] (from 6)
2025-10-10 04:36:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:36:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:36:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:37:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:37:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.388580, avg_loss=0.598726, seen=480, correct=333, accuracy=0.693750
2025-10-10 04:37:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:37:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:37:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:37:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2130MB allocated=2057MB
2025-10-10 04:37:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.92940858006477, 'train_avg_loss': 0.6077450715005398, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 04:37:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.3885803222656, 'train_avg_loss': 0.5987262090047201, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 04:37:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 287.3885803222656, 'train_avg_loss': 0.5987262090047201, 'train_seen': 480, 'train_correct': 333, 'train_acc': 0.69375}}
2025-10-10 04:37:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:37:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:37:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 04:37:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:37:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:37:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:37:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:37:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:37:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:38:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:38:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.448334, avg_loss=0.686351, seen=480, correct=266, accuracy=0.554167
2025-10-10 04:38:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:38:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:38:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:38:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2114MB allocated=2057MB
2025-10-10 04:38:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32001656293869, 'train_avg_loss': 0.6860001380244891, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:38:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4483337402344, 'train_avg_loss': 0.686350695292155, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 04:38:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 329.4483337402344, 'train_avg_loss': 0.686350695292155, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 04:38:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:38:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:38:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:38:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:38:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.177856, avg_loss=0.698287, seen=480, correct=251, accuracy=0.522917
2025-10-10 04:38:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:38:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:39:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2110MB allocated=2057MB
2025-10-10 04:39:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.10480886697769, 'train_avg_loss': 0.7092067405581475, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 04:39:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.1778564453125, 'train_avg_loss': 0.6982872009277343, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:39:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 335.1778564453125, 'train_avg_loss': 0.6982872009277343, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 04:39:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:39:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:39:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 04:39:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:39:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:39:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:39:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:39:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:39:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:39:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.871002, avg_loss=0.670565, seen=480, correct=270, accuracy=0.562500
2025-10-10 04:39:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:39:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:39:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2110MB allocated=2057MB
2025-10-10 04:39:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.97780704498291, 'train_avg_loss': 0.6914817253748576, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 04:39:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.8710021972656, 'train_avg_loss': 0.6705645879109701, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:39:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 321.8710021972656, 'train_avg_loss': 0.6705645879109701, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 04:39:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:39:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:39:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #135, planning to set LR to 1.00e-05
2025-10-10 04:39:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1979, total=7916)
2025-10-10 04:39:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:39:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:39:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:39:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:39:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=990, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:40:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:40:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.086426, avg_loss=0.646013, seen=480, correct=297, accuracy=0.618750
2025-10-10 04:40:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:40:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:40:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:40:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=135 reserved=2110MB allocated=2057MB
2025-10-10 04:40:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #44', 'Round': 135, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.02480429410934, 'train_avg_loss': 0.6252067024509113, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 04:40:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #44', 'Round': 135, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.08642578125, 'train_avg_loss': 0.6460133870442708, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 04:40:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #44', 'Round': 135, 'Results_raw': {'train_total': 480, 'train_loss': 310.08642578125, 'train_avg_loss': 0.6460133870442708, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 04:40:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #136) -------------
2025-10-10 04:40:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=136 aidx=4 | s=5 (candidates=6)
2025-10-10 04:40:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[25, 30, 24, 4, 27] (from 6)
2025-10-10 04:40:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:40:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:40:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:40:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:40:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:41:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:41:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.485901, avg_loss=0.667679, seen=480, correct=275, accuracy=0.572917
2025-10-10 04:41:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:41:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:41:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:41:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2110MB allocated=2057MB
2025-10-10 04:41:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.81292086839676, 'train_avg_loss': 0.6651076739033063, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:41:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.48590087890625, 'train_avg_loss': 0.667678960164388, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 04:41:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 320.48590087890625, 'train_avg_loss': 0.667678960164388, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 04:41:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:41:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:41:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:41:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:41:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.094238, avg_loss=0.668946, seen=480, correct=278, accuracy=0.579167
2025-10-10 04:41:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:41:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:41:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:41:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2110MB allocated=2057MB
2025-10-10 04:41:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.00968253612518, 'train_avg_loss': 0.6917473544677099, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:41:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.09423828125, 'train_avg_loss': 0.6689463297526042, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 04:41:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 321.09423828125, 'train_avg_loss': 0.6689463297526042, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 04:42:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:42:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:42:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:42:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:42:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.089081, avg_loss=0.698102, seen=480, correct=255, accuracy=0.531250
2025-10-10 04:42:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:42:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:42:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:42:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2110MB allocated=2057MB
2025-10-10 04:42:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.07215189933777, 'train_avg_loss': 0.7089345991611481, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 04:42:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.0890808105469, 'train_avg_loss': 0.6981022516886394, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 04:42:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 335.0890808105469, 'train_avg_loss': 0.6981022516886394, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 04:42:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:42:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:42:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:43:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.190857, avg_loss=0.596231, seen=480, correct=336, accuracy=0.700000
2025-10-10 04:43:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:43:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:43:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:43:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2130MB allocated=2057MB
2025-10-10 04:43:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.1837546825409, 'train_avg_loss': 0.6015312890211741, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 04:43:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.19085693359375, 'train_avg_loss': 0.596230951944987, 'train_seen': 480, 'train_correct': 336, 'train_acc': 0.7}}
2025-10-10 04:43:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 286.19085693359375, 'train_avg_loss': 0.596230951944987, 'train_seen': 480, 'train_correct': 336, 'train_acc': 0.7}}
2025-10-10 04:43:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #136, planning to set LR to 1.00e-05
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:43:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:43:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:44:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.222015, avg_loss=0.687963, seen=480, correct=271, accuracy=0.564583
2025-10-10 04:44:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:44:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:44:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=136 reserved=2114MB allocated=2057MB
2025-10-10 04:44:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 136, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.81051629781723, 'train_avg_loss': 0.6900876358151435, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:44:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 136, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.2220153808594, 'train_avg_loss': 0.687962532043457, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 04:44:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 136, 'Results_raw': {'train_total': 480, 'train_loss': 330.2220153808594, 'train_avg_loss': 0.687962532043457, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 04:44:11 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #137) -------------
2025-10-10 04:44:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=137 aidx=4 | s=5 (candidates=6)
2025-10-10 04:44:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[24, 25, 4, 30, 27] (from 6)
2025-10-10 04:44:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:44:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:44:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 04:44:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1236, total=4944)
2025-10-10 04:44:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:44:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:44:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:44:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=618, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:44:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:44:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.106018, avg_loss=0.693971, seen=480, correct=254, accuracy=0.529167
2025-10-10 04:44:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:44:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:44:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2110MB allocated=2057MB
2025-10-10 04:44:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #24', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.21238958835602, 'train_avg_loss': 0.7017699132363001, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 04:44:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #24', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.10601806640625, 'train_avg_loss': 0.6939708709716796, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 04:44:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #24', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 333.10601806640625, 'train_avg_loss': 0.6939708709716796, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 04:44:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1162, total=4647)
2025-10-10 04:44:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:44:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=581, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:45:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:45:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.692352, avg_loss=0.670192, seen=480, correct=280, accuracy=0.583333
2025-10-10 04:45:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:45:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:45:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:45:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2110MB allocated=2057MB
2025-10-10 04:45:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #25', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.13789874315262, 'train_avg_loss': 0.6678158228596052, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 04:45:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #25', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.6923522949219, 'train_avg_loss': 0.6701924006144205, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 04:45:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #25', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 321.6923522949219, 'train_avg_loss': 0.6701924006144205, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 04:45:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=54, total=213)
2025-10-10 04:45:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:45:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=27, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:46:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:46:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=287.954376, avg_loss=0.599905, seen=480, correct=338, accuracy=0.704167
2025-10-10 04:46:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:46:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:46:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:46:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2130MB allocated=2057MB
2025-10-10 04:46:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #4', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.47314286231995, 'train_avg_loss': 0.5956095238526662, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 04:46:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #4', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 287.9543762207031, 'train_avg_loss': 0.5999049504597982, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 04:46:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #4', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 287.9543762207031, 'train_avg_loss': 0.5999049504597982, 'train_seen': 480, 'train_correct': 338, 'train_acc': 0.7041666666666667}}
2025-10-10 04:46:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=812, total=3247)
2025-10-10 04:46:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:46:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=406, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:47:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:47:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.366333, avg_loss=0.667430, seen=480, correct=279, accuracy=0.581250
2025-10-10 04:47:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:47:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:47:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:47:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2110MB allocated=2057MB
2025-10-10 04:47:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #30', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.58795255422592, 'train_avg_loss': 0.6882329379518827, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:47:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #30', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.3663330078125, 'train_avg_loss': 0.6674298604329427, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 04:47:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #30', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 320.3663330078125, 'train_avg_loss': 0.6674298604329427, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 04:47:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:47:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:47:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #137, planning to set LR to 1.00e-05
2025-10-10 04:47:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=586, total=2342)
2025-10-10 04:47:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:47:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:47:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:47:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:47:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=293, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:47:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:47:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.542603, avg_loss=0.674047, seen=480, correct=279, accuracy=0.581250
2025-10-10 04:47:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:47:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:47:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:47:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=137 reserved=2114MB allocated=2057MB
2025-10-10 04:47:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #27', 'Round': 137, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.02185010910034, 'train_avg_loss': 0.6751820842425028, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 04:47:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #27', 'Round': 137, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.5426025390625, 'train_avg_loss': 0.6740470886230469, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 04:47:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #27', 'Round': 137, 'Results_raw': {'train_total': 480, 'train_loss': 323.5426025390625, 'train_avg_loss': 0.6740470886230469, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 04:47:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #138) -------------
2025-10-10 04:47:52 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=138 aidx=5 | s=5 (candidates=7)
2025-10-10 04:47:52 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 26, 47, 1, 34] (from 7)
2025-10-10 04:47:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:47:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:47:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 04:47:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 04:47:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:47:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:47:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:47:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:47:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:48:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:48:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=345.128723, avg_loss=0.719018, seen=480, correct=238, accuracy=0.495833
2025-10-10 04:48:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:48:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:48:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:48:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2442MB allocated=2124MB
2025-10-10 04:48:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.52189898490906, 'train_avg_loss': 0.7126824915409088, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 04:48:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 345.12872314453125, 'train_avg_loss': 0.7190181732177734, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 04:48:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 345.12872314453125, 'train_avg_loss': 0.7190181732177734, 'train_seen': 480, 'train_correct': 238, 'train_acc': 0.49583333333333335}}
2025-10-10 04:48:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:48:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:48:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 04:48:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 04:48:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:48:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:48:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:48:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:48:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:49:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:49:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.125916, avg_loss=0.714846, seen=480, correct=235, accuracy=0.489583
2025-10-10 04:49:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:49:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:49:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:49:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2390MB allocated=2132MB
2025-10-10 04:49:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.2834644317627, 'train_avg_loss': 0.7106955369313558, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 04:49:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.12591552734375, 'train_avg_loss': 0.7148456573486328, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 04:49:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 343.12591552734375, 'train_avg_loss': 0.7148456573486328, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 04:49:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:49:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:49:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 04:49:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 04:49:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:49:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:49:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:49:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:49:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:50:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:50:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.918274, avg_loss=0.701913, seen=480, correct=259, accuracy=0.539583
2025-10-10 04:50:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:50:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:50:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:50:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2396MB allocated=2141MB
2025-10-10 04:50:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 90.29242986440659, 'train_avg_loss': 0.7524369155367215, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 04:50:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.91827392578125, 'train_avg_loss': 0.7019130706787109, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 04:50:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 336.91827392578125, 'train_avg_loss': 0.7019130706787109, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 04:50:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 04:50:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:50:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:50:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:50:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=346.958191, avg_loss=0.722830, seen=480, correct=235, accuracy=0.489583
2025-10-10 04:50:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:50:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:50:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:50:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2388MB allocated=2149MB
2025-10-10 04:50:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.62843799591064, 'train_avg_loss': 0.7052369832992553, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:50:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 346.95819091796875, 'train_avg_loss': 0.7228295644124348, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 04:50:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 346.95819091796875, 'train_avg_loss': 0.7228295644124348, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 04:50:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:50:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:50:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #138, planning to set LR to 1.00e-05
2025-10-10 04:50:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 04:50:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:50:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:50:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:50:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:50:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:51:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:51:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.238373, avg_loss=0.717163, seen=480, correct=239, accuracy=0.497917
2025-10-10 04:51:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:51:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:51:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:51:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=138 reserved=2408MB allocated=2158MB
2025-10-10 04:51:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 138, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.18784403800964, 'train_avg_loss': 0.7182320336500804, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 04:51:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 138, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.2383728027344, 'train_avg_loss': 0.7171632766723632, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 04:51:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 138, 'Results_raw': {'train_total': 480, 'train_loss': 344.2383728027344, 'train_avg_loss': 0.7171632766723632, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 04:51:35 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #139) -------------
2025-10-10 04:51:36 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=139 aidx=5 | s=5 (candidates=7)
2025-10-10 04:51:36 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5, 29, 34, 26, 1] (from 7)
2025-10-10 04:51:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:51:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:51:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 04:51:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 04:51:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:51:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:51:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:51:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:51:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:52:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:52:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=348.278748, avg_loss=0.725581, seen=480, correct=244, accuracy=0.508333
2025-10-10 04:52:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:52:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:52:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:52:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2514MB allocated=2225MB
2025-10-10 04:52:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.15199089050293, 'train_avg_loss': 0.7095999240875244, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 04:52:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 348.27874755859375, 'train_avg_loss': 0.7255807240804036, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 04:52:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 348.27874755859375, 'train_avg_loss': 0.7255807240804036, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 04:52:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 04:52:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:52:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:53:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:53:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.599915, avg_loss=0.703333, seen=480, correct=247, accuracy=0.514583
2025-10-10 04:53:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:53:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:53:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:53:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2440MB allocated=2166MB
2025-10-10 04:53:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.70747405290604, 'train_avg_loss': 0.7225622837742169, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 04:53:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.59991455078125, 'train_avg_loss': 0.7033331553141277, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 04:53:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 337.59991455078125, 'train_avg_loss': 0.7033331553141277, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 04:53:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 04:53:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:53:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:53:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:53:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.091553, avg_loss=0.710607, seen=480, correct=233, accuracy=0.485417
2025-10-10 04:53:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:53:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:53:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:53:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2428MB allocated=2166MB
2025-10-10 04:53:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12958914041519, 'train_avg_loss': 0.7010799095034599, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 04:53:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.091552734375, 'train_avg_loss': 0.710607401529948, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 04:53:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 341.091552734375, 'train_avg_loss': 0.710607401529948, 'train_seen': 480, 'train_correct': 233, 'train_acc': 0.48541666666666666}}
2025-10-10 04:53:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 04:53:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:53:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:54:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:54:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.883667, avg_loss=0.716424, seen=480, correct=222, accuracy=0.462500
2025-10-10 04:54:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:54:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:54:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:54:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2422MB allocated=2166MB
2025-10-10 04:54:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.12141364812851, 'train_avg_loss': 0.7010117804010709, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 04:54:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.8836669921875, 'train_avg_loss': 0.716424306233724, 'train_seen': 480, 'train_correct': 222, 'train_acc': 0.4625}}
2025-10-10 04:54:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 343.8836669921875, 'train_avg_loss': 0.716424306233724, 'train_seen': 480, 'train_correct': 222, 'train_acc': 0.4625}}
2025-10-10 04:54:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:54:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:54:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #139, planning to set LR to 1.00e-05
2025-10-10 04:54:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 04:54:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:54:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:54:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:54:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:54:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:55:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:55:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=346.231750, avg_loss=0.721316, seen=480, correct=243, accuracy=0.506250
2025-10-10 04:55:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:55:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:55:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:55:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=139 reserved=2422MB allocated=2166MB
2025-10-10 04:55:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 139, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.01279044151306, 'train_avg_loss': 0.7251065870126089, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 04:55:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 139, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 346.23175048828125, 'train_avg_loss': 0.721316146850586, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 04:55:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 139, 'Results_raw': {'train_total': 480, 'train_loss': 346.23175048828125, 'train_avg_loss': 0.721316146850586, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 04:55:24 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #140) -------------
2025-10-10 04:55:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=140 aidx=5 | s=5 (candidates=7)
2025-10-10 04:55:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5, 45, 26, 1, 34] (from 7)
2025-10-10 04:55:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 04:55:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:55:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:56:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:56:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=344.117371, avg_loss=0.716911, seen=480, correct=246, accuracy=0.512500
2025-10-10 04:56:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:56:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:56:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:56:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2408MB allocated=2107MB
2025-10-10 04:56:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.18364298343658, 'train_avg_loss': 0.7098636915286382, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:56:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 344.11737060546875, 'train_avg_loss': 0.7169111887613933, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 04:56:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 344.11737060546875, 'train_avg_loss': 0.7169111887613933, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 04:56:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:56:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:56:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 04:56:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 04:56:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:56:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:56:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:56:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:56:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:56:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:56:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.375793, avg_loss=0.690366, seen=480, correct=254, accuracy=0.529167
2025-10-10 04:56:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:56:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:56:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:56:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2400MB allocated=2175MB
2025-10-10 04:56:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.40609937906265, 'train_avg_loss': 0.6950508281588554, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 04:56:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.37579345703125, 'train_avg_loss': 0.6903662363688151, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 04:56:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 331.37579345703125, 'train_avg_loss': 0.6903662363688151, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 04:56:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 04:56:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:56:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:57:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:57:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.937988, avg_loss=0.708204, seen=480, correct=227, accuracy=0.472917
2025-10-10 04:57:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:57:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:57:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:57:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2362MB allocated=2116MB
2025-10-10 04:57:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.3395527601242, 'train_avg_loss': 0.694496273001035, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 04:57:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.93798828125, 'train_avg_loss': 0.7082041422526042, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-10 04:57:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 339.93798828125, 'train_avg_loss': 0.7082041422526042, 'train_seen': 480, 'train_correct': 227, 'train_acc': 0.47291666666666665}}
2025-10-10 04:57:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 04:57:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:57:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:58:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:58:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.033203, avg_loss=0.706319, seen=480, correct=241, accuracy=0.502083
2025-10-10 04:58:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:58:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:58:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:58:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2362MB allocated=2116MB
2025-10-10 04:58:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.61811935901642, 'train_avg_loss': 0.7051509946584702, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 04:58:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.033203125, 'train_avg_loss': 0.7063191731770834, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 04:58:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 339.033203125, 'train_avg_loss': 0.7063191731770834, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 04:58:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:58:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:58:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #140, planning to set LR to 1.00e-05
2025-10-10 04:58:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 04:58:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:58:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:58:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:58:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:58:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:59:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:59:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.737885, avg_loss=0.701537, seen=480, correct=231, accuracy=0.481250
2025-10-10 04:59:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:59:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:59:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=140 reserved=2366MB allocated=2116MB
2025-10-10 04:59:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 140, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.56088238954544, 'train_avg_loss': 0.6963406865795453, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 04:59:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 140, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.7378845214844, 'train_avg_loss': 0.7015372594197591, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 04:59:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 140, 'Results_raw': {'train_total': 480, 'train_loss': 336.7378845214844, 'train_avg_loss': 0.7015372594197591, 'train_seen': 480, 'train_correct': 231, 'train_acc': 0.48125}}
2025-10-10 04:59:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #141) -------------
2025-10-10 04:59:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=141 aidx=5 | s=5 (candidates=7)
2025-10-10 04:59:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 45, 26, 5, 34] (from 7)
2025-10-10 04:59:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:59:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:59:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 04:59:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 04:59:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:59:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:59:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:59:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 04:59:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 04:59:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.521210, avg_loss=0.703169, seen=480, correct=245, accuracy=0.510417
2025-10-10 04:59:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 04:59:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 04:59:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2362MB allocated=2116MB
2025-10-10 04:59:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.24423742294312, 'train_avg_loss': 0.7020353118578593, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 04:59:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.5212097167969, 'train_avg_loss': 0.7031691869099935, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 04:59:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 337.5212097167969, 'train_avg_loss': 0.7031691869099935, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 04:59:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 04:59:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 04:59:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:00:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:00:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.811066, avg_loss=0.691273, seen=480, correct=255, accuracy=0.531250
2025-10-10 05:00:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:00:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:00:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:00:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2362MB allocated=2116MB
2025-10-10 05:00:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.04871505498886, 'train_avg_loss': 0.6920726254582406, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:00:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.8110656738281, 'train_avg_loss': 0.691273053487142, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:00:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 331.8110656738281, 'train_avg_loss': 0.691273053487142, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:00:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:00:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:00:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 05:00:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:00:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:00:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:00:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:00:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:00:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:01:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:01:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=341.086487, avg_loss=0.710597, seen=480, correct=222, accuracy=0.462500
2025-10-10 05:01:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:01:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:01:19 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:01:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2362MB allocated=2116MB
2025-10-10 05:01:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.16870105266571, 'train_avg_loss': 0.6930725087722143, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 05:01:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 341.08648681640625, 'train_avg_loss': 0.7105968475341797, 'train_seen': 480, 'train_correct': 222, 'train_acc': 0.4625}}
2025-10-10 05:01:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 341.08648681640625, 'train_avg_loss': 0.7105968475341797, 'train_seen': 480, 'train_correct': 222, 'train_acc': 0.4625}}
2025-10-10 05:01:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:01:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:01:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 05:01:21 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:01:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:01:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:01:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:01:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:01:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:02:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:02:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.740509, avg_loss=0.716126, seen=480, correct=251, accuracy=0.522917
2025-10-10 05:02:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:02:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:02:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2408MB allocated=2116MB
2025-10-10 05:02:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43423402309418, 'train_avg_loss': 0.7036186168591182, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:02:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.7405090332031, 'train_avg_loss': 0.7161260604858398, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 05:02:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 343.7405090332031, 'train_avg_loss': 0.7161260604858398, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 05:02:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:02:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:02:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #141, planning to set LR to 1.00e-05
2025-10-10 05:02:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:02:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:02:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:02:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:02:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:02:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:02:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.037384, avg_loss=0.700078, seen=480, correct=245, accuracy=0.510417
2025-10-10 05:02:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:02:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:02:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=141 reserved=2366MB allocated=2116MB
2025-10-10 05:02:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 141, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.6914473772049, 'train_avg_loss': 0.6890953948100408, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:02:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 141, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.0373840332031, 'train_avg_loss': 0.7000778834025065, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 05:02:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 141, 'Results_raw': {'train_total': 480, 'train_loss': 336.0373840332031, 'train_avg_loss': 0.7000778834025065, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 05:02:47 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #142) -------------
2025-10-10 05:02:48 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=142 aidx=5 | s=5 (candidates=7)
2025-10-10 05:02:48 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 29, 45, 47, 34] (from 7)
2025-10-10 05:02:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:02:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:02:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:03:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:03:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.600769, avg_loss=0.709585, seen=480, correct=229, accuracy=0.477083
2025-10-10 05:03:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:03:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:03:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:03:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2362MB allocated=2116MB
2025-10-10 05:03:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.03127491474152, 'train_avg_loss': 0.6919272909561793, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:03:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.60076904296875, 'train_avg_loss': 0.7095849355061848, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 05:03:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 340.60076904296875, 'train_avg_loss': 0.7095849355061848, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 05:03:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:03:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:03:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:04:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:04:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.687164, avg_loss=0.697265, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:04:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:04:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:04:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2384MB allocated=2116MB
2025-10-10 05:04:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.67618757486343, 'train_avg_loss': 0.7139682297905287, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:04:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.6871643066406, 'train_avg_loss': 0.6972649256388347, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:04:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 334.6871643066406, 'train_avg_loss': 0.6972649256388347, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:04:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:04:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:04:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:04:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:04:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.749939, avg_loss=0.693229, seen=480, correct=260, accuracy=0.541667
2025-10-10 05:04:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:04:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:04:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:04:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2362MB allocated=2116MB
2025-10-10 05:04:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.14363372325897, 'train_avg_loss': 0.6928636143604915, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:04:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.74993896484375, 'train_avg_loss': 0.6932290395100912, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 05:04:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 332.74993896484375, 'train_avg_loss': 0.6932290395100912, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 05:04:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:05:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:05:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:05:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:05:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.681091, avg_loss=0.688919, seen=480, correct=248, accuracy=0.516667
2025-10-10 05:05:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:05:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:05:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:05:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2366MB allocated=2116MB
2025-10-10 05:05:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.58423483371735, 'train_avg_loss': 0.6882019569476445, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:05:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.68109130859375, 'train_avg_loss': 0.688918940226237, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:05:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 330.68109130859375, 'train_avg_loss': 0.688918940226237, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:05:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #142, planning to set LR to 1.00e-05
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:05:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:05:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:06:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:06:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.494446, avg_loss=0.692697, seen=480, correct=251, accuracy=0.522917
2025-10-10 05:06:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:06:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:06:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:06:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=142 reserved=2366MB allocated=2116MB
2025-10-10 05:06:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 142, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.54508918523788, 'train_avg_loss': 0.6878757432103157, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:06:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 142, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.49444580078125, 'train_avg_loss': 0.6926967620849609, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 05:06:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 142, 'Results_raw': {'train_total': 480, 'train_loss': 332.49444580078125, 'train_avg_loss': 0.6926967620849609, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 05:06:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #143) -------------
2025-10-10 05:06:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=143 aidx=5 | s=5 (candidates=7)
2025-10-10 05:06:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 34, 29, 47, 5] (from 7)
2025-10-10 05:06:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:06:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:06:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:07:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:07:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.309631, avg_loss=0.702728, seen=480, correct=235, accuracy=0.489583
2025-10-10 05:07:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:07:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:07:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2362MB allocated=2116MB
2025-10-10 05:07:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.68232834339142, 'train_avg_loss': 0.7056860695282619, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 05:07:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.30963134765625, 'train_avg_loss': 0.7027283986409505, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 05:07:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 337.30963134765625, 'train_avg_loss': 0.7027283986409505, 'train_seen': 480, 'train_correct': 235, 'train_acc': 0.4895833333333333}}
2025-10-10 05:07:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:07:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:07:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:07:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:07:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.701599, avg_loss=0.688962, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:07:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:07:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:07:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:07:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2366MB allocated=2116MB
2025-10-10 05:07:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.75347626209259, 'train_avg_loss': 0.6812789688507715, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:07:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.70159912109375, 'train_avg_loss': 0.6889616648356119, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:07:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 330.70159912109375, 'train_avg_loss': 0.6889616648356119, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:08:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:08:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:08:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:08:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:08:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.272156, avg_loss=0.694317, seen=480, correct=265, accuracy=0.552083
2025-10-10 05:08:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:08:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:08:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:08:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2384MB allocated=2116MB
2025-10-10 05:08:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.94037395715714, 'train_avg_loss': 0.7078364496429761, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:08:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.27215576171875, 'train_avg_loss': 0.6943169911702474, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 05:08:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 333.27215576171875, 'train_avg_loss': 0.6943169911702474, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 05:08:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:08:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:08:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 05:08:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:08:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:08:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:08:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:08:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:08:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:09:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:09:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.917114, avg_loss=0.689411, seen=480, correct=248, accuracy=0.516667
2025-10-10 05:09:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:09:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:09:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:09:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2366MB allocated=2116MB
2025-10-10 05:09:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61234879493713, 'train_avg_loss': 0.6884362399578094, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:09:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9171142578125, 'train_avg_loss': 0.689410654703776, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:09:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 330.9171142578125, 'train_avg_loss': 0.689410654703776, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:09:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #143, planning to set LR to 1.00e-05
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:09:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:09:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:10:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:10:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=343.646606, avg_loss=0.715930, seen=480, correct=244, accuracy=0.508333
2025-10-10 05:10:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:10:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:10:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=143 reserved=2408MB allocated=2116MB
2025-10-10 05:10:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 143, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.91192549467087, 'train_avg_loss': 0.7075993791222572, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:10:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 143, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 343.6466064453125, 'train_avg_loss': 0.715930430094401, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 05:10:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 143, 'Results_raw': {'train_total': 480, 'train_loss': 343.6466064453125, 'train_avg_loss': 0.715930430094401, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 05:10:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #144) -------------
2025-10-10 05:10:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=144 aidx=5 | s=5 (candidates=7)
2025-10-10 05:10:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 34, 5, 29, 45] (from 7)
2025-10-10 05:10:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:10:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:10:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 05:10:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:10:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:10:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:10:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:10:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:10:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:10:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.414673, avg_loss=0.705031, seen=480, correct=232, accuracy=0.483333
2025-10-10 05:10:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:10:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:10:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:11:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2362MB allocated=2116MB
2025-10-10 05:11:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.53214144706726, 'train_avg_loss': 0.6877678453922271, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:11:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.4146728515625, 'train_avg_loss': 0.7050305684407552, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-10 05:11:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 338.4146728515625, 'train_avg_loss': 0.7050305684407552, 'train_seen': 480, 'train_correct': 232, 'train_acc': 0.48333333333333334}}
2025-10-10 05:11:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:11:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:11:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:11:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:11:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.440918, avg_loss=0.686335, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:11:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:11:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:11:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:11:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2366MB allocated=2116MB
2025-10-10 05:11:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0762654542923, 'train_avg_loss': 0.6839688787857692, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:11:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.44091796875, 'train_avg_loss': 0.6863352457682291, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:11:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 329.44091796875, 'train_avg_loss': 0.6863352457682291, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:11:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:11:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:11:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:12:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:12:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.825806, avg_loss=0.701720, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:12:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:12:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:12:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:12:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2408MB allocated=2116MB
2025-10-10 05:12:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.11526155471802, 'train_avg_loss': 0.7009605129559835, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:12:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.8258056640625, 'train_avg_loss': 0.7017204284667968, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:12:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 336.8258056640625, 'train_avg_loss': 0.7017204284667968, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:12:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:12:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:12:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:13:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:13:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.144257, avg_loss=0.696134, seen=480, correct=249, accuracy=0.518750
2025-10-10 05:13:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:13:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:13:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:13:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2384MB allocated=2116MB
2025-10-10 05:13:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.48883032798767, 'train_avg_loss': 0.7040735860665639, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:13:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1442565917969, 'train_avg_loss': 0.6961338678995769, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:13:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 334.1442565917969, 'train_avg_loss': 0.6961338678995769, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:13:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #144, planning to set LR to 1.00e-05
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:13:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:13:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:13:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:13:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.590546, avg_loss=0.690814, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:13:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:13:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:14:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:14:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=144 reserved=2362MB allocated=2116MB
2025-10-10 05:14:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 144, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.13159269094467, 'train_avg_loss': 0.692763272424539, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:14:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 144, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.5905456542969, 'train_avg_loss': 0.6908136367797851, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:14:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 144, 'Results_raw': {'train_total': 480, 'train_loss': 331.5905456542969, 'train_avg_loss': 0.6908136367797851, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:14:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #145) -------------
2025-10-10 05:14:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=145 aidx=5 | s=5 (candidates=7)
2025-10-10 05:14:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 26, 47, 29, 45] (from 7)
2025-10-10 05:14:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:14:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:14:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:14:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:14:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.313812, avg_loss=0.683987, seen=480, correct=264, accuracy=0.550000
2025-10-10 05:14:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:14:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:14:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:14:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2366MB allocated=2116MB
2025-10-10 05:14:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.0858108997345, 'train_avg_loss': 0.6840484241644541, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:14:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.3138122558594, 'train_avg_loss': 0.6839871088663737, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:14:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 328.3138122558594, 'train_avg_loss': 0.6839871088663737, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:14:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:14:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:14:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 05:14:50 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:14:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:14:50 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:14:50 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:14:50 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:14:50 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:15:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:15:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.431732, avg_loss=0.700899, seen=480, correct=236, accuracy=0.491667
2025-10-10 05:15:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:15:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:15:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:15:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2362MB allocated=2116MB
2025-10-10 05:15:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.11391615867615, 'train_avg_loss': 0.6842826346556345, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:15:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.4317321777344, 'train_avg_loss': 0.7008994420369467, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:15:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 336.4317321777344, 'train_avg_loss': 0.7008994420369467, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:15:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:15:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:15:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 05:15:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:15:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:15:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:15:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:15:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:15:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:16:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:16:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.957214, avg_loss=0.689494, seen=480, correct=254, accuracy=0.529167
2025-10-10 05:16:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:16:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:16:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:16:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2366MB allocated=2116MB
2025-10-10 05:16:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.74166095256805, 'train_avg_loss': 0.7061805079380671, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:16:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.95721435546875, 'train_avg_loss': 0.6894941965738932, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:16:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 330.95721435546875, 'train_avg_loss': 0.6894941965738932, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 05:16:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:16:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:16:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 05:16:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:16:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:16:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:16:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:16:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:16:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:16:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:16:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.010437, avg_loss=0.700022, seen=480, correct=249, accuracy=0.518750
2025-10-10 05:16:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:16:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:16:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:16:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2384MB allocated=2116MB
2025-10-10 05:16:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.22566479444504, 'train_avg_loss': 0.7018805399537087, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 05:16:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.01043701171875, 'train_avg_loss': 0.7000217437744141, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:16:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 336.01043701171875, 'train_avg_loss': 0.7000217437744141, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:16:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:16:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:16:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #145, planning to set LR to 1.00e-05
2025-10-10 05:16:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:17:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:17:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:17:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:17:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:17:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:17:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:17:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.725128, avg_loss=0.684844, seen=480, correct=264, accuracy=0.550000
2025-10-10 05:17:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:17:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:17:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:17:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=145 reserved=2362MB allocated=2116MB
2025-10-10 05:17:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 145, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.92134439945221, 'train_avg_loss': 0.6910112033287684, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 05:17:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 145, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.7251281738281, 'train_avg_loss': 0.6848440170288086, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:17:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 145, 'Results_raw': {'train_total': 480, 'train_loss': 328.7251281738281, 'train_avg_loss': 0.6848440170288086, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:17:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #146) -------------
2025-10-10 05:17:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=146 aidx=5 | s=5 (candidates=7)
2025-10-10 05:17:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 34, 1, 47, 45] (from 7)
2025-10-10 05:17:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:17:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:17:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:18:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:18:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.315887, avg_loss=0.698575, seen=480, correct=247, accuracy=0.514583
2025-10-10 05:18:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:18:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:18:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:18:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2384MB allocated=2116MB
2025-10-10 05:18:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.15167981386185, 'train_avg_loss': 0.7012639984488487, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 05:18:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.3158874511719, 'train_avg_loss': 0.6985747655232747, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 05:18:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 335.3158874511719, 'train_avg_loss': 0.6985747655232747, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 05:18:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:18:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:18:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:19:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:19:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.787903, avg_loss=0.684975, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:19:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:19:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:19:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:19:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2366MB allocated=2116MB
2025-10-10 05:19:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.70278537273407, 'train_avg_loss': 0.6808565447727839, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:19:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.78790283203125, 'train_avg_loss': 0.6849747975667317, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:19:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 328.78790283203125, 'train_avg_loss': 0.6849747975667317, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:19:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:19:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:19:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 05:19:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:19:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:19:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:19:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:19:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:19:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:19:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:19:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.961060, avg_loss=0.697836, seen=480, correct=251, accuracy=0.522917
2025-10-10 05:19:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:19:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:19:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:19:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2362MB allocated=2116MB
2025-10-10 05:19:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5726523399353, 'train_avg_loss': 0.6881054361661275, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 05:19:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9610595703125, 'train_avg_loss': 0.6978355407714844, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 05:19:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 334.9610595703125, 'train_avg_loss': 0.6978355407714844, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 05:19:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:19:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:19:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 05:19:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:19:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:19:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:19:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:19:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:19:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:20:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:20:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.968628, avg_loss=0.689518, seen=480, correct=253, accuracy=0.527083
2025-10-10 05:20:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:20:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:20:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:20:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2366MB allocated=2116MB
2025-10-10 05:20:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.91840893030167, 'train_avg_loss': 0.7076534077525138, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 05:20:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9686279296875, 'train_avg_loss': 0.6895179748535156, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 05:20:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 330.9686279296875, 'train_avg_loss': 0.6895179748535156, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 05:20:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #146, planning to set LR to 1.00e-05
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:20:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:20:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:21:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:21:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.310974, avg_loss=0.679815, seen=480, correct=278, accuracy=0.579167
2025-10-10 05:21:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:21:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:21:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:21:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=146 reserved=2362MB allocated=2116MB
2025-10-10 05:21:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 146, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.54266887903214, 'train_avg_loss': 0.6878555739919344, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:21:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 146, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.31097412109375, 'train_avg_loss': 0.6798145294189453, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:21:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 146, 'Results_raw': {'train_total': 480, 'train_loss': 326.31097412109375, 'train_avg_loss': 0.6798145294189453, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:21:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #147) -------------
2025-10-10 05:21:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=147 aidx=5 | s=5 (candidates=7)
2025-10-10 05:21:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 34, 29, 1, 47] (from 7)
2025-10-10 05:21:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:21:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:21:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:22:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:22:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.770203, avg_loss=0.699521, seen=480, correct=239, accuracy=0.497917
2025-10-10 05:22:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:22:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:22:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:22:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2362MB allocated=2116MB
2025-10-10 05:22:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99222028255463, 'train_avg_loss': 0.6832685023546219, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:22:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.77020263671875, 'train_avg_loss': 0.699521255493164, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 05:22:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 335.77020263671875, 'train_avg_loss': 0.699521255493164, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 05:22:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:22:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:22:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 05:22:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:22:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:22:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:22:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:22:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:22:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:22:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:22:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.193542, avg_loss=0.685820, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:22:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:22:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:23:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2366MB allocated=2116MB
2025-10-10 05:23:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.85199278593063, 'train_avg_loss': 0.6820999398827553, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:23:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.19354248046875, 'train_avg_loss': 0.6858198801676433, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:23:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 329.19354248046875, 'train_avg_loss': 0.6858198801676433, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:23:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:23:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:23:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:23:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:23:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.402985, avg_loss=0.698756, seen=480, correct=240, accuracy=0.500000
2025-10-10 05:23:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:23:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:23:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2384MB allocated=2116MB
2025-10-10 05:23:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.93787175416946, 'train_avg_loss': 0.6994822646180788, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:23:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.4029846191406, 'train_avg_loss': 0.698756217956543, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 05:23:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 335.4029846191406, 'train_avg_loss': 0.698756217956543, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 05:23:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:23:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:23:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:24:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:24:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.988708, avg_loss=0.697893, seen=480, correct=243, accuracy=0.506250
2025-10-10 05:24:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:24:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:24:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:24:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2362MB allocated=2116MB
2025-10-10 05:24:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61886179447174, 'train_avg_loss': 0.6884905149539312, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:24:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.98870849609375, 'train_avg_loss': 0.6978931427001953, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:24:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 334.98870849609375, 'train_avg_loss': 0.6978931427001953, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:24:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #147, planning to set LR to 1.00e-05
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:24:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:24:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:25:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:25:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.196350, avg_loss=0.689992, seen=480, correct=258, accuracy=0.537500
2025-10-10 05:25:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:25:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:25:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=147 reserved=2366MB allocated=2116MB
2025-10-10 05:25:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 147, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.68576800823212, 'train_avg_loss': 0.7057147334019344, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 05:25:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 147, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.19635009765625, 'train_avg_loss': 0.6899923960367839, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:25:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 147, 'Results_raw': {'train_total': 480, 'train_loss': 331.19635009765625, 'train_avg_loss': 0.6899923960367839, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 05:25:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #148) -------------
2025-10-10 05:25:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=148 aidx=5 | s=5 (candidates=7)
2025-10-10 05:25:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 5, 26, 34, 29] (from 7)
2025-10-10 05:25:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:25:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:25:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 05:25:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:25:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:25:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:25:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:25:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:25:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:25:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.556396, avg_loss=0.699076, seen=480, correct=236, accuracy=0.491667
2025-10-10 05:25:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:25:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:25:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:25:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2362MB allocated=2116MB
2025-10-10 05:25:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.4080855846405, 'train_avg_loss': 0.6950673798720042, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 05:25:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.556396484375, 'train_avg_loss': 0.6990758260091146, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:25:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 335.556396484375, 'train_avg_loss': 0.6990758260091146, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:26:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:26:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:26:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:26:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:26:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.297119, avg_loss=0.700619, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:26:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:26:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:26:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:26:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2408MB allocated=2116MB
2025-10-10 05:26:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.91165935993195, 'train_avg_loss': 0.6992638279994329, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:26:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.297119140625, 'train_avg_loss': 0.7006189982096355, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:26:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 336.297119140625, 'train_avg_loss': 0.7006189982096355, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:26:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:26:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:26:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:27:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:27:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.671906, avg_loss=0.701400, seen=480, correct=229, accuracy=0.477083
2025-10-10 05:27:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:27:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:27:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:27:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2362MB allocated=2116MB
2025-10-10 05:27:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.83095240592957, 'train_avg_loss': 0.6819246033827464, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:27:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.6719055175781, 'train_avg_loss': 0.7013998031616211, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 05:27:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 336.6719055175781, 'train_avg_loss': 0.7013998031616211, 'train_seen': 480, 'train_correct': 229, 'train_acc': 0.47708333333333336}}
2025-10-10 05:27:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:27:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:27:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 05:27:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:27:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:27:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:27:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:27:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:27:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:28:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:28:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.334290, avg_loss=0.686113, seen=480, correct=257, accuracy=0.535417
2025-10-10 05:28:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:28:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:28:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2366MB allocated=2116MB
2025-10-10 05:28:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.8355165719986, 'train_avg_loss': 0.6819626380999882, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:28:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.33428955078125, 'train_avg_loss': 0.6861131032307942, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:28:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 329.33428955078125, 'train_avg_loss': 0.6861131032307942, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 05:28:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #148, planning to set LR to 1.00e-05
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:28:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:28:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:28:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:28:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.269745, avg_loss=0.696395, seen=480, correct=262, accuracy=0.545833
2025-10-10 05:28:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:28:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:28:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:28:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=148 reserved=2384MB allocated=2116MB
2025-10-10 05:28:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 148, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.38969886302948, 'train_avg_loss': 0.7032474905252457, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:28:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 148, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.2697448730469, 'train_avg_loss': 0.6963953018188477, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 05:28:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 148, 'Results_raw': {'train_total': 480, 'train_loss': 334.2697448730469, 'train_avg_loss': 0.6963953018188477, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 05:28:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #149) -------------
2025-10-10 05:29:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=149 aidx=5 | s=5 (candidates=7)
2025-10-10 05:29:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 1, 26, 45, 5] (from 7)
2025-10-10 05:29:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:29:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:29:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:29:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:29:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.182678, avg_loss=0.683714, seen=480, correct=263, accuracy=0.547917
2025-10-10 05:29:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:29:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:29:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:29:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2366MB allocated=2116MB
2025-10-10 05:29:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.24985182285309, 'train_avg_loss': 0.6854154318571091, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:29:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.18267822265625, 'train_avg_loss': 0.6837139129638672, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 05:29:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 328.18267822265625, 'train_avg_loss': 0.6837139129638672, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 05:29:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:29:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:29:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:30:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:30:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.206482, avg_loss=0.694180, seen=480, correct=256, accuracy=0.533333
2025-10-10 05:30:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:30:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:30:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:30:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2362MB allocated=2116MB
2025-10-10 05:30:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66015756130219, 'train_avg_loss': 0.6805013130108516, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 05:30:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.20648193359375, 'train_avg_loss': 0.6941801706949869, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 05:30:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 333.20648193359375, 'train_avg_loss': 0.6941801706949869, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 05:30:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:30:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:30:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:31:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:31:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.144958, avg_loss=0.698219, seen=480, correct=243, accuracy=0.506250
2025-10-10 05:31:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:31:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:31:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:31:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2362MB allocated=2116MB
2025-10-10 05:31:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.6998450756073, 'train_avg_loss': 0.6808320422967274, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:31:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.14495849609375, 'train_avg_loss': 0.6982186635335287, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:31:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 335.14495849609375, 'train_avg_loss': 0.6982186635335287, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 05:31:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:31:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:31:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:31:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:31:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.032898, avg_loss=0.677152, seen=480, correct=275, accuracy=0.572917
2025-10-10 05:31:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:31:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:32:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:32:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2362MB allocated=2116MB
2025-10-10 05:32:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.37285602092743, 'train_avg_loss': 0.6864404668410619, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:32:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.03289794921875, 'train_avg_loss': 0.677151870727539, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 05:32:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 325.03289794921875, 'train_avg_loss': 0.677151870727539, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 05:32:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:32:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:32:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #149, planning to set LR to 1.00e-05
2025-10-10 05:32:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:32:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:32:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:32:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:32:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:32:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:32:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:32:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.131744, avg_loss=0.702358, seen=480, correct=236, accuracy=0.491667
2025-10-10 05:32:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:32:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:32:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:32:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=149 reserved=2408MB allocated=2116MB
2025-10-10 05:32:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 149, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.66477382183075, 'train_avg_loss': 0.7055397818485896, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:32:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 149, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.1317443847656, 'train_avg_loss': 0.702357800801595, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:32:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 149, 'Results_raw': {'train_total': 480, 'train_loss': 337.1317443847656, 'train_avg_loss': 0.702357800801595, 'train_seen': 480, 'train_correct': 236, 'train_acc': 0.49166666666666664}}
2025-10-10 05:32:45 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #150) -------------
2025-10-10 05:32:46 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=150 aidx=5 | s=5 (candidates=7)
2025-10-10 05:32:46 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 45, 5, 26, 34] (from 7)
2025-10-10 05:32:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:32:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:32:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:33:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:33:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.363037, avg_loss=0.686173, seen=480, correct=267, accuracy=0.556250
2025-10-10 05:33:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:33:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:33:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:33:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2384MB allocated=2116MB
2025-10-10 05:33:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9710858464241, 'train_avg_loss': 0.6997590487202009, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:33:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.363037109375, 'train_avg_loss': 0.6861729939778646, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:33:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 329.363037109375, 'train_avg_loss': 0.6861729939778646, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:33:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:33:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:33:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:34:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:34:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.630066, avg_loss=0.676313, seen=480, correct=278, accuracy=0.579167
2025-10-10 05:34:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:34:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:34:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:34:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2362MB allocated=2116MB
2025-10-10 05:34:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.48589026927948, 'train_avg_loss': 0.679049085577329, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:34:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.63006591796875, 'train_avg_loss': 0.6763126373291015, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:34:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 324.63006591796875, 'train_avg_loss': 0.6763126373291015, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:34:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:34:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:34:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:34:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:34:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.608429, avg_loss=0.688768, seen=480, correct=278, accuracy=0.579167
2025-10-10 05:34:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:34:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:34:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:34:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2408MB allocated=2116MB
2025-10-10 05:34:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99621111154556, 'train_avg_loss': 0.6833017592628797, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 05:34:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.6084289550781, 'train_avg_loss': 0.6887675603230794, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:34:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 330.6084289550781, 'train_avg_loss': 0.6887675603230794, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:34:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:35:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:35:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:35:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:35:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.926971, avg_loss=0.701931, seen=480, correct=230, accuracy=0.479167
2025-10-10 05:35:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:35:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:35:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:35:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2362MB allocated=2116MB
2025-10-10 05:35:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.83673429489136, 'train_avg_loss': 0.6819727857907613, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:35:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.9269714355469, 'train_avg_loss': 0.7019311904907226, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 05:35:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 336.9269714355469, 'train_avg_loss': 0.7019311904907226, 'train_seen': 480, 'train_correct': 230, 'train_acc': 0.4791666666666667}}
2025-10-10 05:35:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #150, planning to set LR to 1.00e-05
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:35:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:35:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:36:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:36:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.196838, avg_loss=0.687910, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:36:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:36:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:36:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:36:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=150 reserved=2366MB allocated=2116MB
2025-10-10 05:36:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 150, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.66468369960785, 'train_avg_loss': 0.6805390308300654, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:36:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 150, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.19683837890625, 'train_avg_loss': 0.6879100799560547, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:36:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 150, 'Results_raw': {'train_total': 480, 'train_loss': 330.19683837890625, 'train_avg_loss': 0.6879100799560547, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:36:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #151) -------------
2025-10-10 05:36:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=151 aidx=5 | s=5 (candidates=7)
2025-10-10 05:36:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 45, 34, 5, 47] (from 7)
2025-10-10 05:36:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:36:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:36:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:37:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:37:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.275757, avg_loss=0.683908, seen=480, correct=274, accuracy=0.570833
2025-10-10 05:37:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:37:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:37:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:37:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2384MB allocated=2116MB
2025-10-10 05:37:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.88340920209885, 'train_avg_loss': 0.6990284100174904, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:37:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.2757568359375, 'train_avg_loss': 0.6839078267415365, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 05:37:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 328.2757568359375, 'train_avg_loss': 0.6839078267415365, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 05:37:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:37:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:37:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:37:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:37:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.553223, avg_loss=0.676153, seen=480, correct=278, accuracy=0.579167
2025-10-10 05:37:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:37:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:37:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:38:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2362MB allocated=2116MB
2025-10-10 05:38:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.19173687696457, 'train_avg_loss': 0.6765978073080381, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:38:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.55322265625, 'train_avg_loss': 0.6761525472005209, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:38:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 324.55322265625, 'train_avg_loss': 0.6761525472005209, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 05:38:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:38:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:38:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 05:38:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:38:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:38:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:38:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:38:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:38:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:38:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.020630, avg_loss=0.683376, seen=480, correct=264, accuracy=0.550000
2025-10-10 05:38:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:38:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:38:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2366MB allocated=2116MB
2025-10-10 05:38:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.95075625181198, 'train_avg_loss': 0.6745896354317665, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 05:38:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0206298828125, 'train_avg_loss': 0.6833763122558594, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:38:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 328.0206298828125, 'train_avg_loss': 0.6833763122558594, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:38:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:38:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:38:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:39:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:39:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.097900, avg_loss=0.691871, seen=480, correct=274, accuracy=0.570833
2025-10-10 05:39:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:39:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:39:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:39:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2408MB allocated=2116MB
2025-10-10 05:39:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.10344624519348, 'train_avg_loss': 0.6841953853766124, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:39:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.097900390625, 'train_avg_loss': 0.6918706258138021, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 05:39:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 332.097900390625, 'train_avg_loss': 0.6918706258138021, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 05:39:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:39:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:39:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #151, planning to set LR to 1.00e-05
2025-10-10 05:39:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:39:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:39:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:39:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:39:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:39:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:40:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:40:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.404480, avg_loss=0.682093, seen=480, correct=275, accuracy=0.572917
2025-10-10 05:40:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:40:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:40:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:40:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=151 reserved=2366MB allocated=2116MB
2025-10-10 05:40:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 151, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.56382948160172, 'train_avg_loss': 0.6796985790133476, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:40:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 151, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.40447998046875, 'train_avg_loss': 0.6820926666259766, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 05:40:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 151, 'Results_raw': {'train_total': 480, 'train_loss': 327.40447998046875, 'train_avg_loss': 0.6820926666259766, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 05:40:12 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #152) -------------
2025-10-10 05:40:13 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=152 aidx=5 | s=5 (candidates=7)
2025-10-10 05:40:13 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[47, 26, 45, 1, 29] (from 7)
2025-10-10 05:40:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:40:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:40:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 05:40:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:40:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:40:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:40:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:40:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:40:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:40:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:40:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.880981, avg_loss=0.674752, seen=480, correct=273, accuracy=0.568750
2025-10-10 05:40:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:40:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:40:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:40:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2366MB allocated=2116MB
2025-10-10 05:40:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.01948863267899, 'train_avg_loss': 0.6834957386056583, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 05:40:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.8809814453125, 'train_avg_loss': 0.6747520446777344, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:40:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 323.8809814453125, 'train_avg_loss': 0.6747520446777344, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:40:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:41:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:41:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:41:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:41:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.711395, avg_loss=0.699399, seen=480, correct=246, accuracy=0.512500
2025-10-10 05:41:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:41:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:41:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2362MB allocated=2116MB
2025-10-10 05:41:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.65822982788086, 'train_avg_loss': 0.6804852485656738, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:41:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.7113952636719, 'train_avg_loss': 0.6993987401326497, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:41:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 335.7113952636719, 'train_avg_loss': 0.6993987401326497, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 05:41:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:41:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:41:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:42:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:42:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.193573, avg_loss=0.675403, seen=480, correct=277, accuracy=0.577083
2025-10-10 05:42:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:42:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:42:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:42:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2362MB allocated=2116MB
2025-10-10 05:42:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.70724487304688, 'train_avg_loss': 0.6808937072753907, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:42:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.1935729980469, 'train_avg_loss': 0.6754032770792643, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 05:42:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 324.1935729980469, 'train_avg_loss': 0.6754032770792643, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 05:42:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:42:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:42:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 05:42:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:42:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:42:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:43:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:43:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.487000, avg_loss=0.694765, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:43:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:43:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:43:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2362MB allocated=2116MB
2025-10-10 05:43:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.57201778888702, 'train_avg_loss': 0.6881001482407252, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 05:43:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.48699951171875, 'train_avg_loss': 0.6947645823160807, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:43:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 333.48699951171875, 'train_avg_loss': 0.6947645823160807, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:43:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:43:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:43:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #152, planning to set LR to 1.00e-05
2025-10-10 05:43:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:43:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:43:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:43:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:43:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:43:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.505615, avg_loss=0.686470, seen=480, correct=272, accuracy=0.566667
2025-10-10 05:43:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:43:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:43:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:43:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=152 reserved=2384MB allocated=2116MB
2025-10-10 05:43:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 152, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.23481613397598, 'train_avg_loss': 0.6936234677831332, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 05:43:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 152, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.505615234375, 'train_avg_loss': 0.6864700317382812, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:43:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 152, 'Results_raw': {'train_total': 480, 'train_loss': 329.505615234375, 'train_avg_loss': 0.6864700317382812, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:43:57 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #153) -------------
2025-10-10 05:43:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=153 aidx=5 | s=5 (candidates=7)
2025-10-10 05:43:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 26, 34, 5, 1] (from 7)
2025-10-10 05:43:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:43:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:43:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 05:44:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:44:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:44:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:44:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:44:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:44:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:44:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:44:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.599701, avg_loss=0.676249, seen=480, correct=273, accuracy=0.568750
2025-10-10 05:44:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:44:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:44:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:44:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2362MB allocated=2116MB
2025-10-10 05:44:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.68627893924713, 'train_avg_loss': 0.6807189911603928, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:44:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.5997009277344, 'train_avg_loss': 0.67624937693278, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:44:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 324.5997009277344, 'train_avg_loss': 0.67624937693278, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 05:44:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:44:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:44:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 05:44:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:44:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:44:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:44:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:44:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:44:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:45:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:45:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.472321, avg_loss=0.694734, seen=480, correct=248, accuracy=0.516667
2025-10-10 05:45:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:45:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:45:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:45:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2362MB allocated=2116MB
2025-10-10 05:45:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.35900104045868, 'train_avg_loss': 0.6779916753371557, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 05:45:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.4723205566406, 'train_avg_loss': 0.694734001159668, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:45:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 333.4723205566406, 'train_avg_loss': 0.694734001159668, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 05:45:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:45:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:45:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:46:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:46:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.312988, avg_loss=0.675652, seen=480, correct=272, accuracy=0.566667
2025-10-10 05:46:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:46:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:46:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:46:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2366MB allocated=2116MB
2025-10-10 05:46:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.67442935705185, 'train_avg_loss': 0.6806202446420987, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:46:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.31298828125, 'train_avg_loss': 0.6756520589192708, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:46:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 324.31298828125, 'train_avg_loss': 0.6756520589192708, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:46:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:46:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:46:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:46:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:46:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.868011, avg_loss=0.689308, seen=480, correct=255, accuracy=0.531250
2025-10-10 05:46:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:46:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:46:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:46:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2408MB allocated=2116MB
2025-10-10 05:46:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.24023830890656, 'train_avg_loss': 0.6936686525742213, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:46:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8680114746094, 'train_avg_loss': 0.6893083572387695, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:46:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 330.8680114746094, 'train_avg_loss': 0.6893083572387695, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 05:46:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #153, planning to set LR to 1.00e-05
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:46:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:46:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:47:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:47:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.493164, avg_loss=0.692694, seen=480, correct=249, accuracy=0.518750
2025-10-10 05:47:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:47:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:47:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:47:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=153 reserved=2362MB allocated=2116MB
2025-10-10 05:47:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 153, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.83857774734497, 'train_avg_loss': 0.6819881478945414, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:47:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 153, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.4931640625, 'train_avg_loss': 0.692694091796875, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:47:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 153, 'Results_raw': {'train_total': 480, 'train_loss': 332.4931640625, 'train_avg_loss': 0.692694091796875, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 05:47:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #154) -------------
2025-10-10 05:47:40 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=154 aidx=5 | s=5 (candidates=7)
2025-10-10 05:47:40 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[45, 29, 26, 1, 47] (from 7)
2025-10-10 05:47:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:47:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:47:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:48:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:48:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.270905, avg_loss=0.677648, seen=480, correct=269, accuracy=0.560417
2025-10-10 05:48:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:48:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:48:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:48:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2362MB allocated=2116MB
2025-10-10 05:48:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.58641773462296, 'train_avg_loss': 0.6798868144551913, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:48:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.2709045410156, 'train_avg_loss': 0.6776477177937825, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 05:48:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 325.2709045410156, 'train_avg_loss': 0.6776477177937825, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 05:48:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:48:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:48:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:49:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:49:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.509094, avg_loss=0.678144, seen=480, correct=283, accuracy=0.589583
2025-10-10 05:49:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:49:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:49:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:49:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2384MB allocated=2116MB
2025-10-10 05:49:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.68846499919891, 'train_avg_loss': 0.6890705416599909, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 05:49:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.50909423828125, 'train_avg_loss': 0.6781439463297526, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 05:49:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 325.50909423828125, 'train_avg_loss': 0.6781439463297526, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 05:49:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:49:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:49:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:49:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:49:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.411621, avg_loss=0.696691, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:49:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:49:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:49:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:49:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2362MB allocated=2116MB
2025-10-10 05:49:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.31382584571838, 'train_avg_loss': 0.6776152153809866, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:49:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.41162109375, 'train_avg_loss': 0.6966908772786459, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:49:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 334.41162109375, 'train_avg_loss': 0.6966908772786459, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:49:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:49:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:49:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 05:49:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:49:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:49:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:49:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:49:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:49:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:50:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:50:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.824158, avg_loss=0.689217, seen=480, correct=266, accuracy=0.554167
2025-10-10 05:50:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:50:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:50:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:50:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2362MB allocated=2116MB
2025-10-10 05:50:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.1005744934082, 'train_avg_loss': 0.6841714541117351, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:50:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.82415771484375, 'train_avg_loss': 0.6892169952392578, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 05:50:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 330.82415771484375, 'train_avg_loss': 0.6892169952392578, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 05:50:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #154, planning to set LR to 1.00e-05
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 05:50:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:50:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:51:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:51:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.948395, avg_loss=0.672809, seen=480, correct=291, accuracy=0.606250
2025-10-10 05:51:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:51:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:51:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:51:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=154 reserved=2366MB allocated=2116MB
2025-10-10 05:51:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 154, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.7591120004654, 'train_avg_loss': 0.6813259333372116, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:51:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 154, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.9483947753906, 'train_avg_loss': 0.6728091557820638, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 05:51:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 154, 'Results_raw': {'train_total': 480, 'train_loss': 322.9483947753906, 'train_avg_loss': 0.6728091557820638, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 05:51:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #155) -------------
2025-10-10 05:51:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=155 aidx=5 | s=5 (candidates=7)
2025-10-10 05:51:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 34, 1, 5, 45] (from 7)
2025-10-10 05:51:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:51:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:51:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:52:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:52:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.836426, avg_loss=0.695493, seen=480, correct=252, accuracy=0.525000
2025-10-10 05:52:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:52:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:52:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:52:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2362MB allocated=2116MB
2025-10-10 05:52:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.00506579875946, 'train_avg_loss': 0.6750422149896622, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 05:52:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.83642578125, 'train_avg_loss': 0.6954925537109375, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:52:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 333.83642578125, 'train_avg_loss': 0.6954925537109375, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 05:52:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:52:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:52:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:52:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:52:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.066254, avg_loss=0.677221, seen=480, correct=267, accuracy=0.556250
2025-10-10 05:52:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:52:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:52:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:52:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2366MB allocated=2116MB
2025-10-10 05:52:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.40208631753922, 'train_avg_loss': 0.6783507193128268, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 05:52:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0662536621094, 'train_avg_loss': 0.6772213617960612, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:52:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 325.0662536621094, 'train_avg_loss': 0.6772213617960612, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 05:52:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:52:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:52:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 05:52:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:52:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:52:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:52:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:52:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:52:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:53:32 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:53:32 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.319489, avg_loss=0.688166, seen=480, correct=259, accuracy=0.539583
2025-10-10 05:53:32 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:53:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:53:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:53:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2362MB allocated=2116MB
2025-10-10 05:53:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.99850904941559, 'train_avg_loss': 0.6833209087451299, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 05:53:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.3194885253906, 'train_avg_loss': 0.6881656010945638, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:53:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 330.3194885253906, 'train_avg_loss': 0.6881656010945638, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 05:53:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:53:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:53:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:54:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:54:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.431519, avg_loss=0.684232, seen=480, correct=272, accuracy=0.566667
2025-10-10 05:54:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:54:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:54:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:54:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2408MB allocated=2116MB
2025-10-10 05:54:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.7843188047409, 'train_avg_loss': 0.6815359900395076, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:54:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.4315185546875, 'train_avg_loss': 0.6842323303222656, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:54:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 328.4315185546875, 'train_avg_loss': 0.6842323303222656, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 05:54:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:54:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:54:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #155, planning to set LR to 1.00e-05
2025-10-10 05:54:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:54:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:54:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:54:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:54:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:54:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:54:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:54:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.054840, avg_loss=0.675114, seen=480, correct=279, accuracy=0.581250
2025-10-10 05:54:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:54:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:55:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:55:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=155 reserved=2362MB allocated=2116MB
2025-10-10 05:55:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 155, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.54523515701294, 'train_avg_loss': 0.6795436263084411, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:55:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 155, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0548400878906, 'train_avg_loss': 0.6751142501831054, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 05:55:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 155, 'Results_raw': {'train_total': 480, 'train_loss': 324.0548400878906, 'train_avg_loss': 0.6751142501831054, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 05:55:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #156) -------------
2025-10-10 05:55:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=156 aidx=5 | s=5 (candidates=7)
2025-10-10 05:55:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 5, 29, 45, 34] (from 7)
2025-10-10 05:55:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:55:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:55:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 05:55:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 05:55:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:55:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:55:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:55:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:55:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:55:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:55:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.181458, avg_loss=0.685795, seen=480, correct=264, accuracy=0.550000
2025-10-10 05:55:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:55:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:55:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:55:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2362MB allocated=2116MB
2025-10-10 05:55:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.59173953533173, 'train_avg_loss': 0.6715978294610977, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 05:55:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.18145751953125, 'train_avg_loss': 0.6857947031656901, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:55:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 329.18145751953125, 'train_avg_loss': 0.6857947031656901, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:55:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 05:55:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:55:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:56:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:56:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.587646, avg_loss=0.686641, seen=480, correct=269, accuracy=0.560417
2025-10-10 05:56:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:56:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:56:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:56:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2408MB allocated=2116MB
2025-10-10 05:56:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.5413693189621, 'train_avg_loss': 0.6878447443246841, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 05:56:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.587646484375, 'train_avg_loss': 0.6866409301757812, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 05:56:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 329.587646484375, 'train_avg_loss': 0.6866409301757812, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 05:56:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:56:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:56:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:57:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:57:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.150513, avg_loss=0.679480, seen=480, correct=264, accuracy=0.550000
2025-10-10 05:57:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:57:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:57:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:57:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2384MB allocated=2116MB
2025-10-10 05:57:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.2465307712555, 'train_avg_loss': 0.6853877564271291, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 05:57:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1505126953125, 'train_avg_loss': 0.679480234781901, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:57:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 326.1505126953125, 'train_avg_loss': 0.679480234781901, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 05:57:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 05:57:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:57:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:57:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:57:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.818817, avg_loss=0.668373, seen=480, correct=281, accuracy=0.585417
2025-10-10 05:57:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:57:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:57:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:57:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2362MB allocated=2116MB
2025-10-10 05:58:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.38367229700089, 'train_avg_loss': 0.6698639358083407, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:58:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.8188171386719, 'train_avg_loss': 0.6683725357055664, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 05:58:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 320.8188171386719, 'train_avg_loss': 0.6683725357055664, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 05:58:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #156, planning to set LR to 1.00e-05
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 05:58:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:58:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:58:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:58:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.031219, avg_loss=0.675065, seen=480, correct=268, accuracy=0.558333
2025-10-10 05:58:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:58:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:58:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=156 reserved=2366MB allocated=2116MB
2025-10-10 05:58:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 156, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.27618008852005, 'train_avg_loss': 0.677301500737667, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 05:58:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 156, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.0312194824219, 'train_avg_loss': 0.6750650405883789, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 05:58:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 156, 'Results_raw': {'train_total': 480, 'train_loss': 324.0312194824219, 'train_avg_loss': 0.6750650405883789, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 05:58:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #157) -------------
2025-10-10 05:58:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=157 aidx=5 | s=5 (candidates=7)
2025-10-10 05:58:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[29, 26, 34, 1, 47] (from 7)
2025-10-10 05:58:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:58:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:58:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 05:58:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 05:58:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:58:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:58:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:58:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:58:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 05:59:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 05:59:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.868896, avg_loss=0.670560, seen=480, correct=277, accuracy=0.577083
2025-10-10 05:59:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 05:59:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:59:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 05:59:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2384MB allocated=2116MB
2025-10-10 05:59:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.41887474060059, 'train_avg_loss': 0.6868239561716716, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 05:59:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.868896484375, 'train_avg_loss': 0.6705602010091146, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 05:59:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 321.868896484375, 'train_avg_loss': 0.6705602010091146, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 05:59:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 05:59:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 05:59:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 05:59:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 05:59:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 05:59:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 05:59:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 05:59:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 05:59:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:00:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:00:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.232300, avg_loss=0.700484, seen=480, correct=249, accuracy=0.518750
2025-10-10 06:00:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:00:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:00:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:00:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2362MB allocated=2116MB
2025-10-10 06:00:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.43445265293121, 'train_avg_loss': 0.6786204387744268, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:00:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.2322998046875, 'train_avg_loss': 0.7004839579264323, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 06:00:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 336.2322998046875, 'train_avg_loss': 0.7004839579264323, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 06:00:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:00:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:00:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:00:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:00:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.889832, avg_loss=0.674770, seen=480, correct=269, accuracy=0.560417
2025-10-10 06:00:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:00:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:01:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2366MB allocated=2116MB
2025-10-10 06:01:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.40559333562851, 'train_avg_loss': 0.6700466111302376, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:01:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.88983154296875, 'train_avg_loss': 0.6747704823811849, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 06:01:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 323.88983154296875, 'train_avg_loss': 0.6747704823811849, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 06:01:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:01:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:01:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:01:42 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:01:42 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.783447, avg_loss=0.691216, seen=480, correct=261, accuracy=0.543750
2025-10-10 06:01:42 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:01:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2362MB allocated=2116MB
2025-10-10 06:01:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.011714220047, 'train_avg_loss': 0.6834309518337249, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 06:01:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.783447265625, 'train_avg_loss': 0.6912155151367188, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 06:01:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 331.783447265625, 'train_avg_loss': 0.6912155151367188, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 06:01:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #157, planning to set LR to 1.00e-05
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:01:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:01:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:02:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:02:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.933777, avg_loss=0.666529, seen=480, correct=293, accuracy=0.610417
2025-10-10 06:02:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:02:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:02:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:02:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=157 reserved=2366MB allocated=2116MB
2025-10-10 06:02:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 157, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.84105324745178, 'train_avg_loss': 0.6653421103954316, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:02:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 157, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.93377685546875, 'train_avg_loss': 0.6665287017822266, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 06:02:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 157, 'Results_raw': {'train_total': 480, 'train_loss': 319.93377685546875, 'train_avg_loss': 0.6665287017822266, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 06:02:30 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #158) -------------
2025-10-10 06:02:31 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=158 aidx=5 | s=5 (candidates=7)
2025-10-10 06:02:31 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 5, 45, 29, 26] (from 7)
2025-10-10 06:02:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:02:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:02:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:03:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:03:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.673523, avg_loss=0.686820, seen=480, correct=264, accuracy=0.550000
2025-10-10 06:03:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:03:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:03:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:03:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2362MB allocated=2116MB
2025-10-10 06:03:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.10660338401794, 'train_avg_loss': 0.6758883615334829, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:03:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.67352294921875, 'train_avg_loss': 0.6868198394775391, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:03:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 329.67352294921875, 'train_avg_loss': 0.6868198394775391, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 06:03:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 06:03:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:03:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:03:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:03:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.522797, avg_loss=0.688589, seen=480, correct=279, accuracy=0.581250
2025-10-10 06:03:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:03:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:03:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:03:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2408MB allocated=2116MB
2025-10-10 06:03:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.93522667884827, 'train_avg_loss': 0.6827935556570689, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:03:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.5227966308594, 'train_avg_loss': 0.6885891596476237, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:03:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 330.5227966308594, 'train_avg_loss': 0.6885891596476237, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:03:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:03:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:03:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 06:03:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:03:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:03:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:03:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:03:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:03:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:04:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:04:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.718811, avg_loss=0.666081, seen=480, correct=284, accuracy=0.591667
2025-10-10 06:04:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:04:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:04:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:04:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2362MB allocated=2116MB
2025-10-10 06:04:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.35694521665573, 'train_avg_loss': 0.6696412101387977, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:04:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.71881103515625, 'train_avg_loss': 0.6660808563232422, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 06:04:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 319.71881103515625, 'train_avg_loss': 0.6660808563232422, 'train_seen': 480, 'train_correct': 284, 'train_acc': 0.5916666666666667}}
2025-10-10 06:04:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:04:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:04:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 06:04:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 06:04:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:04:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:04:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:04:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:04:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:05:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:05:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.378357, avg_loss=0.673705, seen=480, correct=274, accuracy=0.570833
2025-10-10 06:05:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:05:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:05:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:05:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2384MB allocated=2116MB
2025-10-10 06:05:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.3757728934288, 'train_avg_loss': 0.6864647741119067, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:05:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.37835693359375, 'train_avg_loss': 0.6737049102783204, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 06:05:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 323.37835693359375, 'train_avg_loss': 0.6737049102783204, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 06:05:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #158, planning to set LR to 1.00e-05
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:05:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:05:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:06:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:06:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.467102, avg_loss=0.696806, seen=480, correct=252, accuracy=0.525000
2025-10-10 06:06:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:06:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:06:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=158 reserved=2362MB allocated=2116MB
2025-10-10 06:06:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 158, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.16487967967987, 'train_avg_loss': 0.6763739973306656, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:06:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 158, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.46710205078125, 'train_avg_loss': 0.6968064626057943, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:06:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 158, 'Results_raw': {'train_total': 480, 'train_loss': 334.46710205078125, 'train_avg_loss': 0.6968064626057943, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:06:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #159) -------------
2025-10-10 06:06:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=159 aidx=5 | s=5 (candidates=7)
2025-10-10 06:06:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[34, 26, 5, 45, 1] (from 7)
2025-10-10 06:06:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:06:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:06:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:06:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:06:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.940399, avg_loss=0.670709, seen=480, correct=274, accuracy=0.570833
2025-10-10 06:06:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:06:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:06:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:06:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2366MB allocated=2116MB
2025-10-10 06:06:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.36734104156494, 'train_avg_loss': 0.6697278420130411, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 06:06:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.9403991699219, 'train_avg_loss': 0.6707091649373372, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 06:06:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 321.9403991699219, 'train_avg_loss': 0.6707091649373372, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 06:06:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:07:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:07:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:07:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:07:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.567200, avg_loss=0.688682, seen=480, correct=259, accuracy=0.539583
2025-10-10 06:07:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:07:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:07:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:07:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2362MB allocated=2116MB
2025-10-10 06:07:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.15362894535065, 'train_avg_loss': 0.6679469078779221, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:07:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.56719970703125, 'train_avg_loss': 0.6886816660563151, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:07:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 330.56719970703125, 'train_avg_loss': 0.6886816660563151, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:07:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:07:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:07:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 06:07:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 06:07:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:07:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:07:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:07:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:07:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:08:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:08:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.487274, avg_loss=0.686432, seen=480, correct=278, accuracy=0.579167
2025-10-10 06:08:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:08:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:08:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:08:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2408MB allocated=2116MB
2025-10-10 06:08:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62282258272171, 'train_avg_loss': 0.6801901881893476, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 06:08:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4872741699219, 'train_avg_loss': 0.6864318211873373, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 06:08:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 329.4872741699219, 'train_avg_loss': 0.6864318211873373, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 06:08:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:08:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:08:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:09:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:09:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.380981, avg_loss=0.665377, seen=480, correct=283, accuracy=0.589583
2025-10-10 06:09:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:09:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:09:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2362MB allocated=2116MB
2025-10-10 06:09:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.59994781017303, 'train_avg_loss': 0.6633328984181086, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 06:09:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.3809814453125, 'train_avg_loss': 0.6653770446777344, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 06:09:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 319.3809814453125, 'train_avg_loss': 0.6653770446777344, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 06:09:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #159, planning to set LR to 1.00e-05
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:09:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:09:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:09:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:09:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.438782, avg_loss=0.688414, seen=480, correct=262, accuracy=0.545833
2025-10-10 06:09:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:09:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:09:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=159 reserved=2362MB allocated=2116MB
2025-10-10 06:09:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 159, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.48346984386444, 'train_avg_loss': 0.679028915365537, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 06:09:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 159, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.43878173828125, 'train_avg_loss': 0.6884141286214193, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 06:09:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 159, 'Results_raw': {'train_total': 480, 'train_loss': 330.43878173828125, 'train_avg_loss': 0.6884141286214193, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 06:09:55 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #160) -------------
2025-10-10 06:09:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=160 aidx=5 | s=5 (candidates=7)
2025-10-10 06:09:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[26, 29, 34, 1, 47] (from 7)
2025-10-10 06:09:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:09:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:09:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 06:09:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:09:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:09:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:09:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:09:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:09:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:10:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:10:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.825256, avg_loss=0.687136, seen=480, correct=260, accuracy=0.541667
2025-10-10 06:10:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:10:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:10:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:10:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2362MB allocated=2116MB
2025-10-10 06:10:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.81354981660843, 'train_avg_loss': 0.6651129151384035, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 06:10:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.82525634765625, 'train_avg_loss': 0.6871359507242839, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 06:10:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 329.82525634765625, 'train_avg_loss': 0.6871359507242839, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 06:10:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 06:10:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:10:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:11:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:11:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.509491, avg_loss=0.669811, seen=480, correct=290, accuracy=0.604167
2025-10-10 06:11:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:11:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:11:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:11:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2384MB allocated=2116MB
2025-10-10 06:11:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.36696100234985, 'train_avg_loss': 0.6780580083529154, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:11:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.5094909667969, 'train_avg_loss': 0.6698114395141601, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:11:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 321.5094909667969, 'train_avg_loss': 0.6698114395141601, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:11:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:11:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:11:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 06:11:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:11:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:11:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:11:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:11:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:11:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:12:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:12:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.786621, avg_loss=0.672472, seen=480, correct=275, accuracy=0.572917
2025-10-10 06:12:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:12:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:12:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:12:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2366MB allocated=2116MB
2025-10-10 06:12:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.21661525964737, 'train_avg_loss': 0.6768051271637281, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 06:12:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.78662109375, 'train_avg_loss': 0.6724721272786458, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 06:12:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 322.78662109375, 'train_avg_loss': 0.6724721272786458, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 06:12:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:12:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:12:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:12:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:12:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.059387, avg_loss=0.681374, seen=480, correct=268, accuracy=0.558333
2025-10-10 06:12:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:12:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:12:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:12:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2362MB allocated=2116MB
2025-10-10 06:12:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.26348578929901, 'train_avg_loss': 0.6771957149108251, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:12:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.05938720703125, 'train_avg_loss': 0.6813737233479817, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 06:12:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 327.05938720703125, 'train_avg_loss': 0.6813737233479817, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 06:12:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:12:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:12:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #160, planning to set LR to 1.00e-05
2025-10-10 06:12:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:12:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:12:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:12:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:12:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:12:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:13:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:13:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.119934, avg_loss=0.658583, seen=480, correct=295, accuracy=0.614583
2025-10-10 06:13:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:13:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:13:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:13:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=160 reserved=2366MB allocated=2116MB
2025-10-10 06:13:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 160, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.24039679765701, 'train_avg_loss': 0.6603366399804751, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 06:13:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 160, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.11993408203125, 'train_avg_loss': 0.6585831960042318, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 06:13:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 160, 'Results_raw': {'train_total': 480, 'train_loss': 316.11993408203125, 'train_avg_loss': 0.6585831960042318, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 06:13:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #161) -------------
2025-10-10 06:13:44 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=161 aidx=5 | s=5 (candidates=7)
2025-10-10 06:13:44 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[5, 45, 34, 47, 26] (from 7)
2025-10-10 06:13:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:13:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:13:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 06:13:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 06:13:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:13:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:13:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:13:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:13:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:14:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:14:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.195465, avg_loss=0.683741, seen=480, correct=279, accuracy=0.581250
2025-10-10 06:14:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:14:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:14:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:14:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2408MB allocated=2116MB
2025-10-10 06:14:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5632238984108, 'train_avg_loss': 0.6796935324867567, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:14:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1954650878906, 'train_avg_loss': 0.6837405522664388, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:14:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 328.1954650878906, 'train_avg_loss': 0.6837405522664388, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 06:14:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:14:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:14:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:15:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:15:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.684998, avg_loss=0.663927, seen=480, correct=285, accuracy=0.593750
2025-10-10 06:15:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:15:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:15:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:15:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2362MB allocated=2116MB
2025-10-10 06:15:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.60271126031876, 'train_avg_loss': 0.663355927169323, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:15:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.68499755859375, 'train_avg_loss': 0.6639270782470703, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 06:15:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 318.68499755859375, 'train_avg_loss': 0.6639270782470703, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 06:15:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:15:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:15:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 06:15:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:15:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:15:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:15:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:15:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:15:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:15:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:15:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.940613, avg_loss=0.670710, seen=480, correct=275, accuracy=0.572917
2025-10-10 06:15:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:15:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:15:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:15:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2366MB allocated=2116MB
2025-10-10 06:15:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.19670879840851, 'train_avg_loss': 0.6766392399867376, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:15:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.94061279296875, 'train_avg_loss': 0.6707096099853516, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 06:15:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 321.94061279296875, 'train_avg_loss': 0.6707096099853516, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 06:15:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:15:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:15:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 06:15:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:15:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:15:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:15:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:15:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:15:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:16:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:16:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.723999, avg_loss=0.647342, seen=480, correct=305, accuracy=0.635417
2025-10-10 06:16:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:16:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:16:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:16:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2366MB allocated=2116MB
2025-10-10 06:16:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.2752839922905, 'train_avg_loss': 0.6522940332690875, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:16:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.7239990234375, 'train_avg_loss': 0.6473416646321615, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 06:16:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 310.7239990234375, 'train_avg_loss': 0.6473416646321615, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 06:16:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:16:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:16:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #161, planning to set LR to 1.00e-05
2025-10-10 06:16:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:16:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:16:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:16:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:16:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:16:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:17:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:17:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.714417, avg_loss=0.686905, seen=480, correct=258, accuracy=0.537500
2025-10-10 06:17:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:17:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:17:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:17:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=161 reserved=2362MB allocated=2116MB
2025-10-10 06:17:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 161, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.20903116464615, 'train_avg_loss': 0.6684085930387179, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 06:17:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 161, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.71441650390625, 'train_avg_loss': 0.686905034383138, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 06:17:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 161, 'Results_raw': {'train_total': 480, 'train_loss': 329.71441650390625, 'train_avg_loss': 0.686905034383138, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 06:17:23 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #162) -------------
2025-10-10 06:17:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=162 aidx=5 | s=5 (candidates=7)
2025-10-10 06:17:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 34, 29, 5, 47] (from 7)
2025-10-10 06:17:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:17:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:17:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 06:17:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:17:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:17:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:17:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:17:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:17:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:18:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:18:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.263458, avg_loss=0.681799, seen=480, correct=271, accuracy=0.564583
2025-10-10 06:18:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:18:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:18:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:18:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2362MB allocated=2116MB
2025-10-10 06:18:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.78513705730438, 'train_avg_loss': 0.6732094754775365, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 06:18:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.2634582519531, 'train_avg_loss': 0.6817988713582357, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:18:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 327.2634582519531, 'train_avg_loss': 0.6817988713582357, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 06:18:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:18:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:18:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:18:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:18:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.458923, avg_loss=0.671789, seen=480, correct=280, accuracy=0.583333
2025-10-10 06:18:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:18:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:18:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:18:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2366MB allocated=2116MB
2025-10-10 06:18:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.39620757102966, 'train_avg_loss': 0.6783017297585805, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:18:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.45892333984375, 'train_avg_loss': 0.6717894236246745, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:18:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 322.45892333984375, 'train_avg_loss': 0.6717894236246745, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 06:18:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:18:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:18:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 06:18:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1548, total=6191)
2025-10-10 06:18:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:18:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:18:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:18:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:18:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=774, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:19:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:19:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.032104, avg_loss=0.664650, seen=480, correct=285, accuracy=0.593750
2025-10-10 06:19:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:19:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:19:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:19:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2384MB allocated=2116MB
2025-10-10 06:19:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #29', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.2811348438263, 'train_avg_loss': 0.6690094570318857, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 06:19:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #29', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.0321044921875, 'train_avg_loss': 0.6646502176920573, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 06:19:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #29', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 319.0321044921875, 'train_avg_loss': 0.6646502176920573, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 06:19:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 06:19:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:19:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:20:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:20:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.801819, avg_loss=0.685004, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:20:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:20:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:20:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:20:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2408MB allocated=2116MB
2025-10-10 06:20:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.07499426603317, 'train_avg_loss': 0.6756249522169431, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:20:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.80181884765625, 'train_avg_loss': 0.6850037892659505, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:20:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 328.80181884765625, 'train_avg_loss': 0.6850037892659505, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #162, planning to set LR to 1.00e-05
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:20:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:20:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:21:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:21:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.857422, avg_loss=0.649703, seen=480, correct=296, accuracy=0.616667
2025-10-10 06:21:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:21:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:21:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:21:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=162 reserved=2366MB allocated=2116MB
2025-10-10 06:21:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 162, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.77018588781357, 'train_avg_loss': 0.6480848823984464, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:21:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 162, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.857421875, 'train_avg_loss': 0.6497029622395833, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:21:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 162, 'Results_raw': {'train_total': 480, 'train_loss': 311.857421875, 'train_avg_loss': 0.6497029622395833, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 06:21:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #163) -------------
2025-10-10 06:21:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=163 aidx=5 | s=5 (candidates=7)
2025-10-10 06:21:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 5, 26, 45, 34] (from 7)
2025-10-10 06:21:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:21:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:21:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:21:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:21:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.450745, avg_loss=0.682189, seen=480, correct=272, accuracy=0.566667
2025-10-10 06:21:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:21:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:21:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:21:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2362MB allocated=2116MB
2025-10-10 06:21:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.56618863344193, 'train_avg_loss': 0.6713849052786827, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:21:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.45074462890625, 'train_avg_loss': 0.6821890513102213, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:21:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 327.45074462890625, 'train_avg_loss': 0.6821890513102213, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:21:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=72, total=285)
2025-10-10 06:21:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:21:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=36, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:22:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:22:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.569366, avg_loss=0.686603, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:22:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:22:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:22:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:22:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2408MB allocated=2116MB
2025-10-10 06:22:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #5', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.22048395872116, 'train_avg_loss': 0.6768373663226763, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:22:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #5', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.5693664550781, 'train_avg_loss': 0.6866028467814128, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:22:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #5', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 329.5693664550781, 'train_avg_loss': 0.6866028467814128, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:22:35 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:22:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:22:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:23:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:23:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.440308, avg_loss=0.675917, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:23:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:23:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:23:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:23:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2362MB allocated=2116MB
2025-10-10 06:23:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.19463312625885, 'train_avg_loss': 0.6599552760521571, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 06:23:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.4403076171875, 'train_avg_loss': 0.6759173075358073, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:23:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 324.4403076171875, 'train_avg_loss': 0.6759173075358073, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:23:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:23:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:23:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:24:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:24:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.816010, avg_loss=0.662117, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:24:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:24:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:24:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2362MB allocated=2116MB
2025-10-10 06:24:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.8124892115593, 'train_avg_loss': 0.6651040767629941, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:24:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.8160095214844, 'train_avg_loss': 0.6621166865030924, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:24:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 317.8160095214844, 'train_avg_loss': 0.6621166865030924, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:24:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #163, planning to set LR to 1.00e-05
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:24:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:24:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:24:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:24:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.074524, avg_loss=0.668905, seen=480, correct=276, accuracy=0.575000
2025-10-10 06:24:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:24:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:24:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=163 reserved=2366MB allocated=2116MB
2025-10-10 06:24:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 163, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.97888219356537, 'train_avg_loss': 0.6831573516130447, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:24:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 163, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.07452392578125, 'train_avg_loss': 0.6689052581787109, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:24:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 163, 'Results_raw': {'train_total': 480, 'train_loss': 321.07452392578125, 'train_avg_loss': 0.6689052581787109, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 06:24:52 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #164) -------------
2025-10-10 06:24:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=164 aidx=5 | s=5 (candidates=7)
2025-10-10 06:24:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[1, 26, 34, 45, 47] (from 7)
2025-10-10 06:24:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=699, total=2793)
2025-10-10 06:24:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:24:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=350, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:25:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:25:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.820984, avg_loss=0.685044, seen=480, correct=266, accuracy=0.554167
2025-10-10 06:25:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:25:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:25:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:25:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2362MB allocated=2116MB
2025-10-10 06:25:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #1', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.08258646726608, 'train_avg_loss': 0.6756882205605507, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:25:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #1', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.82098388671875, 'train_avg_loss': 0.6850437164306641, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 06:25:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #1', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 328.82098388671875, 'train_avg_loss': 0.6850437164306641, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 06:25:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:25:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:25:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 06:25:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=766, total=3063)
2025-10-10 06:25:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:25:38 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:25:38 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:25:38 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:25:38 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=383, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:26:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:26:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.905212, avg_loss=0.678969, seen=480, correct=273, accuracy=0.568750
2025-10-10 06:26:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:26:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:26:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:26:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2362MB allocated=2116MB
2025-10-10 06:26:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #26', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.86447334289551, 'train_avg_loss': 0.6572039445241292, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:26:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #26', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.90521240234375, 'train_avg_loss': 0.6789691925048829, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 06:26:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #26', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 325.90521240234375, 'train_avg_loss': 0.6789691925048829, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 06:26:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:26:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:26:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1122, total=4486)
2025-10-10 06:26:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:26:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=561, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:27:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:27:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.230286, avg_loss=0.658813, seen=480, correct=290, accuracy=0.604167
2025-10-10 06:27:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:27:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:27:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2366MB allocated=2116MB
2025-10-10 06:27:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #34', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.11825448274612, 'train_avg_loss': 0.667652120689551, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 06:27:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #34', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.23028564453125, 'train_avg_loss': 0.6588130950927734, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:27:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #34', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 316.23028564453125, 'train_avg_loss': 0.6588130950927734, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 06:27:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=476, total=1901)
2025-10-10 06:27:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:27:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=238, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:27:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:27:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.178101, avg_loss=0.662871, seen=480, correct=292, accuracy=0.608333
2025-10-10 06:27:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:27:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:27:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2362MB allocated=2116MB
2025-10-10 06:27:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #45', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.67320156097412, 'train_avg_loss': 0.6556100130081177, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 06:27:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #45', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.1781005859375, 'train_avg_loss': 0.6628710428873698, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:27:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #45', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 318.1781005859375, 'train_avg_loss': 0.6628710428873698, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 06:27:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:27:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:27:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #164, planning to set LR to 1.00e-05
2025-10-10 06:27:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=703, total=2812)
2025-10-10 06:27:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:27:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:27:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:27:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:27:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=352, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:28:29 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:28:29 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.002350, avg_loss=0.635422, seen=480, correct=315, accuracy=0.656250
2025-10-10 06:28:29 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:28:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:28:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:28:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=164 reserved=2366MB allocated=2116MB
2025-10-10 06:28:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #47', 'Round': 164, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.80974400043488, 'train_avg_loss': 0.6234145333369573, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 06:28:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #47', 'Round': 164, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.0023498535156, 'train_avg_loss': 0.6354215621948243, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 06:28:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #47', 'Round': 164, 'Results_raw': {'train_total': 480, 'train_loss': 305.0023498535156, 'train_avg_loss': 0.6354215621948243, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 06:28:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #165) -------------
2025-10-10 06:28:33 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=165 aidx=6 | s=5 (candidates=12)
2025-10-10 06:28:33 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 49, 14, 13, 38] (from 12)
2025-10-10 06:28:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:28:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:28:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 06:28:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 06:28:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:28:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:28:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:28:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:28:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:29:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:29:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.158661, avg_loss=0.706581, seen=480, correct=262, accuracy=0.545833
2025-10-10 06:29:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:29:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:29:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2388MB allocated=2183MB
2025-10-10 06:29:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.39500939846039, 'train_avg_loss': 0.70329174498717, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:29:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.1586608886719, 'train_avg_loss': 0.7065805435180664, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 06:29:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 339.1586608886719, 'train_avg_loss': 0.7065805435180664, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 06:29:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:29:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:29:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 06:29:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 06:29:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:29:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:29:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:29:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:29:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=351.149506, avg_loss=0.731561, seen=480, correct=240, accuracy=0.500000
2025-10-10 06:29:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:29:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:29:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:30:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2434MB allocated=2191MB
2025-10-10 06:30:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 91.69836604595184, 'train_avg_loss': 0.764153050382932, 'train_seen': 120, 'train_correct': 47, 'train_acc': 0.39166666666666666}}
2025-10-10 06:30:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 351.1495056152344, 'train_avg_loss': 0.7315614700317383, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 06:30:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 351.1495056152344, 'train_avg_loss': 0.7315614700317383, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 06:30:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:30:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:30:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 06:30:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 06:30:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:30:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:30:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:30:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:30:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:30:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:30:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=349.027679, avg_loss=0.727141, seen=480, correct=250, accuracy=0.520833
2025-10-10 06:30:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:30:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:30:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:30:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2388MB allocated=2200MB
2025-10-10 06:30:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.95181781053543, 'train_avg_loss': 0.7162651484211285, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 06:30:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 349.0276794433594, 'train_avg_loss': 0.727140998840332, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 06:30:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 349.0276794433594, 'train_avg_loss': 0.727140998840332, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 06:30:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:30:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:30:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 06:30:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 06:30:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:30:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:30:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:30:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:30:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:31:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:31:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=340.446930, avg_loss=0.709264, seen=480, correct=252, accuracy=0.525000
2025-10-10 06:31:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:31:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:31:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:31:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2388MB allocated=2209MB
2025-10-10 06:31:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.75235456228256, 'train_avg_loss': 0.7062696213523547, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 06:31:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 340.4469299316406, 'train_avg_loss': 0.7092644373575846, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:31:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 340.4469299316406, 'train_avg_loss': 0.7092644373575846, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:31:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:31:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:31:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #165, planning to set LR to 1.00e-05
2025-10-10 06:31:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 06:31:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:31:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:31:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:31:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:31:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:32:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:32:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.974426, avg_loss=0.704113, seen=480, correct=252, accuracy=0.525000
2025-10-10 06:32:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:32:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:32:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=165 reserved=2420MB allocated=2217MB
2025-10-10 06:32:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 165, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.19985121488571, 'train_avg_loss': 0.7016654267907143, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:32:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 165, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.97442626953125, 'train_avg_loss': 0.7041133880615235, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:32:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 165, 'Results_raw': {'train_total': 480, 'train_loss': 337.97442626953125, 'train_avg_loss': 0.7041133880615235, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:32:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #166) -------------
2025-10-10 06:32:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=166 aidx=6 | s=5 (candidates=12)
2025-10-10 06:32:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[19, 52, 10, 53, 13] (from 12)
2025-10-10 06:32:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:32:18 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:32:18 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 06:32:18 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 06:32:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:32:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:32:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:32:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:32:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:32:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.034424, avg_loss=0.702155, seen=480, correct=251, accuracy=0.522917
2025-10-10 06:32:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:32:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:32:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:32:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2518MB allocated=2284MB
2025-10-10 06:32:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.17934477329254, 'train_avg_loss': 0.7098278731107712, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 06:32:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.034423828125, 'train_avg_loss': 0.7021550496419271, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 06:32:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 337.034423828125, 'train_avg_loss': 0.7021550496419271, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 06:33:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:33:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:33:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 06:33:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 06:33:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:33:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:33:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:33:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:33:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:33:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:33:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.784241, avg_loss=0.705801, seen=480, correct=240, accuracy=0.500000
2025-10-10 06:33:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:33:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:33:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:33:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2450MB allocated=2292MB
2025-10-10 06:33:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.89445745944977, 'train_avg_loss': 0.6907871454954148, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 06:33:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.78424072265625, 'train_avg_loss': 0.7058005015055339, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 06:33:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 338.78424072265625, 'train_avg_loss': 0.7058005015055339, 'train_seen': 480, 'train_correct': 240, 'train_acc': 0.5}}
2025-10-10 06:33:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 06:33:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:33:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:34:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:34:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.842072, avg_loss=0.703838, seen=480, correct=252, accuracy=0.525000
2025-10-10 06:34:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:34:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:34:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:34:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2476MB allocated=2301MB
2025-10-10 06:34:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.18793326616287, 'train_avg_loss': 0.6932327772180239, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:34:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.8420715332031, 'train_avg_loss': 0.7038376490275066, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:34:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 337.8420715332031, 'train_avg_loss': 0.7038376490275066, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 06:34:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:34:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:34:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 06:34:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 06:34:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:34:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:34:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:34:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:34:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:35:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:35:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.346375, avg_loss=0.704888, seen=480, correct=243, accuracy=0.506250
2025-10-10 06:35:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:35:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:35:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:35:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2460MB allocated=2309MB
2025-10-10 06:35:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.60040080547333, 'train_avg_loss': 0.705003340045611, 'train_seen': 120, 'train_correct': 63, 'train_acc': 0.525}}
2025-10-10 06:35:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.34637451171875, 'train_avg_loss': 0.7048882802327474, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 06:35:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 338.34637451171875, 'train_avg_loss': 0.7048882802327474, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 06:35:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #166, planning to set LR to 1.00e-05
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 06:35:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:35:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:35:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:35:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.243408, avg_loss=0.702590, seen=480, correct=249, accuracy=0.518750
2025-10-10 06:35:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:35:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:36:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:36:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=166 reserved=2422MB allocated=2250MB
2025-10-10 06:36:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 166, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.38872075080872, 'train_avg_loss': 0.7032393395900727, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:36:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 166, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.243408203125, 'train_avg_loss': 0.7025904337565104, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 06:36:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 166, 'Results_raw': {'train_total': 480, 'train_loss': 337.243408203125, 'train_avg_loss': 0.7025904337565104, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 06:36:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #167) -------------
2025-10-10 06:36:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=167 aidx=6 | s=5 (candidates=12)
2025-10-10 06:36:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 46, 38, 49, 52] (from 12)
2025-10-10 06:36:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:36:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:36:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 06:36:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 06:36:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:36:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:36:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:36:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:36:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:36:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:36:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=339.521851, avg_loss=0.707337, seen=480, correct=246, accuracy=0.512500
2025-10-10 06:36:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:36:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:36:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:36:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2438MB allocated=2259MB
2025-10-10 06:36:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.93943870067596, 'train_avg_loss': 0.7161619891722997, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 06:36:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 339.5218505859375, 'train_avg_loss': 0.7073371887207032, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 06:36:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 339.5218505859375, 'train_avg_loss': 0.7073371887207032, 'train_seen': 480, 'train_correct': 246, 'train_acc': 0.5125}}
2025-10-10 06:36:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:36:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:36:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 06:36:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:36:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:36:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:36:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:36:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:36:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:37:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:37:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.714722, avg_loss=0.701489, seen=480, correct=249, accuracy=0.518750
2025-10-10 06:37:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:37:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:37:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:37:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2428MB allocated=2267MB
2025-10-10 06:37:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 87.07328522205353, 'train_avg_loss': 0.7256107101837794, 'train_seen': 120, 'train_correct': 52, 'train_acc': 0.43333333333333335}}
2025-10-10 06:37:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.7147216796875, 'train_avg_loss': 0.701489003499349, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 06:37:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 336.7147216796875, 'train_avg_loss': 0.701489003499349, 'train_seen': 480, 'train_correct': 249, 'train_acc': 0.51875}}
2025-10-10 06:37:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 06:37:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:37:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:38:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:38:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.872070, avg_loss=0.687233, seen=480, correct=270, accuracy=0.562500
2025-10-10 06:38:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:38:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:38:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:38:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2372MB allocated=2209MB
2025-10-10 06:38:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.56891751289368, 'train_avg_loss': 0.6797409792741139, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 06:38:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.8720703125, 'train_avg_loss': 0.6872334798177083, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 06:38:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 329.8720703125, 'train_avg_loss': 0.6872334798177083, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 06:38:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 06:38:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:38:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:39:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:39:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=342.250000, avg_loss=0.713021, seen=480, correct=242, accuracy=0.504167
2025-10-10 06:39:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:39:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:39:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:39:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2372MB allocated=2209MB
2025-10-10 06:39:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.83143997192383, 'train_avg_loss': 0.7235953330993652, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 06:39:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 342.25, 'train_avg_loss': 0.7130208333333333, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 06:39:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 342.25, 'train_avg_loss': 0.7130208333333333, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 06:39:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #167, planning to set LR to 1.00e-05
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 06:39:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:39:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:39:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:39:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.228485, avg_loss=0.702559, seen=480, correct=250, accuracy=0.520833
2025-10-10 06:39:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:39:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:39:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:39:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=167 reserved=2362MB allocated=2209MB
2025-10-10 06:39:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 167, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.75695049762726, 'train_avg_loss': 0.6896412541468938, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:39:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 167, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.2284851074219, 'train_avg_loss': 0.7025593439737956, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 06:39:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 167, 'Results_raw': {'train_total': 480, 'train_loss': 337.2284851074219, 'train_avg_loss': 0.7025593439737956, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 06:39:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #168) -------------
2025-10-10 06:39:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=168 aidx=6 | s=5 (candidates=12)
2025-10-10 06:39:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 52, 19, 46, 10] (from 12)
2025-10-10 06:39:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:39:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:39:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 06:39:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 06:39:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:39:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:39:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:39:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:39:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:40:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:40:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.127106, avg_loss=0.683598, seen=480, correct=272, accuracy=0.566667
2025-10-10 06:40:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:40:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:40:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:40:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2372MB allocated=2209MB
2025-10-10 06:40:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.5340023636818, 'train_avg_loss': 0.6794500196973483, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:40:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.1271057128906, 'train_avg_loss': 0.6835981369018554, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:40:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 328.1271057128906, 'train_avg_loss': 0.6835981369018554, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:40:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 06:40:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:40:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:41:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:41:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.017303, avg_loss=0.693786, seen=480, correct=255, accuracy=0.531250
2025-10-10 06:41:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:41:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:41:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:41:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2362MB allocated=2209MB
2025-10-10 06:41:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.97725385427475, 'train_avg_loss': 0.6831437821189562, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 06:41:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.0173034667969, 'train_avg_loss': 0.6937860488891602, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:41:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 333.0173034667969, 'train_avg_loss': 0.6937860488891602, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:41:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 06:41:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:41:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:42:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:42:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.075073, avg_loss=0.698073, seen=480, correct=248, accuracy=0.516667
2025-10-10 06:42:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:42:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:42:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2420MB allocated=2209MB
2025-10-10 06:42:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.67763960361481, 'train_avg_loss': 0.7056469966967901, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 06:42:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.0750732421875, 'train_avg_loss': 0.6980730692545573, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:42:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 335.0750732421875, 'train_avg_loss': 0.6980730692545573, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:42:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:42:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:42:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:42:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:42:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.927826, avg_loss=0.699850, seen=480, correct=244, accuracy=0.508333
2025-10-10 06:42:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:42:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:42:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2382MB allocated=2209MB
2025-10-10 06:42:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.69442582130432, 'train_avg_loss': 0.7224535485108693, 'train_seen': 120, 'train_correct': 51, 'train_acc': 0.425}}
2025-10-10 06:42:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.9278259277344, 'train_avg_loss': 0.6998496373494466, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 06:42:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 335.9278259277344, 'train_avg_loss': 0.6998496373494466, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 06:42:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #168, planning to set LR to 1.00e-05
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 06:42:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:42:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:43:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:43:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.025574, avg_loss=0.695887, seen=480, correct=255, accuracy=0.531250
2025-10-10 06:43:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:43:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:43:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:43:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=168 reserved=2390MB allocated=2209MB
2025-10-10 06:43:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 168, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.61948370933533, 'train_avg_loss': 0.6884956975777944, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:43:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 168, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.02557373046875, 'train_avg_loss': 0.6958866119384766, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:43:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 168, 'Results_raw': {'train_total': 480, 'train_loss': 334.02557373046875, 'train_avg_loss': 0.6958866119384766, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:43:36 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #169) -------------
2025-10-10 06:43:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=169 aidx=6 | s=5 (candidates=12)
2025-10-10 06:43:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 10, 19, 52, 38] (from 12)
2025-10-10 06:43:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:43:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:43:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 06:43:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:43:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:43:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:43:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:43:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:43:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:44:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:44:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.643036, avg_loss=0.699256, seen=480, correct=242, accuracy=0.504167
2025-10-10 06:44:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:44:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:44:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:44:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2382MB allocated=2209MB
2025-10-10 06:44:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.41854095458984, 'train_avg_loss': 0.7201545079549153, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 06:44:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.6430358886719, 'train_avg_loss': 0.6992563247680664, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 06:44:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 335.6430358886719, 'train_avg_loss': 0.6992563247680664, 'train_seen': 480, 'train_correct': 242, 'train_acc': 0.5041666666666667}}
2025-10-10 06:44:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 06:44:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:44:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:45:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:45:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.654266, avg_loss=0.686780, seen=480, correct=260, accuracy=0.541667
2025-10-10 06:45:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:45:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:45:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:45:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2390MB allocated=2209MB
2025-10-10 06:45:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.17008155584335, 'train_avg_loss': 0.684750679632028, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 06:45:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6542663574219, 'train_avg_loss': 0.6867797215779622, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 06:45:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 329.6542663574219, 'train_avg_loss': 0.6867797215779622, 'train_seen': 480, 'train_correct': 260, 'train_acc': 0.5416666666666666}}
2025-10-10 06:45:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:45:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:45:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 06:45:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 06:45:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:45:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:45:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:45:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:45:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:45:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:45:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.844940, avg_loss=0.695510, seen=480, correct=254, accuracy=0.529167
2025-10-10 06:45:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:45:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:45:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:45:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2420MB allocated=2209MB
2025-10-10 06:45:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.98635149002075, 'train_avg_loss': 0.6998862624168396, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 06:45:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.8449401855469, 'train_avg_loss': 0.6955102920532227, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 06:45:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 333.8449401855469, 'train_avg_loss': 0.6955102920532227, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 06:45:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:45:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:45:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 06:45:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 06:45:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:45:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:45:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:45:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:45:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:46:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:46:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.829803, avg_loss=0.689229, seen=480, correct=259, accuracy=0.539583
2025-10-10 06:46:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:46:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:46:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:46:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2362MB allocated=2209MB
2025-10-10 06:46:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.43885207176208, 'train_avg_loss': 0.6786571005980174, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:46:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.8298034667969, 'train_avg_loss': 0.6892287572224934, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:46:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 330.8298034667969, 'train_avg_loss': 0.6892287572224934, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:46:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:46:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:46:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #169, planning to set LR to 1.00e-05
2025-10-10 06:46:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 06:46:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:46:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:46:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:46:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:46:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:47:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:47:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.797363, avg_loss=0.680828, seen=480, correct=272, accuracy=0.566667
2025-10-10 06:47:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:47:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:47:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:47:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=169 reserved=2372MB allocated=2209MB
2025-10-10 06:47:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 169, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.40702176094055, 'train_avg_loss': 0.6783918480078379, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:47:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 169, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.79736328125, 'train_avg_loss': 0.6808278401692708, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:47:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 169, 'Results_raw': {'train_total': 480, 'train_loss': 326.79736328125, 'train_avg_loss': 0.6808278401692708, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 06:47:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #170) -------------
2025-10-10 06:47:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=170 aidx=6 | s=5 (candidates=12)
2025-10-10 06:47:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 18, 14, 46, 23] (from 12)
2025-10-10 06:47:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:47:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:47:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 06:47:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 06:47:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:47:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:47:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=30, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:47:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:47:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:48:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:48:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.967957, avg_loss=0.704100, seen=480, correct=245, accuracy=0.510417
2025-10-10 06:48:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:48:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:48:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:48:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2388MB allocated=2276MB
2025-10-10 06:48:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.23456335067749, 'train_avg_loss': 0.7019546945889791, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 06:48:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.96795654296875, 'train_avg_loss': 0.7040999094645183, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 06:48:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 337.96795654296875, 'train_avg_loss': 0.7040999094645183, 'train_seen': 480, 'train_correct': 245, 'train_acc': 0.5104166666666666}}
2025-10-10 06:48:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:48:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:48:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 06:48:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 06:48:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:48:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:48:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:48:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:48:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:48:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:48:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.518280, avg_loss=0.705246, seen=480, correct=241, accuracy=0.502083
2025-10-10 06:48:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:48:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:48:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:48:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2388MB allocated=2217MB
2025-10-10 06:48:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.1864048242569, 'train_avg_loss': 0.7182200402021408, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 06:48:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.5182800292969, 'train_avg_loss': 0.7052464167277018, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 06:48:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 338.5182800292969, 'train_avg_loss': 0.7052464167277018, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 06:48:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 06:48:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:48:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:49:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:49:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=338.794373, avg_loss=0.705822, seen=480, correct=261, accuracy=0.543750
2025-10-10 06:49:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:49:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:49:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:49:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2362MB allocated=2217MB
2025-10-10 06:49:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.20127046108246, 'train_avg_loss': 0.6850105871756872, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 06:49:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 338.79437255859375, 'train_avg_loss': 0.7058216094970703, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 06:49:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 338.79437255859375, 'train_avg_loss': 0.7058216094970703, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 06:49:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:49:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:49:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:50:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:50:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.439697, avg_loss=0.698833, seen=480, correct=248, accuracy=0.516667
2025-10-10 06:50:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:50:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:50:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:50:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2384MB allocated=2217MB
2025-10-10 06:50:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.16508388519287, 'train_avg_loss': 0.7180423657099406, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 06:50:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.439697265625, 'train_avg_loss': 0.6988327026367187, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:50:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 335.439697265625, 'train_avg_loss': 0.6988327026367187, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:50:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:50:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:50:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #170, planning to set LR to 1.00e-05
2025-10-10 06:50:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 06:50:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:50:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:50:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:50:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:50:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:51:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:51:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.713562, avg_loss=0.701487, seen=480, correct=256, accuracy=0.533333
2025-10-10 06:51:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:51:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:51:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:51:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=170 reserved=2362MB allocated=2217MB
2025-10-10 06:51:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 170, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.99670875072479, 'train_avg_loss': 0.70830590625604, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:51:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 170, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.71356201171875, 'train_avg_loss': 0.7014865875244141, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 06:51:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 170, 'Results_raw': {'train_total': 480, 'train_loss': 336.71356201171875, 'train_avg_loss': 0.7014865875244141, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 06:51:14 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #171) -------------
2025-10-10 06:51:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=171 aidx=6 | s=5 (candidates=12)
2025-10-10 06:51:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 23, 13, 46, 18] (from 12)
2025-10-10 06:51:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:51:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:51:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 06:51:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 06:51:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:51:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:51:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:51:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:51:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:51:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:51:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.130157, avg_loss=0.696104, seen=480, correct=255, accuracy=0.531250
2025-10-10 06:51:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:51:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:51:59 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:51:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2362MB allocated=2217MB
2025-10-10 06:52:00 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.16668260097504, 'train_avg_loss': 0.6930556883414586, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 06:52:00 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.1301574707031, 'train_avg_loss': 0.6961044947306315, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:52:00 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 334.1301574707031, 'train_avg_loss': 0.6961044947306315, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:52:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 06:52:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:52:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:52:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:52:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.672302, avg_loss=0.693067, seen=480, correct=259, accuracy=0.539583
2025-10-10 06:52:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:52:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:52:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2362MB allocated=2217MB
2025-10-10 06:52:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.5672482252121, 'train_avg_loss': 0.7047270685434341, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 06:52:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.67230224609375, 'train_avg_loss': 0.6930672963460286, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:52:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 332.67230224609375, 'train_avg_loss': 0.6930672963460286, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 06:52:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:52:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:52:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 06:52:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 06:52:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:52:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:52:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:52:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:52:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:53:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:53:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.667236, avg_loss=0.684723, seen=480, correct=254, accuracy=0.529167
2025-10-10 06:53:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:53:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:53:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:53:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2362MB allocated=2217MB
2025-10-10 06:53:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.46387779712677, 'train_avg_loss': 0.6788656483093898, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 06:53:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.667236328125, 'train_avg_loss': 0.6847234090169271, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 06:53:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 328.667236328125, 'train_avg_loss': 0.6847234090169271, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 06:53:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:53:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:53:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:54:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:54:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.517944, avg_loss=0.696912, seen=480, correct=248, accuracy=0.516667
2025-10-10 06:54:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:54:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:54:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:54:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2386MB allocated=2217MB
2025-10-10 06:54:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.79802852869034, 'train_avg_loss': 0.7149835710724195, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 06:54:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.5179443359375, 'train_avg_loss': 0.6969123840332031, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:54:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 334.5179443359375, 'train_avg_loss': 0.6969123840332031, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:54:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:54:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:54:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #171, planning to set LR to 1.00e-05
2025-10-10 06:54:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 06:54:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:54:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:54:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:54:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:54:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:54:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:54:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=336.227325, avg_loss=0.700474, seen=480, correct=248, accuracy=0.516667
2025-10-10 06:54:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:54:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:54:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:54:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=171 reserved=2390MB allocated=2217MB
2025-10-10 06:54:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 171, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.48822748661041, 'train_avg_loss': 0.7124018957217534, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 06:54:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 171, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 336.2273254394531, 'train_avg_loss': 0.7004735946655274, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:54:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 171, 'Results_raw': {'train_total': 480, 'train_loss': 336.2273254394531, 'train_avg_loss': 0.7004735946655274, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:54:58 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #172) -------------
2025-10-10 06:54:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=172 aidx=6 | s=5 (candidates=12)
2025-10-10 06:54:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 39, 13, 53, 46] (from 12)
2025-10-10 06:54:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 06:55:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:55:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:55:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:55:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=335.536530, avg_loss=0.699034, seen=480, correct=263, accuracy=0.547917
2025-10-10 06:55:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:55:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:55:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2362MB allocated=2217MB
2025-10-10 06:55:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.83550691604614, 'train_avg_loss': 0.6736292243003845, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 06:55:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 335.5365295410156, 'train_avg_loss': 0.6990344365437825, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 06:55:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 335.5365295410156, 'train_avg_loss': 0.6990344365437825, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 06:55:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 06:55:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:55:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:56:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:56:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=337.369690, avg_loss=0.702854, seen=480, correct=248, accuracy=0.516667
2025-10-10 06:56:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:56:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:56:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:56:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2362MB allocated=2217MB
2025-10-10 06:56:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.6648461818695, 'train_avg_loss': 0.6972070515155793, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 06:56:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 337.36968994140625, 'train_avg_loss': 0.7028535207112631, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:56:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 337.36968994140625, 'train_avg_loss': 0.7028535207112631, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 06:56:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 06:56:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:56:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:57:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:57:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.839478, avg_loss=0.680916, seen=480, correct=265, accuracy=0.552083
2025-10-10 06:57:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:57:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:57:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2362MB allocated=2217MB
2025-10-10 06:57:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.65937668085098, 'train_avg_loss': 0.6804948056737582, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 06:57:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.8394775390625, 'train_avg_loss': 0.6809155782063802, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 06:57:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 326.8394775390625, 'train_avg_loss': 0.6809155782063802, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 06:57:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 06:57:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:57:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:57:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:57:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.017914, avg_loss=0.695871, seen=480, correct=255, accuracy=0.531250
2025-10-10 06:57:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:57:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:57:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2362MB allocated=2217MB
2025-10-10 06:57:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.37540006637573, 'train_avg_loss': 0.6947950005531311, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 06:57:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.0179138183594, 'train_avg_loss': 0.6958706537882487, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:57:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 334.0179138183594, 'train_avg_loss': 0.6958706537882487, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 06:57:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:57:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:57:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #172, planning to set LR to 1.00e-05
2025-10-10 06:57:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:57:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:57:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:57:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:57:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:57:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:58:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:58:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.905640, avg_loss=0.697720, seen=480, correct=250, accuracy=0.520833
2025-10-10 06:58:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:58:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:58:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:58:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=172 reserved=2386MB allocated=2217MB
2025-10-10 06:58:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 172, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.06744426488876, 'train_avg_loss': 0.708895368874073, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 06:58:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 172, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.9056396484375, 'train_avg_loss': 0.6977200826009115, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 06:58:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 172, 'Results_raw': {'train_total': 480, 'train_loss': 334.9056396484375, 'train_avg_loss': 0.6977200826009115, 'train_seen': 480, 'train_correct': 250, 'train_acc': 0.5208333333333334}}
2025-10-10 06:58:40 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #173) -------------
2025-10-10 06:58:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=173 aidx=6 | s=5 (candidates=12)
2025-10-10 06:58:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 46, 49, 13, 53] (from 12)
2025-10-10 06:58:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 06:58:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:58:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 06:59:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 06:59:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.627808, avg_loss=0.690891, seen=480, correct=261, accuracy=0.543750
2025-10-10 06:59:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 06:59:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:59:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 06:59:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2362MB allocated=2217MB
2025-10-10 06:59:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.9855227470398, 'train_avg_loss': 0.6998793562253316, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 06:59:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6278076171875, 'train_avg_loss': 0.6908912658691406, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 06:59:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 331.6278076171875, 'train_avg_loss': 0.6908912658691406, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 06:59:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 06:59:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 06:59:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 06:59:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 06:59:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 06:59:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 06:59:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 06:59:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 06:59:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:00:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:00:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.179810, avg_loss=0.689958, seen=480, correct=252, accuracy=0.525000
2025-10-10 07:00:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:00:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:00:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2386MB allocated=2217MB
2025-10-10 07:00:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.68752324581146, 'train_avg_loss': 0.7057293603817621, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 07:00:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1798095703125, 'train_avg_loss': 0.6899579366048177, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 07:00:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 331.1798095703125, 'train_avg_loss': 0.6899579366048177, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 07:00:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:00:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:00:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:00:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:00:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.958679, avg_loss=0.697831, seen=480, correct=241, accuracy=0.502083
2025-10-10 07:00:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:00:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:00:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2380MB allocated=2217MB
2025-10-10 07:00:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.79510909318924, 'train_avg_loss': 0.7066259091099103, 'train_seen': 120, 'train_correct': 54, 'train_acc': 0.45}}
2025-10-10 07:00:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.95867919921875, 'train_avg_loss': 0.6978305816650391, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 07:00:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 334.95867919921875, 'train_avg_loss': 0.6978305816650391, 'train_seen': 480, 'train_correct': 241, 'train_acc': 0.5020833333333333}}
2025-10-10 07:00:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 07:00:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:00:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:01:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:01:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.998810, avg_loss=0.681248, seen=480, correct=255, accuracy=0.531250
2025-10-10 07:01:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:01:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:01:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:01:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2362MB allocated=2217MB
2025-10-10 07:01:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.76357710361481, 'train_avg_loss': 0.6813631425301234, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:01:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.9988098144531, 'train_avg_loss': 0.6812475204467774, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 07:01:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 326.9988098144531, 'train_avg_loss': 0.6812475204467774, 'train_seen': 480, 'train_correct': 255, 'train_acc': 0.53125}}
2025-10-10 07:01:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #173, planning to set LR to 1.00e-05
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:01:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:01:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:02:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:02:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.779083, avg_loss=0.695373, seen=480, correct=248, accuracy=0.516667
2025-10-10 07:02:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:02:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:02:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:02:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=173 reserved=2362MB allocated=2217MB
2025-10-10 07:02:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 173, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.27547132968903, 'train_avg_loss': 0.6939622610807419, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:02:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 173, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.7790832519531, 'train_avg_loss': 0.6953730901082357, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 07:02:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 173, 'Results_raw': {'train_total': 480, 'train_loss': 333.7790832519531, 'train_avg_loss': 0.6953730901082357, 'train_seen': 480, 'train_correct': 248, 'train_acc': 0.5166666666666667}}
2025-10-10 07:02:25 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #174) -------------
2025-10-10 07:02:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=174 aidx=6 | s=5 (candidates=12)
2025-10-10 07:02:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 53, 13, 10, 38] (from 12)
2025-10-10 07:02:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:02:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:02:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 07:02:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:02:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:02:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:02:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:02:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:02:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:03:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:03:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.394043, avg_loss=0.690404, seen=480, correct=253, accuracy=0.527083
2025-10-10 07:03:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:03:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:03:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2386MB allocated=2217MB
2025-10-10 07:03:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.2922733426094, 'train_avg_loss': 0.7024356111884117, 'train_seen': 120, 'train_correct': 61, 'train_acc': 0.5083333333333333}}
2025-10-10 07:03:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.39404296875, 'train_avg_loss': 0.6904042561848959, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 07:03:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 331.39404296875, 'train_avg_loss': 0.6904042561848959, 'train_seen': 480, 'train_correct': 253, 'train_acc': 0.5270833333333333}}
2025-10-10 07:03:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:03:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:03:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:03:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:03:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.489227, avg_loss=0.688519, seen=480, correct=261, accuracy=0.543750
2025-10-10 07:03:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:03:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:03:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2362MB allocated=2217MB
2025-10-10 07:03:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.23220407962799, 'train_avg_loss': 0.6852683673302332, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:03:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.4892272949219, 'train_avg_loss': 0.6885192235310872, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 07:03:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 330.4892272949219, 'train_avg_loss': 0.6885192235310872, 'train_seen': 480, 'train_correct': 261, 'train_acc': 0.54375}}
2025-10-10 07:03:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 07:03:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:03:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:04:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:04:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.666687, avg_loss=0.682639, seen=480, correct=264, accuracy=0.550000
2025-10-10 07:04:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:04:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:04:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:04:38 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2362MB allocated=2217MB
2025-10-10 07:04:38 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.59452676773071, 'train_avg_loss': 0.6799543897310892, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:04:38 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.66668701171875, 'train_avg_loss': 0.6826389312744141, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:04:38 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 327.66668701171875, 'train_avg_loss': 0.6826389312744141, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:04:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:04:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:04:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 07:04:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 07:04:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:04:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:04:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:04:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:04:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:05:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:05:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.738312, avg_loss=0.678621, seen=480, correct=264, accuracy=0.550000
2025-10-10 07:05:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:05:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:05:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:05:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2388MB allocated=2217MB
2025-10-10 07:05:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.76217496395111, 'train_avg_loss': 0.6730181246995925, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:05:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.7383117675781, 'train_avg_loss': 0.678621482849121, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:05:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 325.7383117675781, 'train_avg_loss': 0.678621482849121, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:05:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #174, planning to set LR to 1.00e-05
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 07:05:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:05:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:06:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:06:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.939331, avg_loss=0.681124, seen=480, correct=270, accuracy=0.562500
2025-10-10 07:06:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:06:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:06:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:06:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=174 reserved=2374MB allocated=2217MB
2025-10-10 07:06:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 174, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.62266612052917, 'train_avg_loss': 0.6801888843377432, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 07:06:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 174, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.9393310546875, 'train_avg_loss': 0.6811236063639323, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 07:06:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 174, 'Results_raw': {'train_total': 480, 'train_loss': 326.9393310546875, 'train_avg_loss': 0.6811236063639323, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 07:06:06 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #175) -------------
2025-10-10 07:06:07 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=175 aidx=6 | s=5 (candidates=12)
2025-10-10 07:06:07 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 49, 52, 23, 10] (from 12)
2025-10-10 07:06:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:06:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:06:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:06:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:06:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.958801, avg_loss=0.693664, seen=480, correct=244, accuracy=0.508333
2025-10-10 07:06:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:06:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:06:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:06:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2388MB allocated=2217MB
2025-10-10 07:06:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.85328018665314, 'train_avg_loss': 0.7071106682221094, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 07:06:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.95880126953125, 'train_avg_loss': 0.6936641693115234, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 07:06:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 332.95880126953125, 'train_avg_loss': 0.6936641693115234, 'train_seen': 480, 'train_correct': 244, 'train_acc': 0.5083333333333333}}
2025-10-10 07:06:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:06:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:06:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 07:06:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:06:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:06:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:06:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:06:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:06:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:07:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:07:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=334.317932, avg_loss=0.696496, seen=480, correct=239, accuracy=0.497917
2025-10-10 07:07:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:07:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:07:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:07:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2380MB allocated=2217MB
2025-10-10 07:07:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 85.16178548336029, 'train_avg_loss': 0.7096815456946691, 'train_seen': 120, 'train_correct': 49, 'train_acc': 0.4083333333333333}}
2025-10-10 07:07:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 334.31793212890625, 'train_avg_loss': 0.6964956919352213, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 07:07:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 334.31793212890625, 'train_avg_loss': 0.6964956919352213, 'train_seen': 480, 'train_correct': 239, 'train_acc': 0.4979166666666667}}
2025-10-10 07:07:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:07:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:07:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 07:07:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 07:07:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:07:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:07:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:07:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:07:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:08:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:08:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.725220, avg_loss=0.680678, seen=480, correct=265, accuracy=0.552083
2025-10-10 07:08:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:08:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:08:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:08:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2362MB allocated=2217MB
2025-10-10 07:08:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.41920375823975, 'train_avg_loss': 0.6701600313186645, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:08:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.7252197265625, 'train_avg_loss': 0.6806775410970052, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 07:08:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 326.7252197265625, 'train_avg_loss': 0.6806775410970052, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 07:08:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:08:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:08:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:09:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:09:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.887939, avg_loss=0.689350, seen=480, correct=264, accuracy=0.550000
2025-10-10 07:09:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:09:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:09:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:09:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2362MB allocated=2217MB
2025-10-10 07:09:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.49864554405212, 'train_avg_loss': 0.6958220462004344, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:09:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.887939453125, 'train_avg_loss': 0.689349873860677, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:09:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 330.887939453125, 'train_avg_loss': 0.689349873860677, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:09:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #175, planning to set LR to 1.00e-05
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 07:09:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:09:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:09:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:09:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.433533, avg_loss=0.675903, seen=480, correct=283, accuracy=0.589583
2025-10-10 07:09:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:09:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:09:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:09:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=175 reserved=2388MB allocated=2217MB
2025-10-10 07:09:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 175, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.66834062337875, 'train_avg_loss': 0.6722361718614897, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:09:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 175, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.43353271484375, 'train_avg_loss': 0.6759031931559245, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 07:09:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 175, 'Results_raw': {'train_total': 480, 'train_loss': 324.43353271484375, 'train_avg_loss': 0.6759031931559245, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 07:09:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #176) -------------
2025-10-10 07:09:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=176 aidx=6 | s=5 (candidates=12)
2025-10-10 07:09:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 18, 39, 23, 53] (from 12)
2025-10-10 07:09:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 07:09:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:09:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:10:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:10:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.051117, avg_loss=0.677190, seen=480, correct=269, accuracy=0.560417
2025-10-10 07:10:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:10:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:10:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:10:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2362MB allocated=2217MB
2025-10-10 07:10:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.8840401172638, 'train_avg_loss': 0.6657003343105317, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:10:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0511169433594, 'train_avg_loss': 0.677189826965332, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 07:10:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 325.0511169433594, 'train_avg_loss': 0.677189826965332, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 07:10:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:10:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:10:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:11:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:11:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.141449, avg_loss=0.689878, seen=480, correct=247, accuracy=0.514583
2025-10-10 07:11:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:11:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:11:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:11:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2388MB allocated=2217MB
2025-10-10 07:11:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.48318684101105, 'train_avg_loss': 0.7040265570084254, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 07:11:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1414489746094, 'train_avg_loss': 0.6898780186971029, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 07:11:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 331.1414489746094, 'train_avg_loss': 0.6898780186971029, 'train_seen': 480, 'train_correct': 247, 'train_acc': 0.5145833333333333}}
2025-10-10 07:11:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:11:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:11:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:12:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:12:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.196289, avg_loss=0.694159, seen=480, correct=254, accuracy=0.529167
2025-10-10 07:12:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:12:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:12:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:12:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2362MB allocated=2217MB
2025-10-10 07:12:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.00898730754852, 'train_avg_loss': 0.6917415608962377, 'train_seen': 120, 'train_correct': 60, 'train_acc': 0.5}}
2025-10-10 07:12:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.1962890625, 'train_avg_loss': 0.694158935546875, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 07:12:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 333.1962890625, 'train_avg_loss': 0.694158935546875, 'train_seen': 480, 'train_correct': 254, 'train_acc': 0.5291666666666667}}
2025-10-10 07:12:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:12:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:12:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 07:12:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:12:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:12:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:12:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:12:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:12:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:12:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:12:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.712097, avg_loss=0.686900, seen=480, correct=268, accuracy=0.558333
2025-10-10 07:12:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:12:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:12:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:12:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2362MB allocated=2217MB
2025-10-10 07:12:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.74498355388641, 'train_avg_loss': 0.6895415296157201, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:12:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.71209716796875, 'train_avg_loss': 0.6869002024332682, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 07:12:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 329.71209716796875, 'train_avg_loss': 0.6869002024332682, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 07:12:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #176, planning to set LR to 1.00e-05
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:12:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:12:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:13:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:13:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.834656, avg_loss=0.687156, seen=480, correct=262, accuracy=0.545833
2025-10-10 07:13:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:13:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:13:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:13:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=176 reserved=2362MB allocated=2217MB
2025-10-10 07:13:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 176, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.6228152513504, 'train_avg_loss': 0.6801901270945867, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:13:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 176, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.83465576171875, 'train_avg_loss': 0.6871555328369141, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 07:13:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 176, 'Results_raw': {'train_total': 480, 'train_loss': 329.83465576171875, 'train_avg_loss': 0.6871555328369141, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 07:13:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #177) -------------
2025-10-10 07:13:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=177 aidx=6 | s=5 (candidates=12)
2025-10-10 07:13:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 53, 46, 13, 18] (from 12)
2025-10-10 07:13:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:13:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:13:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 07:13:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:13:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:13:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:13:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:13:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:13:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:14:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:14:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.786316, avg_loss=0.693305, seen=480, correct=263, accuracy=0.547917
2025-10-10 07:14:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:14:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:14:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:14:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2362MB allocated=2217MB
2025-10-10 07:14:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.93686079978943, 'train_avg_loss': 0.6911405066649119, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:14:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.78631591796875, 'train_avg_loss': 0.6933048248291016, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 07:14:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 332.78631591796875, 'train_avg_loss': 0.6933048248291016, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 07:14:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:14:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:14:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:15:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:15:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.152618, avg_loss=0.681568, seen=480, correct=257, accuracy=0.535417
2025-10-10 07:15:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:15:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:03 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:15:03 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2362MB allocated=2217MB
2025-10-10 07:15:03 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.15487986803055, 'train_avg_loss': 0.6762906655669212, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:15:03 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.1526184082031, 'train_avg_loss': 0.6815679550170899, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 07:15:03 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 327.1526184082031, 'train_avg_loss': 0.6815679550170899, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 07:15:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:15:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:15:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 07:15:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:15:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:15:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:15:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:15:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:15:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:15:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.686127, avg_loss=0.688929, seen=480, correct=256, accuracy=0.533333
2025-10-10 07:15:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:15:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:15:46 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2386MB allocated=2217MB
2025-10-10 07:15:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.3277615904808, 'train_avg_loss': 0.70273134658734, 'train_seen': 120, 'train_correct': 59, 'train_acc': 0.49166666666666664}}
2025-10-10 07:15:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.6861267089844, 'train_avg_loss': 0.6889294306437175, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 07:15:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 330.6861267089844, 'train_avg_loss': 0.6889294306437175, 'train_seen': 480, 'train_correct': 256, 'train_acc': 0.5333333333333333}}
2025-10-10 07:15:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 07:15:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:15:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:16:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:16:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.197357, avg_loss=0.673328, seen=480, correct=272, accuracy=0.566667
2025-10-10 07:16:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:16:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:16:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:16:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2362MB allocated=2217MB
2025-10-10 07:16:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.98934769630432, 'train_avg_loss': 0.674911230802536, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:16:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.1973571777344, 'train_avg_loss': 0.6733278274536133, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 07:16:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 323.1973571777344, 'train_avg_loss': 0.6733278274536133, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 07:16:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:16:30 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:16:30 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #177, planning to set LR to 1.00e-05
2025-10-10 07:16:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:16:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:16:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:16:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:16:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:16:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:17:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:17:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.014496, avg_loss=0.689614, seen=480, correct=243, accuracy=0.506250
2025-10-10 07:17:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:17:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:17:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:17:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=177 reserved=2388MB allocated=2217MB
2025-10-10 07:17:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 177, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.47777432203293, 'train_avg_loss': 0.7039814526836078, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 07:17:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 177, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.0144958496094, 'train_avg_loss': 0.6896135330200195, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 07:17:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 177, 'Results_raw': {'train_total': 480, 'train_loss': 331.0144958496094, 'train_avg_loss': 0.6896135330200195, 'train_seen': 480, 'train_correct': 243, 'train_acc': 0.50625}}
2025-10-10 07:17:14 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #178) -------------
2025-10-10 07:17:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=178 aidx=6 | s=5 (candidates=12)
2025-10-10 07:17:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 46, 49, 14, 39] (from 12)
2025-10-10 07:17:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 07:17:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:17:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:17:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:17:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.066833, avg_loss=0.675139, seen=480, correct=265, accuracy=0.552083
2025-10-10 07:17:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:17:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:17:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:17:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2362MB allocated=2217MB
2025-10-10 07:17:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.42518246173859, 'train_avg_loss': 0.6618765205144882, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:17:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.06683349609375, 'train_avg_loss': 0.6751392364501954, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 07:17:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 324.06683349609375, 'train_avg_loss': 0.6751392364501954, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 07:17:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:18:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:18:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 07:18:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:18:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:18:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:18:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:18:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:18:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:18:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.604279, avg_loss=0.690842, seen=480, correct=268, accuracy=0.558333
2025-10-10 07:18:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:18:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:18:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2386MB allocated=2217MB
2025-10-10 07:18:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.05850511789322, 'train_avg_loss': 0.7004875426491102, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:18:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.6042785644531, 'train_avg_loss': 0.6908422470092773, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 07:18:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 331.6042785644531, 'train_avg_loss': 0.6908422470092773, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 07:18:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:18:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:18:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:19:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:19:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=333.275055, avg_loss=0.694323, seen=480, correct=252, accuracy=0.525000
2025-10-10 07:19:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:19:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:19:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:19:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2380MB allocated=2217MB
2025-10-10 07:19:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 86.10277420282364, 'train_avg_loss': 0.7175231183568637, 'train_seen': 120, 'train_correct': 50, 'train_acc': 0.4166666666666667}}
2025-10-10 07:19:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 333.2750549316406, 'train_avg_loss': 0.6943230311075846, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 07:19:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 333.2750549316406, 'train_avg_loss': 0.6943230311075846, 'train_seen': 480, 'train_correct': 252, 'train_acc': 0.525}}
2025-10-10 07:19:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 07:19:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:19:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:20:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:20:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.961731, avg_loss=0.687420, seen=480, correct=266, accuracy=0.554167
2025-10-10 07:20:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:20:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:20:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2362MB allocated=2217MB
2025-10-10 07:20:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.61681717634201, 'train_avg_loss': 0.6551401431361834, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:20:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.96173095703125, 'train_avg_loss': 0.6874202728271485, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 07:20:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 329.96173095703125, 'train_avg_loss': 0.6874202728271485, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 07:20:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #178, planning to set LR to 1.00e-05
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:20:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:20:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:20:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:20:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=332.738220, avg_loss=0.693205, seen=480, correct=265, accuracy=0.552083
2025-10-10 07:20:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:20:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:20:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:20:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=178 reserved=2362MB allocated=2217MB
2025-10-10 07:20:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 178, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.72559237480164, 'train_avg_loss': 0.6893799364566803, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:20:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 178, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 332.73822021484375, 'train_avg_loss': 0.6932046254475911, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 07:20:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 178, 'Results_raw': {'train_total': 480, 'train_loss': 332.73822021484375, 'train_avg_loss': 0.6932046254475911, 'train_seen': 480, 'train_correct': 265, 'train_acc': 0.5520833333333334}}
2025-10-10 07:20:57 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #179) -------------
2025-10-10 07:20:58 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=179 aidx=6 | s=5 (candidates=12)
2025-10-10 07:20:58 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 49, 23, 52, 38] (from 12)
2025-10-10 07:20:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 07:21:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:21:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:21:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:21:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.915161, avg_loss=0.689407, seen=480, correct=263, accuracy=0.547917
2025-10-10 07:21:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:21:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:21:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:21:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2362MB allocated=2217MB
2025-10-10 07:21:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.12034088373184, 'train_avg_loss': 0.6593361740310987, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:21:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.9151611328125, 'train_avg_loss': 0.6894065856933593, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 07:21:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 330.9151611328125, 'train_avg_loss': 0.6894065856933593, 'train_seen': 480, 'train_correct': 263, 'train_acc': 0.5479166666666667}}
2025-10-10 07:21:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:21:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:21:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:22:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:22:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.464661, avg_loss=0.688468, seen=480, correct=251, accuracy=0.522917
2025-10-10 07:22:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:22:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:22:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:22:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2380MB allocated=2217MB
2025-10-10 07:22:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.01855897903442, 'train_avg_loss': 0.7001546581586202, 'train_seen': 120, 'train_correct': 56, 'train_acc': 0.4666666666666667}}
2025-10-10 07:22:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.46466064453125, 'train_avg_loss': 0.6884680430094401, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 07:22:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 330.46466064453125, 'train_avg_loss': 0.6884680430094401, 'train_seen': 480, 'train_correct': 251, 'train_acc': 0.5229166666666667}}
2025-10-10 07:22:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:22:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:22:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:23:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:23:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.645477, avg_loss=0.684678, seen=480, correct=267, accuracy=0.556250
2025-10-10 07:23:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:23:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:23:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2362MB allocated=2217MB
2025-10-10 07:23:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.57045614719391, 'train_avg_loss': 0.6880871345599492, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:23:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.6454772949219, 'train_avg_loss': 0.6846780776977539, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 07:23:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 328.6454772949219, 'train_avg_loss': 0.6846780776977539, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 07:23:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 07:23:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:23:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:23:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:23:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.632111, avg_loss=0.676317, seen=480, correct=271, accuracy=0.564583
2025-10-10 07:23:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:23:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:23:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2362MB allocated=2217MB
2025-10-10 07:23:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.70205497741699, 'train_avg_loss': 0.664183791478475, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 07:23:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.6321105957031, 'train_avg_loss': 0.6763168970743815, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 07:23:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 324.6321105957031, 'train_avg_loss': 0.6763168970743815, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 07:23:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #179, planning to set LR to 1.00e-05
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 07:23:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:23:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:24:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:24:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.775757, avg_loss=0.668283, seen=480, correct=285, accuracy=0.593750
2025-10-10 07:24:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:24:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:24:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:24:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=179 reserved=2374MB allocated=2217MB
2025-10-10 07:24:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 179, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.88661605119705, 'train_avg_loss': 0.6657218004266421, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:24:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 179, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.7757568359375, 'train_avg_loss': 0.6682828267415365, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 07:24:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 179, 'Results_raw': {'train_total': 480, 'train_loss': 320.7757568359375, 'train_avg_loss': 0.6682828267415365, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 07:24:42 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #180) -------------
2025-10-10 07:24:42 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=180 aidx=6 | s=5 (candidates=12)
2025-10-10 07:24:42 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 14, 53, 19, 39] (from 12)
2025-10-10 07:24:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:24:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:24:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 07:24:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 07:24:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:24:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:24:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:24:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:24:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:25:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:25:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.893677, avg_loss=0.656028, seen=480, correct=298, accuracy=0.620833
2025-10-10 07:25:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:25:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:25:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:25:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2374MB allocated=2217MB
2025-10-10 07:25:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.08824914693832, 'train_avg_loss': 0.6507354095578194, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 07:25:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.8936767578125, 'train_avg_loss': 0.6560284932454427, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 07:25:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 314.8936767578125, 'train_avg_loss': 0.6560284932454427, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 07:25:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 07:25:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:25:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:26:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:26:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.256348, avg_loss=0.683867, seen=480, correct=270, accuracy=0.562500
2025-10-10 07:26:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:26:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:26:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:26:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2362MB allocated=2217MB
2025-10-10 07:26:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.50830835103989, 'train_avg_loss': 0.6459025695919991, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 07:26:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.25634765625, 'train_avg_loss': 0.6838673909505208, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 07:26:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 328.25634765625, 'train_avg_loss': 0.6838673909505208, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 07:26:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:26:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:26:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:26:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:26:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.612701, avg_loss=0.680443, seen=480, correct=268, accuracy=0.558333
2025-10-10 07:26:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:26:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:26:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:26:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2362MB allocated=2217MB
2025-10-10 07:26:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.39893037080765, 'train_avg_loss': 0.6699910864233971, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 07:26:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.6127014160156, 'train_avg_loss': 0.6804431279500326, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 07:26:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 326.6127014160156, 'train_avg_loss': 0.6804431279500326, 'train_seen': 480, 'train_correct': 268, 'train_acc': 0.5583333333333333}}
2025-10-10 07:26:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 07:27:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:27:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:27:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:27:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.932678, avg_loss=0.674860, seen=480, correct=276, accuracy=0.575000
2025-10-10 07:27:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:27:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:27:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:27:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2420MB allocated=2217MB
2025-10-10 07:27:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.32388246059418, 'train_avg_loss': 0.6610323538382848, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:27:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.93267822265625, 'train_avg_loss': 0.6748597462972005, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:27:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 323.93267822265625, 'train_avg_loss': 0.6748597462972005, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:27:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #180, planning to set LR to 1.00e-05
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:27:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:27:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:28:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:28:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.417908, avg_loss=0.684204, seen=480, correct=272, accuracy=0.566667
2025-10-10 07:28:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:28:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:28:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:28:25 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=180 reserved=2362MB allocated=2217MB
2025-10-10 07:28:25 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 180, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.42261856794357, 'train_avg_loss': 0.6785218213995298, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 07:28:25 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 180, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.41790771484375, 'train_avg_loss': 0.6842039744059245, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 07:28:25 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 180, 'Results_raw': {'train_total': 480, 'train_loss': 328.41790771484375, 'train_avg_loss': 0.6842039744059245, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 07:28:26 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #181) -------------
2025-10-10 07:28:26 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=181 aidx=6 | s=5 (candidates=12)
2025-10-10 07:28:26 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 46, 14, 49, 18] (from 12)
2025-10-10 07:28:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:28:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:28:28 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:29:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:29:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.041992, avg_loss=0.677171, seen=480, correct=280, accuracy=0.583333
2025-10-10 07:29:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:29:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:29:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:29:09 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2362MB allocated=2217MB
2025-10-10 07:29:09 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.35830408334732, 'train_avg_loss': 0.6696525340278944, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:29:09 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.0419921875, 'train_avg_loss': 0.6771708170572917, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 07:29:09 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 325.0419921875, 'train_avg_loss': 0.6771708170572917, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 07:29:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:29:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:29:11 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:29:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:29:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=331.115204, avg_loss=0.689823, seen=480, correct=269, accuracy=0.560417
2025-10-10 07:29:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:29:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:29:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:29:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2380MB allocated=2217MB
2025-10-10 07:29:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.66817194223404, 'train_avg_loss': 0.705568099518617, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 07:29:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 331.1152038574219, 'train_avg_loss': 0.6898233413696289, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 07:29:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 331.1152038574219, 'train_avg_loss': 0.6898233413696289, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 07:29:55 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 07:29:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:29:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:30:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:30:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.135925, avg_loss=0.683617, seen=480, correct=272, accuracy=0.566667
2025-10-10 07:30:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:30:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:30:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:30:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2362MB allocated=2217MB
2025-10-10 07:30:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.54084479808807, 'train_avg_loss': 0.6461737066507339, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 07:30:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.13592529296875, 'train_avg_loss': 0.6836165110270183, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 07:30:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 328.13592529296875, 'train_avg_loss': 0.6836165110270183, 'train_seen': 480, 'train_correct': 272, 'train_acc': 0.5666666666666667}}
2025-10-10 07:30:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:30:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:30:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 07:30:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:30:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:30:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:30:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:30:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:30:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:31:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:31:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.377136, avg_loss=0.688286, seen=480, correct=258, accuracy=0.537500
2025-10-10 07:31:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:31:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:31:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:31:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2380MB allocated=2217MB
2025-10-10 07:31:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36344319581985, 'train_avg_loss': 0.7030286932984988, 'train_seen': 120, 'train_correct': 57, 'train_acc': 0.475}}
2025-10-10 07:31:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.37713623046875, 'train_avg_loss': 0.6882857004801433, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 07:31:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 330.37713623046875, 'train_avg_loss': 0.6882857004801433, 'train_seen': 480, 'train_correct': 258, 'train_acc': 0.5375}}
2025-10-10 07:31:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:31:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:31:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #181, planning to set LR to 1.00e-05
2025-10-10 07:31:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:31:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:31:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:31:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:31:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:31:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:32:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:32:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.142853, avg_loss=0.679464, seen=480, correct=273, accuracy=0.568750
2025-10-10 07:32:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:32:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:32:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:32:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=181 reserved=2394MB allocated=2217MB
2025-10-10 07:32:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 181, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.46437937021255, 'train_avg_loss': 0.6955364947517713, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 07:32:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 181, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.1428527832031, 'train_avg_loss': 0.6794642766316732, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 07:32:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 181, 'Results_raw': {'train_total': 480, 'train_loss': 326.1428527832031, 'train_avg_loss': 0.6794642766316732, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 07:32:15 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #182) -------------
2025-10-10 07:32:16 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=182 aidx=6 | s=5 (candidates=12)
2025-10-10 07:32:16 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 39, 10, 18, 19] (from 12)
2025-10-10 07:32:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:32:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:32:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 07:32:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:32:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:32:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:32:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:32:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:32:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:32:57 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:32:57 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.260101, avg_loss=0.679709, seen=480, correct=266, accuracy=0.554167
2025-10-10 07:32:57 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:32:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:33:00 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2362MB allocated=2217MB
2025-10-10 07:33:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.51236379146576, 'train_avg_loss': 0.687603031595548, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 07:33:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.2601013183594, 'train_avg_loss': 0.6797085444132487, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 07:33:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 326.2601013183594, 'train_avg_loss': 0.6797085444132487, 'train_seen': 480, 'train_correct': 266, 'train_acc': 0.5541666666666667}}
2025-10-10 07:33:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:33:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:33:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 07:33:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:33:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:33:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:33:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:33:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:33:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:33:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.782867, avg_loss=0.676631, seen=480, correct=279, accuracy=0.581250
2025-10-10 07:33:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:33:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:33:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2362MB allocated=2217MB
2025-10-10 07:33:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.99901783466339, 'train_avg_loss': 0.6666584819555282, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:33:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.7828674316406, 'train_avg_loss': 0.676630973815918, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 07:33:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 324.7828674316406, 'train_avg_loss': 0.676630973815918, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 07:33:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 07:33:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:33:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:34:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:34:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.761688, avg_loss=0.649504, seen=480, correct=296, accuracy=0.616667
2025-10-10 07:34:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:34:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:34:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:34:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2388MB allocated=2217MB
2025-10-10 07:34:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.68427586555481, 'train_avg_loss': 0.6473689655462901, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:34:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.7616882324219, 'train_avg_loss': 0.649503517150879, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 07:34:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 311.7616882324219, 'train_avg_loss': 0.649503517150879, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 07:34:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:34:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:34:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 07:34:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:34:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:34:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:34:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:34:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:34:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:35:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:35:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.818420, avg_loss=0.674622, seen=480, correct=267, accuracy=0.556250
2025-10-10 07:35:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:35:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:35:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:35:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2388MB allocated=2217MB
2025-10-10 07:35:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.07795691490173, 'train_avg_loss': 0.6923163076241811, 'train_seen': 120, 'train_correct': 62, 'train_acc': 0.5166666666666667}}
2025-10-10 07:35:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.81842041015625, 'train_avg_loss': 0.6746217091878255, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 07:35:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 323.81842041015625, 'train_avg_loss': 0.6746217091878255, 'train_seen': 480, 'train_correct': 267, 'train_acc': 0.55625}}
2025-10-10 07:35:12 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #182, planning to set LR to 1.00e-05
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 07:35:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:35:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:35:52 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:35:52 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.396515, avg_loss=0.673743, seen=480, correct=282, accuracy=0.587500
2025-10-10 07:35:52 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:35:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:35:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:35:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=182 reserved=2420MB allocated=2217MB
2025-10-10 07:35:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 182, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.15073508024216, 'train_avg_loss': 0.6512561256686846, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:35:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 182, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.3965148925781, 'train_avg_loss': 0.6737427393595378, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 07:35:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 182, 'Results_raw': {'train_total': 480, 'train_loss': 323.3965148925781, 'train_avg_loss': 0.6737427393595378, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 07:35:56 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #183) -------------
2025-10-10 07:35:56 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=183 aidx=6 | s=5 (candidates=12)
2025-10-10 07:35:56 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 13, 23, 49, 46] (from 12)
2025-10-10 07:35:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 07:35:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:35:58 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:36:38 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:36:38 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.252380, avg_loss=0.681776, seen=480, correct=270, accuracy=0.562500
2025-10-10 07:36:38 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:36:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:36:40 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:36:41 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2362MB allocated=2217MB
2025-10-10 07:36:41 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.86222171783447, 'train_avg_loss': 0.6488518476486206, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:36:41 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.25238037109375, 'train_avg_loss': 0.6817757924397786, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 07:36:41 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 327.25238037109375, 'train_avg_loss': 0.6817757924397786, 'train_seen': 480, 'train_correct': 270, 'train_acc': 0.5625}}
2025-10-10 07:36:41 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 07:36:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:36:42 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:37:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:37:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.583618, avg_loss=0.659549, seen=480, correct=297, accuracy=0.618750
2025-10-10 07:37:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:37:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:37:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:37:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2362MB allocated=2217MB
2025-10-10 07:37:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.43585681915283, 'train_avg_loss': 0.6619654734929402, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:37:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.5836181640625, 'train_avg_loss': 0.6595492045084635, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:37:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 316.5836181640625, 'train_avg_loss': 0.6595492045084635, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:37:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:37:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:37:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:38:02 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:38:02 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.325073, avg_loss=0.681927, seen=480, correct=276, accuracy=0.575000
2025-10-10 07:38:02 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:38:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:38:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2362MB allocated=2217MB
2025-10-10 07:38:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.36099523305893, 'train_avg_loss': 0.6863416269421577, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 07:38:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.3250732421875, 'train_avg_loss': 0.681927235921224, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:38:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 327.3250732421875, 'train_avg_loss': 0.681927235921224, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:38:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:38:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:38:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 07:38:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:38:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:38:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:38:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:38:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:38:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:38:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=330.329529, avg_loss=0.688187, seen=480, correct=257, accuracy=0.535417
2025-10-10 07:38:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:38:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:38:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2380MB allocated=2217MB
2025-10-10 07:38:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.15758395195007, 'train_avg_loss': 0.7013131995995839, 'train_seen': 120, 'train_correct': 53, 'train_acc': 0.44166666666666665}}
2025-10-10 07:38:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 330.32952880859375, 'train_avg_loss': 0.688186518351237, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 07:38:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 330.32952880859375, 'train_avg_loss': 0.688186518351237, 'train_seen': 480, 'train_correct': 257, 'train_acc': 0.5354166666666667}}
2025-10-10 07:38:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #183, planning to set LR to 1.00e-05
2025-10-10 07:38:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:38:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:38:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:38:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:38:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:38:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:39:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:39:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.857239, avg_loss=0.687203, seen=480, correct=271, accuracy=0.564583
2025-10-10 07:39:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:39:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:39:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:39:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=183 reserved=2386MB allocated=2217MB
2025-10-10 07:39:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 183, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.33634167909622, 'train_avg_loss': 0.7028028473258019, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:39:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 183, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.85723876953125, 'train_avg_loss': 0.6872025807698567, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 07:39:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 183, 'Results_raw': {'train_total': 480, 'train_loss': 329.85723876953125, 'train_avg_loss': 0.6872025807698567, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 07:39:37 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #184) -------------
2025-10-10 07:39:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=184 aidx=6 | s=5 (candidates=12)
2025-10-10 07:39:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 18, 53, 52, 10] (from 12)
2025-10-10 07:39:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:39:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:39:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 07:39:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:39:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:39:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:39:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:39:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:39:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:40:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:40:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.617828, avg_loss=0.686704, seen=480, correct=259, accuracy=0.539583
2025-10-10 07:40:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:40:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:40:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:40:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2380MB allocated=2217MB
2025-10-10 07:40:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.36354833841324, 'train_avg_loss': 0.703029569486777, 'train_seen': 120, 'train_correct': 55, 'train_acc': 0.4583333333333333}}
2025-10-10 07:40:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.6178283691406, 'train_avg_loss': 0.6867038091023763, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 07:40:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 329.6178283691406, 'train_avg_loss': 0.6867038091023763, 'train_seen': 480, 'train_correct': 259, 'train_acc': 0.5395833333333333}}
2025-10-10 07:40:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:40:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:40:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:41:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:41:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.317932, avg_loss=0.671496, seen=480, correct=277, accuracy=0.577083
2025-10-10 07:41:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:41:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:41:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2388MB allocated=2217MB
2025-10-10 07:41:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.32830822467804, 'train_avg_loss': 0.6860692352056503, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:41:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.31793212890625, 'train_avg_loss': 0.6714956919352214, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 07:41:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 322.31793212890625, 'train_avg_loss': 0.6714956919352214, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 07:41:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:41:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:41:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:41:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:41:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.420532, avg_loss=0.673793, seen=480, correct=276, accuracy=0.575000
2025-10-10 07:41:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:41:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:50 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:41:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2362MB allocated=2217MB
2025-10-10 07:41:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.30506122112274, 'train_avg_loss': 0.6608755101760229, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 07:41:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.4205322265625, 'train_avg_loss': 0.6737927754720052, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:41:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 323.4205322265625, 'train_avg_loss': 0.6737927754720052, 'train_seen': 480, 'train_correct': 276, 'train_acc': 0.575}}
2025-10-10 07:41:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 07:41:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:41:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:42:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:42:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.385803, avg_loss=0.669554, seen=480, correct=275, accuracy=0.572917
2025-10-10 07:42:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:42:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:42:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:42:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2362MB allocated=2217MB
2025-10-10 07:42:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.36747568845749, 'train_avg_loss': 0.6530622974038124, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 07:42:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.38580322265625, 'train_avg_loss': 0.6695537567138672, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 07:42:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 321.38580322265625, 'train_avg_loss': 0.6695537567138672, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 07:42:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #184, planning to set LR to 1.00e-05
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 07:42:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:42:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:43:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:43:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.811127, avg_loss=0.647523, seen=480, correct=293, accuracy=0.610417
2025-10-10 07:43:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:43:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:43:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:43:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=184 reserved=2388MB allocated=2217MB
2025-10-10 07:43:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 184, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.27655071020126, 'train_avg_loss': 0.6439712559183438, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:43:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 184, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.8111267089844, 'train_avg_loss': 0.6475231806437175, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:43:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 184, 'Results_raw': {'train_total': 480, 'train_loss': 310.8111267089844, 'train_avg_loss': 0.6475231806437175, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 07:43:24 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #185) -------------
2025-10-10 07:43:25 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=185 aidx=6 | s=5 (candidates=12)
2025-10-10 07:43:25 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[19, 52, 39, 13, 46] (from 12)
2025-10-10 07:43:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:43:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:43:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 07:43:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 07:43:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:43:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:43:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:43:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:43:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:44:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:44:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.006927, avg_loss=0.658348, seen=480, correct=297, accuracy=0.618750
2025-10-10 07:44:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:44:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:44:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:44:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2420MB allocated=2217MB
2025-10-10 07:44:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.67507821321487, 'train_avg_loss': 0.638958985110124, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 07:44:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.0069274902344, 'train_avg_loss': 0.6583477656046549, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:44:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 316.0069274902344, 'train_avg_loss': 0.6583477656046549, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:44:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:44:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:44:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 07:44:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 07:44:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:44:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:44:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:44:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:44:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:44:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:44:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.309113, avg_loss=0.665227, seen=480, correct=281, accuracy=0.585417
2025-10-10 07:44:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:44:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:44:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:44:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2362MB allocated=2217MB
2025-10-10 07:44:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.50821352005005, 'train_avg_loss': 0.6542351126670838, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 07:44:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.3091125488281, 'train_avg_loss': 0.6652273178100586, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:44:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 319.3091125488281, 'train_avg_loss': 0.6652273178100586, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:44:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:44:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:44:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 07:44:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:44:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:44:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:44:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:44:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:44:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:45:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:45:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.804443, avg_loss=0.672509, seen=480, correct=281, accuracy=0.585417
2025-10-10 07:45:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:45:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:45:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:45:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2362MB allocated=2217MB
2025-10-10 07:45:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.71290576457977, 'train_avg_loss': 0.6642742147048314, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 07:45:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.804443359375, 'train_avg_loss': 0.6725092569986979, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:45:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 322.804443359375, 'train_avg_loss': 0.6725092569986979, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:45:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 07:45:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:45:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:46:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:46:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.816010, avg_loss=0.649617, seen=480, correct=315, accuracy=0.656250
2025-10-10 07:46:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:46:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:46:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:46:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2362MB allocated=2217MB
2025-10-10 07:46:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.71005350351334, 'train_avg_loss': 0.6559171125292778, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 07:46:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.8160095214844, 'train_avg_loss': 0.6496166865030925, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 07:46:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 311.8160095214844, 'train_avg_loss': 0.6496166865030925, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 07:46:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:46:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:46:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #185, planning to set LR to 1.00e-05
2025-10-10 07:46:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:46:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:46:21 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:46:21 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:46:21 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:46:21 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:46:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:46:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.008911, avg_loss=0.683352, seen=480, correct=274, accuracy=0.570833
2025-10-10 07:46:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:46:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:47:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:47:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=185 reserved=2386MB allocated=2217MB
2025-10-10 07:47:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 185, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.68623381853104, 'train_avg_loss': 0.6890519484877586, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 07:47:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 185, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.0089111328125, 'train_avg_loss': 0.6833518981933594, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 07:47:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 185, 'Results_raw': {'train_total': 480, 'train_loss': 328.0089111328125, 'train_avg_loss': 0.6833518981933594, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 07:47:03 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #186) -------------
2025-10-10 07:47:04 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=186 aidx=6 | s=5 (candidates=12)
2025-10-10 07:47:04 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 23, 53, 49, 18] (from 12)
2025-10-10 07:47:04 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:47:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:47:05 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:47:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:47:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.568848, avg_loss=0.676185, seen=480, correct=282, accuracy=0.587500
2025-10-10 07:47:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:47:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:47:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:47:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2386MB allocated=2217MB
2025-10-10 07:47:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.55813318490982, 'train_avg_loss': 0.6796511098742485, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 07:47:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.56884765625, 'train_avg_loss': 0.6761850992838542, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 07:47:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 324.56884765625, 'train_avg_loss': 0.6761850992838542, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 07:47:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:47:50 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:47:50 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 07:47:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:47:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:47:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:47:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:47:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:47:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:48:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:48:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.215363, avg_loss=0.675449, seen=480, correct=273, accuracy=0.568750
2025-10-10 07:48:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:48:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:48:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:48:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2362MB allocated=2217MB
2025-10-10 07:48:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.79953670501709, 'train_avg_loss': 0.6816628058751424, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 07:48:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.2153625488281, 'train_avg_loss': 0.6754486719767253, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 07:48:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 324.2153625488281, 'train_avg_loss': 0.6754486719767253, 'train_seen': 480, 'train_correct': 273, 'train_acc': 0.56875}}
2025-10-10 07:48:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:48:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:48:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 07:48:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:48:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:48:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:48:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:48:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:48:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:49:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:49:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.812927, avg_loss=0.674610, seen=480, correct=274, accuracy=0.570833
2025-10-10 07:49:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:49:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:49:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:49:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2362MB allocated=2217MB
2025-10-10 07:49:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.0742837190628, 'train_avg_loss': 0.6589523643255234, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 07:49:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.81292724609375, 'train_avg_loss': 0.6746102650960286, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 07:49:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 323.81292724609375, 'train_avg_loss': 0.6746102650960286, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 07:49:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:49:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:49:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:50:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:50:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.410950, avg_loss=0.684189, seen=480, correct=262, accuracy=0.545833
2025-10-10 07:50:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:50:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:50:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:50:04 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2380MB allocated=2217MB
2025-10-10 07:50:04 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.43847244977951, 'train_avg_loss': 0.7036539370814959, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 07:50:04 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.41094970703125, 'train_avg_loss': 0.6841894785563151, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 07:50:04 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 328.41094970703125, 'train_avg_loss': 0.6841894785563151, 'train_seen': 480, 'train_correct': 262, 'train_acc': 0.5458333333333333}}
2025-10-10 07:50:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #186, planning to set LR to 1.00e-05
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:50:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:50:06 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:50:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:50:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.604065, avg_loss=0.667925, seen=480, correct=278, accuracy=0.579167
2025-10-10 07:50:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:50:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:50:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:50:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=186 reserved=2388MB allocated=2217MB
2025-10-10 07:50:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 186, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.28331023454666, 'train_avg_loss': 0.6856942519545555, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 07:50:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 186, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.60406494140625, 'train_avg_loss': 0.6679251352945964, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 07:50:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 186, 'Results_raw': {'train_total': 480, 'train_loss': 320.60406494140625, 'train_avg_loss': 0.6679251352945964, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 07:50:50 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #187) -------------
2025-10-10 07:50:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=187 aidx=6 | s=5 (candidates=12)
2025-10-10 07:50:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[39, 53, 13, 10, 19] (from 12)
2025-10-10 07:50:51 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 07:50:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:50:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:51:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:51:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.304291, avg_loss=0.673551, seen=480, correct=288, accuracy=0.600000
2025-10-10 07:51:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:51:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:51:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:51:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2362MB allocated=2217MB
2025-10-10 07:51:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.7901691198349, 'train_avg_loss': 0.6649180759986242, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:51:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.3042907714844, 'train_avg_loss': 0.6735506057739258, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 07:51:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 323.3042907714844, 'train_avg_loss': 0.6735506057739258, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 07:51:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:51:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:51:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 07:51:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 07:51:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:51:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:51:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:51:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:51:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:52:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:52:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.387878, avg_loss=0.675808, seen=480, correct=271, accuracy=0.564583
2025-10-10 07:52:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:52:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:52:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:52:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2362MB allocated=2217MB
2025-10-10 07:52:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.28123033046722, 'train_avg_loss': 0.6606769194205602, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:52:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.38787841796875, 'train_avg_loss': 0.6758080800374349, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 07:52:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 324.38787841796875, 'train_avg_loss': 0.6758080800374349, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 07:52:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 07:52:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:52:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:52:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:52:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.055023, avg_loss=0.645948, seen=480, correct=322, accuracy=0.670833
2025-10-10 07:52:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:52:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:53:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:53:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2362MB allocated=2217MB
2025-10-10 07:53:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.94555622339249, 'train_avg_loss': 0.6578796351949374, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:53:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.0550231933594, 'train_avg_loss': 0.6459479649861654, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 07:53:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 310.0550231933594, 'train_avg_loss': 0.6459479649861654, 'train_seen': 480, 'train_correct': 322, 'train_acc': 0.6708333333333333}}
2025-10-10 07:53:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 07:53:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:53:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:53:43 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:53:43 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.424469, avg_loss=0.630051, seen=480, correct=308, accuracy=0.641667
2025-10-10 07:53:43 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:53:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:53:45 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:53:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2388MB allocated=2217MB
2025-10-10 07:53:46 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.4200245141983, 'train_avg_loss': 0.6285002042849859, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:53:46 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.4244689941406, 'train_avg_loss': 0.6300509770711263, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 07:53:46 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 302.4244689941406, 'train_avg_loss': 0.6300509770711263, 'train_seen': 480, 'train_correct': 308, 'train_acc': 0.6416666666666667}}
2025-10-10 07:53:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:53:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:53:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #187, planning to set LR to 1.00e-05
2025-10-10 07:53:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 07:53:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:53:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:53:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:53:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:53:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:54:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:54:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.705353, avg_loss=0.657719, seen=480, correct=295, accuracy=0.614583
2025-10-10 07:54:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:54:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:54:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:54:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=187 reserved=2420MB allocated=2217MB
2025-10-10 07:54:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 187, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.99690979719162, 'train_avg_loss': 0.6333075816432635, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 07:54:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 187, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.7053527832031, 'train_avg_loss': 0.6577194849650065, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:54:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 187, 'Results_raw': {'train_total': 480, 'train_loss': 315.7053527832031, 'train_avg_loss': 0.6577194849650065, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 07:54:28 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #188) -------------
2025-10-10 07:54:28 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=188 aidx=6 | s=5 (candidates=12)
2025-10-10 07:54:28 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 14, 49, 10, 19] (from 12)
2025-10-10 07:54:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:54:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:54:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 07:54:30 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 07:54:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:54:30 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:54:30 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:54:30 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:54:30 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:55:07 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:55:07 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.921448, avg_loss=0.674836, seen=480, correct=275, accuracy=0.572917
2025-10-10 07:55:07 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:55:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:55:09 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:55:10 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2386MB allocated=2217MB
2025-10-10 07:55:10 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.51995122432709, 'train_avg_loss': 0.6793329268693924, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 07:55:10 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.92144775390625, 'train_avg_loss': 0.6748363494873046, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 07:55:10 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 323.92144775390625, 'train_avg_loss': 0.6748363494873046, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 07:55:10 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:55:11 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:55:11 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 07:55:11 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 07:55:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:55:12 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:55:12 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:55:12 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:55:12 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:55:54 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:55:54 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.876587, avg_loss=0.670576, seen=480, correct=283, accuracy=0.589583
2025-10-10 07:55:54 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:55:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:55:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:55:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2362MB allocated=2217MB
2025-10-10 07:55:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.49802696704865, 'train_avg_loss': 0.6291502247254054, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:55:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.8765869140625, 'train_avg_loss': 0.6705762227376302, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 07:55:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 321.8765869140625, 'train_avg_loss': 0.6705762227376302, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 07:55:57 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:55:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:55:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:56:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:56:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.727570, avg_loss=0.684849, seen=480, correct=264, accuracy=0.550000
2025-10-10 07:56:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:56:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:56:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:56:43 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2380MB allocated=2217MB
2025-10-10 07:56:43 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.88567268848419, 'train_avg_loss': 0.699047272404035, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 07:56:43 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.7275695800781, 'train_avg_loss': 0.6848491032918295, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:56:43 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 328.7275695800781, 'train_avg_loss': 0.6848491032918295, 'train_seen': 480, 'train_correct': 264, 'train_acc': 0.55}}
2025-10-10 07:56:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 07:56:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:56:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:57:24 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:57:24 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.189423, avg_loss=0.625395, seen=480, correct=312, accuracy=0.650000
2025-10-10 07:57:24 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:57:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:57:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:57:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2388MB allocated=2217MB
2025-10-10 07:57:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.19568318128586, 'train_avg_loss': 0.6182973598440488, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 07:57:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.1894226074219, 'train_avg_loss': 0.625394630432129, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 07:57:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 300.1894226074219, 'train_avg_loss': 0.625394630432129, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 07:57:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #188, planning to set LR to 1.00e-05
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 07:57:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:57:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:58:09 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:58:09 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.251129, avg_loss=0.646357, seen=480, correct=297, accuracy=0.618750
2025-10-10 07:58:09 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:58:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:58:11 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:58:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=188 reserved=2420MB allocated=2217MB
2025-10-10 07:58:12 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 188, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.55725914239883, 'train_avg_loss': 0.6296438261866569, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 07:58:12 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 188, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.2511291503906, 'train_avg_loss': 0.6463565190633138, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:58:12 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 188, 'Results_raw': {'train_total': 480, 'train_loss': 310.2511291503906, 'train_avg_loss': 0.6463565190633138, 'train_seen': 480, 'train_correct': 297, 'train_acc': 0.61875}}
2025-10-10 07:58:13 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #189) -------------
2025-10-10 07:58:14 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=189 aidx=6 | s=5 (candidates=12)
2025-10-10 07:58:14 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[23, 18, 49, 39, 19] (from 12)
2025-10-10 07:58:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:58:15 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:58:15 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 07:58:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 07:58:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:58:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:58:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:58:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:58:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:58:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:58:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.940460, avg_loss=0.674876, seen=480, correct=281, accuracy=0.585417
2025-10-10 07:58:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:58:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:58:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:58:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2362MB allocated=2217MB
2025-10-10 07:58:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.19269299507141, 'train_avg_loss': 0.6849391082922618, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 07:58:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.9404602050781, 'train_avg_loss': 0.6748759587605794, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:58:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 323.9404602050781, 'train_avg_loss': 0.6748759587605794, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 07:58:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 07:59:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:59:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 07:59:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 07:59:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.459534, avg_loss=0.653041, seen=480, correct=292, accuracy=0.608333
2025-10-10 07:59:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 07:59:42 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 07:59:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2388MB allocated=2217MB
2025-10-10 07:59:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.25887376070023, 'train_avg_loss': 0.6688239480058352, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 07:59:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.45953369140625, 'train_avg_loss': 0.6530406951904297, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:59:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 313.45953369140625, 'train_avg_loss': 0.6530406951904297, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 07:59:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 07:59:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 07:59:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 07:59:47 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 07:59:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 07:59:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 07:59:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 07:59:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 07:59:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:00:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:00:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.126526, avg_loss=0.683597, seen=480, correct=269, accuracy=0.560417
2025-10-10 08:00:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:00:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:00:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:00:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2380MB allocated=2217MB
2025-10-10 08:00:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.56813806295395, 'train_avg_loss': 0.7047344838579496, 'train_seen': 120, 'train_correct': 58, 'train_acc': 0.48333333333333334}}
2025-10-10 08:00:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.12652587890625, 'train_avg_loss': 0.6835969289143881, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 08:00:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 328.12652587890625, 'train_avg_loss': 0.6835969289143881, 'train_seen': 480, 'train_correct': 269, 'train_acc': 0.5604166666666667}}
2025-10-10 08:00:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:00:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:00:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:00:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:00:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:01:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:01:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.122192, avg_loss=0.671088, seen=480, correct=274, accuracy=0.570833
2025-10-10 08:01:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:01:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:01:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:01:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2362MB allocated=2217MB
2025-10-10 08:01:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.83058398962021, 'train_avg_loss': 0.6652548665801684, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 08:01:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.1221923828125, 'train_avg_loss': 0.671087900797526, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 08:01:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 322.1221923828125, 'train_avg_loss': 0.671087900797526, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 08:01:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #189, planning to set LR to 1.00e-05
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 08:01:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:01:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:01:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:01:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.187134, avg_loss=0.635807, seen=480, correct=306, accuracy=0.637500
2025-10-10 08:01:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:01:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:01:57 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:01:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=189 reserved=2420MB allocated=2217MB
2025-10-10 08:01:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 189, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.79679828882217, 'train_avg_loss': 0.6233066524068515, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:01:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 189, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.1871337890625, 'train_avg_loss': 0.6358065287272135, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:01:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 189, 'Results_raw': {'train_total': 480, 'train_loss': 305.1871337890625, 'train_avg_loss': 0.6358065287272135, 'train_seen': 480, 'train_correct': 306, 'train_acc': 0.6375}}
2025-10-10 08:01:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #190) -------------
2025-10-10 08:01:59 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=190 aidx=6 | s=5 (candidates=12)
2025-10-10 08:01:59 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 23, 10, 38, 13] (from 12)
2025-10-10 08:02:00 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:02:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:02:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:02:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:02:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.904907, avg_loss=0.674802, seen=480, correct=280, accuracy=0.583333
2025-10-10 08:02:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:02:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:02:43 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:02:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2386MB allocated=2217MB
2025-10-10 08:02:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.75929129123688, 'train_avg_loss': 0.6729940940936406, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:02:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.9049072265625, 'train_avg_loss': 0.6748018900553385, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 08:02:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 323.9049072265625, 'train_avg_loss': 0.6748018900553385, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 08:02:44 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:02:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:02:45 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:03:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:03:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.940216, avg_loss=0.676959, seen=480, correct=283, accuracy=0.589583
2025-10-10 08:03:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:03:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:03:27 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:03:28 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2362MB allocated=2217MB
2025-10-10 08:03:28 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.86223328113556, 'train_avg_loss': 0.6905186106761296, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 08:03:28 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.9402160644531, 'train_avg_loss': 0.6769587834676106, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 08:03:28 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 324.9402160644531, 'train_avg_loss': 0.6769587834676106, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 08:03:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 08:03:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:03:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:04:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:04:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.516418, avg_loss=0.621909, seen=480, correct=311, accuracy=0.647917
2025-10-10 08:04:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:04:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:04:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2388MB allocated=2217MB
2025-10-10 08:04:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.3459934592247, 'train_avg_loss': 0.6195499454935391, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:04:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.51641845703125, 'train_avg_loss': 0.6219092051188151, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 08:04:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 298.51641845703125, 'train_avg_loss': 0.6219092051188151, 'train_seen': 480, 'train_correct': 311, 'train_acc': 0.6479166666666667}}
2025-10-10 08:04:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:04:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:04:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 08:04:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:04:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:04:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:04:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:04:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:04:56 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:04:56 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.941284, avg_loss=0.649878, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:04:56 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:04:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:04:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:04:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2374MB allocated=2217MB
2025-10-10 08:04:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.75494056940079, 'train_avg_loss': 0.6396245047450065, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:04:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.9412841796875, 'train_avg_loss': 0.6498776753743489, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:04:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 311.9412841796875, 'train_avg_loss': 0.6498776753743489, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:04:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:05:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:05:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #190, planning to set LR to 1.00e-05
2025-10-10 08:05:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 08:05:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:05:01 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:05:01 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:05:01 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:05:01 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:05:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:05:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.998596, avg_loss=0.637497, seen=480, correct=316, accuracy=0.658333
2025-10-10 08:05:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:05:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:05:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:05:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=190 reserved=2362MB allocated=2217MB
2025-10-10 08:05:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 190, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.03581660985947, 'train_avg_loss': 0.6502984717488289, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:05:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 190, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.99859619140625, 'train_avg_loss': 0.637497075398763, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 08:05:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 190, 'Results_raw': {'train_total': 480, 'train_loss': 305.99859619140625, 'train_avg_loss': 0.637497075398763, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 08:05:43 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #191) -------------
2025-10-10 08:05:43 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=191 aidx=6 | s=5 (candidates=12)
2025-10-10 08:05:43 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 39, 52, 46, 23] (from 12)
2025-10-10 08:05:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 08:05:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:05:46 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:06:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:06:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.502136, avg_loss=0.651046, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:06:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:06:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:06:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:06:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2388MB allocated=2217MB
2025-10-10 08:06:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.00606763362885, 'train_avg_loss': 0.6667172302802403, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 08:06:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.50213623046875, 'train_avg_loss': 0.6510461171468099, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:06:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 312.50213623046875, 'train_avg_loss': 0.6510461171468099, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:06:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:06:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:06:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:07:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:07:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.979401, avg_loss=0.672874, seen=480, correct=280, accuracy=0.583333
2025-10-10 08:07:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:07:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:07:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:07:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2362MB allocated=2217MB
2025-10-10 08:07:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.44342958927155, 'train_avg_loss': 0.6620285799105962, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 08:07:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.9794006347656, 'train_avg_loss': 0.6728737513224284, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 08:07:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 322.9794006347656, 'train_avg_loss': 0.6728737513224284, 'train_seen': 480, 'train_correct': 280, 'train_acc': 0.5833333333333334}}
2025-10-10 08:07:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:07:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:07:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 08:07:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 08:07:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:07:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:07:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:07:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:07:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:07:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:07:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.411224, avg_loss=0.661273, seen=480, correct=282, accuracy=0.587500
2025-10-10 08:07:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:07:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:08:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:08:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2362MB allocated=2217MB
2025-10-10 08:08:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.12412297725677, 'train_avg_loss': 0.6427010248104731, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:08:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.4112243652344, 'train_avg_loss': 0.6612733840942383, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 08:08:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 317.4112243652344, 'train_avg_loss': 0.6612733840942383, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 08:08:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:08:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:08:03 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:08:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:08:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.389282, avg_loss=0.677894, seen=480, correct=278, accuracy=0.579167
2025-10-10 08:08:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:08:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:08:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:08:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2386MB allocated=2217MB
2025-10-10 08:08:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.20924037694931, 'train_avg_loss': 0.6850770031412442, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:08:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.3892822265625, 'train_avg_loss': 0.6778943379720052, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 08:08:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 325.3892822265625, 'train_avg_loss': 0.6778943379720052, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 08:08:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:08:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:08:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #191, planning to set LR to 1.00e-05
2025-10-10 08:08:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:08:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:08:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:08:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:08:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:08:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:09:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:09:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=326.345032, avg_loss=0.679885, seen=480, correct=285, accuracy=0.593750
2025-10-10 08:09:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:09:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:09:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:09:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=191 reserved=2362MB allocated=2217MB
2025-10-10 08:09:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 191, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.84515291452408, 'train_avg_loss': 0.698709607621034, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 08:09:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 191, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 326.34503173828125, 'train_avg_loss': 0.6798854827880859, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:09:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 191, 'Results_raw': {'train_total': 480, 'train_loss': 326.34503173828125, 'train_avg_loss': 0.6798854827880859, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:09:32 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #192) -------------
2025-10-10 08:09:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=192 aidx=6 | s=5 (candidates=12)
2025-10-10 08:09:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 10, 53, 46, 14] (from 12)
2025-10-10 08:09:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:09:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:09:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 08:09:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:09:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:09:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:09:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:09:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:09:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:10:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:10:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=327.479675, avg_loss=0.682249, seen=480, correct=271, accuracy=0.564583
2025-10-10 08:10:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:10:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:10:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:10:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2380MB allocated=2217MB
2025-10-10 08:10:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.57298791408539, 'train_avg_loss': 0.6964415659507116, 'train_seen': 120, 'train_correct': 64, 'train_acc': 0.5333333333333333}}
2025-10-10 08:10:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 327.47967529296875, 'train_avg_loss': 0.6822493235270183, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 08:10:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 327.47967529296875, 'train_avg_loss': 0.6822493235270183, 'train_seen': 480, 'train_correct': 271, 'train_acc': 0.5645833333333333}}
2025-10-10 08:10:17 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 08:10:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:10:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:10:59 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:10:59 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.142914, avg_loss=0.619048, seen=480, correct=313, accuracy=0.652083
2025-10-10 08:10:59 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:10:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:01 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:11:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2388MB allocated=2217MB
2025-10-10 08:11:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.14918404817581, 'train_avg_loss': 0.6179098670681318, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:11:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.1429138183594, 'train_avg_loss': 0.619047737121582, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 08:11:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 297.1429138183594, 'train_avg_loss': 0.619047737121582, 'train_seen': 480, 'train_correct': 313, 'train_acc': 0.6520833333333333}}
2025-10-10 08:11:02 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:11:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:11:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:11:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:11:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.382721, avg_loss=0.671631, seen=480, correct=285, accuracy=0.593750
2025-10-10 08:11:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:11:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:44 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:11:45 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2362MB allocated=2217MB
2025-10-10 08:11:45 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.40522974729538, 'train_avg_loss': 0.6450435812274615, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:11:45 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.3827209472656, 'train_avg_loss': 0.6716306686401368, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:11:45 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 322.3827209472656, 'train_avg_loss': 0.6716306686401368, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:11:45 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:11:46 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:11:46 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 08:11:46 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:11:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:11:47 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:11:47 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:11:47 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:11:47 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:12:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:12:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.670959, avg_loss=0.674314, seen=480, correct=281, accuracy=0.585417
2025-10-10 08:12:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:12:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:12:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:12:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2384MB allocated=2217MB
2025-10-10 08:12:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.02748316526413, 'train_avg_loss': 0.6752290263772011, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:12:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.67095947265625, 'train_avg_loss': 0.6743144989013672, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 08:12:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 323.67095947265625, 'train_avg_loss': 0.6743144989013672, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 08:12:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:12:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:12:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #192, planning to set LR to 1.00e-05
2025-10-10 08:12:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 08:12:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:12:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:12:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:12:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:12:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:13:13 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:13:13 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.940002, avg_loss=0.660292, seen=480, correct=290, accuracy=0.604167
2025-10-10 08:13:13 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:13:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:13:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:13:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=192 reserved=2362MB allocated=2217MB
2025-10-10 08:13:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 192, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.52511131763458, 'train_avg_loss': 0.6127092609802882, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:13:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 192, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.94000244140625, 'train_avg_loss': 0.6602916717529297, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 08:13:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 192, 'Results_raw': {'train_total': 480, 'train_loss': 316.94000244140625, 'train_avg_loss': 0.6602916717529297, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 08:13:16 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #193) -------------
2025-10-10 08:13:17 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=193 aidx=6 | s=5 (candidates=12)
2025-10-10 08:13:17 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 46, 19, 23, 38] (from 12)
2025-10-10 08:13:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:13:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:13:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:14:00 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:14:00 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=329.491852, avg_loss=0.686441, seen=480, correct=278, accuracy=0.579167
2025-10-10 08:14:00 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:14:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:02 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:14:02 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2380MB allocated=2217MB
2025-10-10 08:14:02 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.37178808450699, 'train_avg_loss': 0.6697649007042249, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:14:02 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 329.4918518066406, 'train_avg_loss': 0.6864413579305013, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 08:14:02 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 329.4918518066406, 'train_avg_loss': 0.6864413579305013, 'train_seen': 480, 'train_correct': 278, 'train_acc': 0.5791666666666667}}
2025-10-10 08:14:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:14:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:14:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:14:46 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:14:46 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=328.381348, avg_loss=0.684128, seen=480, correct=277, accuracy=0.577083
2025-10-10 08:14:46 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:14:46 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:48 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:14:49 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2386MB allocated=2217MB
2025-10-10 08:14:49 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.08055752515793, 'train_avg_loss': 0.7006713127096494, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 08:14:49 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 328.38134765625, 'train_avg_loss': 0.6841278076171875, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 08:14:49 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 328.38134765625, 'train_avg_loss': 0.6841278076171875, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 08:14:49 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 08:14:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:14:51 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:15:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:15:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.597534, avg_loss=0.644995, seen=480, correct=301, accuracy=0.627083
2025-10-10 08:15:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:15:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:15:30 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:15:31 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2420MB allocated=2217MB
2025-10-10 08:15:31 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.1338341832161, 'train_avg_loss': 0.6594486181934675, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 08:15:31 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.5975341796875, 'train_avg_loss': 0.6449948628743489, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:15:31 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 309.5975341796875, 'train_avg_loss': 0.6449948628743489, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:15:31 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:15:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:15:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:16:11 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:16:11 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.821075, avg_loss=0.678794, seen=480, correct=274, accuracy=0.570833
2025-10-10 08:16:11 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:16:11 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:16:13 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:16:14 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2362MB allocated=2217MB
2025-10-10 08:16:14 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 84.11904937028885, 'train_avg_loss': 0.7009920780857404, 'train_seen': 120, 'train_correct': 66, 'train_acc': 0.55}}
2025-10-10 08:16:14 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.8210754394531, 'train_avg_loss': 0.6787939071655273, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 08:16:14 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 325.8210754394531, 'train_avg_loss': 0.6787939071655273, 'train_seen': 480, 'train_correct': 274, 'train_acc': 0.5708333333333333}}
2025-10-10 08:16:14 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #193, planning to set LR to 1.00e-05
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:16:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:16:16 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:16:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:16:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.638367, avg_loss=0.653413, seen=480, correct=299, accuracy=0.622917
2025-10-10 08:16:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:16:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:16:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:16:58 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=193 reserved=2374MB allocated=2217MB
2025-10-10 08:16:58 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 193, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.42776817083359, 'train_avg_loss': 0.6452314014236132, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:16:58 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 193, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.63836669921875, 'train_avg_loss': 0.6534132639567057, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:16:58 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 193, 'Results_raw': {'train_total': 480, 'train_loss': 313.63836669921875, 'train_avg_loss': 0.6534132639567057, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:16:59 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #194) -------------
2025-10-10 08:17:00 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=194 aidx=6 | s=5 (candidates=12)
2025-10-10 08:17:00 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 10, 38, 39, 23] (from 12)
2025-10-10 08:17:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:17:01 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:17:01 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 08:17:01 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:17:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:17:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:17:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:17:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:17:40 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:17:40 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.643799, avg_loss=0.670091, seen=480, correct=285, accuracy=0.593750
2025-10-10 08:17:40 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:17:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:17:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2362MB allocated=2217MB
2025-10-10 08:17:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.4049112200737, 'train_avg_loss': 0.6450409268339475, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:17:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.643798828125, 'train_avg_loss': 0.6700912475585937, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:17:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 321.643798828125, 'train_avg_loss': 0.6700912475585937, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:17:43 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 08:17:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:17:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:18:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:18:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.818115, avg_loss=0.616288, seen=480, correct=312, accuracy=0.650000
2025-10-10 08:18:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:18:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:18:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:18:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2388MB allocated=2217MB
2025-10-10 08:18:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.77853184938431, 'train_avg_loss': 0.6148210987448692, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:18:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.818115234375, 'train_avg_loss': 0.6162877400716146, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 08:18:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 295.818115234375, 'train_avg_loss': 0.6162877400716146, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 08:18:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:18:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:18:27 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:19:08 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:19:08 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.901062, avg_loss=0.635211, seen=480, correct=301, accuracy=0.627083
2025-10-10 08:19:08 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:19:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:10 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:19:11 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2374MB allocated=2217MB
2025-10-10 08:19:11 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.17190581560135, 'train_avg_loss': 0.6264325484633446, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:19:11 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.90106201171875, 'train_avg_loss': 0.6352105458577474, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:19:11 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 304.90106201171875, 'train_avg_loss': 0.6352105458577474, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:19:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:19:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:19:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 08:19:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:19:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:19:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:19:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:19:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.994232, avg_loss=0.668738, seen=480, correct=281, accuracy=0.585417
2025-10-10 08:19:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:19:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:19:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2362MB allocated=2217MB
2025-10-10 08:19:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.74233067035675, 'train_avg_loss': 0.6561860889196396, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:19:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.9942321777344, 'train_avg_loss': 0.6687379837036133, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 08:19:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 320.9942321777344, 'train_avg_loss': 0.6687379837036133, 'train_seen': 480, 'train_correct': 281, 'train_acc': 0.5854166666666667}}
2025-10-10 08:19:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #194, planning to set LR to 1.00e-05
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:19:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:19:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:20:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:20:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=317.666565, avg_loss=0.661805, seen=480, correct=289, accuracy=0.602083
2025-10-10 08:20:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:20:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:20:36 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:20:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=194 reserved=2362MB allocated=2217MB
2025-10-10 08:20:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 194, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 82.09049916267395, 'train_avg_loss': 0.6840874930222829, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 08:20:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 194, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 317.66656494140625, 'train_avg_loss': 0.6618053436279296, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:20:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 194, 'Results_raw': {'train_total': 480, 'train_loss': 317.66656494140625, 'train_avg_loss': 0.6618053436279296, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:20:38 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #195) -------------
2025-10-10 08:20:38 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=195 aidx=6 | s=5 (candidates=12)
2025-10-10 08:20:38 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 13, 14, 46, 39] (from 12)
2025-10-10 08:20:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 08:20:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:20:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:21:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:21:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.570892, avg_loss=0.655356, seen=480, correct=285, accuracy=0.593750
2025-10-10 08:21:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:21:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:21:24 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:21:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2362MB allocated=2217MB
2025-10-10 08:21:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.5418963432312, 'train_avg_loss': 0.6461824695269267, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:21:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.5708923339844, 'train_avg_loss': 0.6553560256958008, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:21:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 314.5708923339844, 'train_avg_loss': 0.6553560256958008, 'train_seen': 480, 'train_correct': 285, 'train_acc': 0.59375}}
2025-10-10 08:21:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 08:21:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:21:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:22:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:22:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.464966, avg_loss=0.621802, seen=480, correct=319, accuracy=0.664583
2025-10-10 08:22:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:22:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:22:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2362MB allocated=2217MB
2025-10-10 08:22:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.34410399198532, 'train_avg_loss': 0.6362008665998776, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:22:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.4649658203125, 'train_avg_loss': 0.621802012125651, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 08:22:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 298.4649658203125, 'train_avg_loss': 0.621802012125651, 'train_seen': 480, 'train_correct': 319, 'train_acc': 0.6645833333333333}}
2025-10-10 08:22:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:22:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:22:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 08:22:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 08:22:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:22:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:22:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:22:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:22:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:22:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.453979, avg_loss=0.648862, seen=480, correct=301, accuracy=0.627083
2025-10-10 08:22:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:22:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:22:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2362MB allocated=2217MB
2025-10-10 08:22:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.05326986312866, 'train_avg_loss': 0.6004439155260722, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:22:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.4539794921875, 'train_avg_loss': 0.6488624572753906, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:22:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 311.4539794921875, 'train_avg_loss': 0.6488624572753906, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:22:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:22:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:22:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:23:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:23:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.633911, avg_loss=0.672154, seen=480, correct=282, accuracy=0.587500
2025-10-10 08:23:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:23:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:23:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:23:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2384MB allocated=2217MB
2025-10-10 08:23:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.2468199133873, 'train_avg_loss': 0.6687234992782275, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 08:23:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.6339111328125, 'train_avg_loss': 0.6721539815266927, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 08:23:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 322.6339111328125, 'train_avg_loss': 0.6721539815266927, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 08:23:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #195, planning to set LR to 1.00e-05
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:23:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:23:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:24:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:24:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.770691, avg_loss=0.668272, seen=480, correct=289, accuracy=0.602083
2025-10-10 08:24:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:24:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:24:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:24:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=195 reserved=2362MB allocated=2217MB
2025-10-10 08:24:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 195, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.89382547140121, 'train_avg_loss': 0.6574485455950101, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:24:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 195, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.77069091796875, 'train_avg_loss': 0.6682722727457683, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:24:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 195, 'Results_raw': {'train_total': 480, 'train_loss': 320.77069091796875, 'train_avg_loss': 0.6682722727457683, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:24:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #196) -------------
2025-10-10 08:24:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=196 aidx=6 | s=5 (candidates=12)
2025-10-10 08:24:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 52, 18, 38, 49] (from 12)
2025-10-10 08:24:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 08:24:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:24:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:25:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:25:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.248169, avg_loss=0.621350, seen=480, correct=317, accuracy=0.660417
2025-10-10 08:25:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:25:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:25:06 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:25:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2362MB allocated=2217MB
2025-10-10 08:25:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.05568051338196, 'train_avg_loss': 0.6337973376115164, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:25:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.2481689453125, 'train_avg_loss': 0.621350351969401, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 08:25:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 298.2481689453125, 'train_avg_loss': 0.621350351969401, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 08:25:07 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:25:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:25:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 08:25:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 08:25:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:25:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:25:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:25:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:25:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:25:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:25:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=315.375061, avg_loss=0.657031, seen=480, correct=288, accuracy=0.600000
2025-10-10 08:25:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:25:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:25:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:25:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2362MB allocated=2217MB
2025-10-10 08:25:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.35496687889099, 'train_avg_loss': 0.6446247239907582, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:25:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 315.37506103515625, 'train_avg_loss': 0.6570313771565756, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 08:25:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 315.37506103515625, 'train_avg_loss': 0.6570313771565756, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 08:25:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:25:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:25:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 08:25:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 08:25:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:25:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:25:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:25:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:25:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:26:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:26:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.291534, avg_loss=0.648524, seen=480, correct=301, accuracy=0.627083
2025-10-10 08:26:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:26:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:26:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:26:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2388MB allocated=2217MB
2025-10-10 08:26:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.2690424323082, 'train_avg_loss': 0.6689086869359017, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 08:26:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.2915344238281, 'train_avg_loss': 0.6485240300496419, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:26:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 311.2915344238281, 'train_avg_loss': 0.6485240300496419, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:26:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:26:40 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:26:40 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:27:22 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:27:22 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.986877, avg_loss=0.637473, seen=480, correct=301, accuracy=0.627083
2025-10-10 08:27:22 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:27:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:27:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:27:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2374MB allocated=2217MB
2025-10-10 08:27:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.90293610095978, 'train_avg_loss': 0.6325244675079982, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:27:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.98687744140625, 'train_avg_loss': 0.637472661336263, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:27:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 305.98687744140625, 'train_avg_loss': 0.637472661336263, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 08:27:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #196, planning to set LR to 1.00e-05
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:27:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:27:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:28:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:28:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=325.419739, avg_loss=0.677958, seen=480, correct=277, accuracy=0.577083
2025-10-10 08:28:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:28:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:28:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:28:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=196 reserved=2380MB allocated=2217MB
2025-10-10 08:28:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 196, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 83.02511441707611, 'train_avg_loss': 0.6918759534756342, 'train_seen': 120, 'train_correct': 65, 'train_acc': 0.5416666666666666}}
2025-10-10 08:28:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 196, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 325.41973876953125, 'train_avg_loss': 0.6779577891031902, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 08:28:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 196, 'Results_raw': {'train_total': 480, 'train_loss': 325.41973876953125, 'train_avg_loss': 0.6779577891031902, 'train_seen': 480, 'train_correct': 277, 'train_acc': 0.5770833333333333}}
2025-10-10 08:28:07 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #197) -------------
2025-10-10 08:28:08 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=197 aidx=6 | s=5 (candidates=12)
2025-10-10 08:28:08 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[18, 13, 46, 39, 23] (from 12)
2025-10-10 08:28:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:28:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:28:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 08:28:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 08:28:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:28:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:28:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:28:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:28:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:28:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:28:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=310.811584, avg_loss=0.647524, seen=480, correct=300, accuracy=0.625000
2025-10-10 08:28:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:28:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:28:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:28:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2388MB allocated=2217MB
2025-10-10 08:28:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.39969259500504, 'train_avg_loss': 0.6699974382917087, 'train_seen': 120, 'train_correct': 68, 'train_acc': 0.5666666666666667}}
2025-10-10 08:28:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 310.81158447265625, 'train_avg_loss': 0.6475241343180339, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 08:28:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 310.81158447265625, 'train_avg_loss': 0.6475241343180339, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 08:28:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 08:28:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:28:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:29:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:29:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.416321, avg_loss=0.619617, seen=480, correct=321, accuracy=0.668750
2025-10-10 08:29:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:29:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:29:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:29:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2362MB allocated=2217MB
2025-10-10 08:29:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.96475023031235, 'train_avg_loss': 0.6330395852526028, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:29:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.41632080078125, 'train_avg_loss': 0.6196173350016276, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 08:29:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 297.41632080078125, 'train_avg_loss': 0.6196173350016276, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 08:29:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:29:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:29:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:30:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:30:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.456482, avg_loss=0.671784, seen=480, correct=287, accuracy=0.597917
2025-10-10 08:30:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:30:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:30:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:30:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2386MB allocated=2217MB
2025-10-10 08:30:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.71804094314575, 'train_avg_loss': 0.664317007859548, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:30:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.45648193359375, 'train_avg_loss': 0.6717843373616537, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 08:30:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 322.45648193359375, 'train_avg_loss': 0.6717843373616537, 'train_seen': 480, 'train_correct': 287, 'train_acc': 0.5979166666666667}}
2025-10-10 08:30:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:30:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:30:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 08:30:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:30:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:30:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:30:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:30:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:30:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:31:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:31:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.859070, avg_loss=0.660123, seen=480, correct=296, accuracy=0.616667
2025-10-10 08:31:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:31:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:31:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:31:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2362MB allocated=2217MB
2025-10-10 08:31:07 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.5836523771286, 'train_avg_loss': 0.6465304364760717, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:31:07 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.85906982421875, 'train_avg_loss': 0.660123062133789, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 08:31:07 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 316.85906982421875, 'train_avg_loss': 0.660123062133789, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 08:31:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #197, planning to set LR to 1.00e-05
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:31:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:31:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:31:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:31:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.263733, avg_loss=0.648466, seen=480, correct=299, accuracy=0.622917
2025-10-10 08:31:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:31:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:31:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:31:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=197 reserved=2362MB allocated=2217MB
2025-10-10 08:31:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 197, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.96437820792198, 'train_avg_loss': 0.6663698183993498, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 08:31:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 197, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.26373291015625, 'train_avg_loss': 0.6484661102294922, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:31:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 197, 'Results_raw': {'train_total': 480, 'train_loss': 311.26373291015625, 'train_avg_loss': 0.6484661102294922, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:31:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #198) -------------
2025-10-10 08:31:53 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=198 aidx=6 | s=5 (candidates=12)
2025-10-10 08:31:53 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 10, 19, 49, 13] (from 12)
2025-10-10 08:31:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:31:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:31:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:32:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:32:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.616089, avg_loss=0.638784, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:32:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:32:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:32:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:32:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2374MB allocated=2217MB
2025-10-10 08:32:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.11033755540848, 'train_avg_loss': 0.6425861462950706, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 08:32:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.6160888671875, 'train_avg_loss': 0.6387835184733073, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:32:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 306.6160888671875, 'train_avg_loss': 0.6387835184733073, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:32:40 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 08:32:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:32:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:33:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:33:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.423279, avg_loss=0.615465, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:33:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:33:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:33:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:33:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2388MB allocated=2217MB
2025-10-10 08:33:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.45392566919327, 'train_avg_loss': 0.6121160472432773, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 08:33:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.42327880859375, 'train_avg_loss': 0.6154651641845703, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:33:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 295.42327880859375, 'train_avg_loss': 0.6154651641845703, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:33:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 08:33:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:33:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:34:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:34:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=298.515198, avg_loss=0.621907, seen=480, correct=316, accuracy=0.658333
2025-10-10 08:34:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:34:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:34:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:34:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2420MB allocated=2217MB
2025-10-10 08:34:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.48646664619446, 'train_avg_loss': 0.6040538887182871, 'train_seen': 120, 'train_correct': 85, 'train_acc': 0.7083333333333334}}
2025-10-10 08:34:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 298.51519775390625, 'train_avg_loss': 0.6219066619873047, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 08:34:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 298.51519775390625, 'train_avg_loss': 0.6219066619873047, 'train_seen': 480, 'train_correct': 316, 'train_acc': 0.6583333333333333}}
2025-10-10 08:34:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:34:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:34:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:34:51 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:34:51 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.011047, avg_loss=0.666690, seen=480, correct=289, accuracy=0.602083
2025-10-10 08:34:51 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:34:52 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:34:53 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:34:54 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2380MB allocated=2217MB
2025-10-10 08:34:54 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.82117947936058, 'train_avg_loss': 0.6735098289946715, 'train_seen': 120, 'train_correct': 73, 'train_acc': 0.6083333333333333}}
2025-10-10 08:34:54 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.01104736328125, 'train_avg_loss': 0.666689682006836, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:34:54 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 320.01104736328125, 'train_avg_loss': 0.666689682006836, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 08:34:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #198, planning to set LR to 1.00e-05
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 08:34:56 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:34:56 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:35:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:35:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=297.442291, avg_loss=0.619671, seen=480, correct=325, accuracy=0.677083
2025-10-10 08:35:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:35:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:35:39 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:35:40 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=198 reserved=2362MB allocated=2217MB
2025-10-10 08:35:40 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 198, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.28549599647522, 'train_avg_loss': 0.6357124666372935, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:35:40 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 198, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 297.4422912597656, 'train_avg_loss': 0.6196714401245117, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 08:35:40 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 198, 'Results_raw': {'train_total': 480, 'train_loss': 297.4422912597656, 'train_avg_loss': 0.6196714401245117, 'train_seen': 480, 'train_correct': 325, 'train_acc': 0.6770833333333334}}
2025-10-10 08:35:41 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #199) -------------
2025-10-10 08:35:41 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=199 aidx=6 | s=5 (candidates=12)
2025-10-10 08:35:41 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[52, 18, 38, 10, 19] (from 12)
2025-10-10 08:35:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 08:35:43 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:35:43 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:36:25 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:36:25 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.049255, avg_loss=0.654269, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:36:25 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:36:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:36:26 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:36:27 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2362MB allocated=2217MB
2025-10-10 08:36:27 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.05074375867844, 'train_avg_loss': 0.6420895313223203, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:36:27 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.04925537109375, 'train_avg_loss': 0.654269282023112, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:36:27 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 314.04925537109375, 'train_avg_loss': 0.654269282023112, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:36:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:36:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:36:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 08:36:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:36:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:37:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:37:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=309.139832, avg_loss=0.644041, seen=480, correct=303, accuracy=0.631250
2025-10-10 08:37:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:37:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:37:12 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2388MB allocated=2217MB
2025-10-10 08:37:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.05083322525024, 'train_avg_loss': 0.6670902768770853, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 08:37:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 309.13983154296875, 'train_avg_loss': 0.6440413157145183, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 08:37:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 309.13983154296875, 'train_avg_loss': 0.6440413157145183, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 08:37:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:37:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:37:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:37:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:37:15 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:37:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:37:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.305725, avg_loss=0.633970, seen=480, correct=315, accuracy=0.656250
2025-10-10 08:37:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:37:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:56 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:37:57 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2374MB allocated=2217MB
2025-10-10 08:37:57 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.05608594417572, 'train_avg_loss': 0.6338007162014644, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:37:57 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.30572509765625, 'train_avg_loss': 0.6339702606201172, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 08:37:57 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 304.30572509765625, 'train_avg_loss': 0.6339702606201172, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 08:37:58 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 08:37:59 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:37:59 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:38:39 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:38:39 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.270966, avg_loss=0.615148, seen=480, correct=307, accuracy=0.639583
2025-10-10 08:38:39 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:38:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:38:41 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:38:42 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2388MB allocated=2217MB
2025-10-10 08:38:42 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.29422849416733, 'train_avg_loss': 0.6107852374513943, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:38:42 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.2709655761719, 'train_avg_loss': 0.6151478449503581, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:38:42 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 295.2709655761719, 'train_avg_loss': 0.6151478449503581, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:38:42 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #199, planning to set LR to 1.00e-05
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 08:38:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:38:44 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:39:23 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:39:23 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=299.796143, avg_loss=0.624575, seen=480, correct=314, accuracy=0.654167
2025-10-10 08:39:23 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:39:23 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:39:25 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:39:26 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=199 reserved=2420MB allocated=2217MB
2025-10-10 08:39:26 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 199, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.05846971273422, 'train_avg_loss': 0.6171539142727852, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 08:39:26 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 199, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 299.796142578125, 'train_avg_loss': 0.6245752970377604, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 08:39:26 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 199, 'Results_raw': {'train_total': 480, 'train_loss': 299.796142578125, 'train_avg_loss': 0.6245752970377604, 'train_seen': 480, 'train_correct': 314, 'train_acc': 0.6541666666666667}}
2025-10-10 08:39:27 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #200) -------------
2025-10-10 08:39:27 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=200 aidx=6 | s=5 (candidates=12)
2025-10-10 08:39:27 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 49, 19, 52, 39] (from 12)
2025-10-10 08:39:28 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:39:28 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:39:28 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 08:39:29 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:39:29 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:39:29 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:39:29 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:39:29 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:39:29 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:40:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:40:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=324.420624, avg_loss=0.675876, seen=480, correct=291, accuracy=0.606250
2025-10-10 08:40:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:40:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:40:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2362MB allocated=2217MB
2025-10-10 08:40:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.46808505058289, 'train_avg_loss': 0.6372340420881907, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 08:40:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 324.4206237792969, 'train_avg_loss': 0.6758762995402018, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 08:40:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 324.4206237792969, 'train_avg_loss': 0.6758762995402018, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 08:40:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:40:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:40:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:40:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:40:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=321.321106, avg_loss=0.669419, seen=480, correct=296, accuracy=0.616667
2025-10-10 08:40:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:40:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:40:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2380MB allocated=2217MB
2025-10-10 08:40:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.09373369812965, 'train_avg_loss': 0.6757811141510804, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:40:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 321.32110595703125, 'train_avg_loss': 0.6694189707438151, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 08:40:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 321.32110595703125, 'train_avg_loss': 0.6694189707438151, 'train_seen': 480, 'train_correct': 296, 'train_acc': 0.6166666666666667}}
2025-10-10 08:40:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 08:40:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:40:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:41:34 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.729858, avg_loss=0.607771, seen=480, correct=317, accuracy=0.660417
2025-10-10 08:41:34 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:41:34 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:41:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:41:36 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2420MB allocated=2217MB
2025-10-10 08:41:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.94215098023415, 'train_avg_loss': 0.5911845915019512, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 08:41:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.7298583984375, 'train_avg_loss': 0.6077705383300781, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 08:41:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 291.7298583984375, 'train_avg_loss': 0.6077705383300781, 'train_seen': 480, 'train_correct': 317, 'train_acc': 0.6604166666666667}}
2025-10-10 08:41:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 08:41:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:41:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:42:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:42:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.428528, avg_loss=0.655059, seen=480, correct=290, accuracy=0.604167
2025-10-10 08:42:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:42:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:42:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:42:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2362MB allocated=2217MB
2025-10-10 08:42:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.9258462190628, 'train_avg_loss': 0.64104871849219, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:42:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.42852783203125, 'train_avg_loss': 0.6550594329833984, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 08:42:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 314.42852783203125, 'train_avg_loss': 0.6550594329833984, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 08:42:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #200, planning to set LR to 1.00e-05
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:42:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:42:22 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:43:01 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:43:01 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.572632, avg_loss=0.659526, seen=480, correct=295, accuracy=0.614583
2025-10-10 08:43:01 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:43:01 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:43:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:43:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=200 reserved=2362MB allocated=2217MB
2025-10-10 08:43:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 200, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.09868264198303, 'train_avg_loss': 0.6424890220165252, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:43:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 200, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.5726318359375, 'train_avg_loss': 0.6595263163248698, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 08:43:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 200, 'Results_raw': {'train_total': 480, 'train_loss': 316.5726318359375, 'train_avg_loss': 0.6595263163248698, 'train_seen': 480, 'train_correct': 295, 'train_acc': 0.6145833333333334}}
2025-10-10 08:43:05 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #201) -------------
2025-10-10 08:43:06 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=201 aidx=6 | s=5 (candidates=12)
2025-10-10 08:43:06 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 38, 10, 14, 23] (from 12)
2025-10-10 08:43:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:43:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:43:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 08:43:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:43:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:43:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:43:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:43:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:43:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:43:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:43:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.870148, avg_loss=0.674729, seen=480, correct=283, accuracy=0.589583
2025-10-10 08:43:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:43:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:43:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:43:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2362MB allocated=2217MB
2025-10-10 08:43:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.20569866895676, 'train_avg_loss': 0.635047488907973, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:43:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.8701477050781, 'train_avg_loss': 0.6747294743855794, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 08:43:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 323.8701477050781, 'train_avg_loss': 0.6747294743855794, 'train_seen': 480, 'train_correct': 283, 'train_acc': 0.5895833333333333}}
2025-10-10 08:43:50 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:43:51 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:43:51 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 08:43:51 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:43:51 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:43:52 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:43:52 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:43:52 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:43:52 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:44:31 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:44:31 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.965790, avg_loss=0.635345, seen=480, correct=309, accuracy=0.643750
2025-10-10 08:44:31 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:44:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:44:33 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:44:34 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2374MB allocated=2217MB
2025-10-10 08:44:34 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.27838933467865, 'train_avg_loss': 0.6273199111223221, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:44:34 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.9657897949219, 'train_avg_loss': 0.6353453954060873, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 08:44:34 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 304.9657897949219, 'train_avg_loss': 0.6353453954060873, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 08:44:34 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:44:35 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:44:35 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 08:44:35 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 08:44:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:44:36 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:44:36 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:44:36 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:44:36 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:45:16 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:45:16 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=291.766724, avg_loss=0.607847, seen=480, correct=326, accuracy=0.679167
2025-10-10 08:45:16 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:45:16 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:45:18 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:45:19 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2388MB allocated=2217MB
2025-10-10 08:45:19 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.8716499209404, 'train_avg_loss': 0.60726374934117, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 08:45:19 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 291.7667236328125, 'train_avg_loss': 0.6078473409016927, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:45:19 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 291.7667236328125, 'train_avg_loss': 0.6078473409016927, 'train_seen': 480, 'train_correct': 326, 'train_acc': 0.6791666666666667}}
2025-10-10 08:45:19 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 08:45:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:45:20 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:46:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:46:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.223114, avg_loss=0.631715, seen=480, correct=302, accuracy=0.629167
2025-10-10 08:46:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:46:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:46:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:46:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2362MB allocated=2217MB
2025-10-10 08:46:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.29237616062164, 'train_avg_loss': 0.569103134671847, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 08:46:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.2231140136719, 'train_avg_loss': 0.6317148208618164, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 08:46:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 303.2231140136719, 'train_avg_loss': 0.6317148208618164, 'train_seen': 480, 'train_correct': 302, 'train_acc': 0.6291666666666667}}
2025-10-10 08:46:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #201, planning to set LR to 1.00e-05
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:46:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:46:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:46:47 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:46:47 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=303.411438, avg_loss=0.632107, seen=480, correct=303, accuracy=0.631250
2025-10-10 08:46:47 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:46:47 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:46:49 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:46:50 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=201 reserved=2362MB allocated=2217MB
2025-10-10 08:46:50 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 201, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.24828344583511, 'train_avg_loss': 0.6604023620486259, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:46:50 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 201, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 303.41143798828125, 'train_avg_loss': 0.632107162475586, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 08:46:50 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 201, 'Results_raw': {'train_total': 480, 'train_loss': 303.41143798828125, 'train_avg_loss': 0.632107162475586, 'train_seen': 480, 'train_correct': 303, 'train_acc': 0.63125}}
2025-10-10 08:46:51 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #202) -------------
2025-10-10 08:46:51 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=202 aidx=6 | s=5 (candidates=12)
2025-10-10 08:46:51 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 23, 39, 49, 53] (from 12)
2025-10-10 08:46:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:46:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:46:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:47:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:47:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.355072, avg_loss=0.634073, seen=480, correct=307, accuracy=0.639583
2025-10-10 08:47:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:47:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:47:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:47:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2374MB allocated=2217MB
2025-10-10 08:47:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.57135301828384, 'train_avg_loss': 0.6297612751523654, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:47:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.3550720214844, 'train_avg_loss': 0.6340730667114258, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:47:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 304.3550720214844, 'train_avg_loss': 0.6340730667114258, 'train_seen': 480, 'train_correct': 307, 'train_acc': 0.6395833333333333}}
2025-10-10 08:47:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:47:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:47:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:48:20 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:48:20 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=295.586365, avg_loss=0.615805, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:48:20 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:48:20 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:48:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:48:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2362MB allocated=2217MB
2025-10-10 08:48:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.23544123768806, 'train_avg_loss': 0.6519620103140672, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 08:48:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 295.58636474609375, 'train_avg_loss': 0.615804926554362, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:48:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 295.58636474609375, 'train_avg_loss': 0.615804926554362, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:48:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:48:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:48:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:49:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:49:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.775757, avg_loss=0.653699, seen=480, correct=299, accuracy=0.622917
2025-10-10 08:49:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:49:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:49:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:49:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2362MB allocated=2217MB
2025-10-10 08:49:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.66944622993469, 'train_avg_loss': 0.6472453852494557, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:49:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.7757568359375, 'train_avg_loss': 0.6536994934082031, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:49:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 313.7757568359375, 'train_avg_loss': 0.6536994934082031, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:49:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:49:07 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:49:07 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 08:49:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:49:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:49:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:49:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:49:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:49:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:49:48 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:49:48 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.128906, avg_loss=0.666935, seen=480, correct=293, accuracy=0.610417
2025-10-10 08:49:48 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:49:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:49:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:49:51 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2380MB allocated=2217MB
2025-10-10 08:49:51 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.12883067131042, 'train_avg_loss': 0.6760735889275868, 'train_seen': 120, 'train_correct': 75, 'train_acc': 0.625}}
2025-10-10 08:49:51 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.12890625, 'train_avg_loss': 0.6669352213541667, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:49:51 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 320.12890625, 'train_avg_loss': 0.6669352213541667, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 08:49:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #202, planning to set LR to 1.00e-05
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:49:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:49:53 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:50:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:50:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=323.283020, avg_loss=0.673506, seen=480, correct=291, accuracy=0.606250
2025-10-10 08:50:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:50:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:50:35 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:50:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=202 reserved=2362MB allocated=2217MB
2025-10-10 08:50:35 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 202, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.64625561237335, 'train_avg_loss': 0.6387187967697779, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:50:35 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 202, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 323.28302001953125, 'train_avg_loss': 0.6735062917073568, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 08:50:35 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 202, 'Results_raw': {'train_total': 480, 'train_loss': 323.28302001953125, 'train_avg_loss': 0.6735062917073568, 'train_seen': 480, 'train_correct': 291, 'train_acc': 0.60625}}
2025-10-10 08:50:36 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #203) -------------
2025-10-10 08:50:37 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=203 aidx=6 | s=5 (candidates=12)
2025-10-10 08:50:37 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 38, 13, 39, 46] (from 12)
2025-10-10 08:50:37 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:50:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:50:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 08:50:38 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 08:50:38 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:50:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:50:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:50:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:50:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:51:18 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:51:18 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=318.522644, avg_loss=0.663589, seen=480, correct=288, accuracy=0.600000
2025-10-10 08:51:18 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:51:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:51:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:51:21 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2380MB allocated=2217MB
2025-10-10 08:51:21 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 81.20383933186531, 'train_avg_loss': 0.6766986610988776, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:51:21 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 318.52264404296875, 'train_avg_loss': 0.6635888417561849, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 08:51:21 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 318.52264404296875, 'train_avg_loss': 0.6635888417561849, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 08:51:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:51:22 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:51:22 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 08:51:22 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:51:22 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:51:23 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:51:23 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:51:23 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:51:23 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:52:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:52:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.558563, avg_loss=0.634497, seen=480, correct=309, accuracy=0.643750
2025-10-10 08:52:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:52:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:52:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2374MB allocated=2217MB
2025-10-10 08:52:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.55499476194382, 'train_avg_loss': 0.6296249563495319, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:52:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.5585632324219, 'train_avg_loss': 0.6344970067342123, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 08:52:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 304.5585632324219, 'train_avg_loss': 0.6344970067342123, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 08:52:09 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 08:52:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:52:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:52:50 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:52:50 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.060120, avg_loss=0.610542, seen=480, correct=331, accuracy=0.689583
2025-10-10 08:52:50 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:52:50 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:52:53 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2362MB allocated=2217MB
2025-10-10 08:52:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.19369047880173, 'train_avg_loss': 0.6266140873233478, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 08:52:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.06011962890625, 'train_avg_loss': 0.6105419158935547, 'train_seen': 480, 'train_correct': 331, 'train_acc': 0.6895833333333333}}
2025-10-10 08:52:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 293.06011962890625, 'train_avg_loss': 0.6105419158935547, 'train_seen': 480, 'train_correct': 331, 'train_acc': 0.6895833333333333}}
2025-10-10 08:52:53 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:52:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:52:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 08:52:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:52:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:53:33 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:53:33 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.882935, avg_loss=0.649756, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:53:33 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:53:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:53:34 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:53:35 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2362MB allocated=2217MB
2025-10-10 08:53:36 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.5823387503624, 'train_avg_loss': 0.6465194895863533, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:53:36 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.8829345703125, 'train_avg_loss': 0.649756113688151, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:53:36 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 311.8829345703125, 'train_avg_loss': 0.649756113688151, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:53:36 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #203, planning to set LR to 1.00e-05
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:53:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:53:37 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:54:17 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:54:17 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=322.046295, avg_loss=0.670930, seen=480, correct=275, accuracy=0.572917
2025-10-10 08:54:17 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:54:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:54:20 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:54:20 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=203 reserved=2386MB allocated=2217MB
2025-10-10 08:54:20 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 203, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.777658700943, 'train_avg_loss': 0.6648138225078583, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 08:54:20 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 203, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 322.0462951660156, 'train_avg_loss': 0.6709297815958659, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 08:54:20 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 203, 'Results_raw': {'train_total': 480, 'train_loss': 322.0462951660156, 'train_avg_loss': 0.6709297815958659, 'train_seen': 480, 'train_correct': 275, 'train_acc': 0.5729166666666666}}
2025-10-10 08:54:22 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #204) -------------
2025-10-10 08:54:23 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=204 aidx=6 | s=5 (candidates=12)
2025-10-10 08:54:23 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[53, 19, 52, 23, 46] (from 12)
2025-10-10 08:54:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:54:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:54:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:55:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:55:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.577606, avg_loss=0.655370, seen=480, correct=310, accuracy=0.645833
2025-10-10 08:55:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:55:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:04 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:55:05 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2362MB allocated=2217MB
2025-10-10 08:55:05 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.00775104761124, 'train_avg_loss': 0.6333979253967603, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 08:55:05 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.5776062011719, 'train_avg_loss': 0.6553700129191081, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:55:05 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 314.5776062011719, 'train_avg_loss': 0.6553700129191081, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 08:55:05 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:55:06 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:55:06 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 08:55:07 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:55:07 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:55:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:55:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.510223, avg_loss=0.609396, seen=480, correct=321, accuracy=0.668750
2025-10-10 08:55:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:55:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:55:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2420MB allocated=2217MB
2025-10-10 08:55:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.7603405714035, 'train_avg_loss': 0.5896695047616959, 'train_seen': 120, 'train_correct': 87, 'train_acc': 0.725}}
2025-10-10 08:55:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.5102233886719, 'train_avg_loss': 0.6093962987263998, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 08:55:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 292.5102233886719, 'train_avg_loss': 0.6093962987263998, 'train_seen': 480, 'train_correct': 321, 'train_acc': 0.66875}}
2025-10-10 08:55:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 08:55:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:55:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:56:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:56:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.244324, avg_loss=0.652592, seen=480, correct=290, accuracy=0.604167
2025-10-10 08:56:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:56:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:56:31 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:56:32 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2362MB allocated=2217MB
2025-10-10 08:56:32 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.9448595046997, 'train_avg_loss': 0.6328738292058309, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 08:56:32 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.24432373046875, 'train_avg_loss': 0.6525923411051432, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 08:56:32 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 313.24432373046875, 'train_avg_loss': 0.6525923411051432, 'train_seen': 480, 'train_correct': 290, 'train_acc': 0.6041666666666666}}
2025-10-10 08:56:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=146, total=583)
2025-10-10 08:56:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:56:33 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=73, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:57:14 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:57:14 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=296.471558, avg_loss=0.617649, seen=480, correct=320, accuracy=0.666667
2025-10-10 08:57:14 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:57:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:57:15 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:57:16 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2362MB allocated=2217MB
2025-10-10 08:57:16 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #23', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.08383756875992, 'train_avg_loss': 0.6423653130729993, 'train_seen': 120, 'train_correct': 74, 'train_acc': 0.6166666666666667}}
2025-10-10 08:57:16 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #23', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 296.4715576171875, 'train_avg_loss': 0.6176490783691406, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 08:57:16 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #23', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 296.4715576171875, 'train_avg_loss': 0.6176490783691406, 'train_seen': 480, 'train_correct': 320, 'train_acc': 0.6666666666666666}}
2025-10-10 08:57:16 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:57:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:57:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #204, planning to set LR to 1.00e-05
2025-10-10 08:57:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 08:57:18 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:57:18 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:57:18 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:57:18 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:57:18 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:57:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:57:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.669495, avg_loss=0.659728, seen=480, correct=279, accuracy=0.581250
2025-10-10 08:57:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:57:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:58:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:58:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=204 reserved=2386MB allocated=2217MB
2025-10-10 08:58:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 204, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 78.40808480978012, 'train_avg_loss': 0.6534007067481676, 'train_seen': 120, 'train_correct': 72, 'train_acc': 0.6}}
2025-10-10 08:58:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 204, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.66949462890625, 'train_avg_loss': 0.6597281138102213, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 08:58:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 204, 'Results_raw': {'train_total': 480, 'train_loss': 316.66949462890625, 'train_avg_loss': 0.6597281138102213, 'train_seen': 480, 'train_correct': 279, 'train_acc': 0.58125}}
2025-10-10 08:58:02 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #205) -------------
2025-10-10 08:58:03 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=205 aidx=6 | s=5 (candidates=12)
2025-10-10 08:58:03 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[14, 38, 53, 10, 13] (from 12)
2025-10-10 08:58:03 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 08:58:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:58:04 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:58:44 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:58:44 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.258240, avg_loss=0.640121, seen=480, correct=299, accuracy=0.622917
2025-10-10 08:58:44 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:58:44 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:58:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:58:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2362MB allocated=2217MB
2025-10-10 08:58:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 70.97346293926239, 'train_avg_loss': 0.5914455244938532, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 08:58:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.25823974609375, 'train_avg_loss': 0.640121332804362, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:58:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 307.25823974609375, 'train_avg_loss': 0.640121332804362, 'train_seen': 480, 'train_correct': 299, 'train_acc': 0.6229166666666667}}
2025-10-10 08:58:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 08:58:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:58:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 08:59:26 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 08:59:26 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=304.858429, avg_loss=0.635122, seen=480, correct=305, accuracy=0.635417
2025-10-10 08:59:26 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 08:59:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:59:28 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 08:59:29 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2374MB allocated=2217MB
2025-10-10 08:59:29 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.54181516170502, 'train_avg_loss': 0.6295151263475418, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 08:59:29 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 304.8584289550781, 'train_avg_loss': 0.6351217269897461, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 08:59:29 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 304.8584289550781, 'train_avg_loss': 0.6351217269897461, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 08:59:29 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 08:59:31 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 08:59:31 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:00:10 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:00:10 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.512390, avg_loss=0.655234, seen=480, correct=305, accuracy=0.635417
2025-10-10 09:00:10 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:00:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:12 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:00:13 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2362MB allocated=2217MB
2025-10-10 09:00:13 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.93086361885071, 'train_avg_loss': 0.6327571968237559, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 09:00:13 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.51239013671875, 'train_avg_loss': 0.6552341461181641, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 09:00:13 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 314.51239013671875, 'train_avg_loss': 0.6552341461181641, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 09:00:13 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 09:00:14 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:00:14 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:00:55 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:00:55 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.801483, avg_loss=0.614170, seen=480, correct=312, accuracy=0.650000
2025-10-10 09:00:55 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:00:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:00:58 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:00:59 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2388MB allocated=2217MB
2025-10-10 09:00:59 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.44891780614853, 'train_avg_loss': 0.6120743150512378, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 09:00:59 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.8014831542969, 'train_avg_loss': 0.6141697565714518, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:00:59 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 294.8014831542969, 'train_avg_loss': 0.6141697565714518, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:00:59 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #205, planning to set LR to 1.00e-05
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 09:01:00 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:01:00 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:01:41 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:01:41 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=293.195343, avg_loss=0.610824, seen=480, correct=328, accuracy=0.683333
2025-10-10 09:01:41 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:01:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:01:42 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:01:44 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=205 reserved=2362MB allocated=2217MB
2025-10-10 09:01:44 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 205, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.8244257569313, 'train_avg_loss': 0.6235368813077609, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 09:01:44 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 205, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 293.1953430175781, 'train_avg_loss': 0.6108236312866211, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 09:01:44 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 205, 'Results_raw': {'train_total': 480, 'train_loss': 293.1953430175781, 'train_avg_loss': 0.6108236312866211, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 09:01:44 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #206) -------------
2025-10-10 09:01:45 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=206 aidx=6 | s=5 (candidates=12)
2025-10-10 09:01:45 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 10, 19, 13, 52] (from 12)
2025-10-10 09:01:46 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:01:47 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:01:47 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 09:01:48 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 09:01:48 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:01:48 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:01:48 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:01:48 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:01:48 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:02:28 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:02:28 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=302.990021, avg_loss=0.631229, seen=480, correct=310, accuracy=0.645833
2025-10-10 09:02:28 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:02:28 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:02:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:02:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2374MB allocated=2217MB
2025-10-10 09:02:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.10407137870789, 'train_avg_loss': 0.6258672614892323, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 09:02:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 302.9900207519531, 'train_avg_loss': 0.6312292098999024, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 09:02:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 302.9900207519531, 'train_avg_loss': 0.6312292098999024, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 09:02:30 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 09:02:32 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:02:32 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:03:12 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:03:12 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=294.290100, avg_loss=0.613104, seen=480, correct=312, accuracy=0.650000
2025-10-10 09:03:12 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:03:13 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:03:14 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:03:15 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2388MB allocated=2217MB
2025-10-10 09:03:15 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.05200207233429, 'train_avg_loss': 0.6004333506027858, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 09:03:15 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 294.29010009765625, 'train_avg_loss': 0.6131043752034505, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:03:15 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 294.29010009765625, 'train_avg_loss': 0.6131043752034505, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:03:15 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 09:03:17 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:03:17 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:03:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:03:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.499207, avg_loss=0.609373, seen=480, correct=318, accuracy=0.662500
2025-10-10 09:03:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:03:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:03:54 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:03:55 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2420MB allocated=2217MB
2025-10-10 09:03:55 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.50955820083618, 'train_avg_loss': 0.5959129850069682, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 09:03:55 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.49920654296875, 'train_avg_loss': 0.6093733469645183, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 09:03:55 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 292.49920654296875, 'train_avg_loss': 0.6093733469645183, 'train_seen': 480, 'train_correct': 318, 'train_acc': 0.6625}}
2025-10-10 09:03:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 09:03:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:03:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:04:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:04:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.758636, avg_loss=0.591164, seen=480, correct=334, accuracy=0.695833
2025-10-10 09:04:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:04:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:04:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:04:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2362MB allocated=2217MB
2025-10-10 09:04:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.93988233804703, 'train_avg_loss': 0.6078323528170586, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 09:04:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.7586364746094, 'train_avg_loss': 0.5911638259887695, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 09:04:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 283.7586364746094, 'train_avg_loss': 0.5911638259887695, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 09:04:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #206, planning to set LR to 1.00e-05
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 09:04:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:04:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:05:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:05:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=313.647186, avg_loss=0.653432, seen=480, correct=292, accuracy=0.608333
2025-10-10 09:05:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:05:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:05:21 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:05:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=206 reserved=2362MB allocated=2217MB
2025-10-10 09:05:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 206, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 77.12774223089218, 'train_avg_loss': 0.6427311852574349, 'train_seen': 120, 'train_correct': 76, 'train_acc': 0.6333333333333333}}
2025-10-10 09:05:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 206, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 313.6471862792969, 'train_avg_loss': 0.6534316380818684, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 09:05:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 206, 'Results_raw': {'train_total': 480, 'train_loss': 313.6471862792969, 'train_avg_loss': 0.6534316380818684, 'train_seen': 480, 'train_correct': 292, 'train_acc': 0.6083333333333333}}
2025-10-10 09:05:23 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #207) -------------
2025-10-10 09:05:24 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=207 aidx=6 | s=5 (candidates=12)
2025-10-10 09:05:24 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[49, 39, 52, 18, 10] (from 12)
2025-10-10 09:05:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 09:05:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:05:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:06:05 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:06:05 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=319.623108, avg_loss=0.665881, seen=480, correct=282, accuracy=0.587500
2025-10-10 09:06:05 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:06:05 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:06:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:06:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2380MB allocated=2217MB
2025-10-10 09:06:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7582859992981, 'train_avg_loss': 0.6729857166608174, 'train_seen': 120, 'train_correct': 67, 'train_acc': 0.5583333333333333}}
2025-10-10 09:06:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 319.62310791015625, 'train_avg_loss': 0.6658814748128256, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 09:06:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 319.62310791015625, 'train_avg_loss': 0.6658814748128256, 'train_seen': 480, 'train_correct': 282, 'train_acc': 0.5875}}
2025-10-10 09:06:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:06:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:06:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 09:06:09 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 09:06:09 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:06:09 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:06:09 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:06:09 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:06:09 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:06:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:06:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=311.388947, avg_loss=0.648727, seen=480, correct=298, accuracy=0.620833
2025-10-10 09:06:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:06:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:06:51 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:06:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2362MB allocated=2217MB
2025-10-10 09:06:52 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.53020060062408, 'train_avg_loss': 0.629418338338534, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 09:06:52 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 311.3889465332031, 'train_avg_loss': 0.6487269719441732, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 09:06:52 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 311.3889465332031, 'train_avg_loss': 0.6487269719441732, 'train_seen': 480, 'train_correct': 298, 'train_acc': 0.6208333333333333}}
2025-10-10 09:06:52 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=898, total=3589)
2025-10-10 09:06:54 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:06:54 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=449, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:07:35 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:07:35 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.294861, avg_loss=0.638114, seen=480, correct=305, accuracy=0.635417
2025-10-10 09:07:35 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:07:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:07:37 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:07:37 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2362MB allocated=2217MB
2025-10-10 09:07:37 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #52', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.86761224269867, 'train_avg_loss': 0.6238967686891556, 'train_seen': 120, 'train_correct': 78, 'train_acc': 0.65}}
2025-10-10 09:07:37 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #52', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.29486083984375, 'train_avg_loss': 0.6381142934163412, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 09:07:37 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #52', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 306.29486083984375, 'train_avg_loss': 0.6381142934163412, 'train_seen': 480, 'train_correct': 305, 'train_acc': 0.6354166666666666}}
2025-10-10 09:07:38 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:07:38 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:07:38 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 09:07:39 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 09:07:39 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:07:39 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:07:39 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:07:39 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:07:39 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:08:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:08:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=306.607513, avg_loss=0.638766, seen=480, correct=310, accuracy=0.645833
2025-10-10 09:08:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:08:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:08:23 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:08:24 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2388MB allocated=2217MB
2025-10-10 09:08:24 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 79.82766085863113, 'train_avg_loss': 0.6652305071552594, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 09:08:24 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 306.6075134277344, 'train_avg_loss': 0.6387656529744467, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 09:08:24 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 306.6075134277344, 'train_avg_loss': 0.6387656529744467, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 09:08:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:08:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:08:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #207, planning to set LR to 1.00e-05
2025-10-10 09:08:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 09:08:26 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:08:26 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:08:26 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:08:26 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:08:26 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:09:06 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:09:06 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=292.709991, avg_loss=0.609812, seen=480, correct=312, accuracy=0.650000
2025-10-10 09:09:06 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:09:06 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:09:08 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:09:08 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=207 reserved=2388MB allocated=2217MB
2025-10-10 09:09:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 207, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 71.65766733884811, 'train_avg_loss': 0.5971472278237343, 'train_seen': 120, 'train_correct': 81, 'train_acc': 0.675}}
2025-10-10 09:09:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 207, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 292.7099914550781, 'train_avg_loss': 0.6098124821980794, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:09:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 207, 'Results_raw': {'train_total': 480, 'train_loss': 292.7099914550781, 'train_avg_loss': 0.6098124821980794, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:09:10 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #208) -------------
2025-10-10 09:09:11 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=208 aidx=6 | s=5 (candidates=12)
2025-10-10 09:09:11 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[46, 53, 18, 10, 39] (from 12)
2025-10-10 09:09:11 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:09:12 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:09:12 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 09:09:12 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 09:09:12 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:09:13 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:09:13 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:09:13 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:09:13 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:09:53 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:09:53 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.346497, avg_loss=0.650722, seen=480, correct=293, accuracy=0.610417
2025-10-10 09:09:53 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:09:53 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:09:55 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:09:56 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2386MB allocated=2217MB
2025-10-10 09:09:56 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.61032050848007, 'train_avg_loss': 0.630086004237334, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 09:09:56 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.34649658203125, 'train_avg_loss': 0.6507218678792318, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 09:09:56 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 312.34649658203125, 'train_avg_loss': 0.6507218678792318, 'train_seen': 480, 'train_correct': 293, 'train_acc': 0.6104166666666667}}
2025-10-10 09:09:56 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1698, total=6791)
2025-10-10 09:09:57 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:09:57 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=849, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:10:37 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:10:37 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=320.339111, avg_loss=0.667373, seen=480, correct=300, accuracy=0.625000
2025-10-10 09:10:37 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:10:37 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:10:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:10:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2362MB allocated=2217MB
2025-10-10 09:10:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #53', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.62469235062599, 'train_avg_loss': 0.6302057695885499, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 09:10:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #53', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 320.339111328125, 'train_avg_loss': 0.6673731486002604, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 09:10:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #53', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 320.339111328125, 'train_avg_loss': 0.6673731486002604, 'train_seen': 480, 'train_correct': 300, 'train_acc': 0.625}}
2025-10-10 09:10:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:10:40 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:10:40 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 09:10:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 09:10:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:10:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:10:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:10:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:10:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:11:21 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:11:21 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=307.657593, avg_loss=0.640953, seen=480, correct=312, accuracy=0.650000
2025-10-10 09:11:21 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:11:21 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:11:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:11:23 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2388MB allocated=2217MB
2025-10-10 09:11:23 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.79003673791885, 'train_avg_loss': 0.6732503061493238, 'train_seen': 120, 'train_correct': 70, 'train_acc': 0.5833333333333334}}
2025-10-10 09:11:23 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 307.6575927734375, 'train_avg_loss': 0.6409533182779948, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:11:23 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 307.6575927734375, 'train_avg_loss': 0.6409533182779948, 'train_seen': 480, 'train_correct': 312, 'train_acc': 0.65}}
2025-10-10 09:11:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 09:11:25 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:11:25 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:12:04 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:12:04 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=283.662384, avg_loss=0.590963, seen=480, correct=330, accuracy=0.687500
2025-10-10 09:12:04 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:12:04 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:07 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:12:07 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2388MB allocated=2217MB
2025-10-10 09:12:08 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.59890249371529, 'train_avg_loss': 0.5799908541142941, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 09:12:08 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 283.6623840332031, 'train_avg_loss': 0.5909633000691732, 'train_seen': 480, 'train_correct': 330, 'train_acc': 0.6875}}
2025-10-10 09:12:08 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 283.6623840332031, 'train_avg_loss': 0.5909633000691732, 'train_seen': 480, 'train_correct': 330, 'train_acc': 0.6875}}
2025-10-10 09:12:08 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:12:09 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:12:09 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #208, planning to set LR to 1.00e-05
2025-10-10 09:12:10 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 09:12:10 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:10 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:12:10 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:12:10 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:12:10 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:12:49 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:12:49 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=312.032257, avg_loss=0.650067, seen=480, correct=301, accuracy=0.627083
2025-10-10 09:12:49 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:12:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:52 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:12:52 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=208 reserved=2362MB allocated=2217MB
2025-10-10 09:12:53 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 208, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 76.51950630545616, 'train_avg_loss': 0.637662552545468, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 09:12:53 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 208, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 312.0322570800781, 'train_avg_loss': 0.6500672022501628, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 09:12:53 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 208, 'Results_raw': {'train_total': 480, 'train_loss': 312.0322570800781, 'train_avg_loss': 0.6500672022501628, 'train_seen': 480, 'train_correct': 301, 'train_acc': 0.6270833333333333}}
2025-10-10 09:12:53 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #209) -------------
2025-10-10 09:12:54 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=209 aidx=6 | s=5 (candidates=12)
2025-10-10 09:12:54 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[13, 19, 10, 39, 46] (from 12)
2025-10-10 09:12:54 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=343, total=1372)
2025-10-10 09:12:55 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:12:55 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=172, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:13:36 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:13:36 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=280.681549, avg_loss=0.584753, seen=480, correct=337, accuracy=0.702083
2025-10-10 09:13:36 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:13:36 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:13:38 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:13:39 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2362MB allocated=2217MB
2025-10-10 09:13:39 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #13', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 72.34812557697296, 'train_avg_loss': 0.6029010464747747, 'train_seen': 120, 'train_correct': 80, 'train_acc': 0.6666666666666666}}
2025-10-10 09:13:39 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #13', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 280.6815490722656, 'train_avg_loss': 0.5847532272338867, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-10 09:13:39 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #13', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 280.6815490722656, 'train_avg_loss': 0.5847532272338867, 'train_seen': 480, 'train_correct': 337, 'train_acc': 0.7020833333333333}}
2025-10-10 09:13:39 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=526, total=2102)
2025-10-10 09:13:41 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:13:41 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:14:19 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:14:19 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=286.381104, avg_loss=0.596627, seen=480, correct=334, accuracy=0.695833
2025-10-10 09:14:19 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:14:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:14:22 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:14:22 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2420MB allocated=2217MB
2025-10-10 09:14:22 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #19', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 67.58021181821823, 'train_avg_loss': 0.5631684318184853, 'train_seen': 120, 'train_correct': 86, 'train_acc': 0.7166666666666667}}
2025-10-10 09:14:22 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #19', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 286.381103515625, 'train_avg_loss': 0.5966272989908854, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 09:14:22 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #19', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 286.381103515625, 'train_avg_loss': 0.5966272989908854, 'train_seen': 480, 'train_correct': 334, 'train_acc': 0.6958333333333333}}
2025-10-10 09:14:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 09:14:24 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:14:24 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:15:03 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:15:03 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=282.493317, avg_loss=0.588528, seen=480, correct=328, accuracy=0.683333
2025-10-10 09:15:03 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:15:03 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:05 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:15:06 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2388MB allocated=2217MB
2025-10-10 09:15:06 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 69.73326602578163, 'train_avg_loss': 0.5811105502148469, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 09:15:06 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 282.4933166503906, 'train_avg_loss': 0.5885277430216471, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 09:15:06 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 282.4933166503906, 'train_avg_loss': 0.5885277430216471, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 09:15:06 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=399, total=1594)
2025-10-10 09:15:08 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:15:08 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=200, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:15:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:15:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.625549, avg_loss=0.636720, seen=480, correct=309, accuracy=0.643750
2025-10-10 09:15:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:15:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:46 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:15:47 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2362MB allocated=2217MB
2025-10-10 09:15:47 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #39', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 74.9965147972107, 'train_avg_loss': 0.6249709566434224, 'train_seen': 120, 'train_correct': 82, 'train_acc': 0.6833333333333333}}
2025-10-10 09:15:47 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #39', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.62554931640625, 'train_avg_loss': 0.6367198944091796, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 09:15:47 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #39', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 305.62554931640625, 'train_avg_loss': 0.6367198944091796, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 09:15:47 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:15:48 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:15:48 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #209, planning to set LR to 1.00e-05
2025-10-10 09:15:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=525, total=2100)
2025-10-10 09:15:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:15:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:15:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:15:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:15:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=263, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:16:27 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:16:27 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=314.183533, avg_loss=0.654549, seen=480, correct=288, accuracy=0.600000
2025-10-10 09:16:27 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:16:27 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:16:29 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:16:30 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=209 reserved=2380MB allocated=2217MB
2025-10-10 09:16:30 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #46', 'Round': 209, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 75.97874653339386, 'train_avg_loss': 0.6331562211116155, 'train_seen': 120, 'train_correct': 77, 'train_acc': 0.6416666666666667}}
2025-10-10 09:16:30 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #46', 'Round': 209, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 314.18353271484375, 'train_avg_loss': 0.6545490264892578, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 09:16:30 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #46', 'Round': 209, 'Results_raw': {'train_total': 480, 'train_loss': 314.18353271484375, 'train_avg_loss': 0.6545490264892578, 'train_seen': 480, 'train_correct': 288, 'train_acc': 0.6}}
2025-10-10 09:16:31 (federatedscope.core.workers.server:466) INFO: ----------- Starting a new training round (Round #210) -------------
2025-10-10 09:16:32 (federatedscope.core.sampler:206) INFO: [ClusterSampler] round=210 aidx=6 | s=5 (candidates=12)
2025-10-10 09:16:32 (federatedscope.core.sampler:214) INFO: [ClusterSampler] picked=[38, 49, 14, 18, 10] (from 12)
2025-10-10 09:16:32 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-10 09:16:33 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=1543, total=6171)
2025-10-10 09:16:33 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:16:34 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:16:34 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:16:34 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:16:34 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=772, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:17:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.654968, avg_loss=0.626365, seen=480, correct=309, accuracy=0.643750
2025-10-10 09:17:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:17:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:17:16 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:17:17 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2374MB allocated=2217MB
2025-10-10 09:17:17 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #38', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 73.40053579211235, 'train_avg_loss': 0.6116711316009362, 'train_seen': 120, 'train_correct': 79, 'train_acc': 0.6583333333333333}}
2025-10-10 09:17:17 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #38', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.65496826171875, 'train_avg_loss': 0.6263645172119141, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 09:17:17 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #38', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 300.65496826171875, 'train_avg_loss': 0.6263645172119141, 'train_seen': 480, 'train_correct': 309, 'train_acc': 0.64375}}
2025-10-10 09:17:18 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=631, total=2521)
2025-10-10 09:17:19 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:17:19 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=316, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:17:58 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:17:58 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=316.969727, avg_loss=0.660354, seen=480, correct=289, accuracy=0.602083
2025-10-10 09:17:58 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:17:58 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:18:00 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:18:01 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2380MB allocated=2217MB
2025-10-10 09:18:01 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #49', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.7685067653656, 'train_avg_loss': 0.67307088971138, 'train_seen': 120, 'train_correct': 69, 'train_acc': 0.575}}
2025-10-10 09:18:01 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #49', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 316.9697265625, 'train_avg_loss': 0.6603535970052083, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 09:18:01 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #49', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 316.9697265625, 'train_avg_loss': 0.6603535970052083, 'train_seen': 480, 'train_correct': 289, 'train_acc': 0.6020833333333333}}
2025-10-10 09:18:01 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=764, total=3055)
2025-10-10 09:18:02 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:18:02 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=382, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:18:45 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:18:45 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=300.569672, avg_loss=0.626187, seen=480, correct=310, accuracy=0.645833
2025-10-10 09:18:45 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:18:45 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:18:47 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:18:48 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2362MB allocated=2217MB
2025-10-10 09:18:48 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #14', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.04250675439835, 'train_avg_loss': 0.5670208896199862, 'train_seen': 120, 'train_correct': 83, 'train_acc': 0.6916666666666667}}
2025-10-10 09:18:48 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #14', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 300.5696716308594, 'train_avg_loss': 0.6261868158976237, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 09:18:48 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #14', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 300.5696716308594, 'train_avg_loss': 0.6261868158976237, 'train_seen': 480, 'train_correct': 310, 'train_acc': 0.6458333333333334}}
2025-10-10 09:18:48 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=644, total=2576)
2025-10-10 09:18:49 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:18:49 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=322, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:19:30 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:19:30 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=305.784058, avg_loss=0.637050, seen=480, correct=315, accuracy=0.656250
2025-10-10 09:19:30 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:19:30 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:19:32 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:19:33 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2388MB allocated=2217MB
2025-10-10 09:19:33 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #18', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 80.75827252864838, 'train_avg_loss': 0.6729856044054031, 'train_seen': 120, 'train_correct': 71, 'train_acc': 0.5916666666666667}}
2025-10-10 09:19:33 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #18', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 305.7840576171875, 'train_avg_loss': 0.6370501200358073, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 09:19:33 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #18', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 305.7840576171875, 'train_avg_loss': 0.6370501200358073, 'train_seen': 480, 'train_correct': 315, 'train_acc': 0.65625}}
2025-10-10 09:19:33 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:19:34 (federatedscope.llm.trainer.trainer:402) INFO: [mid-eval] every_n_train_steps=-1
2025-10-10 09:19:34 (federatedscope.llm.trainer.trainer:443) INFO: [Stateless LR Controller] In Round #210, planning to set LR to 1.00e-05
2025-10-10 09:19:34 (federatedscope.llm.trainer.trainer:314) INFO: Dataloader for 'train' has been reset and recreated. (sharded=True, world_size=4, rank=0, local_count=303, total=1209)
2025-10-10 09:19:35 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=after-reset-train][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:19:35 (federatedscope.llm.trainer.trainer:833) INFO: Successfully applied new LR 1.00e-05 to the optimizer.
2025-10-10 09:19:35 (federatedscope.llm.trainer.trainer:854) INFO: [fit-start] batch_or_epoch=None, train_iter=None, num_train_batch=30, num_train_batch_last_epoch=60, num_train_epoch=1, grad_accum_step=2, accum_in_accel=2
2025-10-10 09:19:35 (federatedscope.llm.trainer.trainer:875) INFO: [force-step-schedule] epoch=1, num_batches=30, grad_accum_step=2 (=> total micro-batches = 60)
2025-10-10 09:19:35 (federatedscope.llm.trainer.trainer:562) INFO: [run-batch-setup] split=train, len(loader)=152, num_batches(ctx)=30, grad_accum_step=2, will_run_step(loops)=60
2025-10-10 09:20:15 (federatedscope.core.trainers.trainer:443) INFO: [agg debug] using_accel=True, world=4, rank=0, local_total=120
2025-10-10 09:20:15 (federatedscope.llm.trainer.trainer:1280) INFO: [train|final] total=480, loss_sum=284.042938, avg_loss=0.591756, seen=480, correct=328, accuracy=0.683333
2025-10-10 09:20:15 (federatedscope.llm.trainer.trainer:1308) INFO: [Memory Cleanup] Deleted ctx attrs: ['val_loader', 'test_loader', 'loss_batch_total', 'loss_regular_total', 'ys_true', 'data_batch']
2025-10-10 09:20:15 (federatedscope.llm.misc.debug_utils:120) INFO: [DBG_EMB][tag=before-accel-free_memory][rank=0] tok_len=151643 | base=AdapterModel | in_emb=(Embedding) num=151646 ptr=139791857352704 | out_emb=(None) num=None ptr=None | lora_ptr=None
2025-10-10 09:20:17 (federatedscope.llm.trainer.trainer:1332) INFO: Accelerator memory has been freed (object preserved).
2025-10-10 09:20:18 (federatedscope.llm.trainer.trainer:1355) INFO: [VRAM] round=210 reserved=2388MB allocated=2217MB
2025-10-10 09:20:18 (federatedscope.core.workers.client:463) INFO: {'Role': 'Client #10', 'Round': 210, 'Split': 'train', 'Rank': '0/4', 'Local': True, 'Results': {'train_total': 120, 'train_loss': 68.88037011027336, 'train_avg_loss': 0.574003084252278, 'train_seen': 120, 'train_correct': 84, 'train_acc': 0.7}}
2025-10-10 09:20:18 (federatedscope.core.workers.client:475) INFO: {'Role': 'Client #10', 'Round': 210, 'Split': 'train', 'Aggregated': True, 'Results_raw': {'train_total': 480, 'train_loss': 284.0429382324219, 'train_avg_loss': 0.5917561213175456, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 09:20:18 (federatedscope.core.workers.client:247) INFO: {'Role': 'Client #10', 'Round': 210, 'Results_raw': {'train_total': 480, 'train_loss': 284.0429382324219, 'train_avg_loss': 0.5917561213175456, 'train_seen': 480, 'train_correct': 328, 'train_acc': 0.6833333333333333}}
2025-10-10 09:20:20 (federatedscope.core.workers.server:488) INFO: Server: Training is finished! (skip final evaluation)
2025-10-10 09:20:20 (federatedscope.core.monitors.monitor:268) INFO: In worker #0, the system-related metrics are: {'id': 0, 'fl_end_time_minutes': 709.0724838499999, 'total_model_size': 0, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 155280, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:20 (federatedscope.core.workers.client:842) INFO: ================= client 1 received finish message =================
2025-10-10 09:20:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:20 (federatedscope.core.monitors.monitor:268) INFO: In worker #1, the system-related metrics are: {'id': 1, 'fl_end_time_minutes': 709.07515485, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:20 (federatedscope.core.workers.client:842) INFO: ================= client 2 received finish message =================
2025-10-10 09:20:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:20 (federatedscope.core.monitors.monitor:268) INFO: In worker #2, the system-related metrics are: {'id': 2, 'fl_end_time_minutes': 709.0066570666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347936, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:20 (federatedscope.core.workers.client:842) INFO: ================= client 3 received finish message =================
2025-10-10 09:20:20 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:20 (federatedscope.core.monitors.monitor:268) INFO: In worker #3, the system-related metrics are: {'id': 3, 'fl_end_time_minutes': 708.9643557166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:20 (federatedscope.core.workers.client:842) INFO: ================= client 4 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #4, the system-related metrics are: {'id': 4, 'fl_end_time_minutes': 708.9223351, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 5 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #5, the system-related metrics are: {'id': 5, 'fl_end_time_minutes': 708.88075655, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15521848, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 6 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #6, the system-related metrics are: {'id': 6, 'fl_end_time_minutes': 708.8327242, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 7 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #7, the system-related metrics are: {'id': 7, 'fl_end_time_minutes': 708.7904207166666, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 8 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #8, the system-related metrics are: {'id': 8, 'fl_end_time_minutes': 708.7423961833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347936, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 9 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #9, the system-related metrics are: {'id': 9, 'fl_end_time_minutes': 708.6997544166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 10 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #10, the system-related metrics are: {'id': 10, 'fl_end_time_minutes': 708.6576010333333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 11 received finish message =================
2025-10-10 09:20:21 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:21 (federatedscope.core.monitors.monitor:268) INFO: In worker #11, the system-related metrics are: {'id': 11, 'fl_end_time_minutes': 708.5930830166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347936, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:21 (federatedscope.core.workers.client:842) INFO: ================= client 12 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #12, the system-related metrics are: {'id': 12, 'fl_end_time_minutes': 708.5492019333334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15521848, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 13 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #13, the system-related metrics are: {'id': 13, 'fl_end_time_minutes': 708.5055260833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 14 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #14, the system-related metrics are: {'id': 14, 'fl_end_time_minutes': 708.4629084666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12782704, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 15 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #15, the system-related metrics are: {'id': 15, 'fl_end_time_minutes': 708.41977335, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 16 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #16, the system-related metrics are: {'id': 16, 'fl_end_time_minutes': 708.3728671499999, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 17 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #17, the system-related metrics are: {'id': 17, 'fl_end_time_minutes': 708.3298181833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 18 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #18, the system-related metrics are: {'id': 18, 'fl_end_time_minutes': 708.2873776166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 19 received finish message =================
2025-10-10 09:20:22 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:22 (federatedscope.core.monitors.monitor:268) INFO: In worker #19, the system-related metrics are: {'id': 19, 'fl_end_time_minutes': 708.2449247833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 14608800, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:22 (federatedscope.core.workers.client:842) INFO: ================= client 20 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #20, the system-related metrics are: {'id': 20, 'fl_end_time_minutes': 708.2022746833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 10043560, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 21 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #21, the system-related metrics are: {'id': 21, 'fl_end_time_minutes': 708.1378018333332, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15521848, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 22 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #22, the system-related metrics are: {'id': 22, 'fl_end_time_minutes': 708.0948412833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20087088, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 23 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #23, the system-related metrics are: {'id': 23, 'fl_end_time_minutes': 708.0509975833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 24 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #24, the system-related metrics are: {'id': 24, 'fl_end_time_minutes': 708.0078908166666, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 25 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #25, the system-related metrics are: {'id': 25, 'fl_end_time_minutes': 707.9649553166668, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 26 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #26, the system-related metrics are: {'id': 26, 'fl_end_time_minutes': 707.9221622666666, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20087088, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 27 received finish message =================
2025-10-10 09:20:23 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:23 (federatedscope.core.monitors.monitor:268) INFO: In worker #27, the system-related metrics are: {'id': 27, 'fl_end_time_minutes': 707.8776708666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18260992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:23 (federatedscope.core.workers.client:842) INFO: ================= client 28 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #28, the system-related metrics are: {'id': 28, 'fl_end_time_minutes': 707.8309817833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 29 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #29, the system-related metrics are: {'id': 29, 'fl_end_time_minutes': 707.7879063166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 30 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #30, the system-related metrics are: {'id': 30, 'fl_end_time_minutes': 707.7442232166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15521848, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 31 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #31, the system-related metrics are: {'id': 31, 'fl_end_time_minutes': 707.6846114666666, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 32 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #32, the system-related metrics are: {'id': 32, 'fl_end_time_minutes': 707.6412480500001, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18260992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 33 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #33, the system-related metrics are: {'id': 33, 'fl_end_time_minutes': 707.5984081666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 20087088, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 34 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #34, the system-related metrics are: {'id': 34, 'fl_end_time_minutes': 707.5556504666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21913184, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 35 received finish message =================
2025-10-10 09:20:24 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:24 (federatedscope.core.monitors.monitor:268) INFO: In worker #35, the system-related metrics are: {'id': 35, 'fl_end_time_minutes': 707.5128067, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:24 (federatedscope.core.workers.client:842) INFO: ================= client 36 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #36, the system-related metrics are: {'id': 36, 'fl_end_time_minutes': 707.4654976833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18260992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 37 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #37, the system-related metrics are: {'id': 37, 'fl_end_time_minutes': 707.4226134833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15521848, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 38 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #38, the system-related metrics are: {'id': 38, 'fl_end_time_minutes': 707.3801381833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 39 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #39, the system-related metrics are: {'id': 39, 'fl_end_time_minutes': 707.3371322666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 40 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #40, the system-related metrics are: {'id': 40, 'fl_end_time_minutes': 707.2944798833333, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 41 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #41, the system-related metrics are: {'id': 41, 'fl_end_time_minutes': 707.2348340333334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 21000136, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 42 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #42, the system-related metrics are: {'id': 42, 'fl_end_time_minutes': 707.19272665, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18260992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 43 received finish message =================
2025-10-10 09:20:25 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:25 (federatedscope.core.monitors.monitor:268) INFO: In worker #43, the system-related metrics are: {'id': 43, 'fl_end_time_minutes': 707.15105425, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:25 (federatedscope.core.workers.client:842) INFO: ================= client 44 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #44, the system-related metrics are: {'id': 44, 'fl_end_time_minutes': 707.1091390833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 15521848, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 45 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #45, the system-related metrics are: {'id': 45, 'fl_end_time_minutes': 707.0638940833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 46 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #46, the system-related metrics are: {'id': 46, 'fl_end_time_minutes': 707.0204386500001, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 22826232, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 47 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #47, the system-related metrics are: {'id': 47, 'fl_end_time_minutes': 706.97813535, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 12782704, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 48 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #48, the system-related metrics are: {'id': 48, 'fl_end_time_minutes': 706.9349006166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 25565376, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 49 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #49, the system-related metrics are: {'id': 49, 'fl_end_time_minutes': 706.8916803666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 19174040, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 50 received finish message =================
2025-10-10 09:20:26 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:26 (federatedscope.core.monitors.monitor:268) INFO: In worker #50, the system-related metrics are: {'id': 50, 'fl_end_time_minutes': 706.8489366166667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 18260992, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:26 (federatedscope.core.workers.client:842) INFO: ================= client 51 received finish message =================
2025-10-10 09:20:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #51, the system-related metrics are: {'id': 51, 'fl_end_time_minutes': 706.7915575999999, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 13695752, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:27 (federatedscope.core.workers.client:842) INFO: ================= client 52 received finish message =================
2025-10-10 09:20:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #52, the system-related metrics are: {'id': 52, 'fl_end_time_minutes': 706.7491665833334, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 16434896, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:27 (federatedscope.core.workers.client:842) INFO: ================= client 53 received finish message =================
2025-10-10 09:20:27 (federatedscope.core.trainers.torch_trainer:169) INFO: [Model Sync] lenient load | loaded=2688 skipped=0 missing=291 unexpected=0
2025-10-10 09:20:27 (federatedscope.core.monitors.monitor:268) INFO: In worker #53, the system-related metrics are: {'id': 53, 'fl_end_time_minutes': 706.7066078666667, 'total_model_size': 528965760, 'total_flops': 0, 'total_upload_bytes': 0, 'total_download_bytes': 17347944, 'global_convergence_round': 0, 'local_convergence_round': 0, 'global_convergence_time_minutes': 0, 'local_convergence_time_minutes': 0}
2025-10-10 09:20:27 (federatedscope.core.monitors.monitor:359) INFO: After merging the system metrics from all works, we got avg: defaultdict(None, {'id': 'sys_avg', 'sys_avg/fl_end_time_minutes': 707.8999534135803, 'sys_avg/total_model_size': '495.12M', 'sys_avg/total_flops': '0.0', 'sys_avg/total_upload_bytes': '0.0', 'sys_avg/total_download_bytes': '16.4M', 'sys_avg/global_convergence_round': 0.0, 'sys_avg/local_convergence_round': 0.0, 'sys_avg/global_convergence_time_minutes': 0.0, 'sys_avg/local_convergence_time_minutes': 0.0})
2025-10-10 09:20:27 (federatedscope.core.monitors.monitor:360) INFO: After merging the system metrics from all works, we got std: defaultdict(None, {'id': 'sys_std', 'sys_std/fl_end_time_minutes': 0.7048939396859999, 'sys_std/total_model_size': '68.01M', 'sys_std/total_flops': '0.0', 'sys_std/total_upload_bytes': '0.0', 'sys_std/total_download_bytes': '3.25M', 'sys_std/global_convergence_round': 0.0, 'sys_std/local_convergence_round': 0.0, 'sys_std/global_convergence_time_minutes': 0.0, 'sys_std/local_convergence_time_minutes': 0.0})
